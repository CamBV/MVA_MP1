{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MVA-MP1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "XSuFEyo013uH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Given functions"
      ]
    },
    {
      "metadata": {
        "id": "7Kle7SZk4tu5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "\n",
        "# On some implementations of matplotlib, you may need to change this value\n",
        "IMAGE_SIZE = 72\n",
        "\n",
        "def generate_a_drawing(figsize, U, V, noise=0.0):\n",
        "    fig = plt.figure(figsize=(figsize,figsize))\n",
        "    ax = plt.subplot(111)\n",
        "    plt.axis('Off')\n",
        "    ax.set_xlim(0,figsize)\n",
        "    ax.set_ylim(0,figsize)\n",
        "    ax.fill(U, V, \"k\")\n",
        "    fig.canvas.draw()\n",
        "    imdata = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)[::3].astype(np.float32)\n",
        "    imdata = imdata + noise * np.random.random(imdata.size)\n",
        "    plt.close(fig)\n",
        "    return imdata\n",
        "\n",
        "def generate_a_rectangle(noise=0.0, free_location=False):\n",
        "    figsize = 1.0    \n",
        "    U = np.zeros(4)\n",
        "    V = np.zeros(4)\n",
        "    if free_location:\n",
        "        corners = np.random.random(4)\n",
        "        top = max(corners[0], corners[1])\n",
        "        bottom = min(corners[0], corners[1])\n",
        "        left = min(corners[2], corners[3])\n",
        "        right = max(corners[2], corners[3])\n",
        "    else:\n",
        "        side = (0.3 + 0.7 * np.random.random()) * figsize\n",
        "        top = figsize/2 + side/2\n",
        "        bottom = figsize/2 - side/2\n",
        "        left = bottom\n",
        "        right = top\n",
        "    U[0] = U[1] = top\n",
        "    U[2] = U[3] = bottom\n",
        "    V[0] = V[3] = left\n",
        "    V[1] = V[2] = right\n",
        "    return generate_a_drawing(figsize, U, V, noise)\n",
        "\n",
        "\n",
        "def generate_a_disk(noise=0.0, free_location=False):\n",
        "    figsize = 1.0\n",
        "    if free_location:\n",
        "        center = np.random.random(2)\n",
        "    else:\n",
        "        center = (figsize/2, figsize/2)\n",
        "    radius = (0.3 + 0.7 * np.random.random()) * figsize/2\n",
        "    N = 50\n",
        "    U = np.zeros(N)\n",
        "    V = np.zeros(N)\n",
        "    i = 0\n",
        "    for t in np.linspace(0, 2*np.pi, N):\n",
        "        U[i] = center[0] + np.cos(t) * radius\n",
        "        V[i] = center[1] + np.sin(t) * radius\n",
        "        i = i + 1\n",
        "    return generate_a_drawing(figsize, U, V, noise)\n",
        "\n",
        "def generate_a_triangle(noise=0.0, free_location=False):\n",
        "    figsize = 1.0\n",
        "    if free_location:\n",
        "        U = np.random.random(3)\n",
        "        V = np.random.random(3)\n",
        "    else:\n",
        "        size = (0.3 + 0.7 * np.random.random())*figsize/2\n",
        "        middle = figsize/2\n",
        "        U = (middle, middle+size, middle-size)\n",
        "        V = (middle+size, middle-size, middle-size)\n",
        "    imdata = generate_a_drawing(figsize, U, V, noise)\n",
        "    return [imdata, [U[0], V[0], U[1], V[1], U[2], V[2]]]\n",
        "\n",
        "\n",
        "def generate_dataset_classification(nb_samples, noise=0.0, free_location=False):\n",
        "    # Getting im_size:\n",
        "    im_size = generate_a_rectangle().shape[0]\n",
        "    X = np.zeros([nb_samples,im_size])\n",
        "    Y = np.zeros(nb_samples)\n",
        "    print('Creating data:')\n",
        "    for i in range(nb_samples):\n",
        "        if i % 10 == 0:\n",
        "            print(i)\n",
        "        category = np.random.randint(3)\n",
        "        if category == 0:\n",
        "            X[i] = generate_a_rectangle(noise, free_location)\n",
        "        elif category == 1: \n",
        "            X[i] = generate_a_disk(noise, free_location)\n",
        "        else:\n",
        "            [X[i], V] = generate_a_triangle(noise, free_location)\n",
        "        Y[i] = category\n",
        "    X = (X + noise) / (255 + 2 * noise)\n",
        "    return [X, Y]\n",
        "\n",
        "def generate_test_set_classification():\n",
        "    np.random.seed(42)\n",
        "    [X_test, Y_test] = generate_dataset_classification(300, 20, True)\n",
        "    Y_test = np_utils.to_categorical(Y_test, 3) \n",
        "    return [X_test, Y_test]\n",
        "\n",
        "def generate_dataset_regression(nb_samples, noise=0.0):\n",
        "    # Getting im_size:\n",
        "    im_size = generate_a_triangle()[0].shape[0]\n",
        "    X = np.zeros([nb_samples,im_size])\n",
        "    Y = np.zeros([nb_samples, 6])\n",
        "    print('Creating data:')\n",
        "    for i in range(nb_samples):\n",
        "        if i % 10 == 0:\n",
        "            print(i)\n",
        "        [X[i], Y[i]] = generate_a_triangle(noise, True)\n",
        "    X = (X + noise) / (255 + 2 * noise)\n",
        "    return [X, Y]\n",
        "\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "def visualize_prediction(x, y):\n",
        "    fig, ax = plt.subplots(figsize=(5, 5))\n",
        "    I = x.reshape((IMAGE_SIZE,IMAGE_SIZE))\n",
        "    ax.imshow(I, extent=[-0.15,1.15,-0.15,1.15],cmap='gray')\n",
        "    ax.set_xlim([0,1])\n",
        "    ax.set_ylim([0,1])\n",
        "\n",
        "    xy = y.reshape(3,2)\n",
        "    tri = patches.Polygon(xy, closed=True, fill = False, edgecolor = 'r', linewidth = 5, alpha = 0.5)\n",
        "    ax.add_patch(tri)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "def generate_test_set_regression():\n",
        "    np.random.seed(42)\n",
        "    [X_test, Y_test] = generate_dataset_regression(300, 20)\n",
        "    return [X_test, Y_test]\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cA4frNt1_ao5",
        "colab_type": "code",
        "outputId": "f180ad86-0611-4743-9b3b-e2d85754884d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        }
      },
      "cell_type": "code",
      "source": [
        "im = generate_a_rectangle(10, True)\n",
        "plt.imshow(im.reshape(IMAGE_SIZE,IMAGE_SIZE), cmap='gray')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fbc68843160>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD7CAYAAABDsImYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngUAPEAs9EOgBYqEHAj3A/wHLFZUE5c7x9AAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fbc688d89b0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "RAo6G6eP_dxu",
        "colab_type": "code",
        "outputId": "5e66cb2c-b1e2-45ad-9b74-46e7e25cb8db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        }
      },
      "cell_type": "code",
      "source": [
        "im = generate_a_disk(10)\n",
        "plt.imshow(im.reshape(IMAGE_SIZE,IMAGE_SIZE), cmap='gray')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fbc65f88a90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD7CAYAAABDsImYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fbc6889bdd8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "NfthkM27_gJU",
        "colab_type": "code",
        "outputId": "b3f809af-4a5c-496b-ce25-f3b0ed72bf86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        }
      },
      "cell_type": "code",
      "source": [
        "[im, v] = generate_a_triangle(20, False)\n",
        "plt.imshow(im.reshape(IMAGE_SIZE,IMAGE_SIZE), cmap='gray')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fbc65eb2438>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD7CAYAAABDsImYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJnog0APERA8EeoCY6IFAD/D/AUkBEDW6Q8CWAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fbc65fdb1d0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "f6NY8BKP8T4K",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Simple classification"
      ]
    },
    {
      "metadata": {
        "id": "c0lMgWepQUUi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ]
    },
    {
      "metadata": {
        "id": "OBTwLIj9QVvz",
        "colab_type": "code",
        "outputId": "c2a75b3d-35e9-4a84-870a-19f03ab7e0d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Conv2D, MaxPooling2D, Flatten\n",
        "from keras.optimizers import SGD, Adam\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "oUxUR8k0HFzk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Metrics\n",
        "\n",
        "Here are some metrics we will use to train our model.\n"
      ]
    },
    {
      "metadata": {
        "id": "yNK67-MAPmA-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "\n",
        "\n",
        "def precision_threshold(threshold=0.5):\n",
        "    def precision(y_true, y_pred):\n",
        "        \"\"\"Precision metric.\n",
        "         Only computes a batch-wise average of precision.\n",
        "         Computes the precision, a metric for multi-label classification of\n",
        "        how many selected items are relevant.\n",
        "        \"\"\"\n",
        "        threshold_value = threshold\n",
        "        y_pred = K.cast(K.greater(K.clip(y_pred, 0, 1), threshold_value), K.floatx())\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        p = true_positives / (predicted_positives + K.epsilon())\n",
        "        return p\n",
        "\n",
        "    return precision\n",
        "\n",
        "\n",
        "def f1_score_threshold(threshold=0.5):\n",
        "    def f1_score(y_true, y_pred, beta=1):\n",
        "        \"\"\"Computes the F score.\n",
        "         The F score is the weighted harmonic mean of precision and recall.\n",
        "        Here it is only computed as a batch-wise average, not globally.\n",
        "         This is useful for multi-label classification, where input samples can be\n",
        "        classified as sets of labels. By only using accuracy (precision) a model\n",
        "        would achieve a perfect score by simply assigning every class to every\n",
        "        input. In order to avoid this, a metric should penalize incorrect class\n",
        "        assignments as well (recall). The F-beta score (ranged from 0.0 to 1.0)\n",
        "        computes this, as a weighted mean of the proportion of correct class\n",
        "        assignments vs. the proportion of incorrect class assignments.\n",
        "         With beta = 1, this is equivalent to a F-measure. With beta < 1, assigning\n",
        "        correct classes becomes more important, and with beta > 1 the metric is\n",
        "        instead weighted towards penalizing incorrect class assignments.\n",
        "        \"\"\"\n",
        "        threshold_value = threshold\n",
        "        if beta < 0:\n",
        "            raise ValueError('The lowest choosable beta is zero (only precision).')\n",
        "        # If there are no true positives, fix the F score at 0 like sklearn.\n",
        "        if K.sum(K.round(K.clip(y_true, 0, 1))) == 0:\n",
        "            return 0\n",
        "        precision = precision_threshold(threshold_value)\n",
        "        recall = recall_threshold(threshold_value)\n",
        "        p = precision(y_true, y_pred)\n",
        "        r = recall(y_true, y_pred)\n",
        "        bb = beta ** 2\n",
        "        fbeta_score = (1 + bb) * (p * r) / (bb * p + r + K.epsilon())\n",
        "        return fbeta_score\n",
        "\n",
        "    return f1_score\n",
        "\n",
        "\n",
        "def recall_threshold(threshold=0.5):\n",
        "    def recall(y_true, y_pred):\n",
        "        \"\"\"Recall metric.\n",
        "         Only computes a batch-wise average of recall.\n",
        "         Computes the recall, a metric for multi-label classification of\n",
        "        how many relevant items are selected.\n",
        "        \"\"\"\n",
        "        threshold_value = threshold\n",
        "        y_pred = K.cast(K.greater(K.clip(y_pred, 0, 1), threshold_value), K.floatx())\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        r = true_positives / (possible_positives + K.epsilon())\n",
        "        return r\n",
        "\n",
        "    return recall\n",
        "\n",
        "\n",
        "def get_metrics(threshold):\n",
        "    return {\n",
        "        'precision': precision_threshold(threshold=threshold),\n",
        "        'recall': recall_threshold(threshold=threshold),\n",
        "        'f1_score': f1_score_threshold(threshold=threshold)\n",
        "    }\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6oIw3TwkP1nd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Model compilation\n",
        "We create a function to create a simple Sequential Dense model with given parameters"
      ]
    },
    {
      "metadata": {
        "id": "rPkB66cW8Tfs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_model(optimizer, loss, metrics):\n",
        "  \"\"\"\n",
        "  Creates then compiles a model and returns it.\n",
        "  The model is very simple : One input layer followed by one Dense layer.\n",
        "  \"\"\"\n",
        "  model = Sequential()\n",
        "  # We use a Dense layer with 3 neurons in order to match the labels's shape.\n",
        "  # Softmax activation to get an output range of [0, 1]\n",
        "  model.add(Dense(3, activation='softmax', input_shape=(IMAGE_SIZE*IMAGE_SIZE,)))\n",
        "  \n",
        "  model.compile(optimizer=optimizer,\n",
        "               loss=loss,\n",
        "               metrics=metrics)\n",
        "  model.summary()\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UuQOKSEUj2a3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Train and validation data\n",
        "We get the data for training and validation. Then we change labels to get an array of 3 element in range of [0, 1]"
      ]
    },
    {
      "metadata": {
        "id": "Xdm6tFtgj2sT",
        "colab_type": "code",
        "outputId": "8ae9fb13-71f2-4517-91a3-fcb32f39039c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        }
      },
      "cell_type": "code",
      "source": [
        "[X_train, Y_train] = generate_dataset_classification(300, 20)\n",
        "[X_valid, Y_valid] = generate_dataset_classification(60, 20)\n",
        "Y_train = np_utils.to_categorical(Y_train)\n",
        "Y_valid = np_utils.to_categorical(Y_valid)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating data:\n",
            "0\n",
            "10\n",
            "20\n",
            "30\n",
            "40\n",
            "50\n",
            "60\n",
            "70\n",
            "80\n",
            "90\n",
            "100\n",
            "110\n",
            "120\n",
            "130\n",
            "140\n",
            "150\n",
            "160\n",
            "170\n",
            "180\n",
            "190\n",
            "200\n",
            "210\n",
            "220\n",
            "230\n",
            "240\n",
            "250\n",
            "260\n",
            "270\n",
            "280\n",
            "290\n",
            "Creating data:\n",
            "0\n",
            "10\n",
            "20\n",
            "30\n",
            "40\n",
            "50\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "X3gWBEQIP5Pm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Model training"
      ]
    },
    {
      "metadata": {
        "id": "iykQSCDr4avw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Stochastic gradient descent\n",
        "We train our model with SGD.\n",
        "We use an important number of epochs because our learning rate is small (in order to avoid oscillations around a minimum)."
      ]
    },
    {
      "metadata": {
        "id": "ouw8L0VkP94Z",
        "colab_type": "code",
        "outputId": "b90e13d2-102b-4b52-c5ab-2cede382044b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68207
        }
      },
      "cell_type": "code",
      "source": [
        "optimizer = SGD(lr=0.0001, momentum=0.0, decay=0.0, nesterov=False) # 0.001 learning rate without modifications during gradient descent\n",
        "loss = 'binary_crossentropy'\n",
        "metrics = [get_metrics(0.5)['precision'], get_metrics(0.5)['recall'], get_metrics(0.5)['f1_score']]\n",
        "\n",
        "model_sgd = get_model(optimizer, loss, metrics)\n",
        "\n",
        "history_sgd = model_sgd.fit(X_train, Y_train,\n",
        "          epochs=2000,\n",
        "          batch_size=64,\n",
        "          validation_data=(X_valid, Y_valid)\n",
        "         )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 3)                 15555     \n",
            "=================================================================\n",
            "Total params: 15,555\n",
            "Trainable params: 15,555\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 300 samples, validate on 60 samples\n",
            "Epoch 1/2000\n",
            "300/300 [==============================] - 0s 572us/step - loss: 0.7269 - precision: 0.4288 - recall: 0.3467 - f1_score: 0.3830 - val_loss: 0.6202 - val_precision: 0.6250 - val_recall: 0.4167 - val_f1_score: 0.5000\n",
            "Epoch 2/2000\n",
            "300/300 [==============================] - 0s 107us/step - loss: 0.6945 - precision: 0.4005 - recall: 0.2933 - f1_score: 0.3380 - val_loss: 0.6069 - val_precision: 0.5897 - val_recall: 0.3833 - val_f1_score: 0.4646\n",
            "Epoch 3/2000\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.6716 - precision: 0.4129 - recall: 0.2767 - f1_score: 0.3310 - val_loss: 0.5984 - val_precision: 0.5789 - val_recall: 0.3667 - val_f1_score: 0.4490\n",
            "Epoch 4/2000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.6553 - precision: 0.4293 - recall: 0.2467 - f1_score: 0.3130 - val_loss: 0.5929 - val_precision: 0.6061 - val_recall: 0.3333 - val_f1_score: 0.4301\n",
            "Epoch 5/2000\n",
            "300/300 [==============================] - 0s 101us/step - loss: 0.6431 - precision: 0.4660 - recall: 0.2367 - f1_score: 0.3132 - val_loss: 0.5898 - val_precision: 0.6897 - val_recall: 0.3333 - val_f1_score: 0.4494\n",
            "Epoch 6/2000\n",
            "300/300 [==============================] - 0s 117us/step - loss: 0.6344 - precision: 0.4679 - recall: 0.2033 - f1_score: 0.2820 - val_loss: 0.5882 - val_precision: 0.8000 - val_recall: 0.3333 - val_f1_score: 0.4706\n",
            "Epoch 7/2000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.6284 - precision: 0.5009 - recall: 0.1967 - f1_score: 0.2814 - val_loss: 0.5879 - val_precision: 0.8696 - val_recall: 0.3333 - val_f1_score: 0.4819\n",
            "Epoch 8/2000\n",
            "300/300 [==============================] - 0s 105us/step - loss: 0.6239 - precision: 0.5120 - recall: 0.1767 - f1_score: 0.2610 - val_loss: 0.5882 - val_precision: 0.9000 - val_recall: 0.3000 - val_f1_score: 0.4500\n",
            "Epoch 9/2000\n",
            "300/300 [==============================] - 0s 108us/step - loss: 0.6207 - precision: 0.5395 - recall: 0.1567 - f1_score: 0.2413 - val_loss: 0.5885 - val_precision: 0.9412 - val_recall: 0.2667 - val_f1_score: 0.4156\n",
            "Epoch 10/2000\n",
            "300/300 [==============================] - 0s 112us/step - loss: 0.6184 - precision: 0.5396 - recall: 0.1400 - f1_score: 0.2198 - val_loss: 0.5893 - val_precision: 0.9375 - val_recall: 0.2500 - val_f1_score: 0.3947\n",
            "Epoch 11/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.6164 - precision: 0.5514 - recall: 0.1433 - f1_score: 0.2248 - val_loss: 0.5894 - val_precision: 1.0000 - val_recall: 0.2500 - val_f1_score: 0.4000\n",
            "Epoch 12/2000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.6152 - precision: 0.5665 - recall: 0.1333 - f1_score: 0.2155 - val_loss: 0.5893 - val_precision: 1.0000 - val_recall: 0.2167 - val_f1_score: 0.3562\n",
            "Epoch 13/2000\n",
            "300/300 [==============================] - 0s 107us/step - loss: 0.6135 - precision: 0.5977 - recall: 0.1200 - f1_score: 0.1986 - val_loss: 0.5889 - val_precision: 1.0000 - val_recall: 0.2000 - val_f1_score: 0.3333\n",
            "Epoch 14/2000\n",
            "300/300 [==============================] - 0s 125us/step - loss: 0.6123 - precision: 0.6454 - recall: 0.1200 - f1_score: 0.1991 - val_loss: 0.5888 - val_precision: 1.0000 - val_recall: 0.1833 - val_f1_score: 0.3099\n",
            "Epoch 15/2000\n",
            "300/300 [==============================] - 0s 110us/step - loss: 0.6111 - precision: 0.6729 - recall: 0.1300 - f1_score: 0.2155 - val_loss: 0.5879 - val_precision: 1.0000 - val_recall: 0.1833 - val_f1_score: 0.3099\n",
            "Epoch 16/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.6100 - precision: 0.6148 - recall: 0.1133 - f1_score: 0.1912 - val_loss: 0.5877 - val_precision: 1.0000 - val_recall: 0.1833 - val_f1_score: 0.3099\n",
            "Epoch 17/2000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.6087 - precision: 0.6690 - recall: 0.1100 - f1_score: 0.1882 - val_loss: 0.5863 - val_precision: 1.0000 - val_recall: 0.2167 - val_f1_score: 0.3562\n",
            "Epoch 18/2000\n",
            "300/300 [==============================] - 0s 106us/step - loss: 0.6076 - precision: 0.7058 - recall: 0.1333 - f1_score: 0.2229 - val_loss: 0.5853 - val_precision: 1.0000 - val_recall: 0.2333 - val_f1_score: 0.3784\n",
            "Epoch 19/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.6062 - precision: 0.6572 - recall: 0.1267 - f1_score: 0.2105 - val_loss: 0.5849 - val_precision: 1.0000 - val_recall: 0.2500 - val_f1_score: 0.4000\n",
            "Epoch 20/2000\n",
            "300/300 [==============================] - 0s 114us/step - loss: 0.6049 - precision: 0.7011 - recall: 0.1367 - f1_score: 0.2262 - val_loss: 0.5847 - val_precision: 1.0000 - val_recall: 0.2667 - val_f1_score: 0.4211\n",
            "Epoch 21/2000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.6038 - precision: 0.7765 - recall: 0.1400 - f1_score: 0.2358 - val_loss: 0.5834 - val_precision: 1.0000 - val_recall: 0.2500 - val_f1_score: 0.4000\n",
            "Epoch 22/2000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.6029 - precision: 0.6626 - recall: 0.1267 - f1_score: 0.2126 - val_loss: 0.5828 - val_precision: 1.0000 - val_recall: 0.2667 - val_f1_score: 0.4211\n",
            "Epoch 23/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.6012 - precision: 0.6930 - recall: 0.1433 - f1_score: 0.2355 - val_loss: 0.5823 - val_precision: 1.0000 - val_recall: 0.2500 - val_f1_score: 0.4000\n",
            "Epoch 24/2000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.6006 - precision: 0.8074 - recall: 0.1233 - f1_score: 0.2124 - val_loss: 0.5811 - val_precision: 1.0000 - val_recall: 0.2667 - val_f1_score: 0.4211\n",
            "Epoch 25/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.5991 - precision: 0.7681 - recall: 0.1433 - f1_score: 0.2406 - val_loss: 0.5803 - val_precision: 1.0000 - val_recall: 0.2500 - val_f1_score: 0.4000\n",
            "Epoch 26/2000\n",
            "300/300 [==============================] - 0s 82us/step - loss: 0.5980 - precision: 0.8088 - recall: 0.1400 - f1_score: 0.2319 - val_loss: 0.5797 - val_precision: 1.0000 - val_recall: 0.2500 - val_f1_score: 0.4000\n",
            "Epoch 27/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.5969 - precision: 0.7627 - recall: 0.1367 - f1_score: 0.2315 - val_loss: 0.5792 - val_precision: 1.0000 - val_recall: 0.2500 - val_f1_score: 0.4000\n",
            "Epoch 28/2000\n",
            "300/300 [==============================] - 0s 110us/step - loss: 0.5960 - precision: 0.8082 - recall: 0.1467 - f1_score: 0.2454 - val_loss: 0.5785 - val_precision: 1.0000 - val_recall: 0.2500 - val_f1_score: 0.4000\n",
            "Epoch 29/2000\n",
            "300/300 [==============================] - 0s 101us/step - loss: 0.5945 - precision: 0.8196 - recall: 0.1433 - f1_score: 0.2436 - val_loss: 0.5774 - val_precision: 1.0000 - val_recall: 0.2500 - val_f1_score: 0.4000\n",
            "Epoch 30/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.5936 - precision: 0.8375 - recall: 0.1300 - f1_score: 0.2237 - val_loss: 0.5763 - val_precision: 1.0000 - val_recall: 0.2500 - val_f1_score: 0.4000\n",
            "Epoch 31/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.5923 - precision: 0.8339 - recall: 0.1467 - f1_score: 0.2476 - val_loss: 0.5751 - val_precision: 1.0000 - val_recall: 0.2500 - val_f1_score: 0.4000\n",
            "Epoch 32/2000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.5915 - precision: 0.8233 - recall: 0.1467 - f1_score: 0.2473 - val_loss: 0.5745 - val_precision: 1.0000 - val_recall: 0.2500 - val_f1_score: 0.4000\n",
            "Epoch 33/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.5904 - precision: 0.8273 - recall: 0.1433 - f1_score: 0.2422 - val_loss: 0.5726 - val_precision: 1.0000 - val_recall: 0.2500 - val_f1_score: 0.4000\n",
            "Epoch 34/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.5888 - precision: 0.8075 - recall: 0.1500 - f1_score: 0.2517 - val_loss: 0.5725 - val_precision: 1.0000 - val_recall: 0.2500 - val_f1_score: 0.4000\n",
            "Epoch 35/2000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.5879 - precision: 0.8406 - recall: 0.1500 - f1_score: 0.2522 - val_loss: 0.5723 - val_precision: 1.0000 - val_recall: 0.2500 - val_f1_score: 0.4000\n",
            "Epoch 36/2000\n",
            "300/300 [==============================] - 0s 102us/step - loss: 0.5866 - precision: 0.8658 - recall: 0.1567 - f1_score: 0.2637 - val_loss: 0.5716 - val_precision: 1.0000 - val_recall: 0.2500 - val_f1_score: 0.4000\n",
            "Epoch 37/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.5855 - precision: 0.8671 - recall: 0.1533 - f1_score: 0.2604 - val_loss: 0.5706 - val_precision: 1.0000 - val_recall: 0.2500 - val_f1_score: 0.4000\n",
            "Epoch 38/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.5843 - precision: 0.8622 - recall: 0.1533 - f1_score: 0.2583 - val_loss: 0.5696 - val_precision: 1.0000 - val_recall: 0.2500 - val_f1_score: 0.4000\n",
            "Epoch 39/2000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.5833 - precision: 0.8723 - recall: 0.1567 - f1_score: 0.2655 - val_loss: 0.5692 - val_precision: 1.0000 - val_recall: 0.2500 - val_f1_score: 0.4000\n",
            "Epoch 40/2000\n",
            "300/300 [==============================] - 0s 112us/step - loss: 0.5821 - precision: 0.9015 - recall: 0.1667 - f1_score: 0.2801 - val_loss: 0.5680 - val_precision: 1.0000 - val_recall: 0.2500 - val_f1_score: 0.4000\n",
            "Epoch 41/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.5811 - precision: 0.8520 - recall: 0.1633 - f1_score: 0.2717 - val_loss: 0.5677 - val_precision: 1.0000 - val_recall: 0.2500 - val_f1_score: 0.4000\n",
            "Epoch 42/2000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.5804 - precision: 0.9032 - recall: 0.1533 - f1_score: 0.2611 - val_loss: 0.5665 - val_precision: 1.0000 - val_recall: 0.2667 - val_f1_score: 0.4211\n",
            "Epoch 43/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.5790 - precision: 0.8633 - recall: 0.1667 - f1_score: 0.2757 - val_loss: 0.5657 - val_precision: 1.0000 - val_recall: 0.2500 - val_f1_score: 0.4000\n",
            "Epoch 44/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.5777 - precision: 0.8567 - recall: 0.1700 - f1_score: 0.2828 - val_loss: 0.5650 - val_precision: 1.0000 - val_recall: 0.2500 - val_f1_score: 0.4000\n",
            "Epoch 45/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.5768 - precision: 0.9273 - recall: 0.1633 - f1_score: 0.2768 - val_loss: 0.5638 - val_precision: 1.0000 - val_recall: 0.2667 - val_f1_score: 0.4211\n",
            "Epoch 46/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.5756 - precision: 0.8894 - recall: 0.1733 - f1_score: 0.2877 - val_loss: 0.5629 - val_precision: 1.0000 - val_recall: 0.2667 - val_f1_score: 0.4211\n",
            "Epoch 47/2000\n",
            "300/300 [==============================] - 0s 110us/step - loss: 0.5745 - precision: 0.8948 - recall: 0.1767 - f1_score: 0.2949 - val_loss: 0.5619 - val_precision: 1.0000 - val_recall: 0.2833 - val_f1_score: 0.4416\n",
            "Epoch 48/2000\n",
            "300/300 [==============================] - 0s 103us/step - loss: 0.5734 - precision: 0.8968 - recall: 0.1700 - f1_score: 0.2850 - val_loss: 0.5610 - val_precision: 1.0000 - val_recall: 0.3000 - val_f1_score: 0.4615\n",
            "Epoch 49/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.5723 - precision: 0.8895 - recall: 0.1800 - f1_score: 0.2973 - val_loss: 0.5597 - val_precision: 1.0000 - val_recall: 0.2833 - val_f1_score: 0.4416\n",
            "Epoch 50/2000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.5715 - precision: 0.9236 - recall: 0.1767 - f1_score: 0.2951 - val_loss: 0.5593 - val_precision: 1.0000 - val_recall: 0.3000 - val_f1_score: 0.4615\n",
            "Epoch 51/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.5708 - precision: 0.9348 - recall: 0.1767 - f1_score: 0.2934 - val_loss: 0.5582 - val_precision: 1.0000 - val_recall: 0.3000 - val_f1_score: 0.4615\n",
            "Epoch 52/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.5694 - precision: 0.9208 - recall: 0.1800 - f1_score: 0.3002 - val_loss: 0.5577 - val_precision: 1.0000 - val_recall: 0.3000 - val_f1_score: 0.4615\n",
            "Epoch 53/2000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.5680 - precision: 0.8934 - recall: 0.1867 - f1_score: 0.3073 - val_loss: 0.5572 - val_precision: 1.0000 - val_recall: 0.3000 - val_f1_score: 0.4615\n",
            "Epoch 54/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.5670 - precision: 0.9202 - recall: 0.1833 - f1_score: 0.3022 - val_loss: 0.5564 - val_precision: 1.0000 - val_recall: 0.3000 - val_f1_score: 0.4615\n",
            "Epoch 55/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.5659 - precision: 0.9329 - recall: 0.1833 - f1_score: 0.3060 - val_loss: 0.5557 - val_precision: 1.0000 - val_recall: 0.3000 - val_f1_score: 0.4615\n",
            "Epoch 56/2000\n",
            "300/300 [==============================] - 0s 101us/step - loss: 0.5650 - precision: 0.9223 - recall: 0.1833 - f1_score: 0.3053 - val_loss: 0.5552 - val_precision: 1.0000 - val_recall: 0.3000 - val_f1_score: 0.4615\n",
            "Epoch 57/2000\n",
            "300/300 [==============================] - 0s 114us/step - loss: 0.5638 - precision: 0.9429 - recall: 0.1867 - f1_score: 0.3096 - val_loss: 0.5544 - val_precision: 1.0000 - val_recall: 0.2833 - val_f1_score: 0.4416\n",
            "Epoch 58/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.5628 - precision: 0.9219 - recall: 0.1833 - f1_score: 0.3028 - val_loss: 0.5535 - val_precision: 1.0000 - val_recall: 0.2833 - val_f1_score: 0.4416\n",
            "Epoch 59/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.5618 - precision: 0.9467 - recall: 0.1833 - f1_score: 0.3050 - val_loss: 0.5525 - val_precision: 1.0000 - val_recall: 0.3000 - val_f1_score: 0.4615\n",
            "Epoch 60/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.5610 - precision: 0.9410 - recall: 0.1933 - f1_score: 0.3185 - val_loss: 0.5514 - val_precision: 1.0000 - val_recall: 0.3000 - val_f1_score: 0.4615\n",
            "Epoch 61/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.5599 - precision: 0.9154 - recall: 0.1800 - f1_score: 0.3000 - val_loss: 0.5511 - val_precision: 1.0000 - val_recall: 0.3000 - val_f1_score: 0.4615\n",
            "Epoch 62/2000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.5588 - precision: 0.9634 - recall: 0.1833 - f1_score: 0.3068 - val_loss: 0.5500 - val_precision: 1.0000 - val_recall: 0.3000 - val_f1_score: 0.4615\n",
            "Epoch 63/2000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.5577 - precision: 0.9435 - recall: 0.1867 - f1_score: 0.3091 - val_loss: 0.5496 - val_precision: 1.0000 - val_recall: 0.3000 - val_f1_score: 0.4615\n",
            "Epoch 64/2000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.5568 - precision: 0.9689 - recall: 0.1933 - f1_score: 0.3222 - val_loss: 0.5493 - val_precision: 1.0000 - val_recall: 0.3000 - val_f1_score: 0.4615\n",
            "Epoch 65/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.5556 - precision: 0.9276 - recall: 0.1967 - f1_score: 0.3234 - val_loss: 0.5482 - val_precision: 1.0000 - val_recall: 0.3000 - val_f1_score: 0.4615\n",
            "Epoch 66/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.5546 - precision: 0.9458 - recall: 0.1933 - f1_score: 0.3188 - val_loss: 0.5475 - val_precision: 1.0000 - val_recall: 0.3167 - val_f1_score: 0.4810\n",
            "Epoch 67/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.5538 - precision: 0.9417 - recall: 0.2000 - f1_score: 0.3289 - val_loss: 0.5472 - val_precision: 1.0000 - val_recall: 0.2833 - val_f1_score: 0.4416\n",
            "Epoch 68/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.5527 - precision: 0.9676 - recall: 0.1900 - f1_score: 0.3173 - val_loss: 0.5464 - val_precision: 1.0000 - val_recall: 0.2833 - val_f1_score: 0.4416\n",
            "Epoch 69/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.5518 - precision: 0.9695 - recall: 0.1867 - f1_score: 0.3121 - val_loss: 0.5460 - val_precision: 1.0000 - val_recall: 0.3167 - val_f1_score: 0.4810\n",
            "Epoch 70/2000\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.5508 - precision: 0.9822 - recall: 0.1900 - f1_score: 0.3181 - val_loss: 0.5449 - val_precision: 1.0000 - val_recall: 0.3167 - val_f1_score: 0.4810\n",
            "Epoch 71/2000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.5498 - precision: 0.9593 - recall: 0.1967 - f1_score: 0.3244 - val_loss: 0.5436 - val_precision: 1.0000 - val_recall: 0.3167 - val_f1_score: 0.4810\n",
            "Epoch 72/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.5489 - precision: 0.9751 - recall: 0.2100 - f1_score: 0.3406 - val_loss: 0.5425 - val_precision: 1.0000 - val_recall: 0.3333 - val_f1_score: 0.5000\n",
            "Epoch 73/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.5476 - precision: 0.9763 - recall: 0.2133 - f1_score: 0.3466 - val_loss: 0.5418 - val_precision: 1.0000 - val_recall: 0.3333 - val_f1_score: 0.5000\n",
            "Epoch 74/2000\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.5468 - precision: 0.9672 - recall: 0.2100 - f1_score: 0.3448 - val_loss: 0.5414 - val_precision: 1.0000 - val_recall: 0.3333 - val_f1_score: 0.5000\n",
            "Epoch 75/2000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.5459 - precision: 0.9531 - recall: 0.2267 - f1_score: 0.3655 - val_loss: 0.5408 - val_precision: 1.0000 - val_recall: 0.3333 - val_f1_score: 0.5000\n",
            "Epoch 76/2000\n",
            "300/300 [==============================] - 0s 108us/step - loss: 0.5450 - precision: 0.9519 - recall: 0.2267 - f1_score: 0.3637 - val_loss: 0.5402 - val_precision: 1.0000 - val_recall: 0.3167 - val_f1_score: 0.4810\n",
            "Epoch 77/2000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.5442 - precision: 0.9806 - recall: 0.2167 - f1_score: 0.3517 - val_loss: 0.5389 - val_precision: 1.0000 - val_recall: 0.3167 - val_f1_score: 0.4810\n",
            "Epoch 78/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.5433 - precision: 0.9745 - recall: 0.2267 - f1_score: 0.3660 - val_loss: 0.5388 - val_precision: 1.0000 - val_recall: 0.3167 - val_f1_score: 0.4810\n",
            "Epoch 79/2000\n",
            "300/300 [==============================] - 0s 112us/step - loss: 0.5418 - precision: 0.9822 - recall: 0.2133 - f1_score: 0.3496 - val_loss: 0.5381 - val_precision: 1.0000 - val_recall: 0.3333 - val_f1_score: 0.5000\n",
            "Epoch 80/2000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.5409 - precision: 0.9867 - recall: 0.2267 - f1_score: 0.3638 - val_loss: 0.5369 - val_precision: 1.0000 - val_recall: 0.3333 - val_f1_score: 0.5000\n",
            "Epoch 81/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.5405 - precision: 0.9577 - recall: 0.2233 - f1_score: 0.3611 - val_loss: 0.5365 - val_precision: 1.0000 - val_recall: 0.3333 - val_f1_score: 0.5000\n",
            "Epoch 82/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.5393 - precision: 0.9741 - recall: 0.2400 - f1_score: 0.3843 - val_loss: 0.5356 - val_precision: 1.0000 - val_recall: 0.3333 - val_f1_score: 0.5000\n",
            "Epoch 83/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.5384 - precision: 0.9893 - recall: 0.2567 - f1_score: 0.4066 - val_loss: 0.5350 - val_precision: 1.0000 - val_recall: 0.3333 - val_f1_score: 0.5000\n",
            "Epoch 84/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.5373 - precision: 0.9888 - recall: 0.2567 - f1_score: 0.4067 - val_loss: 0.5338 - val_precision: 1.0000 - val_recall: 0.3500 - val_f1_score: 0.5185\n",
            "Epoch 85/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.5365 - precision: 0.9787 - recall: 0.2633 - f1_score: 0.4142 - val_loss: 0.5329 - val_precision: 1.0000 - val_recall: 0.3500 - val_f1_score: 0.5185\n",
            "Epoch 86/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.5355 - precision: 0.9597 - recall: 0.2667 - f1_score: 0.4163 - val_loss: 0.5323 - val_precision: 1.0000 - val_recall: 0.3500 - val_f1_score: 0.5185\n",
            "Epoch 87/2000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.5346 - precision: 0.9848 - recall: 0.2600 - f1_score: 0.4101 - val_loss: 0.5316 - val_precision: 1.0000 - val_recall: 0.3500 - val_f1_score: 0.5185\n",
            "Epoch 88/2000\n",
            "300/300 [==============================] - 0s 105us/step - loss: 0.5339 - precision: 0.9652 - recall: 0.2733 - f1_score: 0.4240 - val_loss: 0.5316 - val_precision: 1.0000 - val_recall: 0.3500 - val_f1_score: 0.5185\n",
            "Epoch 89/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.5325 - precision: 0.9875 - recall: 0.2667 - f1_score: 0.4187 - val_loss: 0.5307 - val_precision: 1.0000 - val_recall: 0.3500 - val_f1_score: 0.5185\n",
            "Epoch 90/2000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.5315 - precision: 0.9858 - recall: 0.2700 - f1_score: 0.4223 - val_loss: 0.5301 - val_precision: 1.0000 - val_recall: 0.3500 - val_f1_score: 0.5185\n",
            "Epoch 91/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.5307 - precision: 0.9781 - recall: 0.2767 - f1_score: 0.4280 - val_loss: 0.5297 - val_precision: 1.0000 - val_recall: 0.3667 - val_f1_score: 0.5366\n",
            "Epoch 92/2000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.5298 - precision: 0.9527 - recall: 0.2767 - f1_score: 0.4236 - val_loss: 0.5285 - val_precision: 1.0000 - val_recall: 0.3500 - val_f1_score: 0.5185\n",
            "Epoch 93/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.5291 - precision: 0.9775 - recall: 0.2700 - f1_score: 0.4221 - val_loss: 0.5278 - val_precision: 1.0000 - val_recall: 0.3833 - val_f1_score: 0.5542\n",
            "Epoch 94/2000\n",
            "300/300 [==============================] - 0s 82us/step - loss: 0.5279 - precision: 0.9867 - recall: 0.2700 - f1_score: 0.4213 - val_loss: 0.5269 - val_precision: 1.0000 - val_recall: 0.3833 - val_f1_score: 0.5542\n",
            "Epoch 95/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.5271 - precision: 0.9801 - recall: 0.2900 - f1_score: 0.4450 - val_loss: 0.5263 - val_precision: 1.0000 - val_recall: 0.4000 - val_f1_score: 0.5714\n",
            "Epoch 96/2000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.5263 - precision: 0.9888 - recall: 0.2833 - f1_score: 0.4402 - val_loss: 0.5255 - val_precision: 1.0000 - val_recall: 0.4000 - val_f1_score: 0.5714\n",
            "Epoch 97/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.5251 - precision: 0.9911 - recall: 0.2900 - f1_score: 0.4448 - val_loss: 0.5249 - val_precision: 1.0000 - val_recall: 0.4000 - val_f1_score: 0.5714\n",
            "Epoch 98/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.5244 - precision: 0.9923 - recall: 0.2833 - f1_score: 0.4359 - val_loss: 0.5241 - val_precision: 1.0000 - val_recall: 0.4167 - val_f1_score: 0.5882\n",
            "Epoch 99/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.5235 - precision: 0.9902 - recall: 0.3000 - f1_score: 0.4593 - val_loss: 0.5235 - val_precision: 1.0000 - val_recall: 0.4167 - val_f1_score: 0.5882\n",
            "Epoch 100/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.5227 - precision: 0.9893 - recall: 0.2967 - f1_score: 0.4557 - val_loss: 0.5226 - val_precision: 1.0000 - val_recall: 0.4167 - val_f1_score: 0.5882\n",
            "Epoch 101/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.5220 - precision: 0.9898 - recall: 0.3067 - f1_score: 0.4661 - val_loss: 0.5219 - val_precision: 1.0000 - val_recall: 0.4333 - val_f1_score: 0.6047\n",
            "Epoch 102/2000\n",
            "300/300 [==============================] - 0s 117us/step - loss: 0.5209 - precision: 0.9908 - recall: 0.3100 - f1_score: 0.4715 - val_loss: 0.5215 - val_precision: 1.0000 - val_recall: 0.4167 - val_f1_score: 0.5882\n",
            "Epoch 103/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.5202 - precision: 0.9911 - recall: 0.3100 - f1_score: 0.4697 - val_loss: 0.5204 - val_precision: 1.0000 - val_recall: 0.4333 - val_f1_score: 0.6047\n",
            "Epoch 104/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.5192 - precision: 0.9858 - recall: 0.3167 - f1_score: 0.4755 - val_loss: 0.5200 - val_precision: 1.0000 - val_recall: 0.4667 - val_f1_score: 0.6364\n",
            "Epoch 105/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.5184 - precision: 0.9921 - recall: 0.3300 - f1_score: 0.4930 - val_loss: 0.5194 - val_precision: 1.0000 - val_recall: 0.4667 - val_f1_score: 0.6364\n",
            "Epoch 106/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.5176 - precision: 0.9724 - recall: 0.3400 - f1_score: 0.5021 - val_loss: 0.5194 - val_precision: 1.0000 - val_recall: 0.4500 - val_f1_score: 0.6207\n",
            "Epoch 107/2000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.5170 - precision: 0.9776 - recall: 0.3333 - f1_score: 0.4934 - val_loss: 0.5188 - val_precision: 1.0000 - val_recall: 0.4500 - val_f1_score: 0.6207\n",
            "Epoch 108/2000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.5159 - precision: 0.9623 - recall: 0.3233 - f1_score: 0.4805 - val_loss: 0.5174 - val_precision: 1.0000 - val_recall: 0.4667 - val_f1_score: 0.6364\n",
            "Epoch 109/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.5148 - precision: 0.9907 - recall: 0.3367 - f1_score: 0.5018 - val_loss: 0.5171 - val_precision: 1.0000 - val_recall: 0.4667 - val_f1_score: 0.6364\n",
            "Epoch 110/2000\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.5140 - precision: 0.9853 - recall: 0.3533 - f1_score: 0.5177 - val_loss: 0.5171 - val_precision: 1.0000 - val_recall: 0.4500 - val_f1_score: 0.6207\n",
            "Epoch 111/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.5133 - precision: 0.9848 - recall: 0.3433 - f1_score: 0.5068 - val_loss: 0.5163 - val_precision: 1.0000 - val_recall: 0.4500 - val_f1_score: 0.6207\n",
            "Epoch 112/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.5123 - precision: 0.9726 - recall: 0.3400 - f1_score: 0.5003 - val_loss: 0.5152 - val_precision: 1.0000 - val_recall: 0.4833 - val_f1_score: 0.6517\n",
            "Epoch 113/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.5117 - precision: 0.9875 - recall: 0.3533 - f1_score: 0.5183 - val_loss: 0.5149 - val_precision: 1.0000 - val_recall: 0.4833 - val_f1_score: 0.6517\n",
            "Epoch 114/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.5106 - precision: 0.9818 - recall: 0.3567 - f1_score: 0.5226 - val_loss: 0.5138 - val_precision: 1.0000 - val_recall: 0.4833 - val_f1_score: 0.6517\n",
            "Epoch 115/2000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.5099 - precision: 0.9881 - recall: 0.3533 - f1_score: 0.5166 - val_loss: 0.5132 - val_precision: 1.0000 - val_recall: 0.4833 - val_f1_score: 0.6517\n",
            "Epoch 116/2000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.5089 - precision: 0.9814 - recall: 0.3567 - f1_score: 0.5228 - val_loss: 0.5123 - val_precision: 1.0000 - val_recall: 0.4833 - val_f1_score: 0.6517\n",
            "Epoch 117/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.5084 - precision: 0.9832 - recall: 0.3467 - f1_score: 0.5111 - val_loss: 0.5117 - val_precision: 1.0000 - val_recall: 0.4833 - val_f1_score: 0.6517\n",
            "Epoch 118/2000\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.5074 - precision: 0.9914 - recall: 0.3567 - f1_score: 0.5224 - val_loss: 0.5112 - val_precision: 1.0000 - val_recall: 0.4833 - val_f1_score: 0.6517\n",
            "Epoch 119/2000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.5065 - precision: 0.9902 - recall: 0.3600 - f1_score: 0.5263 - val_loss: 0.5107 - val_precision: 1.0000 - val_recall: 0.4833 - val_f1_score: 0.6517\n",
            "Epoch 120/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.5058 - precision: 0.9903 - recall: 0.3667 - f1_score: 0.5318 - val_loss: 0.5107 - val_precision: 1.0000 - val_recall: 0.4833 - val_f1_score: 0.6517\n",
            "Epoch 121/2000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.5050 - precision: 0.9898 - recall: 0.3667 - f1_score: 0.5328 - val_loss: 0.5103 - val_precision: 1.0000 - val_recall: 0.4833 - val_f1_score: 0.6517\n",
            "Epoch 122/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.5041 - precision: 0.9623 - recall: 0.3633 - f1_score: 0.5244 - val_loss: 0.5093 - val_precision: 1.0000 - val_recall: 0.4833 - val_f1_score: 0.6517\n",
            "Epoch 123/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.5036 - precision: 0.9651 - recall: 0.3700 - f1_score: 0.5344 - val_loss: 0.5080 - val_precision: 1.0000 - val_recall: 0.4833 - val_f1_score: 0.6517\n",
            "Epoch 124/2000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.5025 - precision: 0.9911 - recall: 0.3667 - f1_score: 0.5351 - val_loss: 0.5079 - val_precision: 1.0000 - val_recall: 0.4833 - val_f1_score: 0.6517\n",
            "Epoch 125/2000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.5018 - precision: 0.9734 - recall: 0.3733 - f1_score: 0.5385 - val_loss: 0.5077 - val_precision: 1.0000 - val_recall: 0.4833 - val_f1_score: 0.6517\n",
            "Epoch 126/2000\n",
            "300/300 [==============================] - 0s 108us/step - loss: 0.5009 - precision: 0.9713 - recall: 0.3667 - f1_score: 0.5291 - val_loss: 0.5071 - val_precision: 1.0000 - val_recall: 0.4833 - val_f1_score: 0.6517\n",
            "Epoch 127/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.5001 - precision: 0.9751 - recall: 0.3767 - f1_score: 0.5430 - val_loss: 0.5065 - val_precision: 1.0000 - val_recall: 0.4833 - val_f1_score: 0.6517\n",
            "Epoch 128/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.4993 - precision: 0.9683 - recall: 0.3767 - f1_score: 0.5401 - val_loss: 0.5058 - val_precision: 1.0000 - val_recall: 0.4833 - val_f1_score: 0.6517\n",
            "Epoch 129/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.4986 - precision: 0.9777 - recall: 0.3767 - f1_score: 0.5397 - val_loss: 0.5057 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 130/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.4980 - precision: 0.9600 - recall: 0.3800 - f1_score: 0.5390 - val_loss: 0.5049 - val_precision: 1.0000 - val_recall: 0.4833 - val_f1_score: 0.6517\n",
            "Epoch 131/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.4973 - precision: 0.9727 - recall: 0.3767 - f1_score: 0.5412 - val_loss: 0.5043 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 132/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.4968 - precision: 0.9671 - recall: 0.3733 - f1_score: 0.5382 - val_loss: 0.5033 - val_precision: 1.0000 - val_recall: 0.4833 - val_f1_score: 0.6517\n",
            "Epoch 133/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.4955 - precision: 0.9767 - recall: 0.3767 - f1_score: 0.5374 - val_loss: 0.5029 - val_precision: 1.0000 - val_recall: 0.4833 - val_f1_score: 0.6517\n",
            "Epoch 134/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.4948 - precision: 0.9689 - recall: 0.3767 - f1_score: 0.5405 - val_loss: 0.5019 - val_precision: 1.0000 - val_recall: 0.4833 - val_f1_score: 0.6517\n",
            "Epoch 135/2000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.4938 - precision: 0.9737 - recall: 0.3800 - f1_score: 0.5454 - val_loss: 0.5014 - val_precision: 1.0000 - val_recall: 0.4833 - val_f1_score: 0.6517\n",
            "Epoch 136/2000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.4931 - precision: 0.9712 - recall: 0.3800 - f1_score: 0.5412 - val_loss: 0.5011 - val_precision: 1.0000 - val_recall: 0.4833 - val_f1_score: 0.6517\n",
            "Epoch 137/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.4924 - precision: 0.9660 - recall: 0.3833 - f1_score: 0.5484 - val_loss: 0.4999 - val_precision: 1.0000 - val_recall: 0.4833 - val_f1_score: 0.6517\n",
            "Epoch 138/2000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.4917 - precision: 0.9826 - recall: 0.3800 - f1_score: 0.5479 - val_loss: 0.4996 - val_precision: 1.0000 - val_recall: 0.4833 - val_f1_score: 0.6517\n",
            "Epoch 139/2000\n",
            "300/300 [==============================] - 0s 106us/step - loss: 0.4911 - precision: 0.9678 - recall: 0.3833 - f1_score: 0.5419 - val_loss: 0.4990 - val_precision: 1.0000 - val_recall: 0.4833 - val_f1_score: 0.6517\n",
            "Epoch 140/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.4901 - precision: 0.9678 - recall: 0.3867 - f1_score: 0.5504 - val_loss: 0.4983 - val_precision: 1.0000 - val_recall: 0.4833 - val_f1_score: 0.6517\n",
            "Epoch 141/2000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.4895 - precision: 0.9724 - recall: 0.3867 - f1_score: 0.5521 - val_loss: 0.4982 - val_precision: 1.0000 - val_recall: 0.4833 - val_f1_score: 0.6517\n",
            "Epoch 142/2000\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.4890 - precision: 0.9728 - recall: 0.3867 - f1_score: 0.5523 - val_loss: 0.4975 - val_precision: 1.0000 - val_recall: 0.4833 - val_f1_score: 0.6517\n",
            "Epoch 143/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.4879 - precision: 0.9755 - recall: 0.3867 - f1_score: 0.5526 - val_loss: 0.4974 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 144/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.4872 - precision: 0.9548 - recall: 0.3967 - f1_score: 0.5580 - val_loss: 0.4967 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 145/2000\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.4866 - precision: 0.9619 - recall: 0.4000 - f1_score: 0.5640 - val_loss: 0.4959 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 146/2000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.4861 - precision: 0.9626 - recall: 0.4033 - f1_score: 0.5636 - val_loss: 0.4948 - val_precision: 1.0000 - val_recall: 0.4833 - val_f1_score: 0.6517\n",
            "Epoch 147/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.4849 - precision: 0.9754 - recall: 0.4067 - f1_score: 0.5739 - val_loss: 0.4946 - val_precision: 1.0000 - val_recall: 0.4833 - val_f1_score: 0.6517\n",
            "Epoch 148/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.4841 - precision: 0.9695 - recall: 0.4100 - f1_score: 0.5757 - val_loss: 0.4942 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 149/2000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.4836 - precision: 0.9601 - recall: 0.4133 - f1_score: 0.5766 - val_loss: 0.4939 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 150/2000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.4829 - precision: 0.9676 - recall: 0.4167 - f1_score: 0.5804 - val_loss: 0.4932 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 151/2000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.4822 - precision: 0.9619 - recall: 0.4133 - f1_score: 0.5777 - val_loss: 0.4929 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 152/2000\n",
            "300/300 [==============================] - 0s 105us/step - loss: 0.4815 - precision: 0.9700 - recall: 0.4167 - f1_score: 0.5795 - val_loss: 0.4922 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 153/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.4813 - precision: 0.9566 - recall: 0.4033 - f1_score: 0.5585 - val_loss: 0.4915 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 154/2000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.4799 - precision: 0.9683 - recall: 0.4200 - f1_score: 0.5854 - val_loss: 0.4911 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 155/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.4794 - precision: 0.9569 - recall: 0.4133 - f1_score: 0.5753 - val_loss: 0.4906 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 156/2000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.4788 - precision: 0.9602 - recall: 0.4267 - f1_score: 0.5888 - val_loss: 0.4899 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 157/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.4778 - precision: 0.9649 - recall: 0.4233 - f1_score: 0.5865 - val_loss: 0.4889 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 158/2000\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.4774 - precision: 0.9614 - recall: 0.4200 - f1_score: 0.5838 - val_loss: 0.4885 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 159/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.4767 - precision: 0.9794 - recall: 0.4200 - f1_score: 0.5854 - val_loss: 0.4884 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 160/2000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.4758 - precision: 0.9621 - recall: 0.4233 - f1_score: 0.5871 - val_loss: 0.4879 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 161/2000\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.4751 - precision: 0.9609 - recall: 0.4233 - f1_score: 0.5869 - val_loss: 0.4877 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 162/2000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.4745 - precision: 0.9642 - recall: 0.4367 - f1_score: 0.6001 - val_loss: 0.4874 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 163/2000\n",
            "300/300 [==============================] - 0s 114us/step - loss: 0.4739 - precision: 0.9648 - recall: 0.4300 - f1_score: 0.5916 - val_loss: 0.4866 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 164/2000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.4731 - precision: 0.9678 - recall: 0.4500 - f1_score: 0.6122 - val_loss: 0.4857 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 165/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.4724 - precision: 0.9622 - recall: 0.4367 - f1_score: 0.5985 - val_loss: 0.4852 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 166/2000\n",
            "300/300 [==============================] - 0s 79us/step - loss: 0.4716 - precision: 0.9671 - recall: 0.4433 - f1_score: 0.6061 - val_loss: 0.4845 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 167/2000\n",
            "300/300 [==============================] - 0s 101us/step - loss: 0.4710 - precision: 0.9701 - recall: 0.4433 - f1_score: 0.6071 - val_loss: 0.4840 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 168/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.4705 - precision: 0.9716 - recall: 0.4400 - f1_score: 0.6041 - val_loss: 0.4838 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 169/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.4697 - precision: 0.9618 - recall: 0.4500 - f1_score: 0.6109 - val_loss: 0.4833 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 170/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.4690 - precision: 0.9692 - recall: 0.4467 - f1_score: 0.6096 - val_loss: 0.4830 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 171/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.4684 - precision: 0.9643 - recall: 0.4633 - f1_score: 0.6241 - val_loss: 0.4820 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 172/2000\n",
            "300/300 [==============================] - 0s 105us/step - loss: 0.4677 - precision: 0.9652 - recall: 0.4500 - f1_score: 0.6113 - val_loss: 0.4812 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 173/2000\n",
            "300/300 [==============================] - 0s 82us/step - loss: 0.4671 - precision: 0.9637 - recall: 0.4533 - f1_score: 0.6110 - val_loss: 0.4803 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 174/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.4665 - precision: 0.9706 - recall: 0.4467 - f1_score: 0.6098 - val_loss: 0.4799 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 175/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.4658 - precision: 0.9696 - recall: 0.4467 - f1_score: 0.6092 - val_loss: 0.4797 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 176/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.4651 - precision: 0.9668 - recall: 0.4633 - f1_score: 0.6235 - val_loss: 0.4792 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 177/2000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.4647 - precision: 0.9630 - recall: 0.4400 - f1_score: 0.6021 - val_loss: 0.4787 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 178/2000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.4639 - precision: 0.9654 - recall: 0.4700 - f1_score: 0.6314 - val_loss: 0.4778 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 179/2000\n",
            "300/300 [==============================] - 0s 108us/step - loss: 0.4632 - precision: 0.9671 - recall: 0.4500 - f1_score: 0.6097 - val_loss: 0.4777 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 180/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.4627 - precision: 0.9652 - recall: 0.4667 - f1_score: 0.6276 - val_loss: 0.4766 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 181/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.4618 - precision: 0.9727 - recall: 0.4567 - f1_score: 0.6210 - val_loss: 0.4764 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 182/2000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.4612 - precision: 0.9748 - recall: 0.4600 - f1_score: 0.6218 - val_loss: 0.4760 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 183/2000\n",
            "300/300 [==============================] - 0s 78us/step - loss: 0.4609 - precision: 0.9666 - recall: 0.4600 - f1_score: 0.6217 - val_loss: 0.4761 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 184/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.4601 - precision: 0.9643 - recall: 0.4767 - f1_score: 0.6355 - val_loss: 0.4755 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 185/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.4595 - precision: 0.9664 - recall: 0.4733 - f1_score: 0.6344 - val_loss: 0.4753 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 186/2000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.4588 - precision: 0.9629 - recall: 0.4800 - f1_score: 0.6381 - val_loss: 0.4747 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 187/2000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.4581 - precision: 0.9682 - recall: 0.4800 - f1_score: 0.6395 - val_loss: 0.4742 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 188/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.4575 - precision: 0.9668 - recall: 0.4833 - f1_score: 0.6428 - val_loss: 0.4732 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 189/2000\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.4570 - precision: 0.9624 - recall: 0.4833 - f1_score: 0.6383 - val_loss: 0.4724 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 190/2000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.4566 - precision: 0.9659 - recall: 0.4667 - f1_score: 0.6280 - val_loss: 0.4723 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 191/2000\n",
            "300/300 [==============================] - 0s 82us/step - loss: 0.4558 - precision: 0.9663 - recall: 0.4767 - f1_score: 0.6377 - val_loss: 0.4721 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 192/2000\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.4550 - precision: 0.9667 - recall: 0.4833 - f1_score: 0.6428 - val_loss: 0.4712 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 193/2000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.4546 - precision: 0.9664 - recall: 0.4800 - f1_score: 0.6406 - val_loss: 0.4711 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 194/2000\n",
            "300/300 [==============================] - 0s 104us/step - loss: 0.4538 - precision: 0.9677 - recall: 0.4867 - f1_score: 0.6470 - val_loss: 0.4704 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 195/2000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.4536 - precision: 0.9673 - recall: 0.4867 - f1_score: 0.6466 - val_loss: 0.4704 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 196/2000\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.4529 - precision: 0.9705 - recall: 0.4967 - f1_score: 0.6539 - val_loss: 0.4695 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 197/2000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.4521 - precision: 0.9650 - recall: 0.4833 - f1_score: 0.6427 - val_loss: 0.4694 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 198/2000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.4515 - precision: 0.9671 - recall: 0.4933 - f1_score: 0.6520 - val_loss: 0.4688 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 199/2000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.4510 - precision: 0.9701 - recall: 0.4867 - f1_score: 0.6438 - val_loss: 0.4683 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 200/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.4503 - precision: 0.9684 - recall: 0.5000 - f1_score: 0.6591 - val_loss: 0.4677 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 201/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.4503 - precision: 0.9540 - recall: 0.5067 - f1_score: 0.6607 - val_loss: 0.4672 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 202/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.4496 - precision: 0.9673 - recall: 0.4967 - f1_score: 0.6524 - val_loss: 0.4666 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 203/2000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.4485 - precision: 0.9661 - recall: 0.4933 - f1_score: 0.6517 - val_loss: 0.4663 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 204/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.4480 - precision: 0.9707 - recall: 0.4933 - f1_score: 0.6516 - val_loss: 0.4657 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 205/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.4477 - precision: 0.9602 - recall: 0.5000 - f1_score: 0.6549 - val_loss: 0.4647 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 206/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.4469 - precision: 0.9657 - recall: 0.4933 - f1_score: 0.6508 - val_loss: 0.4644 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 207/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.4465 - precision: 0.9683 - recall: 0.4867 - f1_score: 0.6469 - val_loss: 0.4647 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 208/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.4457 - precision: 0.9664 - recall: 0.4933 - f1_score: 0.6490 - val_loss: 0.4648 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 209/2000\n",
            "300/300 [==============================] - 0s 80us/step - loss: 0.4452 - precision: 0.9720 - recall: 0.5200 - f1_score: 0.6720 - val_loss: 0.4636 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 210/2000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.4445 - precision: 0.9751 - recall: 0.5133 - f1_score: 0.6719 - val_loss: 0.4627 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 211/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.4440 - precision: 0.9678 - recall: 0.5000 - f1_score: 0.6589 - val_loss: 0.4622 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 212/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.4434 - precision: 0.9669 - recall: 0.5033 - f1_score: 0.6591 - val_loss: 0.4619 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 213/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.4429 - precision: 0.9650 - recall: 0.5033 - f1_score: 0.6586 - val_loss: 0.4616 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 214/2000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.4424 - precision: 0.9683 - recall: 0.5100 - f1_score: 0.6677 - val_loss: 0.4612 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 215/2000\n",
            "300/300 [==============================] - 0s 82us/step - loss: 0.4424 - precision: 0.9691 - recall: 0.5000 - f1_score: 0.6583 - val_loss: 0.4612 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 216/2000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.4414 - precision: 0.9733 - recall: 0.5167 - f1_score: 0.6737 - val_loss: 0.4604 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 217/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.4406 - precision: 0.9682 - recall: 0.5133 - f1_score: 0.6657 - val_loss: 0.4601 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 218/2000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.4401 - precision: 0.9759 - recall: 0.5133 - f1_score: 0.6705 - val_loss: 0.4600 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 219/2000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.4398 - precision: 0.9659 - recall: 0.5367 - f1_score: 0.6876 - val_loss: 0.4589 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 220/2000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.4397 - precision: 0.9737 - recall: 0.5200 - f1_score: 0.6739 - val_loss: 0.4589 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 221/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.4385 - precision: 0.9684 - recall: 0.5367 - f1_score: 0.6898 - val_loss: 0.4583 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 222/2000\n",
            "300/300 [==============================] - 0s 125us/step - loss: 0.4381 - precision: 0.9729 - recall: 0.5467 - f1_score: 0.6983 - val_loss: 0.4574 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 223/2000\n",
            "300/300 [==============================] - 0s 102us/step - loss: 0.4374 - precision: 0.9731 - recall: 0.5067 - f1_score: 0.6627 - val_loss: 0.4576 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 224/2000\n",
            "300/300 [==============================] - 0s 114us/step - loss: 0.4371 - precision: 0.9678 - recall: 0.5167 - f1_score: 0.6721 - val_loss: 0.4574 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 225/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.4362 - precision: 0.9764 - recall: 0.5433 - f1_score: 0.6957 - val_loss: 0.4565 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 226/2000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.4358 - precision: 0.9781 - recall: 0.5400 - f1_score: 0.6931 - val_loss: 0.4559 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 227/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.4353 - precision: 0.9693 - recall: 0.5300 - f1_score: 0.6846 - val_loss: 0.4555 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 228/2000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.4347 - precision: 0.9767 - recall: 0.5367 - f1_score: 0.6922 - val_loss: 0.4551 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 229/2000\n",
            "300/300 [==============================] - 0s 102us/step - loss: 0.4340 - precision: 0.9769 - recall: 0.5367 - f1_score: 0.6921 - val_loss: 0.4546 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 230/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.4341 - precision: 0.9735 - recall: 0.5167 - f1_score: 0.6735 - val_loss: 0.4547 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 231/2000\n",
            "300/300 [==============================] - 0s 106us/step - loss: 0.4332 - precision: 0.9706 - recall: 0.5467 - f1_score: 0.6990 - val_loss: 0.4539 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 232/2000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.4326 - precision: 0.9737 - recall: 0.5433 - f1_score: 0.6949 - val_loss: 0.4531 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 233/2000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.4321 - precision: 0.9757 - recall: 0.5433 - f1_score: 0.6955 - val_loss: 0.4523 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 234/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.4317 - precision: 0.9784 - recall: 0.5433 - f1_score: 0.6969 - val_loss: 0.4516 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 235/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.4309 - precision: 0.9702 - recall: 0.5300 - f1_score: 0.6851 - val_loss: 0.4514 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 236/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.4308 - precision: 0.9699 - recall: 0.5200 - f1_score: 0.6762 - val_loss: 0.4517 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 237/2000\n",
            "300/300 [==============================] - 0s 109us/step - loss: 0.4300 - precision: 0.9764 - recall: 0.5467 - f1_score: 0.6987 - val_loss: 0.4513 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 238/2000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.4295 - precision: 0.9745 - recall: 0.5467 - f1_score: 0.6982 - val_loss: 0.4510 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 239/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.4289 - precision: 0.9783 - recall: 0.5467 - f1_score: 0.6974 - val_loss: 0.4508 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 240/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.4288 - precision: 0.9771 - recall: 0.5467 - f1_score: 0.7004 - val_loss: 0.4503 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 241/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.4281 - precision: 0.9759 - recall: 0.5533 - f1_score: 0.7056 - val_loss: 0.4500 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 242/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.4275 - precision: 0.9779 - recall: 0.5500 - f1_score: 0.7009 - val_loss: 0.4500 - val_precision: 0.9355 - val_recall: 0.4833 - val_f1_score: 0.6374\n",
            "Epoch 243/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.4271 - precision: 0.9717 - recall: 0.5567 - f1_score: 0.7064 - val_loss: 0.4497 - val_precision: 0.9355 - val_recall: 0.4833 - val_f1_score: 0.6374\n",
            "Epoch 244/2000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.4265 - precision: 0.9720 - recall: 0.5600 - f1_score: 0.7090 - val_loss: 0.4491 - val_precision: 0.9355 - val_recall: 0.4833 - val_f1_score: 0.6374\n",
            "Epoch 245/2000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.4261 - precision: 0.9714 - recall: 0.5600 - f1_score: 0.7079 - val_loss: 0.4489 - val_precision: 0.9355 - val_recall: 0.4833 - val_f1_score: 0.6374\n",
            "Epoch 246/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.4255 - precision: 0.9706 - recall: 0.5567 - f1_score: 0.7060 - val_loss: 0.4481 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 247/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.4249 - precision: 0.9760 - recall: 0.5633 - f1_score: 0.7099 - val_loss: 0.4477 - val_precision: 0.9655 - val_recall: 0.4667 - val_f1_score: 0.6292\n",
            "Epoch 248/2000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.4245 - precision: 0.9746 - recall: 0.5633 - f1_score: 0.7076 - val_loss: 0.4476 - val_precision: 0.9333 - val_recall: 0.4667 - val_f1_score: 0.6222\n",
            "Epoch 249/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.4242 - precision: 0.9658 - recall: 0.5600 - f1_score: 0.7083 - val_loss: 0.4467 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 250/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.4238 - precision: 0.9770 - recall: 0.5533 - f1_score: 0.7043 - val_loss: 0.4460 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 251/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.4234 - precision: 0.9700 - recall: 0.5567 - f1_score: 0.7041 - val_loss: 0.4452 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 252/2000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.4227 - precision: 0.9772 - recall: 0.5567 - f1_score: 0.7089 - val_loss: 0.4453 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 253/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.4222 - precision: 0.9776 - recall: 0.5600 - f1_score: 0.7115 - val_loss: 0.4450 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 254/2000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.4219 - precision: 0.9779 - recall: 0.5667 - f1_score: 0.7160 - val_loss: 0.4447 - val_precision: 0.9677 - val_recall: 0.5000 - val_f1_score: 0.6593\n",
            "Epoch 255/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.4213 - precision: 0.9725 - recall: 0.5733 - f1_score: 0.7207 - val_loss: 0.4444 - val_precision: 0.9375 - val_recall: 0.5000 - val_f1_score: 0.6522\n",
            "Epoch 256/2000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.4206 - precision: 0.9732 - recall: 0.5733 - f1_score: 0.7184 - val_loss: 0.4439 - val_precision: 0.9677 - val_recall: 0.5000 - val_f1_score: 0.6593\n",
            "Epoch 257/2000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.4200 - precision: 0.9708 - recall: 0.5633 - f1_score: 0.7127 - val_loss: 0.4436 - val_precision: 0.9677 - val_recall: 0.5000 - val_f1_score: 0.6593\n",
            "Epoch 258/2000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.4197 - precision: 0.9717 - recall: 0.5733 - f1_score: 0.7203 - val_loss: 0.4428 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 259/2000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.4194 - precision: 0.9765 - recall: 0.5667 - f1_score: 0.7155 - val_loss: 0.4420 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 260/2000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.4187 - precision: 0.9775 - recall: 0.5633 - f1_score: 0.7133 - val_loss: 0.4420 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 261/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.4183 - precision: 0.9766 - recall: 0.5667 - f1_score: 0.7155 - val_loss: 0.4416 - val_precision: 0.9677 - val_recall: 0.5000 - val_f1_score: 0.6593\n",
            "Epoch 262/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.4178 - precision: 0.9754 - recall: 0.5700 - f1_score: 0.7180 - val_loss: 0.4413 - val_precision: 0.9677 - val_recall: 0.5000 - val_f1_score: 0.6593\n",
            "Epoch 263/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.4177 - precision: 0.9728 - recall: 0.5600 - f1_score: 0.7098 - val_loss: 0.4410 - val_precision: 0.9677 - val_recall: 0.5000 - val_f1_score: 0.6593\n",
            "Epoch 264/2000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.4168 - precision: 0.9721 - recall: 0.5700 - f1_score: 0.7183 - val_loss: 0.4403 - val_precision: 0.9677 - val_recall: 0.5000 - val_f1_score: 0.6593\n",
            "Epoch 265/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.4165 - precision: 0.9770 - recall: 0.5667 - f1_score: 0.7170 - val_loss: 0.4403 - val_precision: 0.9677 - val_recall: 0.5000 - val_f1_score: 0.6593\n",
            "Epoch 266/2000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.4159 - precision: 0.9768 - recall: 0.5733 - f1_score: 0.7205 - val_loss: 0.4395 - val_precision: 0.9677 - val_recall: 0.5000 - val_f1_score: 0.6593\n",
            "Epoch 267/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.4154 - precision: 0.9735 - recall: 0.5733 - f1_score: 0.7202 - val_loss: 0.4387 - val_precision: 0.9667 - val_recall: 0.4833 - val_f1_score: 0.6444\n",
            "Epoch 268/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.4151 - precision: 0.9775 - recall: 0.5767 - f1_score: 0.7247 - val_loss: 0.4384 - val_precision: 0.9677 - val_recall: 0.5000 - val_f1_score: 0.6593\n",
            "Epoch 269/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.4150 - precision: 0.9784 - recall: 0.5767 - f1_score: 0.7251 - val_loss: 0.4383 - val_precision: 0.9677 - val_recall: 0.5000 - val_f1_score: 0.6593\n",
            "Epoch 270/2000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.4142 - precision: 0.9728 - recall: 0.5800 - f1_score: 0.7256 - val_loss: 0.4376 - val_precision: 0.9677 - val_recall: 0.5000 - val_f1_score: 0.6593\n",
            "Epoch 271/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.4137 - precision: 0.9777 - recall: 0.5700 - f1_score: 0.7192 - val_loss: 0.4374 - val_precision: 0.9677 - val_recall: 0.5000 - val_f1_score: 0.6593\n",
            "Epoch 272/2000\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.4132 - precision: 0.9741 - recall: 0.5700 - f1_score: 0.7172 - val_loss: 0.4372 - val_precision: 0.9688 - val_recall: 0.5167 - val_f1_score: 0.6739\n",
            "Epoch 273/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.4127 - precision: 0.9719 - recall: 0.5733 - f1_score: 0.7196 - val_loss: 0.4367 - val_precision: 0.9677 - val_recall: 0.5000 - val_f1_score: 0.6593\n",
            "Epoch 274/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.4124 - precision: 0.9727 - recall: 0.5767 - f1_score: 0.7219 - val_loss: 0.4362 - val_precision: 0.9677 - val_recall: 0.5000 - val_f1_score: 0.6593\n",
            "Epoch 275/2000\n",
            "300/300 [==============================] - 0s 107us/step - loss: 0.4118 - precision: 0.9760 - recall: 0.5767 - f1_score: 0.7245 - val_loss: 0.4361 - val_precision: 0.9688 - val_recall: 0.5167 - val_f1_score: 0.6739\n",
            "Epoch 276/2000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.4114 - precision: 0.9726 - recall: 0.5767 - f1_score: 0.7201 - val_loss: 0.4354 - val_precision: 0.9688 - val_recall: 0.5167 - val_f1_score: 0.6739\n",
            "Epoch 277/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.4112 - precision: 0.9755 - recall: 0.5767 - f1_score: 0.7217 - val_loss: 0.4355 - val_precision: 0.9697 - val_recall: 0.5333 - val_f1_score: 0.6882\n",
            "Epoch 278/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.4105 - precision: 0.9734 - recall: 0.5767 - f1_score: 0.7233 - val_loss: 0.4351 - val_precision: 0.9697 - val_recall: 0.5333 - val_f1_score: 0.6882\n",
            "Epoch 279/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.4108 - precision: 0.9552 - recall: 0.5867 - f1_score: 0.7259 - val_loss: 0.4342 - val_precision: 0.9688 - val_recall: 0.5167 - val_f1_score: 0.6739\n",
            "Epoch 280/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.4096 - precision: 0.9772 - recall: 0.5767 - f1_score: 0.7250 - val_loss: 0.4339 - val_precision: 0.9688 - val_recall: 0.5167 - val_f1_score: 0.6739\n",
            "Epoch 281/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.4094 - precision: 0.9733 - recall: 0.5733 - f1_score: 0.7203 - val_loss: 0.4334 - val_precision: 0.9688 - val_recall: 0.5167 - val_f1_score: 0.6739\n",
            "Epoch 282/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.4089 - precision: 0.9774 - recall: 0.5800 - f1_score: 0.7278 - val_loss: 0.4335 - val_precision: 0.9697 - val_recall: 0.5333 - val_f1_score: 0.6882\n",
            "Epoch 283/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.4083 - precision: 0.9784 - recall: 0.5767 - f1_score: 0.7247 - val_loss: 0.4333 - val_precision: 0.9697 - val_recall: 0.5333 - val_f1_score: 0.6882\n",
            "Epoch 284/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.4079 - precision: 0.9718 - recall: 0.5800 - f1_score: 0.7261 - val_loss: 0.4328 - val_precision: 0.9697 - val_recall: 0.5333 - val_f1_score: 0.6882\n",
            "Epoch 285/2000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.4074 - precision: 0.9792 - recall: 0.5767 - f1_score: 0.7247 - val_loss: 0.4328 - val_precision: 0.9412 - val_recall: 0.5333 - val_f1_score: 0.6809\n",
            "Epoch 286/2000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.4073 - precision: 0.9652 - recall: 0.5833 - f1_score: 0.7266 - val_loss: 0.4324 - val_precision: 0.9412 - val_recall: 0.5333 - val_f1_score: 0.6809\n",
            "Epoch 287/2000\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.4067 - precision: 0.9769 - recall: 0.5833 - f1_score: 0.7289 - val_loss: 0.4322 - val_precision: 0.9429 - val_recall: 0.5500 - val_f1_score: 0.6947\n",
            "Epoch 288/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.4063 - precision: 0.9590 - recall: 0.5900 - f1_score: 0.7295 - val_loss: 0.4310 - val_precision: 0.9697 - val_recall: 0.5333 - val_f1_score: 0.6882\n",
            "Epoch 289/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.4057 - precision: 0.9732 - recall: 0.5833 - f1_score: 0.7287 - val_loss: 0.4307 - val_precision: 0.9697 - val_recall: 0.5333 - val_f1_score: 0.6882\n",
            "Epoch 290/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.4054 - precision: 0.9765 - recall: 0.5800 - f1_score: 0.7254 - val_loss: 0.4309 - val_precision: 0.9412 - val_recall: 0.5333 - val_f1_score: 0.6809\n",
            "Epoch 291/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.4050 - precision: 0.9680 - recall: 0.5833 - f1_score: 0.7259 - val_loss: 0.4308 - val_precision: 0.9429 - val_recall: 0.5500 - val_f1_score: 0.6947\n",
            "Epoch 292/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.4051 - precision: 0.9778 - recall: 0.5867 - f1_score: 0.7305 - val_loss: 0.4303 - val_precision: 0.9429 - val_recall: 0.5500 - val_f1_score: 0.6947\n",
            "Epoch 293/2000\n",
            "300/300 [==============================] - 0s 101us/step - loss: 0.4040 - precision: 0.9716 - recall: 0.5833 - f1_score: 0.7283 - val_loss: 0.4300 - val_precision: 0.9429 - val_recall: 0.5500 - val_f1_score: 0.6947\n",
            "Epoch 294/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.4041 - precision: 0.9788 - recall: 0.5867 - f1_score: 0.7293 - val_loss: 0.4294 - val_precision: 0.9429 - val_recall: 0.5500 - val_f1_score: 0.6947\n",
            "Epoch 295/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.4035 - precision: 0.9606 - recall: 0.5967 - f1_score: 0.7348 - val_loss: 0.4282 - val_precision: 0.9697 - val_recall: 0.5333 - val_f1_score: 0.6882\n",
            "Epoch 296/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.4030 - precision: 0.9776 - recall: 0.5833 - f1_score: 0.7283 - val_loss: 0.4279 - val_precision: 0.9697 - val_recall: 0.5333 - val_f1_score: 0.6882\n",
            "Epoch 297/2000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.4024 - precision: 0.9789 - recall: 0.5900 - f1_score: 0.7348 - val_loss: 0.4277 - val_precision: 0.9697 - val_recall: 0.5333 - val_f1_score: 0.6882\n",
            "Epoch 298/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.4022 - precision: 0.9820 - recall: 0.5833 - f1_score: 0.7304 - val_loss: 0.4280 - val_precision: 0.9429 - val_recall: 0.5500 - val_f1_score: 0.6947\n",
            "Epoch 299/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.4015 - precision: 0.9726 - recall: 0.5933 - f1_score: 0.7345 - val_loss: 0.4276 - val_precision: 0.9706 - val_recall: 0.5500 - val_f1_score: 0.7021\n",
            "Epoch 300/2000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.4010 - precision: 0.9771 - recall: 0.5900 - f1_score: 0.7348 - val_loss: 0.4276 - val_precision: 0.9444 - val_recall: 0.5667 - val_f1_score: 0.7083\n",
            "Epoch 301/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.4006 - precision: 0.9787 - recall: 0.5967 - f1_score: 0.7404 - val_loss: 0.4274 - val_precision: 0.9444 - val_recall: 0.5667 - val_f1_score: 0.7083\n",
            "Epoch 302/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.4004 - precision: 0.9666 - recall: 0.5900 - f1_score: 0.7324 - val_loss: 0.4267 - val_precision: 0.9444 - val_recall: 0.5667 - val_f1_score: 0.7083\n",
            "Epoch 303/2000\n",
            "300/300 [==============================] - 0s 102us/step - loss: 0.4000 - precision: 0.9778 - recall: 0.5933 - f1_score: 0.7377 - val_loss: 0.4266 - val_precision: 0.9444 - val_recall: 0.5667 - val_f1_score: 0.7083\n",
            "Epoch 304/2000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.3997 - precision: 0.9659 - recall: 0.5933 - f1_score: 0.7343 - val_loss: 0.4258 - val_precision: 0.9444 - val_recall: 0.5667 - val_f1_score: 0.7083\n",
            "Epoch 305/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.3991 - precision: 0.9728 - recall: 0.5967 - f1_score: 0.7395 - val_loss: 0.4253 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 306/2000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.3987 - precision: 0.9782 - recall: 0.5933 - f1_score: 0.7383 - val_loss: 0.4253 - val_precision: 0.9444 - val_recall: 0.5667 - val_f1_score: 0.7083\n",
            "Epoch 307/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.3982 - precision: 0.9619 - recall: 0.5900 - f1_score: 0.7291 - val_loss: 0.4244 - val_precision: 0.9706 - val_recall: 0.5500 - val_f1_score: 0.7021\n",
            "Epoch 308/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.3979 - precision: 0.9717 - recall: 0.6000 - f1_score: 0.7414 - val_loss: 0.4236 - val_precision: 0.9706 - val_recall: 0.5500 - val_f1_score: 0.7021\n",
            "Epoch 309/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.3973 - precision: 0.9780 - recall: 0.5967 - f1_score: 0.7401 - val_loss: 0.4236 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 310/2000\n",
            "300/300 [==============================] - 0s 113us/step - loss: 0.3972 - precision: 0.9783 - recall: 0.6033 - f1_score: 0.7452 - val_loss: 0.4236 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 311/2000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.3966 - precision: 0.9786 - recall: 0.5933 - f1_score: 0.7369 - val_loss: 0.4235 - val_precision: 0.9444 - val_recall: 0.5667 - val_f1_score: 0.7083\n",
            "Epoch 312/2000\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.3963 - precision: 0.9727 - recall: 0.6033 - f1_score: 0.7434 - val_loss: 0.4232 - val_precision: 0.9444 - val_recall: 0.5667 - val_f1_score: 0.7083\n",
            "Epoch 313/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.3961 - precision: 0.9784 - recall: 0.5967 - f1_score: 0.7405 - val_loss: 0.4228 - val_precision: 0.9444 - val_recall: 0.5667 - val_f1_score: 0.7083\n",
            "Epoch 314/2000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.3953 - precision: 0.9734 - recall: 0.6000 - f1_score: 0.7405 - val_loss: 0.4221 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 315/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.3952 - precision: 0.9790 - recall: 0.6000 - f1_score: 0.7429 - val_loss: 0.4216 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 316/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.3946 - precision: 0.9776 - recall: 0.6000 - f1_score: 0.7430 - val_loss: 0.4210 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 317/2000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.3945 - precision: 0.9715 - recall: 0.6000 - f1_score: 0.7408 - val_loss: 0.4203 - val_precision: 0.9706 - val_recall: 0.5500 - val_f1_score: 0.7021\n",
            "Epoch 318/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.3939 - precision: 0.9785 - recall: 0.6000 - f1_score: 0.7433 - val_loss: 0.4205 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 319/2000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.3936 - precision: 0.9728 - recall: 0.6000 - f1_score: 0.7403 - val_loss: 0.4203 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 320/2000\n",
            "300/300 [==============================] - 0s 82us/step - loss: 0.3930 - precision: 0.9773 - recall: 0.5967 - f1_score: 0.7398 - val_loss: 0.4201 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 321/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.3927 - precision: 0.9794 - recall: 0.6033 - f1_score: 0.7411 - val_loss: 0.4197 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 322/2000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.3922 - precision: 0.9786 - recall: 0.6000 - f1_score: 0.7425 - val_loss: 0.4195 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 323/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.3918 - precision: 0.9792 - recall: 0.6100 - f1_score: 0.7512 - val_loss: 0.4195 - val_precision: 0.9444 - val_recall: 0.5667 - val_f1_score: 0.7083\n",
            "Epoch 324/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.3917 - precision: 0.9784 - recall: 0.6033 - f1_score: 0.7460 - val_loss: 0.4196 - val_precision: 0.9444 - val_recall: 0.5667 - val_f1_score: 0.7083\n",
            "Epoch 325/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.3913 - precision: 0.9541 - recall: 0.6000 - f1_score: 0.7331 - val_loss: 0.4187 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 326/2000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.3910 - precision: 0.9790 - recall: 0.6033 - f1_score: 0.7449 - val_loss: 0.4181 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 327/2000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.3904 - precision: 0.9710 - recall: 0.6033 - f1_score: 0.7427 - val_loss: 0.4175 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 328/2000\n",
            "300/300 [==============================] - 0s 81us/step - loss: 0.3899 - precision: 0.9800 - recall: 0.6100 - f1_score: 0.7510 - val_loss: 0.4173 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 329/2000\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.3897 - precision: 0.9778 - recall: 0.6033 - f1_score: 0.7447 - val_loss: 0.4175 - val_precision: 0.9444 - val_recall: 0.5667 - val_f1_score: 0.7083\n",
            "Epoch 330/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.3892 - precision: 0.9686 - recall: 0.6067 - f1_score: 0.7443 - val_loss: 0.4168 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 331/2000\n",
            "300/300 [==============================] - 0s 102us/step - loss: 0.3890 - precision: 0.9716 - recall: 0.6033 - f1_score: 0.7423 - val_loss: 0.4161 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 332/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.3886 - precision: 0.9791 - recall: 0.6000 - f1_score: 0.7430 - val_loss: 0.4156 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 333/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.3883 - precision: 0.9786 - recall: 0.6033 - f1_score: 0.7449 - val_loss: 0.4153 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 334/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.3877 - precision: 0.9783 - recall: 0.6067 - f1_score: 0.7476 - val_loss: 0.4146 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 335/2000\n",
            "300/300 [==============================] - 0s 107us/step - loss: 0.3875 - precision: 0.9780 - recall: 0.6033 - f1_score: 0.7436 - val_loss: 0.4144 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 336/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.3872 - precision: 0.9784 - recall: 0.6100 - f1_score: 0.7508 - val_loss: 0.4146 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 337/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.3867 - precision: 0.9692 - recall: 0.6133 - f1_score: 0.7493 - val_loss: 0.4137 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 338/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.3863 - precision: 0.9793 - recall: 0.6067 - f1_score: 0.7454 - val_loss: 0.4137 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 339/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.3861 - precision: 0.9663 - recall: 0.6167 - f1_score: 0.7478 - val_loss: 0.4131 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 340/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.3855 - precision: 0.9783 - recall: 0.6100 - f1_score: 0.7512 - val_loss: 0.4134 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 341/2000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.3850 - precision: 0.9789 - recall: 0.6100 - f1_score: 0.7508 - val_loss: 0.4134 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 342/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.3850 - precision: 0.9785 - recall: 0.6100 - f1_score: 0.7510 - val_loss: 0.4129 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 343/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.3846 - precision: 0.9774 - recall: 0.6033 - f1_score: 0.7455 - val_loss: 0.4132 - val_precision: 0.9444 - val_recall: 0.5667 - val_f1_score: 0.7083\n",
            "Epoch 344/2000\n",
            "300/300 [==============================] - 0s 106us/step - loss: 0.3840 - precision: 0.9687 - recall: 0.6067 - f1_score: 0.7452 - val_loss: 0.4126 - val_precision: 0.9444 - val_recall: 0.5667 - val_f1_score: 0.7083\n",
            "Epoch 345/2000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.3839 - precision: 0.9729 - recall: 0.6033 - f1_score: 0.7409 - val_loss: 0.4127 - val_precision: 0.9444 - val_recall: 0.5667 - val_f1_score: 0.7083\n",
            "Epoch 346/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.3833 - precision: 0.9651 - recall: 0.6133 - f1_score: 0.7485 - val_loss: 0.4122 - val_precision: 0.9444 - val_recall: 0.5667 - val_f1_score: 0.7083\n",
            "Epoch 347/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.3831 - precision: 0.9745 - recall: 0.6133 - f1_score: 0.7523 - val_loss: 0.4121 - val_precision: 0.9444 - val_recall: 0.5667 - val_f1_score: 0.7083\n",
            "Epoch 348/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.3826 - precision: 0.9642 - recall: 0.6200 - f1_score: 0.7538 - val_loss: 0.4114 - val_precision: 0.9444 - val_recall: 0.5667 - val_f1_score: 0.7083\n",
            "Epoch 349/2000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.3823 - precision: 0.9776 - recall: 0.6167 - f1_score: 0.7545 - val_loss: 0.4113 - val_precision: 0.9444 - val_recall: 0.5667 - val_f1_score: 0.7083\n",
            "Epoch 350/2000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.3819 - precision: 0.9631 - recall: 0.6133 - f1_score: 0.7492 - val_loss: 0.4103 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 351/2000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.3814 - precision: 0.9801 - recall: 0.6167 - f1_score: 0.7556 - val_loss: 0.4100 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 352/2000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.3815 - precision: 0.9797 - recall: 0.6133 - f1_score: 0.7536 - val_loss: 0.4098 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 353/2000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.3808 - precision: 0.9741 - recall: 0.6067 - f1_score: 0.7470 - val_loss: 0.4090 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 354/2000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.3806 - precision: 0.9786 - recall: 0.6133 - f1_score: 0.7528 - val_loss: 0.4094 - val_precision: 0.9444 - val_recall: 0.5667 - val_f1_score: 0.7083\n",
            "Epoch 355/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.3802 - precision: 0.9787 - recall: 0.6100 - f1_score: 0.7498 - val_loss: 0.4088 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 356/2000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.3803 - precision: 0.9744 - recall: 0.6167 - f1_score: 0.7545 - val_loss: 0.4092 - val_precision: 0.9444 - val_recall: 0.5667 - val_f1_score: 0.7083\n",
            "Epoch 357/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.3794 - precision: 0.9618 - recall: 0.6100 - f1_score: 0.7446 - val_loss: 0.4084 - val_precision: 0.9444 - val_recall: 0.5667 - val_f1_score: 0.7083\n",
            "Epoch 358/2000\n",
            "300/300 [==============================] - 0s 82us/step - loss: 0.3791 - precision: 0.9781 - recall: 0.6167 - f1_score: 0.7544 - val_loss: 0.4084 - val_precision: 0.9444 - val_recall: 0.5667 - val_f1_score: 0.7083\n",
            "Epoch 359/2000\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.3787 - precision: 0.9734 - recall: 0.6100 - f1_score: 0.7488 - val_loss: 0.4077 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 360/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.3784 - precision: 0.9783 - recall: 0.6100 - f1_score: 0.7510 - val_loss: 0.4077 - val_precision: 0.9444 - val_recall: 0.5667 - val_f1_score: 0.7083\n",
            "Epoch 361/2000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.3781 - precision: 0.9769 - recall: 0.6100 - f1_score: 0.7485 - val_loss: 0.4071 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 362/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.3775 - precision: 0.9792 - recall: 0.6100 - f1_score: 0.7510 - val_loss: 0.4067 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 363/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.3775 - precision: 0.9794 - recall: 0.6200 - f1_score: 0.7578 - val_loss: 0.4071 - val_precision: 0.9444 - val_recall: 0.5667 - val_f1_score: 0.7083\n",
            "Epoch 364/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.3772 - precision: 0.9735 - recall: 0.6100 - f1_score: 0.7489 - val_loss: 0.4061 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 365/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.3766 - precision: 0.9722 - recall: 0.6133 - f1_score: 0.7500 - val_loss: 0.4058 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 366/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.3764 - precision: 0.9792 - recall: 0.6200 - f1_score: 0.7588 - val_loss: 0.4059 - val_precision: 0.9444 - val_recall: 0.5667 - val_f1_score: 0.7083\n",
            "Epoch 367/2000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.3761 - precision: 0.9732 - recall: 0.6200 - f1_score: 0.7559 - val_loss: 0.4058 - val_precision: 0.9444 - val_recall: 0.5667 - val_f1_score: 0.7083\n",
            "Epoch 368/2000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.3757 - precision: 0.9692 - recall: 0.6233 - f1_score: 0.7581 - val_loss: 0.4051 - val_precision: 0.9444 - val_recall: 0.5667 - val_f1_score: 0.7083\n",
            "Epoch 369/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.3752 - precision: 0.9796 - recall: 0.6200 - f1_score: 0.7571 - val_loss: 0.4048 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 370/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.3749 - precision: 0.9782 - recall: 0.6200 - f1_score: 0.7564 - val_loss: 0.4047 - val_precision: 0.9444 - val_recall: 0.5667 - val_f1_score: 0.7083\n",
            "Epoch 371/2000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.3746 - precision: 0.9788 - recall: 0.6133 - f1_score: 0.7541 - val_loss: 0.4044 - val_precision: 0.9444 - val_recall: 0.5667 - val_f1_score: 0.7083\n",
            "Epoch 372/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.3743 - precision: 0.9746 - recall: 0.6200 - f1_score: 0.7560 - val_loss: 0.4041 - val_precision: 0.9444 - val_recall: 0.5667 - val_f1_score: 0.7083\n",
            "Epoch 373/2000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.3739 - precision: 0.9726 - recall: 0.6167 - f1_score: 0.7539 - val_loss: 0.4038 - val_precision: 0.9444 - val_recall: 0.5667 - val_f1_score: 0.7083\n",
            "Epoch 374/2000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.3737 - precision: 0.9781 - recall: 0.6133 - f1_score: 0.7531 - val_loss: 0.4039 - val_precision: 0.9444 - val_recall: 0.5667 - val_f1_score: 0.7083\n",
            "Epoch 375/2000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.3734 - precision: 0.9746 - recall: 0.6133 - f1_score: 0.7523 - val_loss: 0.4035 - val_precision: 0.9444 - val_recall: 0.5667 - val_f1_score: 0.7083\n",
            "Epoch 376/2000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.3728 - precision: 0.9675 - recall: 0.6133 - f1_score: 0.7497 - val_loss: 0.4027 - val_precision: 0.9444 - val_recall: 0.5667 - val_f1_score: 0.7083\n",
            "Epoch 377/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.3732 - precision: 0.9739 - recall: 0.6167 - f1_score: 0.7524 - val_loss: 0.4026 - val_precision: 0.9444 - val_recall: 0.5667 - val_f1_score: 0.7083\n",
            "Epoch 378/2000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.3723 - precision: 0.9799 - recall: 0.6200 - f1_score: 0.7583 - val_loss: 0.4022 - val_precision: 0.9444 - val_recall: 0.5667 - val_f1_score: 0.7083\n",
            "Epoch 379/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.3721 - precision: 0.9698 - recall: 0.6233 - f1_score: 0.7573 - val_loss: 0.4019 - val_precision: 0.9444 - val_recall: 0.5667 - val_f1_score: 0.7083\n",
            "Epoch 380/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.3716 - precision: 0.9735 - recall: 0.6233 - f1_score: 0.7594 - val_loss: 0.4016 - val_precision: 0.9444 - val_recall: 0.5667 - val_f1_score: 0.7083\n",
            "Epoch 381/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.3714 - precision: 0.9792 - recall: 0.6233 - f1_score: 0.7602 - val_loss: 0.4010 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 382/2000\n",
            "300/300 [==============================] - 0s 116us/step - loss: 0.3710 - precision: 0.9748 - recall: 0.6233 - f1_score: 0.7600 - val_loss: 0.4004 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 383/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.3708 - precision: 0.9780 - recall: 0.6233 - f1_score: 0.7598 - val_loss: 0.4000 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 384/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.3704 - precision: 0.9780 - recall: 0.6200 - f1_score: 0.7537 - val_loss: 0.4002 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 385/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.3701 - precision: 0.9797 - recall: 0.6167 - f1_score: 0.7556 - val_loss: 0.3999 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 386/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.3696 - precision: 0.9747 - recall: 0.6233 - f1_score: 0.7586 - val_loss: 0.3991 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 387/2000\n",
            "300/300 [==============================] - 0s 82us/step - loss: 0.3694 - precision: 0.9783 - recall: 0.6200 - f1_score: 0.7583 - val_loss: 0.3988 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 388/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.3691 - precision: 0.9788 - recall: 0.6200 - f1_score: 0.7580 - val_loss: 0.3989 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 389/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.3687 - precision: 0.9793 - recall: 0.6233 - f1_score: 0.7607 - val_loss: 0.3987 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 390/2000\n",
            "300/300 [==============================] - 0s 116us/step - loss: 0.3685 - precision: 0.9791 - recall: 0.6200 - f1_score: 0.7591 - val_loss: 0.3981 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 391/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.3682 - precision: 0.9786 - recall: 0.6233 - f1_score: 0.7609 - val_loss: 0.3977 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 392/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.3676 - precision: 0.9790 - recall: 0.6233 - f1_score: 0.7615 - val_loss: 0.3973 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 393/2000\n",
            "300/300 [==============================] - 0s 119us/step - loss: 0.3675 - precision: 0.9812 - recall: 0.6267 - f1_score: 0.7627 - val_loss: 0.3973 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 394/2000\n",
            "300/300 [==============================] - 0s 105us/step - loss: 0.3671 - precision: 0.9804 - recall: 0.6267 - f1_score: 0.7627 - val_loss: 0.3971 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 395/2000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.3667 - precision: 0.9798 - recall: 0.6267 - f1_score: 0.7630 - val_loss: 0.3971 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 396/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.3665 - precision: 0.9803 - recall: 0.6267 - f1_score: 0.7635 - val_loss: 0.3965 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 397/2000\n",
            "300/300 [==============================] - 0s 82us/step - loss: 0.3662 - precision: 0.9779 - recall: 0.6233 - f1_score: 0.7594 - val_loss: 0.3961 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 398/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.3658 - precision: 0.9803 - recall: 0.6267 - f1_score: 0.7631 - val_loss: 0.3956 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 399/2000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.3656 - precision: 0.9786 - recall: 0.6233 - f1_score: 0.7612 - val_loss: 0.3956 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 400/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.3652 - precision: 0.9794 - recall: 0.6233 - f1_score: 0.7612 - val_loss: 0.3953 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 401/2000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.3650 - precision: 0.9777 - recall: 0.6267 - f1_score: 0.7631 - val_loss: 0.3951 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 402/2000\n",
            "300/300 [==============================] - 0s 102us/step - loss: 0.3646 - precision: 0.9790 - recall: 0.6200 - f1_score: 0.7585 - val_loss: 0.3944 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 403/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.3644 - precision: 0.9789 - recall: 0.6300 - f1_score: 0.7654 - val_loss: 0.3938 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 404/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.3639 - precision: 0.9793 - recall: 0.6267 - f1_score: 0.7628 - val_loss: 0.3934 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 405/2000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.3637 - precision: 0.9773 - recall: 0.6267 - f1_score: 0.7624 - val_loss: 0.3932 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 406/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.3633 - precision: 0.9772 - recall: 0.6267 - f1_score: 0.7627 - val_loss: 0.3932 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 407/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.3630 - precision: 0.9790 - recall: 0.6267 - f1_score: 0.7625 - val_loss: 0.3929 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 408/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.3629 - precision: 0.9791 - recall: 0.6300 - f1_score: 0.7660 - val_loss: 0.3929 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 409/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.3626 - precision: 0.9800 - recall: 0.6300 - f1_score: 0.7652 - val_loss: 0.3931 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 410/2000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.3621 - precision: 0.9799 - recall: 0.6300 - f1_score: 0.7660 - val_loss: 0.3930 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 411/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.3617 - precision: 0.9796 - recall: 0.6267 - f1_score: 0.7626 - val_loss: 0.3922 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 412/2000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.3616 - precision: 0.9794 - recall: 0.6267 - f1_score: 0.7629 - val_loss: 0.3916 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 413/2000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.3613 - precision: 0.9788 - recall: 0.6300 - f1_score: 0.7661 - val_loss: 0.3914 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 414/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.3609 - precision: 0.9792 - recall: 0.6300 - f1_score: 0.7662 - val_loss: 0.3909 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 415/2000\n",
            "300/300 [==============================] - 0s 109us/step - loss: 0.3606 - precision: 0.9812 - recall: 0.6300 - f1_score: 0.7662 - val_loss: 0.3905 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 416/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.3607 - precision: 0.9735 - recall: 0.6300 - f1_score: 0.7631 - val_loss: 0.3900 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 417/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.3600 - precision: 0.9841 - recall: 0.6300 - f1_score: 0.7679 - val_loss: 0.3899 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 418/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.3596 - precision: 0.9786 - recall: 0.6333 - f1_score: 0.7684 - val_loss: 0.3896 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 419/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.3596 - precision: 0.9835 - recall: 0.6300 - f1_score: 0.7669 - val_loss: 0.3898 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 420/2000\n",
            "300/300 [==============================] - 0s 118us/step - loss: 0.3592 - precision: 0.9782 - recall: 0.6267 - f1_score: 0.7621 - val_loss: 0.3891 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 421/2000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.3591 - precision: 0.9792 - recall: 0.6267 - f1_score: 0.7628 - val_loss: 0.3887 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 422/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.3586 - precision: 0.9790 - recall: 0.6300 - f1_score: 0.7648 - val_loss: 0.3886 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 423/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.3582 - precision: 0.9802 - recall: 0.6333 - f1_score: 0.7661 - val_loss: 0.3886 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 424/2000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.3581 - precision: 0.9805 - recall: 0.6300 - f1_score: 0.7648 - val_loss: 0.3883 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 425/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.3577 - precision: 0.9801 - recall: 0.6300 - f1_score: 0.7660 - val_loss: 0.3878 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 426/2000\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.3573 - precision: 0.9771 - recall: 0.6333 - f1_score: 0.7665 - val_loss: 0.3874 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 427/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.3572 - precision: 0.9802 - recall: 0.6333 - f1_score: 0.7684 - val_loss: 0.3876 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 428/2000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.3567 - precision: 0.9793 - recall: 0.6300 - f1_score: 0.7636 - val_loss: 0.3872 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 429/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.3565 - precision: 0.9849 - recall: 0.6300 - f1_score: 0.7666 - val_loss: 0.3873 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 430/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.3562 - precision: 0.9786 - recall: 0.6300 - f1_score: 0.7657 - val_loss: 0.3870 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 431/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.3558 - precision: 0.9796 - recall: 0.6300 - f1_score: 0.7667 - val_loss: 0.3867 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 432/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.3555 - precision: 0.9795 - recall: 0.6333 - f1_score: 0.7687 - val_loss: 0.3864 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 433/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.3554 - precision: 0.9789 - recall: 0.6333 - f1_score: 0.7677 - val_loss: 0.3863 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 434/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.3551 - precision: 0.9796 - recall: 0.6300 - f1_score: 0.7665 - val_loss: 0.3860 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 435/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.3551 - precision: 0.9775 - recall: 0.6300 - f1_score: 0.7649 - val_loss: 0.3856 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 436/2000\n",
            "300/300 [==============================] - 0s 101us/step - loss: 0.3545 - precision: 0.9849 - recall: 0.6333 - f1_score: 0.7706 - val_loss: 0.3858 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 437/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.3542 - precision: 0.9770 - recall: 0.6267 - f1_score: 0.7622 - val_loss: 0.3852 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 438/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.3538 - precision: 0.9794 - recall: 0.6300 - f1_score: 0.7663 - val_loss: 0.3846 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 439/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.3537 - precision: 0.9803 - recall: 0.6333 - f1_score: 0.7685 - val_loss: 0.3846 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 440/2000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.3540 - precision: 0.9730 - recall: 0.6300 - f1_score: 0.7624 - val_loss: 0.3840 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 441/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.3530 - precision: 0.9789 - recall: 0.6333 - f1_score: 0.7687 - val_loss: 0.3836 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 442/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.3527 - precision: 0.9782 - recall: 0.6333 - f1_score: 0.7679 - val_loss: 0.3833 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 443/2000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.3525 - precision: 0.9793 - recall: 0.6333 - f1_score: 0.7687 - val_loss: 0.3828 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 444/2000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.3521 - precision: 0.9840 - recall: 0.6333 - f1_score: 0.7700 - val_loss: 0.3828 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 445/2000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.3521 - precision: 0.9781 - recall: 0.6333 - f1_score: 0.7674 - val_loss: 0.3827 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 446/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.3515 - precision: 0.9784 - recall: 0.6333 - f1_score: 0.7666 - val_loss: 0.3823 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 447/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.3515 - precision: 0.9843 - recall: 0.6333 - f1_score: 0.7700 - val_loss: 0.3820 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 448/2000\n",
            "300/300 [==============================] - 0s 103us/step - loss: 0.3510 - precision: 0.9798 - recall: 0.6333 - f1_score: 0.7691 - val_loss: 0.3814 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 449/2000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.3507 - precision: 0.9894 - recall: 0.6333 - f1_score: 0.7700 - val_loss: 0.3814 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 450/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.3505 - precision: 0.9802 - recall: 0.6333 - f1_score: 0.7654 - val_loss: 0.3811 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 451/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.3506 - precision: 0.9783 - recall: 0.6333 - f1_score: 0.7660 - val_loss: 0.3807 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 452/2000\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.3502 - precision: 0.9806 - recall: 0.6333 - f1_score: 0.7685 - val_loss: 0.3805 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 453/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.3498 - precision: 0.9789 - recall: 0.6300 - f1_score: 0.7663 - val_loss: 0.3802 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 454/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.3495 - precision: 0.9844 - recall: 0.6333 - f1_score: 0.7696 - val_loss: 0.3801 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 455/2000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.3491 - precision: 0.9792 - recall: 0.6333 - f1_score: 0.7689 - val_loss: 0.3794 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 456/2000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.3490 - precision: 0.9954 - recall: 0.6367 - f1_score: 0.7753 - val_loss: 0.3799 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 457/2000\n",
            "300/300 [==============================] - 0s 103us/step - loss: 0.3486 - precision: 0.9791 - recall: 0.6333 - f1_score: 0.7687 - val_loss: 0.3795 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 458/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.3483 - precision: 0.9842 - recall: 0.6333 - f1_score: 0.7706 - val_loss: 0.3793 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 459/2000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.3481 - precision: 0.9796 - recall: 0.6333 - f1_score: 0.7685 - val_loss: 0.3791 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 460/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.3477 - precision: 0.9952 - recall: 0.6333 - f1_score: 0.7731 - val_loss: 0.3791 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 461/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.3476 - precision: 0.9801 - recall: 0.6333 - f1_score: 0.7683 - val_loss: 0.3792 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 462/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.3475 - precision: 0.9817 - recall: 0.6333 - f1_score: 0.7670 - val_loss: 0.3784 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 463/2000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.3472 - precision: 0.9806 - recall: 0.6333 - f1_score: 0.7671 - val_loss: 0.3782 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 464/2000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.3467 - precision: 0.9802 - recall: 0.6333 - f1_score: 0.7687 - val_loss: 0.3780 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 465/2000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.3464 - precision: 0.9947 - recall: 0.6333 - f1_score: 0.7736 - val_loss: 0.3781 - val_precision: 0.9714 - val_recall: 0.5667 - val_f1_score: 0.7158\n",
            "Epoch 466/2000\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.3463 - precision: 0.9800 - recall: 0.6300 - f1_score: 0.7663 - val_loss: 0.3775 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 467/2000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.3459 - precision: 0.9789 - recall: 0.6333 - f1_score: 0.7690 - val_loss: 0.3772 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 468/2000\n",
            "300/300 [==============================] - 0s 81us/step - loss: 0.3456 - precision: 0.9777 - recall: 0.6333 - f1_score: 0.7666 - val_loss: 0.3766 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 469/2000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.3454 - precision: 0.9955 - recall: 0.6367 - f1_score: 0.7747 - val_loss: 0.3769 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 470/2000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.3451 - precision: 0.9788 - recall: 0.6333 - f1_score: 0.7672 - val_loss: 0.3762 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 471/2000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.3454 - precision: 0.9849 - recall: 0.6333 - f1_score: 0.7700 - val_loss: 0.3759 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 472/2000\n",
            "300/300 [==============================] - 0s 102us/step - loss: 0.3445 - precision: 0.9836 - recall: 0.6333 - f1_score: 0.7692 - val_loss: 0.3755 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 473/2000\n",
            "300/300 [==============================] - 0s 82us/step - loss: 0.3442 - precision: 0.9848 - recall: 0.6367 - f1_score: 0.7732 - val_loss: 0.3751 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 474/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.3441 - precision: 0.9789 - recall: 0.6333 - f1_score: 0.7677 - val_loss: 0.3749 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 475/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.3438 - precision: 0.9850 - recall: 0.6367 - f1_score: 0.7731 - val_loss: 0.3748 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 476/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.3435 - precision: 0.9792 - recall: 0.6333 - f1_score: 0.7689 - val_loss: 0.3744 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 477/2000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.3433 - precision: 0.9899 - recall: 0.6367 - f1_score: 0.7741 - val_loss: 0.3743 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 478/2000\n",
            "300/300 [==============================] - 0s 102us/step - loss: 0.3430 - precision: 0.9893 - recall: 0.6367 - f1_score: 0.7738 - val_loss: 0.3740 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 479/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.3430 - precision: 0.9941 - recall: 0.6367 - f1_score: 0.7735 - val_loss: 0.3742 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 480/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.3427 - precision: 0.9792 - recall: 0.6367 - f1_score: 0.7699 - val_loss: 0.3736 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 481/2000\n",
            "300/300 [==============================] - 0s 107us/step - loss: 0.3422 - precision: 0.9843 - recall: 0.6333 - f1_score: 0.7697 - val_loss: 0.3729 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 482/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.3421 - precision: 0.9953 - recall: 0.6467 - f1_score: 0.7834 - val_loss: 0.3733 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 483/2000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.3417 - precision: 0.9854 - recall: 0.6333 - f1_score: 0.7704 - val_loss: 0.3727 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 484/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.3416 - precision: 0.9891 - recall: 0.6333 - f1_score: 0.7708 - val_loss: 0.3723 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 485/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.3413 - precision: 0.9893 - recall: 0.6400 - f1_score: 0.7768 - val_loss: 0.3720 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 486/2000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.3413 - precision: 0.9950 - recall: 0.6400 - f1_score: 0.7763 - val_loss: 0.3719 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 487/2000\n",
            "300/300 [==============================] - 0s 81us/step - loss: 0.3407 - precision: 0.9945 - recall: 0.6367 - f1_score: 0.7758 - val_loss: 0.3718 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 488/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.3404 - precision: 0.9942 - recall: 0.6367 - f1_score: 0.7753 - val_loss: 0.3719 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 489/2000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.3401 - precision: 0.9854 - recall: 0.6333 - f1_score: 0.7698 - val_loss: 0.3711 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 490/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.3399 - precision: 0.9947 - recall: 0.6367 - f1_score: 0.7756 - val_loss: 0.3709 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 491/2000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.3396 - precision: 0.9948 - recall: 0.6400 - f1_score: 0.7770 - val_loss: 0.3707 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 492/2000\n",
            "300/300 [==============================] - 0s 82us/step - loss: 0.3395 - precision: 0.9949 - recall: 0.6400 - f1_score: 0.7788 - val_loss: 0.3704 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 493/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.3396 - precision: 0.9885 - recall: 0.6367 - f1_score: 0.7700 - val_loss: 0.3699 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 494/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.3390 - precision: 0.9945 - recall: 0.6367 - f1_score: 0.7744 - val_loss: 0.3699 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 495/2000\n",
            "300/300 [==============================] - 0s 79us/step - loss: 0.3386 - precision: 0.9952 - recall: 0.6367 - f1_score: 0.7740 - val_loss: 0.3700 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 496/2000\n",
            "300/300 [==============================] - 0s 108us/step - loss: 0.3384 - precision: 0.9890 - recall: 0.6400 - f1_score: 0.7750 - val_loss: 0.3698 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 497/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.3384 - precision: 0.9951 - recall: 0.6400 - f1_score: 0.7748 - val_loss: 0.3695 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 498/2000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.3382 - precision: 0.9947 - recall: 0.6367 - f1_score: 0.7706 - val_loss: 0.3692 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 499/2000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.3377 - precision: 0.9950 - recall: 0.6367 - f1_score: 0.7734 - val_loss: 0.3689 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 500/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.3374 - precision: 0.9933 - recall: 0.6400 - f1_score: 0.7751 - val_loss: 0.3684 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 501/2000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.3371 - precision: 0.9949 - recall: 0.6400 - f1_score: 0.7788 - val_loss: 0.3680 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 502/2000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.3369 - precision: 0.9949 - recall: 0.6400 - f1_score: 0.7787 - val_loss: 0.3679 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 503/2000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.3369 - precision: 0.9949 - recall: 0.6400 - f1_score: 0.7783 - val_loss: 0.3677 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 504/2000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.3367 - precision: 0.9947 - recall: 0.6433 - f1_score: 0.7807 - val_loss: 0.3675 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 505/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.3362 - precision: 0.9954 - recall: 0.6400 - f1_score: 0.7763 - val_loss: 0.3672 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 506/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.3360 - precision: 0.9891 - recall: 0.6367 - f1_score: 0.7726 - val_loss: 0.3670 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 507/2000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.3356 - precision: 0.9950 - recall: 0.6400 - f1_score: 0.7787 - val_loss: 0.3666 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 508/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.3354 - precision: 0.9952 - recall: 0.6433 - f1_score: 0.7803 - val_loss: 0.3664 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 509/2000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.3354 - precision: 0.9951 - recall: 0.6433 - f1_score: 0.7809 - val_loss: 0.3661 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 510/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.3349 - precision: 0.9953 - recall: 0.6400 - f1_score: 0.7762 - val_loss: 0.3658 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 511/2000\n",
            "300/300 [==============================] - 0s 104us/step - loss: 0.3347 - precision: 0.9947 - recall: 0.6467 - f1_score: 0.7834 - val_loss: 0.3656 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 512/2000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.3345 - precision: 0.9947 - recall: 0.6400 - f1_score: 0.7783 - val_loss: 0.3652 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 513/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.3344 - precision: 0.9954 - recall: 0.6467 - f1_score: 0.7830 - val_loss: 0.3650 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 514/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.3339 - precision: 0.9949 - recall: 0.6433 - f1_score: 0.7812 - val_loss: 0.3646 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 515/2000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.3337 - precision: 0.9955 - recall: 0.6433 - f1_score: 0.7800 - val_loss: 0.3646 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 516/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.3335 - precision: 0.9956 - recall: 0.6467 - f1_score: 0.7819 - val_loss: 0.3645 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 517/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.3334 - precision: 0.9947 - recall: 0.6467 - f1_score: 0.7831 - val_loss: 0.3643 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 518/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.3331 - precision: 0.9957 - recall: 0.6433 - f1_score: 0.7769 - val_loss: 0.3641 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 519/2000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.3328 - precision: 0.9949 - recall: 0.6467 - f1_score: 0.7827 - val_loss: 0.3640 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 520/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.3327 - precision: 0.9949 - recall: 0.6533 - f1_score: 0.7886 - val_loss: 0.3641 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 521/2000\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.3323 - precision: 0.9949 - recall: 0.6500 - f1_score: 0.7861 - val_loss: 0.3639 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 522/2000\n",
            "300/300 [==============================] - 0s 82us/step - loss: 0.3321 - precision: 0.9947 - recall: 0.6467 - f1_score: 0.7828 - val_loss: 0.3637 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 523/2000\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.3319 - precision: 0.9947 - recall: 0.6467 - f1_score: 0.7837 - val_loss: 0.3637 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 524/2000\n",
            "300/300 [==============================] - 0s 124us/step - loss: 0.3318 - precision: 0.9949 - recall: 0.6467 - f1_score: 0.7829 - val_loss: 0.3633 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 525/2000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.3313 - precision: 0.9955 - recall: 0.6400 - f1_score: 0.7775 - val_loss: 0.3631 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 526/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.3310 - precision: 0.9945 - recall: 0.6400 - f1_score: 0.7785 - val_loss: 0.3626 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 527/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.3312 - precision: 0.9797 - recall: 0.6400 - f1_score: 0.7732 - val_loss: 0.3622 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 528/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.3306 - precision: 0.9946 - recall: 0.6467 - f1_score: 0.7833 - val_loss: 0.3621 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 529/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.3305 - precision: 0.9950 - recall: 0.6467 - f1_score: 0.7832 - val_loss: 0.3623 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 530/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.3301 - precision: 0.9945 - recall: 0.6400 - f1_score: 0.7771 - val_loss: 0.3619 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 531/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.3303 - precision: 0.9900 - recall: 0.6367 - f1_score: 0.7737 - val_loss: 0.3613 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 532/2000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.3297 - precision: 0.9948 - recall: 0.6500 - f1_score: 0.7862 - val_loss: 0.3607 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 533/2000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.3295 - precision: 0.9955 - recall: 0.6467 - f1_score: 0.7828 - val_loss: 0.3602 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 534/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.3293 - precision: 0.9941 - recall: 0.6467 - f1_score: 0.7795 - val_loss: 0.3600 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 535/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.3293 - precision: 1.0000 - recall: 0.6533 - f1_score: 0.7882 - val_loss: 0.3600 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 536/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.3287 - precision: 1.0000 - recall: 0.6567 - f1_score: 0.7919 - val_loss: 0.3601 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 537/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.3288 - precision: 0.9937 - recall: 0.6400 - f1_score: 0.7764 - val_loss: 0.3596 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 538/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.3285 - precision: 0.9949 - recall: 0.6533 - f1_score: 0.7876 - val_loss: 0.3594 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 539/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.3280 - precision: 0.9949 - recall: 0.6533 - f1_score: 0.7879 - val_loss: 0.3592 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 540/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.3279 - precision: 0.9947 - recall: 0.6500 - f1_score: 0.7841 - val_loss: 0.3593 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 541/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.3279 - precision: 0.9950 - recall: 0.6533 - f1_score: 0.7872 - val_loss: 0.3587 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 542/2000\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.3274 - precision: 0.9953 - recall: 0.6500 - f1_score: 0.7845 - val_loss: 0.3585 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 543/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.3275 - precision: 0.9951 - recall: 0.6533 - f1_score: 0.7886 - val_loss: 0.3584 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 544/2000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.3271 - precision: 0.9947 - recall: 0.6533 - f1_score: 0.7876 - val_loss: 0.3583 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 545/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.3269 - precision: 0.9952 - recall: 0.6500 - f1_score: 0.7847 - val_loss: 0.3580 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 546/2000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.3266 - precision: 0.9952 - recall: 0.6533 - f1_score: 0.7886 - val_loss: 0.3574 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 547/2000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.3262 - precision: 0.9956 - recall: 0.6533 - f1_score: 0.7872 - val_loss: 0.3571 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 548/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.3263 - precision: 0.9951 - recall: 0.6567 - f1_score: 0.7904 - val_loss: 0.3571 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 549/2000\n",
            "300/300 [==============================] - 0s 81us/step - loss: 0.3257 - precision: 0.9947 - recall: 0.6500 - f1_score: 0.7859 - val_loss: 0.3569 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 550/2000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.3255 - precision: 0.9953 - recall: 0.6533 - f1_score: 0.7882 - val_loss: 0.3567 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 551/2000\n",
            "300/300 [==============================] - 0s 82us/step - loss: 0.3254 - precision: 0.9957 - recall: 0.6533 - f1_score: 0.7851 - val_loss: 0.3564 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 552/2000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.3251 - precision: 0.9944 - recall: 0.6600 - f1_score: 0.7919 - val_loss: 0.3563 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 553/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.3249 - precision: 0.9953 - recall: 0.6533 - f1_score: 0.7883 - val_loss: 0.3558 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 554/2000\n",
            "300/300 [==============================] - 0s 108us/step - loss: 0.3246 - precision: 1.0000 - recall: 0.6567 - f1_score: 0.7908 - val_loss: 0.3557 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 555/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.3244 - precision: 0.9958 - recall: 0.6533 - f1_score: 0.7864 - val_loss: 0.3553 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 556/2000\n",
            "300/300 [==============================] - 0s 81us/step - loss: 0.3242 - precision: 0.9952 - recall: 0.6533 - f1_score: 0.7880 - val_loss: 0.3551 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 557/2000\n",
            "300/300 [==============================] - 0s 80us/step - loss: 0.3240 - precision: 0.9952 - recall: 0.6567 - f1_score: 0.7906 - val_loss: 0.3548 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 558/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.3237 - precision: 1.0000 - recall: 0.6600 - f1_score: 0.7944 - val_loss: 0.3547 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 559/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.3237 - precision: 1.0000 - recall: 0.6567 - f1_score: 0.7903 - val_loss: 0.3551 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 560/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.3234 - precision: 0.9942 - recall: 0.6500 - f1_score: 0.7850 - val_loss: 0.3546 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 561/2000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.3234 - precision: 0.9952 - recall: 0.6600 - f1_score: 0.7933 - val_loss: 0.3545 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 562/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.3231 - precision: 0.9954 - recall: 0.6500 - f1_score: 0.7855 - val_loss: 0.3542 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 563/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.3228 - precision: 0.9953 - recall: 0.6600 - f1_score: 0.7929 - val_loss: 0.3542 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 564/2000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.3224 - precision: 0.9941 - recall: 0.6533 - f1_score: 0.7868 - val_loss: 0.3538 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 565/2000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.3222 - precision: 0.9948 - recall: 0.6600 - f1_score: 0.7925 - val_loss: 0.3533 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 566/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.3221 - precision: 0.9954 - recall: 0.6567 - f1_score: 0.7901 - val_loss: 0.3533 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 567/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.3218 - precision: 1.0000 - recall: 0.6567 - f1_score: 0.7911 - val_loss: 0.3532 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 568/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.3219 - precision: 0.9950 - recall: 0.6600 - f1_score: 0.7930 - val_loss: 0.3530 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 569/2000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.3222 - precision: 0.9955 - recall: 0.6567 - f1_score: 0.7883 - val_loss: 0.3526 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 570/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.3212 - precision: 0.9950 - recall: 0.6633 - f1_score: 0.7954 - val_loss: 0.3524 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 571/2000\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.3209 - precision: 0.9955 - recall: 0.6567 - f1_score: 0.7904 - val_loss: 0.3521 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 572/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.3206 - precision: 0.9950 - recall: 0.6600 - f1_score: 0.7918 - val_loss: 0.3520 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 573/2000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.3205 - precision: 0.9954 - recall: 0.6567 - f1_score: 0.7905 - val_loss: 0.3518 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 574/2000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.3203 - precision: 0.9956 - recall: 0.6600 - f1_score: 0.7923 - val_loss: 0.3513 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 575/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.3200 - precision: 1.0000 - recall: 0.6600 - f1_score: 0.7946 - val_loss: 0.3514 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 576/2000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.3199 - precision: 0.9949 - recall: 0.6567 - f1_score: 0.7904 - val_loss: 0.3510 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 577/2000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.3196 - precision: 0.9950 - recall: 0.6600 - f1_score: 0.7910 - val_loss: 0.3508 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 578/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.3195 - precision: 0.9947 - recall: 0.6600 - f1_score: 0.7928 - val_loss: 0.3506 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 579/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.3192 - precision: 0.9954 - recall: 0.6567 - f1_score: 0.7893 - val_loss: 0.3501 - val_precision: 1.0000 - val_recall: 0.5833 - val_f1_score: 0.7368\n",
            "Epoch 580/2000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.3189 - precision: 1.0000 - recall: 0.6600 - f1_score: 0.7947 - val_loss: 0.3499 - val_precision: 1.0000 - val_recall: 0.5833 - val_f1_score: 0.7368\n",
            "Epoch 581/2000\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.3187 - precision: 1.0000 - recall: 0.6600 - f1_score: 0.7941 - val_loss: 0.3497 - val_precision: 1.0000 - val_recall: 0.5833 - val_f1_score: 0.7368\n",
            "Epoch 582/2000\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.3185 - precision: 1.0000 - recall: 0.6600 - f1_score: 0.7945 - val_loss: 0.3495 - val_precision: 1.0000 - val_recall: 0.5833 - val_f1_score: 0.7368\n",
            "Epoch 583/2000\n",
            "300/300 [==============================] - 0s 108us/step - loss: 0.3184 - precision: 1.0000 - recall: 0.6600 - f1_score: 0.7941 - val_loss: 0.3493 - val_precision: 1.0000 - val_recall: 0.5833 - val_f1_score: 0.7368\n",
            "Epoch 584/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.3181 - precision: 1.0000 - recall: 0.6600 - f1_score: 0.7939 - val_loss: 0.3494 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 585/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.3179 - precision: 1.0000 - recall: 0.6600 - f1_score: 0.7942 - val_loss: 0.3492 - val_precision: 1.0000 - val_recall: 0.5833 - val_f1_score: 0.7368\n",
            "Epoch 586/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.3181 - precision: 1.0000 - recall: 0.6567 - f1_score: 0.7924 - val_loss: 0.3492 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 587/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.3177 - precision: 1.0000 - recall: 0.6600 - f1_score: 0.7951 - val_loss: 0.3495 - val_precision: 1.0000 - val_recall: 0.5833 - val_f1_score: 0.7368\n",
            "Epoch 588/2000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.3174 - precision: 0.9954 - recall: 0.6600 - f1_score: 0.7929 - val_loss: 0.3488 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 589/2000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.3171 - precision: 1.0000 - recall: 0.6600 - f1_score: 0.7938 - val_loss: 0.3487 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 590/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.3171 - precision: 1.0000 - recall: 0.6600 - f1_score: 0.7945 - val_loss: 0.3488 - val_precision: 1.0000 - val_recall: 0.5833 - val_f1_score: 0.7368\n",
            "Epoch 591/2000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.3166 - precision: 1.0000 - recall: 0.6633 - f1_score: 0.7960 - val_loss: 0.3486 - val_precision: 1.0000 - val_recall: 0.5833 - val_f1_score: 0.7368\n",
            "Epoch 592/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.3167 - precision: 0.9950 - recall: 0.6633 - f1_score: 0.7941 - val_loss: 0.3477 - val_precision: 1.0000 - val_recall: 0.5833 - val_f1_score: 0.7368\n",
            "Epoch 593/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.3162 - precision: 1.0000 - recall: 0.6633 - f1_score: 0.7970 - val_loss: 0.3473 - val_precision: 1.0000 - val_recall: 0.5833 - val_f1_score: 0.7368\n",
            "Epoch 594/2000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.3161 - precision: 1.0000 - recall: 0.6633 - f1_score: 0.7949 - val_loss: 0.3468 - val_precision: 1.0000 - val_recall: 0.5833 - val_f1_score: 0.7368\n",
            "Epoch 595/2000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.3162 - precision: 1.0000 - recall: 0.6633 - f1_score: 0.7967 - val_loss: 0.3465 - val_precision: 1.0000 - val_recall: 0.5833 - val_f1_score: 0.7368\n",
            "Epoch 596/2000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.3156 - precision: 1.0000 - recall: 0.6600 - f1_score: 0.7940 - val_loss: 0.3465 - val_precision: 1.0000 - val_recall: 0.5833 - val_f1_score: 0.7368\n",
            "Epoch 597/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.3155 - precision: 1.0000 - recall: 0.6667 - f1_score: 0.7985 - val_loss: 0.3467 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 598/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.3151 - precision: 1.0000 - recall: 0.6667 - f1_score: 0.7989 - val_loss: 0.3464 - val_precision: 1.0000 - val_recall: 0.5667 - val_f1_score: 0.7234\n",
            "Epoch 599/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.3153 - precision: 1.0000 - recall: 0.6600 - f1_score: 0.7930 - val_loss: 0.3460 - val_precision: 1.0000 - val_recall: 0.5833 - val_f1_score: 0.7368\n",
            "Epoch 600/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.3151 - precision: 1.0000 - recall: 0.6633 - f1_score: 0.7962 - val_loss: 0.3457 - val_precision: 1.0000 - val_recall: 0.5833 - val_f1_score: 0.7368\n",
            "Epoch 601/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.3145 - precision: 1.0000 - recall: 0.6633 - f1_score: 0.7970 - val_loss: 0.3455 - val_precision: 1.0000 - val_recall: 0.5833 - val_f1_score: 0.7368\n",
            "Epoch 602/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.3144 - precision: 1.0000 - recall: 0.6633 - f1_score: 0.7963 - val_loss: 0.3453 - val_precision: 1.0000 - val_recall: 0.5833 - val_f1_score: 0.7368\n",
            "Epoch 603/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.3143 - precision: 1.0000 - recall: 0.6733 - f1_score: 0.8023 - val_loss: 0.3455 - val_precision: 1.0000 - val_recall: 0.5833 - val_f1_score: 0.7368\n",
            "Epoch 604/2000\n",
            "300/300 [==============================] - 0s 115us/step - loss: 0.3140 - precision: 1.0000 - recall: 0.6600 - f1_score: 0.7935 - val_loss: 0.3451 - val_precision: 1.0000 - val_recall: 0.5833 - val_f1_score: 0.7368\n",
            "Epoch 605/2000\n",
            "300/300 [==============================] - 0s 104us/step - loss: 0.3138 - precision: 1.0000 - recall: 0.6633 - f1_score: 0.7971 - val_loss: 0.3447 - val_precision: 1.0000 - val_recall: 0.5833 - val_f1_score: 0.7368\n",
            "Epoch 606/2000\n",
            "300/300 [==============================] - 0s 112us/step - loss: 0.3140 - precision: 1.0000 - recall: 0.6667 - f1_score: 0.7995 - val_loss: 0.3444 - val_precision: 1.0000 - val_recall: 0.5833 - val_f1_score: 0.7368\n",
            "Epoch 607/2000\n",
            "300/300 [==============================] - 0s 102us/step - loss: 0.3134 - precision: 1.0000 - recall: 0.6667 - f1_score: 0.7990 - val_loss: 0.3439 - val_precision: 1.0000 - val_recall: 0.6000 - val_f1_score: 0.7500\n",
            "Epoch 608/2000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.3132 - precision: 1.0000 - recall: 0.6667 - f1_score: 0.7988 - val_loss: 0.3439 - val_precision: 1.0000 - val_recall: 0.5833 - val_f1_score: 0.7368\n",
            "Epoch 609/2000\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.3131 - precision: 1.0000 - recall: 0.6633 - f1_score: 0.7941 - val_loss: 0.3438 - val_precision: 1.0000 - val_recall: 0.5833 - val_f1_score: 0.7368\n",
            "Epoch 610/2000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.3128 - precision: 1.0000 - recall: 0.6700 - f1_score: 0.8011 - val_loss: 0.3437 - val_precision: 1.0000 - val_recall: 0.5833 - val_f1_score: 0.7368\n",
            "Epoch 611/2000\n",
            "300/300 [==============================] - 0s 128us/step - loss: 0.3126 - precision: 1.0000 - recall: 0.6633 - f1_score: 0.7964 - val_loss: 0.3433 - val_precision: 1.0000 - val_recall: 0.6000 - val_f1_score: 0.7500\n",
            "Epoch 612/2000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.3123 - precision: 1.0000 - recall: 0.6733 - f1_score: 0.8043 - val_loss: 0.3432 - val_precision: 1.0000 - val_recall: 0.5833 - val_f1_score: 0.7368\n",
            "Epoch 613/2000\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.3123 - precision: 1.0000 - recall: 0.6733 - f1_score: 0.8047 - val_loss: 0.3431 - val_precision: 1.0000 - val_recall: 0.5833 - val_f1_score: 0.7368\n",
            "Epoch 614/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.3120 - precision: 1.0000 - recall: 0.6667 - f1_score: 0.7982 - val_loss: 0.3427 - val_precision: 1.0000 - val_recall: 0.6000 - val_f1_score: 0.7500\n",
            "Epoch 615/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.3119 - precision: 1.0000 - recall: 0.6700 - f1_score: 0.8021 - val_loss: 0.3427 - val_precision: 1.0000 - val_recall: 0.6000 - val_f1_score: 0.7500\n",
            "Epoch 616/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.3119 - precision: 1.0000 - recall: 0.6700 - f1_score: 0.8021 - val_loss: 0.3422 - val_precision: 1.0000 - val_recall: 0.6167 - val_f1_score: 0.7629\n",
            "Epoch 617/2000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.3114 - precision: 1.0000 - recall: 0.6733 - f1_score: 0.8040 - val_loss: 0.3424 - val_precision: 1.0000 - val_recall: 0.6000 - val_f1_score: 0.7500\n",
            "Epoch 618/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.3113 - precision: 1.0000 - recall: 0.6700 - f1_score: 0.8009 - val_loss: 0.3424 - val_precision: 1.0000 - val_recall: 0.6000 - val_f1_score: 0.7500\n",
            "Epoch 619/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.3117 - precision: 0.9953 - recall: 0.6700 - f1_score: 0.7992 - val_loss: 0.3417 - val_precision: 1.0000 - val_recall: 0.6167 - val_f1_score: 0.7629\n",
            "Epoch 620/2000\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.3109 - precision: 1.0000 - recall: 0.6733 - f1_score: 0.8014 - val_loss: 0.3419 - val_precision: 1.0000 - val_recall: 0.6167 - val_f1_score: 0.7629\n",
            "Epoch 621/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.3108 - precision: 1.0000 - recall: 0.6733 - f1_score: 0.8039 - val_loss: 0.3414 - val_precision: 1.0000 - val_recall: 0.6333 - val_f1_score: 0.7755\n",
            "Epoch 622/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.3105 - precision: 1.0000 - recall: 0.6700 - f1_score: 0.8011 - val_loss: 0.3410 - val_precision: 1.0000 - val_recall: 0.6167 - val_f1_score: 0.7629\n",
            "Epoch 623/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.3105 - precision: 1.0000 - recall: 0.6800 - f1_score: 0.8083 - val_loss: 0.3408 - val_precision: 1.0000 - val_recall: 0.6167 - val_f1_score: 0.7629\n",
            "Epoch 624/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.3100 - precision: 1.0000 - recall: 0.6733 - f1_score: 0.8037 - val_loss: 0.3407 - val_precision: 1.0000 - val_recall: 0.6167 - val_f1_score: 0.7629\n",
            "Epoch 625/2000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.3098 - precision: 1.0000 - recall: 0.6733 - f1_score: 0.8036 - val_loss: 0.3404 - val_precision: 1.0000 - val_recall: 0.6167 - val_f1_score: 0.7629\n",
            "Epoch 626/2000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.3096 - precision: 1.0000 - recall: 0.6733 - f1_score: 0.8031 - val_loss: 0.3401 - val_precision: 1.0000 - val_recall: 0.6167 - val_f1_score: 0.7629\n",
            "Epoch 627/2000\n",
            "300/300 [==============================] - 0s 110us/step - loss: 0.3097 - precision: 1.0000 - recall: 0.6767 - f1_score: 0.8059 - val_loss: 0.3402 - val_precision: 1.0000 - val_recall: 0.6333 - val_f1_score: 0.7755\n",
            "Epoch 628/2000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.3096 - precision: 1.0000 - recall: 0.6733 - f1_score: 0.8027 - val_loss: 0.3396 - val_precision: 1.0000 - val_recall: 0.6167 - val_f1_score: 0.7629\n",
            "Epoch 629/2000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.3091 - precision: 1.0000 - recall: 0.6733 - f1_score: 0.8043 - val_loss: 0.3394 - val_precision: 1.0000 - val_recall: 0.6167 - val_f1_score: 0.7629\n",
            "Epoch 630/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.3089 - precision: 1.0000 - recall: 0.6733 - f1_score: 0.8032 - val_loss: 0.3392 - val_precision: 1.0000 - val_recall: 0.6167 - val_f1_score: 0.7629\n",
            "Epoch 631/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.3086 - precision: 1.0000 - recall: 0.6767 - f1_score: 0.8068 - val_loss: 0.3390 - val_precision: 1.0000 - val_recall: 0.6167 - val_f1_score: 0.7629\n",
            "Epoch 632/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.3084 - precision: 1.0000 - recall: 0.6800 - f1_score: 0.8081 - val_loss: 0.3391 - val_precision: 1.0000 - val_recall: 0.6333 - val_f1_score: 0.7755\n",
            "Epoch 633/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.3083 - precision: 1.0000 - recall: 0.6733 - f1_score: 0.8040 - val_loss: 0.3390 - val_precision: 1.0000 - val_recall: 0.6333 - val_f1_score: 0.7755\n",
            "Epoch 634/2000\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.3080 - precision: 1.0000 - recall: 0.6733 - f1_score: 0.8047 - val_loss: 0.3387 - val_precision: 1.0000 - val_recall: 0.6333 - val_f1_score: 0.7755\n",
            "Epoch 635/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.3079 - precision: 1.0000 - recall: 0.6767 - f1_score: 0.8045 - val_loss: 0.3389 - val_precision: 1.0000 - val_recall: 0.6333 - val_f1_score: 0.7755\n",
            "Epoch 636/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.3076 - precision: 1.0000 - recall: 0.6767 - f1_score: 0.8065 - val_loss: 0.3385 - val_precision: 1.0000 - val_recall: 0.6333 - val_f1_score: 0.7755\n",
            "Epoch 637/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.3075 - precision: 1.0000 - recall: 0.6767 - f1_score: 0.8068 - val_loss: 0.3382 - val_precision: 1.0000 - val_recall: 0.6333 - val_f1_score: 0.7755\n",
            "Epoch 638/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.3075 - precision: 1.0000 - recall: 0.6667 - f1_score: 0.7987 - val_loss: 0.3379 - val_precision: 1.0000 - val_recall: 0.6333 - val_f1_score: 0.7755\n",
            "Epoch 639/2000\n",
            "300/300 [==============================] - 0s 103us/step - loss: 0.3071 - precision: 1.0000 - recall: 0.6800 - f1_score: 0.8072 - val_loss: 0.3376 - val_precision: 1.0000 - val_recall: 0.6333 - val_f1_score: 0.7755\n",
            "Epoch 640/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.3069 - precision: 1.0000 - recall: 0.6767 - f1_score: 0.8047 - val_loss: 0.3373 - val_precision: 1.0000 - val_recall: 0.6333 - val_f1_score: 0.7755\n",
            "Epoch 641/2000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.3066 - precision: 1.0000 - recall: 0.6833 - f1_score: 0.8111 - val_loss: 0.3374 - val_precision: 1.0000 - val_recall: 0.6333 - val_f1_score: 0.7755\n",
            "Epoch 642/2000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.3064 - precision: 1.0000 - recall: 0.6767 - f1_score: 0.8062 - val_loss: 0.3370 - val_precision: 1.0000 - val_recall: 0.6333 - val_f1_score: 0.7755\n",
            "Epoch 643/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.3064 - precision: 1.0000 - recall: 0.6833 - f1_score: 0.8113 - val_loss: 0.3370 - val_precision: 1.0000 - val_recall: 0.6333 - val_f1_score: 0.7755\n",
            "Epoch 644/2000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.3060 - precision: 1.0000 - recall: 0.6767 - f1_score: 0.8046 - val_loss: 0.3369 - val_precision: 1.0000 - val_recall: 0.6333 - val_f1_score: 0.7755\n",
            "Epoch 645/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.3059 - precision: 1.0000 - recall: 0.6800 - f1_score: 0.8083 - val_loss: 0.3366 - val_precision: 1.0000 - val_recall: 0.6333 - val_f1_score: 0.7755\n",
            "Epoch 646/2000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.3057 - precision: 1.0000 - recall: 0.6767 - f1_score: 0.8055 - val_loss: 0.3365 - val_precision: 1.0000 - val_recall: 0.6333 - val_f1_score: 0.7755\n",
            "Epoch 647/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.3055 - precision: 1.0000 - recall: 0.6800 - f1_score: 0.8075 - val_loss: 0.3362 - val_precision: 1.0000 - val_recall: 0.6333 - val_f1_score: 0.7755\n",
            "Epoch 648/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.3054 - precision: 1.0000 - recall: 0.6800 - f1_score: 0.8083 - val_loss: 0.3358 - val_precision: 1.0000 - val_recall: 0.6333 - val_f1_score: 0.7755\n",
            "Epoch 649/2000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.3054 - precision: 1.0000 - recall: 0.6767 - f1_score: 0.8066 - val_loss: 0.3353 - val_precision: 1.0000 - val_recall: 0.6167 - val_f1_score: 0.7629\n",
            "Epoch 650/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.3052 - precision: 1.0000 - recall: 0.6867 - f1_score: 0.8123 - val_loss: 0.3350 - val_precision: 1.0000 - val_recall: 0.6167 - val_f1_score: 0.7629\n",
            "Epoch 651/2000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.3049 - precision: 1.0000 - recall: 0.6900 - f1_score: 0.8143 - val_loss: 0.3349 - val_precision: 1.0000 - val_recall: 0.6167 - val_f1_score: 0.7629\n",
            "Epoch 652/2000\n",
            "300/300 [==============================] - 0s 101us/step - loss: 0.3049 - precision: 1.0000 - recall: 0.6867 - f1_score: 0.8117 - val_loss: 0.3346 - val_precision: 1.0000 - val_recall: 0.6167 - val_f1_score: 0.7629\n",
            "Epoch 653/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.3045 - precision: 1.0000 - recall: 0.6900 - f1_score: 0.8158 - val_loss: 0.3347 - val_precision: 1.0000 - val_recall: 0.6333 - val_f1_score: 0.7755\n",
            "Epoch 654/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.3044 - precision: 1.0000 - recall: 0.6900 - f1_score: 0.8155 - val_loss: 0.3346 - val_precision: 1.0000 - val_recall: 0.6333 - val_f1_score: 0.7755\n",
            "Epoch 655/2000\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.3042 - precision: 1.0000 - recall: 0.6867 - f1_score: 0.8128 - val_loss: 0.3346 - val_precision: 1.0000 - val_recall: 0.6333 - val_f1_score: 0.7755\n",
            "Epoch 656/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.3039 - precision: 1.0000 - recall: 0.6867 - f1_score: 0.8125 - val_loss: 0.3342 - val_precision: 1.0000 - val_recall: 0.6333 - val_f1_score: 0.7755\n",
            "Epoch 657/2000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.3039 - precision: 1.0000 - recall: 0.6867 - f1_score: 0.8142 - val_loss: 0.3343 - val_precision: 1.0000 - val_recall: 0.6333 - val_f1_score: 0.7755\n",
            "Epoch 658/2000\n",
            "300/300 [==============================] - 0s 81us/step - loss: 0.3035 - precision: 1.0000 - recall: 0.6800 - f1_score: 0.8093 - val_loss: 0.3341 - val_precision: 1.0000 - val_recall: 0.6333 - val_f1_score: 0.7755\n",
            "Epoch 659/2000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.3033 - precision: 1.0000 - recall: 0.6900 - f1_score: 0.8161 - val_loss: 0.3342 - val_precision: 1.0000 - val_recall: 0.6333 - val_f1_score: 0.7755\n",
            "Epoch 660/2000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.3034 - precision: 1.0000 - recall: 0.6833 - f1_score: 0.8108 - val_loss: 0.3341 - val_precision: 1.0000 - val_recall: 0.6333 - val_f1_score: 0.7755\n",
            "Epoch 661/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.3029 - precision: 1.0000 - recall: 0.6867 - f1_score: 0.8118 - val_loss: 0.3342 - val_precision: 1.0000 - val_recall: 0.6333 - val_f1_score: 0.7755\n",
            "Epoch 662/2000\n",
            "300/300 [==============================] - 0s 111us/step - loss: 0.3028 - precision: 1.0000 - recall: 0.6867 - f1_score: 0.8134 - val_loss: 0.3335 - val_precision: 1.0000 - val_recall: 0.6333 - val_f1_score: 0.7755\n",
            "Epoch 663/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.3026 - precision: 1.0000 - recall: 0.6900 - f1_score: 0.8150 - val_loss: 0.3333 - val_precision: 1.0000 - val_recall: 0.6333 - val_f1_score: 0.7755\n",
            "Epoch 664/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.3025 - precision: 1.0000 - recall: 0.6867 - f1_score: 0.8138 - val_loss: 0.3328 - val_precision: 1.0000 - val_recall: 0.6333 - val_f1_score: 0.7755\n",
            "Epoch 665/2000\n",
            "300/300 [==============================] - 0s 102us/step - loss: 0.3022 - precision: 1.0000 - recall: 0.6900 - f1_score: 0.8157 - val_loss: 0.3326 - val_precision: 1.0000 - val_recall: 0.6333 - val_f1_score: 0.7755\n",
            "Epoch 666/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.3020 - precision: 1.0000 - recall: 0.6933 - f1_score: 0.8181 - val_loss: 0.3325 - val_precision: 1.0000 - val_recall: 0.6333 - val_f1_score: 0.7755\n",
            "Epoch 667/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.3018 - precision: 1.0000 - recall: 0.6900 - f1_score: 0.8150 - val_loss: 0.3321 - val_precision: 1.0000 - val_recall: 0.6333 - val_f1_score: 0.7755\n",
            "Epoch 668/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.3018 - precision: 1.0000 - recall: 0.6967 - f1_score: 0.8178 - val_loss: 0.3319 - val_precision: 1.0000 - val_recall: 0.6333 - val_f1_score: 0.7755\n",
            "Epoch 669/2000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.3014 - precision: 1.0000 - recall: 0.6967 - f1_score: 0.8202 - val_loss: 0.3319 - val_precision: 1.0000 - val_recall: 0.6333 - val_f1_score: 0.7755\n",
            "Epoch 670/2000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.3013 - precision: 1.0000 - recall: 0.6900 - f1_score: 0.8118 - val_loss: 0.3315 - val_precision: 1.0000 - val_recall: 0.6333 - val_f1_score: 0.7755\n",
            "Epoch 671/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.3012 - precision: 1.0000 - recall: 0.6933 - f1_score: 0.8184 - val_loss: 0.3312 - val_precision: 1.0000 - val_recall: 0.6333 - val_f1_score: 0.7755\n",
            "Epoch 672/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.3008 - precision: 1.0000 - recall: 0.6933 - f1_score: 0.8173 - val_loss: 0.3309 - val_precision: 1.0000 - val_recall: 0.6333 - val_f1_score: 0.7755\n",
            "Epoch 673/2000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.3008 - precision: 1.0000 - recall: 0.6933 - f1_score: 0.8161 - val_loss: 0.3307 - val_precision: 1.0000 - val_recall: 0.6333 - val_f1_score: 0.7755\n",
            "Epoch 674/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.3007 - precision: 1.0000 - recall: 0.7033 - f1_score: 0.8256 - val_loss: 0.3309 - val_precision: 1.0000 - val_recall: 0.6333 - val_f1_score: 0.7755\n",
            "Epoch 675/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.3003 - precision: 1.0000 - recall: 0.6967 - f1_score: 0.8207 - val_loss: 0.3305 - val_precision: 1.0000 - val_recall: 0.6333 - val_f1_score: 0.7755\n",
            "Epoch 676/2000\n",
            "300/300 [==============================] - 0s 101us/step - loss: 0.3003 - precision: 1.0000 - recall: 0.6867 - f1_score: 0.8132 - val_loss: 0.3301 - val_precision: 1.0000 - val_recall: 0.6333 - val_f1_score: 0.7755\n",
            "Epoch 677/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.3001 - precision: 1.0000 - recall: 0.6967 - f1_score: 0.8196 - val_loss: 0.3301 - val_precision: 1.0000 - val_recall: 0.6333 - val_f1_score: 0.7755\n",
            "Epoch 678/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.2998 - precision: 1.0000 - recall: 0.6933 - f1_score: 0.8173 - val_loss: 0.3302 - val_precision: 1.0000 - val_recall: 0.6333 - val_f1_score: 0.7755\n",
            "Epoch 679/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.2998 - precision: 1.0000 - recall: 0.6933 - f1_score: 0.8182 - val_loss: 0.3299 - val_precision: 1.0000 - val_recall: 0.6333 - val_f1_score: 0.7755\n",
            "Epoch 680/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.2997 - precision: 1.0000 - recall: 0.6933 - f1_score: 0.8165 - val_loss: 0.3301 - val_precision: 1.0000 - val_recall: 0.6333 - val_f1_score: 0.7755\n",
            "Epoch 681/2000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.2992 - precision: 1.0000 - recall: 0.6967 - f1_score: 0.8208 - val_loss: 0.3297 - val_precision: 1.0000 - val_recall: 0.6333 - val_f1_score: 0.7755\n",
            "Epoch 682/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.2993 - precision: 1.0000 - recall: 0.7033 - f1_score: 0.8249 - val_loss: 0.3298 - val_precision: 1.0000 - val_recall: 0.6333 - val_f1_score: 0.7755\n",
            "Epoch 683/2000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.2989 - precision: 1.0000 - recall: 0.6933 - f1_score: 0.8187 - val_loss: 0.3293 - val_precision: 1.0000 - val_recall: 0.6333 - val_f1_score: 0.7755\n",
            "Epoch 684/2000\n",
            "300/300 [==============================] - 0s 106us/step - loss: 0.2988 - precision: 1.0000 - recall: 0.7000 - f1_score: 0.8220 - val_loss: 0.3289 - val_precision: 1.0000 - val_recall: 0.6333 - val_f1_score: 0.7755\n",
            "Epoch 685/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.2986 - precision: 1.0000 - recall: 0.7067 - f1_score: 0.8272 - val_loss: 0.3284 - val_precision: 1.0000 - val_recall: 0.6667 - val_f1_score: 0.8000\n",
            "Epoch 686/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.2984 - precision: 1.0000 - recall: 0.7033 - f1_score: 0.8251 - val_loss: 0.3284 - val_precision: 1.0000 - val_recall: 0.6333 - val_f1_score: 0.7755\n",
            "Epoch 687/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.2982 - precision: 1.0000 - recall: 0.7033 - f1_score: 0.8249 - val_loss: 0.3283 - val_precision: 1.0000 - val_recall: 0.6333 - val_f1_score: 0.7755\n",
            "Epoch 688/2000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.2981 - precision: 1.0000 - recall: 0.7033 - f1_score: 0.8251 - val_loss: 0.3278 - val_precision: 1.0000 - val_recall: 0.6667 - val_f1_score: 0.8000\n",
            "Epoch 689/2000\n",
            "300/300 [==============================] - 0s 82us/step - loss: 0.2978 - precision: 1.0000 - recall: 0.7067 - f1_score: 0.8275 - val_loss: 0.3279 - val_precision: 1.0000 - val_recall: 0.6333 - val_f1_score: 0.7755\n",
            "Epoch 690/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.2976 - precision: 1.0000 - recall: 0.7100 - f1_score: 0.8295 - val_loss: 0.3279 - val_precision: 1.0000 - val_recall: 0.6333 - val_f1_score: 0.7755\n",
            "Epoch 691/2000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.2977 - precision: 1.0000 - recall: 0.7067 - f1_score: 0.8268 - val_loss: 0.3277 - val_precision: 1.0000 - val_recall: 0.6333 - val_f1_score: 0.7755\n",
            "Epoch 692/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.2974 - precision: 1.0000 - recall: 0.7067 - f1_score: 0.8263 - val_loss: 0.3276 - val_precision: 1.0000 - val_recall: 0.6333 - val_f1_score: 0.7755\n",
            "Epoch 693/2000\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.2975 - precision: 1.0000 - recall: 0.7067 - f1_score: 0.8270 - val_loss: 0.3278 - val_precision: 1.0000 - val_recall: 0.6333 - val_f1_score: 0.7755\n",
            "Epoch 694/2000\n",
            "300/300 [==============================] - 0s 102us/step - loss: 0.2971 - precision: 1.0000 - recall: 0.6933 - f1_score: 0.8175 - val_loss: 0.3273 - val_precision: 1.0000 - val_recall: 0.6333 - val_f1_score: 0.7755\n",
            "Epoch 695/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.2969 - precision: 1.0000 - recall: 0.7067 - f1_score: 0.8272 - val_loss: 0.3268 - val_precision: 1.0000 - val_recall: 0.6667 - val_f1_score: 0.8000\n",
            "Epoch 696/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.2967 - precision: 1.0000 - recall: 0.7067 - f1_score: 0.8264 - val_loss: 0.3266 - val_precision: 1.0000 - val_recall: 0.6667 - val_f1_score: 0.8000\n",
            "Epoch 697/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.2964 - precision: 1.0000 - recall: 0.7067 - f1_score: 0.8266 - val_loss: 0.3266 - val_precision: 1.0000 - val_recall: 0.6500 - val_f1_score: 0.7879\n",
            "Epoch 698/2000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.2963 - precision: 1.0000 - recall: 0.7033 - f1_score: 0.8255 - val_loss: 0.3261 - val_precision: 1.0000 - val_recall: 0.6667 - val_f1_score: 0.8000\n",
            "Epoch 699/2000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.2960 - precision: 1.0000 - recall: 0.7100 - f1_score: 0.8293 - val_loss: 0.3262 - val_precision: 1.0000 - val_recall: 0.6667 - val_f1_score: 0.8000\n",
            "Epoch 700/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.2959 - precision: 1.0000 - recall: 0.7100 - f1_score: 0.8291 - val_loss: 0.3261 - val_precision: 1.0000 - val_recall: 0.6333 - val_f1_score: 0.7755\n",
            "Epoch 701/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.2958 - precision: 1.0000 - recall: 0.7067 - f1_score: 0.8276 - val_loss: 0.3261 - val_precision: 1.0000 - val_recall: 0.6333 - val_f1_score: 0.7755\n",
            "Epoch 702/2000\n",
            "300/300 [==============================] - 0s 80us/step - loss: 0.2956 - precision: 1.0000 - recall: 0.7133 - f1_score: 0.8319 - val_loss: 0.3260 - val_precision: 1.0000 - val_recall: 0.6333 - val_f1_score: 0.7755\n",
            "Epoch 703/2000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.2955 - precision: 1.0000 - recall: 0.7100 - f1_score: 0.8292 - val_loss: 0.3261 - val_precision: 1.0000 - val_recall: 0.6333 - val_f1_score: 0.7755\n",
            "Epoch 704/2000\n",
            "300/300 [==============================] - 0s 114us/step - loss: 0.2952 - precision: 1.0000 - recall: 0.7067 - f1_score: 0.8256 - val_loss: 0.3257 - val_precision: 1.0000 - val_recall: 0.6333 - val_f1_score: 0.7755\n",
            "Epoch 705/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.2951 - precision: 1.0000 - recall: 0.7100 - f1_score: 0.8295 - val_loss: 0.3254 - val_precision: 1.0000 - val_recall: 0.6333 - val_f1_score: 0.7755\n",
            "Epoch 706/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.2949 - precision: 1.0000 - recall: 0.7033 - f1_score: 0.8248 - val_loss: 0.3247 - val_precision: 1.0000 - val_recall: 0.6833 - val_f1_score: 0.8119\n",
            "Epoch 707/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.2947 - precision: 1.0000 - recall: 0.7100 - f1_score: 0.8296 - val_loss: 0.3248 - val_precision: 1.0000 - val_recall: 0.6500 - val_f1_score: 0.7879\n",
            "Epoch 708/2000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.2945 - precision: 1.0000 - recall: 0.7100 - f1_score: 0.8297 - val_loss: 0.3246 - val_precision: 1.0000 - val_recall: 0.6667 - val_f1_score: 0.8000\n",
            "Epoch 709/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.2943 - precision: 1.0000 - recall: 0.7100 - f1_score: 0.8292 - val_loss: 0.3244 - val_precision: 1.0000 - val_recall: 0.6833 - val_f1_score: 0.8119\n",
            "Epoch 710/2000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.2943 - precision: 1.0000 - recall: 0.7133 - f1_score: 0.8320 - val_loss: 0.3244 - val_precision: 1.0000 - val_recall: 0.6500 - val_f1_score: 0.7879\n",
            "Epoch 711/2000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.2940 - precision: 1.0000 - recall: 0.7100 - f1_score: 0.8292 - val_loss: 0.3242 - val_precision: 1.0000 - val_recall: 0.6833 - val_f1_score: 0.8119\n",
            "Epoch 712/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.2939 - precision: 1.0000 - recall: 0.7133 - f1_score: 0.8320 - val_loss: 0.3241 - val_precision: 1.0000 - val_recall: 0.6833 - val_f1_score: 0.8119\n",
            "Epoch 713/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.2937 - precision: 1.0000 - recall: 0.7133 - f1_score: 0.8304 - val_loss: 0.3238 - val_precision: 1.0000 - val_recall: 0.6833 - val_f1_score: 0.8119\n",
            "Epoch 714/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.2935 - precision: 1.0000 - recall: 0.7133 - f1_score: 0.8321 - val_loss: 0.3236 - val_precision: 1.0000 - val_recall: 0.6833 - val_f1_score: 0.8119\n",
            "Epoch 715/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.2933 - precision: 1.0000 - recall: 0.7133 - f1_score: 0.8323 - val_loss: 0.3234 - val_precision: 1.0000 - val_recall: 0.6833 - val_f1_score: 0.8119\n",
            "Epoch 716/2000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.2931 - precision: 1.0000 - recall: 0.7133 - f1_score: 0.8321 - val_loss: 0.3231 - val_precision: 1.0000 - val_recall: 0.7000 - val_f1_score: 0.8235\n",
            "Epoch 717/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.2929 - precision: 1.0000 - recall: 0.7167 - f1_score: 0.8345 - val_loss: 0.3230 - val_precision: 1.0000 - val_recall: 0.6833 - val_f1_score: 0.8119\n",
            "Epoch 718/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.2930 - precision: 1.0000 - recall: 0.7233 - f1_score: 0.8389 - val_loss: 0.3231 - val_precision: 1.0000 - val_recall: 0.6833 - val_f1_score: 0.8119\n",
            "Epoch 719/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.2928 - precision: 1.0000 - recall: 0.7133 - f1_score: 0.8310 - val_loss: 0.3227 - val_precision: 1.0000 - val_recall: 0.6833 - val_f1_score: 0.8119\n",
            "Epoch 720/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.2925 - precision: 1.0000 - recall: 0.7200 - f1_score: 0.8358 - val_loss: 0.3225 - val_precision: 1.0000 - val_recall: 0.6833 - val_f1_score: 0.8119\n",
            "Epoch 721/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.2923 - precision: 1.0000 - recall: 0.7267 - f1_score: 0.8408 - val_loss: 0.3224 - val_precision: 1.0000 - val_recall: 0.6833 - val_f1_score: 0.8119\n",
            "Epoch 722/2000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.2921 - precision: 1.0000 - recall: 0.7133 - f1_score: 0.8322 - val_loss: 0.3221 - val_precision: 1.0000 - val_recall: 0.6833 - val_f1_score: 0.8119\n",
            "Epoch 723/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.2919 - precision: 1.0000 - recall: 0.7167 - f1_score: 0.8337 - val_loss: 0.3220 - val_precision: 1.0000 - val_recall: 0.6833 - val_f1_score: 0.8119\n",
            "Epoch 724/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.2919 - precision: 1.0000 - recall: 0.7300 - f1_score: 0.8430 - val_loss: 0.3221 - val_precision: 1.0000 - val_recall: 0.6833 - val_f1_score: 0.8119\n",
            "Epoch 725/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.2917 - precision: 1.0000 - recall: 0.7167 - f1_score: 0.8337 - val_loss: 0.3222 - val_precision: 1.0000 - val_recall: 0.6667 - val_f1_score: 0.8000\n",
            "Epoch 726/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.2916 - precision: 1.0000 - recall: 0.7100 - f1_score: 0.8291 - val_loss: 0.3214 - val_precision: 1.0000 - val_recall: 0.7000 - val_f1_score: 0.8235\n",
            "Epoch 727/2000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.2913 - precision: 1.0000 - recall: 0.7200 - f1_score: 0.8365 - val_loss: 0.3209 - val_precision: 1.0000 - val_recall: 0.7000 - val_f1_score: 0.8235\n",
            "Epoch 728/2000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.2913 - precision: 1.0000 - recall: 0.7300 - f1_score: 0.8436 - val_loss: 0.3208 - val_precision: 1.0000 - val_recall: 0.7000 - val_f1_score: 0.8235\n",
            "Epoch 729/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.2912 - precision: 1.0000 - recall: 0.7333 - f1_score: 0.8448 - val_loss: 0.3207 - val_precision: 1.0000 - val_recall: 0.7000 - val_f1_score: 0.8235\n",
            "Epoch 730/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.2908 - precision: 1.0000 - recall: 0.7167 - f1_score: 0.8322 - val_loss: 0.3204 - val_precision: 1.0000 - val_recall: 0.7000 - val_f1_score: 0.8235\n",
            "Epoch 731/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.2907 - precision: 1.0000 - recall: 0.7300 - f1_score: 0.8435 - val_loss: 0.3204 - val_precision: 1.0000 - val_recall: 0.7000 - val_f1_score: 0.8235\n",
            "Epoch 732/2000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.2905 - precision: 1.0000 - recall: 0.7233 - f1_score: 0.8385 - val_loss: 0.3202 - val_precision: 1.0000 - val_recall: 0.7000 - val_f1_score: 0.8235\n",
            "Epoch 733/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.2902 - precision: 1.0000 - recall: 0.7233 - f1_score: 0.8389 - val_loss: 0.3200 - val_precision: 1.0000 - val_recall: 0.7000 - val_f1_score: 0.8235\n",
            "Epoch 734/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.2901 - precision: 1.0000 - recall: 0.7300 - f1_score: 0.8433 - val_loss: 0.3197 - val_precision: 1.0000 - val_recall: 0.7000 - val_f1_score: 0.8235\n",
            "Epoch 735/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.2902 - precision: 1.0000 - recall: 0.7200 - f1_score: 0.8368 - val_loss: 0.3192 - val_precision: 1.0000 - val_recall: 0.7000 - val_f1_score: 0.8235\n",
            "Epoch 736/2000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.2900 - precision: 1.0000 - recall: 0.7433 - f1_score: 0.8521 - val_loss: 0.3193 - val_precision: 1.0000 - val_recall: 0.7000 - val_f1_score: 0.8235\n",
            "Epoch 737/2000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.2900 - precision: 1.0000 - recall: 0.7233 - f1_score: 0.8390 - val_loss: 0.3192 - val_precision: 1.0000 - val_recall: 0.7000 - val_f1_score: 0.8235\n",
            "Epoch 738/2000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.2895 - precision: 1.0000 - recall: 0.7333 - f1_score: 0.8455 - val_loss: 0.3191 - val_precision: 1.0000 - val_recall: 0.7000 - val_f1_score: 0.8235\n",
            "Epoch 739/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.2893 - precision: 1.0000 - recall: 0.7233 - f1_score: 0.8391 - val_loss: 0.3188 - val_precision: 1.0000 - val_recall: 0.7000 - val_f1_score: 0.8235\n",
            "Epoch 740/2000\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.2894 - precision: 1.0000 - recall: 0.7400 - f1_score: 0.8500 - val_loss: 0.3185 - val_precision: 1.0000 - val_recall: 0.7000 - val_f1_score: 0.8235\n",
            "Epoch 741/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.2890 - precision: 1.0000 - recall: 0.7267 - f1_score: 0.8397 - val_loss: 0.3181 - val_precision: 1.0000 - val_recall: 0.7000 - val_f1_score: 0.8235\n",
            "Epoch 742/2000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.2888 - precision: 1.0000 - recall: 0.7500 - f1_score: 0.8557 - val_loss: 0.3183 - val_precision: 1.0000 - val_recall: 0.7000 - val_f1_score: 0.8235\n",
            "Epoch 743/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.2887 - precision: 1.0000 - recall: 0.7400 - f1_score: 0.8479 - val_loss: 0.3184 - val_precision: 1.0000 - val_recall: 0.7000 - val_f1_score: 0.8235\n",
            "Epoch 744/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.2886 - precision: 1.0000 - recall: 0.7300 - f1_score: 0.8429 - val_loss: 0.3184 - val_precision: 1.0000 - val_recall: 0.7000 - val_f1_score: 0.8235\n",
            "Epoch 745/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.2884 - precision: 1.0000 - recall: 0.7367 - f1_score: 0.8468 - val_loss: 0.3181 - val_precision: 1.0000 - val_recall: 0.7000 - val_f1_score: 0.8235\n",
            "Epoch 746/2000\n",
            "300/300 [==============================] - 0s 101us/step - loss: 0.2883 - precision: 1.0000 - recall: 0.7467 - f1_score: 0.8547 - val_loss: 0.3180 - val_precision: 1.0000 - val_recall: 0.7000 - val_f1_score: 0.8235\n",
            "Epoch 747/2000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.2879 - precision: 1.0000 - recall: 0.7300 - f1_score: 0.8432 - val_loss: 0.3178 - val_precision: 1.0000 - val_recall: 0.7000 - val_f1_score: 0.8235\n",
            "Epoch 748/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.2880 - precision: 1.0000 - recall: 0.7233 - f1_score: 0.8379 - val_loss: 0.3172 - val_precision: 1.0000 - val_recall: 0.7000 - val_f1_score: 0.8235\n",
            "Epoch 749/2000\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.2877 - precision: 1.0000 - recall: 0.7367 - f1_score: 0.8482 - val_loss: 0.3170 - val_precision: 1.0000 - val_recall: 0.7000 - val_f1_score: 0.8235\n",
            "Epoch 750/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.2875 - precision: 1.0000 - recall: 0.7433 - f1_score: 0.8525 - val_loss: 0.3167 - val_precision: 1.0000 - val_recall: 0.7167 - val_f1_score: 0.8350\n",
            "Epoch 751/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.2874 - precision: 1.0000 - recall: 0.7500 - f1_score: 0.8557 - val_loss: 0.3167 - val_precision: 1.0000 - val_recall: 0.7167 - val_f1_score: 0.8350\n",
            "Epoch 752/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.2875 - precision: 1.0000 - recall: 0.7467 - f1_score: 0.8534 - val_loss: 0.3164 - val_precision: 1.0000 - val_recall: 0.7167 - val_f1_score: 0.8350\n",
            "Epoch 753/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.2871 - precision: 1.0000 - recall: 0.7533 - f1_score: 0.8585 - val_loss: 0.3164 - val_precision: 1.0000 - val_recall: 0.7000 - val_f1_score: 0.8235\n",
            "Epoch 754/2000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.2870 - precision: 1.0000 - recall: 0.7533 - f1_score: 0.8590 - val_loss: 0.3166 - val_precision: 1.0000 - val_recall: 0.7000 - val_f1_score: 0.8235\n",
            "Epoch 755/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.2868 - precision: 1.0000 - recall: 0.7433 - f1_score: 0.8512 - val_loss: 0.3164 - val_precision: 1.0000 - val_recall: 0.7000 - val_f1_score: 0.8235\n",
            "Epoch 756/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.2868 - precision: 1.0000 - recall: 0.7467 - f1_score: 0.8543 - val_loss: 0.3166 - val_precision: 1.0000 - val_recall: 0.7000 - val_f1_score: 0.8235\n",
            "Epoch 757/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.2867 - precision: 1.0000 - recall: 0.7367 - f1_score: 0.8462 - val_loss: 0.3164 - val_precision: 1.0000 - val_recall: 0.7000 - val_f1_score: 0.8235\n",
            "Epoch 758/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.2864 - precision: 1.0000 - recall: 0.7367 - f1_score: 0.8480 - val_loss: 0.3162 - val_precision: 1.0000 - val_recall: 0.7000 - val_f1_score: 0.8235\n",
            "Epoch 759/2000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.2861 - precision: 1.0000 - recall: 0.7300 - f1_score: 0.8427 - val_loss: 0.3159 - val_precision: 1.0000 - val_recall: 0.7000 - val_f1_score: 0.8235\n",
            "Epoch 760/2000\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.2859 - precision: 1.0000 - recall: 0.7400 - f1_score: 0.8482 - val_loss: 0.3157 - val_precision: 1.0000 - val_recall: 0.7000 - val_f1_score: 0.8235\n",
            "Epoch 761/2000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.2859 - precision: 1.0000 - recall: 0.7367 - f1_score: 0.8478 - val_loss: 0.3154 - val_precision: 1.0000 - val_recall: 0.7000 - val_f1_score: 0.8235\n",
            "Epoch 762/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.2856 - precision: 1.0000 - recall: 0.7567 - f1_score: 0.8606 - val_loss: 0.3152 - val_precision: 1.0000 - val_recall: 0.7000 - val_f1_score: 0.8235\n",
            "Epoch 763/2000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.2856 - precision: 1.0000 - recall: 0.7333 - f1_score: 0.8460 - val_loss: 0.3148 - val_precision: 1.0000 - val_recall: 0.7167 - val_f1_score: 0.8350\n",
            "Epoch 764/2000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.2852 - precision: 1.0000 - recall: 0.7600 - f1_score: 0.8615 - val_loss: 0.3147 - val_precision: 1.0000 - val_recall: 0.7167 - val_f1_score: 0.8350\n",
            "Epoch 765/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.2852 - precision: 1.0000 - recall: 0.7500 - f1_score: 0.8554 - val_loss: 0.3146 - val_precision: 1.0000 - val_recall: 0.7000 - val_f1_score: 0.8235\n",
            "Epoch 766/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.2850 - precision: 1.0000 - recall: 0.7500 - f1_score: 0.8537 - val_loss: 0.3143 - val_precision: 1.0000 - val_recall: 0.7167 - val_f1_score: 0.8350\n",
            "Epoch 767/2000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.2848 - precision: 1.0000 - recall: 0.7567 - f1_score: 0.8609 - val_loss: 0.3142 - val_precision: 1.0000 - val_recall: 0.7167 - val_f1_score: 0.8350\n",
            "Epoch 768/2000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.2848 - precision: 1.0000 - recall: 0.7533 - f1_score: 0.8583 - val_loss: 0.3138 - val_precision: 1.0000 - val_recall: 0.7167 - val_f1_score: 0.8350\n",
            "Epoch 769/2000\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.2845 - precision: 1.0000 - recall: 0.7533 - f1_score: 0.8589 - val_loss: 0.3139 - val_precision: 1.0000 - val_recall: 0.7167 - val_f1_score: 0.8350\n",
            "Epoch 770/2000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.2843 - precision: 1.0000 - recall: 0.7600 - f1_score: 0.8631 - val_loss: 0.3139 - val_precision: 1.0000 - val_recall: 0.7167 - val_f1_score: 0.8350\n",
            "Epoch 771/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.2842 - precision: 1.0000 - recall: 0.7533 - f1_score: 0.8586 - val_loss: 0.3138 - val_precision: 1.0000 - val_recall: 0.7167 - val_f1_score: 0.8350\n",
            "Epoch 772/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.2841 - precision: 1.0000 - recall: 0.7567 - f1_score: 0.8591 - val_loss: 0.3135 - val_precision: 1.0000 - val_recall: 0.7167 - val_f1_score: 0.8350\n",
            "Epoch 773/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.2842 - precision: 1.0000 - recall: 0.7633 - f1_score: 0.8657 - val_loss: 0.3136 - val_precision: 1.0000 - val_recall: 0.7167 - val_f1_score: 0.8350\n",
            "Epoch 774/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.2837 - precision: 1.0000 - recall: 0.7533 - f1_score: 0.8585 - val_loss: 0.3132 - val_precision: 1.0000 - val_recall: 0.7167 - val_f1_score: 0.8350\n",
            "Epoch 775/2000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.2836 - precision: 1.0000 - recall: 0.7567 - f1_score: 0.8608 - val_loss: 0.3129 - val_precision: 1.0000 - val_recall: 0.7167 - val_f1_score: 0.8350\n",
            "Epoch 776/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.2836 - precision: 1.0000 - recall: 0.7567 - f1_score: 0.8607 - val_loss: 0.3128 - val_precision: 1.0000 - val_recall: 0.7167 - val_f1_score: 0.8350\n",
            "Epoch 777/2000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.2833 - precision: 1.0000 - recall: 0.7600 - f1_score: 0.8623 - val_loss: 0.3128 - val_precision: 1.0000 - val_recall: 0.7167 - val_f1_score: 0.8350\n",
            "Epoch 778/2000\n",
            "300/300 [==============================] - 0s 105us/step - loss: 0.2832 - precision: 1.0000 - recall: 0.7633 - f1_score: 0.8654 - val_loss: 0.3128 - val_precision: 1.0000 - val_recall: 0.7333 - val_f1_score: 0.8462\n",
            "Epoch 779/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.2829 - precision: 1.0000 - recall: 0.7467 - f1_score: 0.8545 - val_loss: 0.3123 - val_precision: 1.0000 - val_recall: 0.7167 - val_f1_score: 0.8350\n",
            "Epoch 780/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.2830 - precision: 1.0000 - recall: 0.7500 - f1_score: 0.8559 - val_loss: 0.3120 - val_precision: 1.0000 - val_recall: 0.7167 - val_f1_score: 0.8350\n",
            "Epoch 781/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.2826 - precision: 1.0000 - recall: 0.7600 - f1_score: 0.8635 - val_loss: 0.3117 - val_precision: 1.0000 - val_recall: 0.7167 - val_f1_score: 0.8350\n",
            "Epoch 782/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.2824 - precision: 1.0000 - recall: 0.7633 - f1_score: 0.8652 - val_loss: 0.3115 - val_precision: 1.0000 - val_recall: 0.7167 - val_f1_score: 0.8350\n",
            "Epoch 783/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.2823 - precision: 1.0000 - recall: 0.7633 - f1_score: 0.8641 - val_loss: 0.3113 - val_precision: 1.0000 - val_recall: 0.7167 - val_f1_score: 0.8350\n",
            "Epoch 784/2000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.2821 - precision: 1.0000 - recall: 0.7600 - f1_score: 0.8634 - val_loss: 0.3111 - val_precision: 1.0000 - val_recall: 0.7167 - val_f1_score: 0.8350\n",
            "Epoch 785/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.2821 - precision: 1.0000 - recall: 0.7633 - f1_score: 0.8638 - val_loss: 0.3110 - val_precision: 1.0000 - val_recall: 0.7167 - val_f1_score: 0.8350\n",
            "Epoch 786/2000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.2819 - precision: 1.0000 - recall: 0.7600 - f1_score: 0.8625 - val_loss: 0.3106 - val_precision: 1.0000 - val_recall: 0.7167 - val_f1_score: 0.8350\n",
            "Epoch 787/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.2819 - precision: 1.0000 - recall: 0.7600 - f1_score: 0.8625 - val_loss: 0.3103 - val_precision: 1.0000 - val_recall: 0.7167 - val_f1_score: 0.8350\n",
            "Epoch 788/2000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.2815 - precision: 1.0000 - recall: 0.7600 - f1_score: 0.8624 - val_loss: 0.3104 - val_precision: 1.0000 - val_recall: 0.7167 - val_f1_score: 0.8350\n",
            "Epoch 789/2000\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.2815 - precision: 1.0000 - recall: 0.7567 - f1_score: 0.8600 - val_loss: 0.3098 - val_precision: 1.0000 - val_recall: 0.7167 - val_f1_score: 0.8350\n",
            "Epoch 790/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.2813 - precision: 1.0000 - recall: 0.7633 - f1_score: 0.8653 - val_loss: 0.3096 - val_precision: 1.0000 - val_recall: 0.7167 - val_f1_score: 0.8350\n",
            "Epoch 791/2000\n",
            "300/300 [==============================] - 0s 103us/step - loss: 0.2811 - precision: 1.0000 - recall: 0.7600 - f1_score: 0.8635 - val_loss: 0.3096 - val_precision: 1.0000 - val_recall: 0.7167 - val_f1_score: 0.8350\n",
            "Epoch 792/2000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.2809 - precision: 1.0000 - recall: 0.7633 - f1_score: 0.8651 - val_loss: 0.3095 - val_precision: 1.0000 - val_recall: 0.7167 - val_f1_score: 0.8350\n",
            "Epoch 793/2000\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.2807 - precision: 1.0000 - recall: 0.7633 - f1_score: 0.8657 - val_loss: 0.3094 - val_precision: 1.0000 - val_recall: 0.7167 - val_f1_score: 0.8350\n",
            "Epoch 794/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.2809 - precision: 1.0000 - recall: 0.7633 - f1_score: 0.8639 - val_loss: 0.3088 - val_precision: 1.0000 - val_recall: 0.7167 - val_f1_score: 0.8350\n",
            "Epoch 795/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.2806 - precision: 1.0000 - recall: 0.7667 - f1_score: 0.8674 - val_loss: 0.3087 - val_precision: 1.0000 - val_recall: 0.7167 - val_f1_score: 0.8350\n",
            "Epoch 796/2000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.2802 - precision: 1.0000 - recall: 0.7667 - f1_score: 0.8670 - val_loss: 0.3087 - val_precision: 1.0000 - val_recall: 0.7167 - val_f1_score: 0.8350\n",
            "Epoch 797/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.2801 - precision: 1.0000 - recall: 0.7667 - f1_score: 0.8667 - val_loss: 0.3086 - val_precision: 1.0000 - val_recall: 0.7167 - val_f1_score: 0.8350\n",
            "Epoch 798/2000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.2803 - precision: 1.0000 - recall: 0.7633 - f1_score: 0.8651 - val_loss: 0.3083 - val_precision: 1.0000 - val_recall: 0.7167 - val_f1_score: 0.8350\n",
            "Epoch 799/2000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.2800 - precision: 1.0000 - recall: 0.7600 - f1_score: 0.8635 - val_loss: 0.3083 - val_precision: 1.0000 - val_recall: 0.7167 - val_f1_score: 0.8350\n",
            "Epoch 800/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.2798 - precision: 1.0000 - recall: 0.7600 - f1_score: 0.8635 - val_loss: 0.3082 - val_precision: 1.0000 - val_recall: 0.7167 - val_f1_score: 0.8350\n",
            "Epoch 801/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.2797 - precision: 1.0000 - recall: 0.7667 - f1_score: 0.8671 - val_loss: 0.3081 - val_precision: 1.0000 - val_recall: 0.7167 - val_f1_score: 0.8350\n",
            "Epoch 802/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.2794 - precision: 1.0000 - recall: 0.7667 - f1_score: 0.8673 - val_loss: 0.3081 - val_precision: 1.0000 - val_recall: 0.7167 - val_f1_score: 0.8350\n",
            "Epoch 803/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.2794 - precision: 1.0000 - recall: 0.7667 - f1_score: 0.8676 - val_loss: 0.3080 - val_precision: 1.0000 - val_recall: 0.7167 - val_f1_score: 0.8350\n",
            "Epoch 804/2000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.2792 - precision: 1.0000 - recall: 0.7633 - f1_score: 0.8656 - val_loss: 0.3079 - val_precision: 1.0000 - val_recall: 0.7333 - val_f1_score: 0.8462\n",
            "Epoch 805/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.2789 - precision: 1.0000 - recall: 0.7667 - f1_score: 0.8677 - val_loss: 0.3076 - val_precision: 1.0000 - val_recall: 0.7167 - val_f1_score: 0.8350\n",
            "Epoch 806/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.2788 - precision: 1.0000 - recall: 0.7667 - f1_score: 0.8677 - val_loss: 0.3074 - val_precision: 1.0000 - val_recall: 0.7167 - val_f1_score: 0.8350\n",
            "Epoch 807/2000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.2788 - precision: 1.0000 - recall: 0.7667 - f1_score: 0.8668 - val_loss: 0.3072 - val_precision: 1.0000 - val_recall: 0.7167 - val_f1_score: 0.8350\n",
            "Epoch 808/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.2785 - precision: 1.0000 - recall: 0.7700 - f1_score: 0.8676 - val_loss: 0.3071 - val_precision: 1.0000 - val_recall: 0.7167 - val_f1_score: 0.8350\n",
            "Epoch 809/2000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.2785 - precision: 1.0000 - recall: 0.7667 - f1_score: 0.8674 - val_loss: 0.3072 - val_precision: 1.0000 - val_recall: 0.7333 - val_f1_score: 0.8462\n",
            "Epoch 810/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.2784 - precision: 1.0000 - recall: 0.7633 - f1_score: 0.8653 - val_loss: 0.3066 - val_precision: 1.0000 - val_recall: 0.7167 - val_f1_score: 0.8350\n",
            "Epoch 811/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.2780 - precision: 1.0000 - recall: 0.7667 - f1_score: 0.8672 - val_loss: 0.3064 - val_precision: 1.0000 - val_recall: 0.7167 - val_f1_score: 0.8350\n",
            "Epoch 812/2000\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.2783 - precision: 1.0000 - recall: 0.7667 - f1_score: 0.8670 - val_loss: 0.3068 - val_precision: 1.0000 - val_recall: 0.7500 - val_f1_score: 0.8571\n",
            "Epoch 813/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.2777 - precision: 1.0000 - recall: 0.7667 - f1_score: 0.8672 - val_loss: 0.3067 - val_precision: 1.0000 - val_recall: 0.7500 - val_f1_score: 0.8571\n",
            "Epoch 814/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.2776 - precision: 1.0000 - recall: 0.7700 - f1_score: 0.8689 - val_loss: 0.3066 - val_precision: 1.0000 - val_recall: 0.7500 - val_f1_score: 0.8571\n",
            "Epoch 815/2000\n",
            "300/300 [==============================] - 0s 102us/step - loss: 0.2776 - precision: 1.0000 - recall: 0.7633 - f1_score: 0.8650 - val_loss: 0.3062 - val_precision: 1.0000 - val_recall: 0.7333 - val_f1_score: 0.8462\n",
            "Epoch 816/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.2773 - precision: 1.0000 - recall: 0.7667 - f1_score: 0.8667 - val_loss: 0.3060 - val_precision: 1.0000 - val_recall: 0.7333 - val_f1_score: 0.8462\n",
            "Epoch 817/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.2772 - precision: 1.0000 - recall: 0.7667 - f1_score: 0.8678 - val_loss: 0.3060 - val_precision: 1.0000 - val_recall: 0.7500 - val_f1_score: 0.8571\n",
            "Epoch 818/2000\n",
            "300/300 [==============================] - 0s 107us/step - loss: 0.2770 - precision: 1.0000 - recall: 0.7733 - f1_score: 0.8706 - val_loss: 0.3055 - val_precision: 1.0000 - val_recall: 0.7333 - val_f1_score: 0.8462\n",
            "Epoch 819/2000\n",
            "300/300 [==============================] - 0s 101us/step - loss: 0.2769 - precision: 1.0000 - recall: 0.7633 - f1_score: 0.8654 - val_loss: 0.3052 - val_precision: 1.0000 - val_recall: 0.7167 - val_f1_score: 0.8350\n",
            "Epoch 820/2000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.2769 - precision: 1.0000 - recall: 0.7667 - f1_score: 0.8671 - val_loss: 0.3050 - val_precision: 1.0000 - val_recall: 0.7333 - val_f1_score: 0.8462\n",
            "Epoch 821/2000\n",
            "300/300 [==============================] - 0s 82us/step - loss: 0.2767 - precision: 1.0000 - recall: 0.7667 - f1_score: 0.8675 - val_loss: 0.3052 - val_precision: 1.0000 - val_recall: 0.7500 - val_f1_score: 0.8571\n",
            "Epoch 822/2000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.2769 - precision: 1.0000 - recall: 0.7667 - f1_score: 0.8672 - val_loss: 0.3045 - val_precision: 1.0000 - val_recall: 0.7167 - val_f1_score: 0.8350\n",
            "Epoch 823/2000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.2763 - precision: 1.0000 - recall: 0.7733 - f1_score: 0.8717 - val_loss: 0.3046 - val_precision: 1.0000 - val_recall: 0.7333 - val_f1_score: 0.8462\n",
            "Epoch 824/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.2761 - precision: 1.0000 - recall: 0.7700 - f1_score: 0.8693 - val_loss: 0.3045 - val_precision: 1.0000 - val_recall: 0.7333 - val_f1_score: 0.8462\n",
            "Epoch 825/2000\n",
            "300/300 [==============================] - 0s 124us/step - loss: 0.2760 - precision: 1.0000 - recall: 0.7700 - f1_score: 0.8678 - val_loss: 0.3043 - val_precision: 1.0000 - val_recall: 0.7333 - val_f1_score: 0.8462\n",
            "Epoch 826/2000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.2759 - precision: 1.0000 - recall: 0.7767 - f1_score: 0.8727 - val_loss: 0.3044 - val_precision: 1.0000 - val_recall: 0.7500 - val_f1_score: 0.8571\n",
            "Epoch 827/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.2758 - precision: 1.0000 - recall: 0.7767 - f1_score: 0.8740 - val_loss: 0.3044 - val_precision: 1.0000 - val_recall: 0.7500 - val_f1_score: 0.8571\n",
            "Epoch 828/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.2757 - precision: 1.0000 - recall: 0.7667 - f1_score: 0.8670 - val_loss: 0.3041 - val_precision: 1.0000 - val_recall: 0.7500 - val_f1_score: 0.8571\n",
            "Epoch 829/2000\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.2755 - precision: 1.0000 - recall: 0.7667 - f1_score: 0.8672 - val_loss: 0.3038 - val_precision: 1.0000 - val_recall: 0.7333 - val_f1_score: 0.8462\n",
            "Epoch 830/2000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.2752 - precision: 1.0000 - recall: 0.7767 - f1_score: 0.8738 - val_loss: 0.3038 - val_precision: 1.0000 - val_recall: 0.7500 - val_f1_score: 0.8571\n",
            "Epoch 831/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.2752 - precision: 1.0000 - recall: 0.7667 - f1_score: 0.8678 - val_loss: 0.3036 - val_precision: 1.0000 - val_recall: 0.7500 - val_f1_score: 0.8571\n",
            "Epoch 832/2000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.2750 - precision: 1.0000 - recall: 0.7733 - f1_score: 0.8713 - val_loss: 0.3032 - val_precision: 1.0000 - val_recall: 0.7333 - val_f1_score: 0.8462\n",
            "Epoch 833/2000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.2751 - precision: 1.0000 - recall: 0.7833 - f1_score: 0.8769 - val_loss: 0.3030 - val_precision: 1.0000 - val_recall: 0.7333 - val_f1_score: 0.8462\n",
            "Epoch 834/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.2749 - precision: 1.0000 - recall: 0.7800 - f1_score: 0.8755 - val_loss: 0.3028 - val_precision: 1.0000 - val_recall: 0.7333 - val_f1_score: 0.8462\n",
            "Epoch 835/2000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.2746 - precision: 1.0000 - recall: 0.7733 - f1_score: 0.8718 - val_loss: 0.3025 - val_precision: 1.0000 - val_recall: 0.7333 - val_f1_score: 0.8462\n",
            "Epoch 836/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.2746 - precision: 1.0000 - recall: 0.7800 - f1_score: 0.8759 - val_loss: 0.3026 - val_precision: 1.0000 - val_recall: 0.7333 - val_f1_score: 0.8462\n",
            "Epoch 837/2000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.2743 - precision: 1.0000 - recall: 0.7833 - f1_score: 0.8784 - val_loss: 0.3027 - val_precision: 1.0000 - val_recall: 0.7500 - val_f1_score: 0.8571\n",
            "Epoch 838/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.2742 - precision: 1.0000 - recall: 0.7833 - f1_score: 0.8783 - val_loss: 0.3028 - val_precision: 1.0000 - val_recall: 0.7500 - val_f1_score: 0.8571\n",
            "Epoch 839/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.2739 - precision: 1.0000 - recall: 0.7800 - f1_score: 0.8761 - val_loss: 0.3026 - val_precision: 1.0000 - val_recall: 0.7500 - val_f1_score: 0.8571\n",
            "Epoch 840/2000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.2739 - precision: 1.0000 - recall: 0.7767 - f1_score: 0.8734 - val_loss: 0.3021 - val_precision: 1.0000 - val_recall: 0.7500 - val_f1_score: 0.8571\n",
            "Epoch 841/2000\n",
            "300/300 [==============================] - 0s 82us/step - loss: 0.2738 - precision: 1.0000 - recall: 0.7767 - f1_score: 0.8729 - val_loss: 0.3017 - val_precision: 1.0000 - val_recall: 0.7500 - val_f1_score: 0.8571\n",
            "Epoch 842/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.2735 - precision: 1.0000 - recall: 0.7733 - f1_score: 0.8717 - val_loss: 0.3015 - val_precision: 1.0000 - val_recall: 0.7500 - val_f1_score: 0.8571\n",
            "Epoch 843/2000\n",
            "300/300 [==============================] - 0s 109us/step - loss: 0.2736 - precision: 1.0000 - recall: 0.7700 - f1_score: 0.8693 - val_loss: 0.3011 - val_precision: 1.0000 - val_recall: 0.7500 - val_f1_score: 0.8571\n",
            "Epoch 844/2000\n",
            "300/300 [==============================] - 0s 104us/step - loss: 0.2733 - precision: 1.0000 - recall: 0.7833 - f1_score: 0.8782 - val_loss: 0.3009 - val_precision: 1.0000 - val_recall: 0.7500 - val_f1_score: 0.8571\n",
            "Epoch 845/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.2733 - precision: 1.0000 - recall: 0.7800 - f1_score: 0.8763 - val_loss: 0.3009 - val_precision: 1.0000 - val_recall: 0.7667 - val_f1_score: 0.8679\n",
            "Epoch 846/2000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.2731 - precision: 1.0000 - recall: 0.7767 - f1_score: 0.8727 - val_loss: 0.3006 - val_precision: 1.0000 - val_recall: 0.7500 - val_f1_score: 0.8571\n",
            "Epoch 847/2000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.2731 - precision: 1.0000 - recall: 0.7800 - f1_score: 0.8762 - val_loss: 0.3004 - val_precision: 1.0000 - val_recall: 0.7500 - val_f1_score: 0.8571\n",
            "Epoch 848/2000\n",
            "300/300 [==============================] - 0s 81us/step - loss: 0.2727 - precision: 1.0000 - recall: 0.7867 - f1_score: 0.8799 - val_loss: 0.3005 - val_precision: 1.0000 - val_recall: 0.7667 - val_f1_score: 0.8679\n",
            "Epoch 849/2000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.2728 - precision: 1.0000 - recall: 0.7900 - f1_score: 0.8827 - val_loss: 0.3008 - val_precision: 1.0000 - val_recall: 0.7500 - val_f1_score: 0.8571\n",
            "Epoch 850/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.2726 - precision: 1.0000 - recall: 0.7733 - f1_score: 0.8715 - val_loss: 0.3009 - val_precision: 1.0000 - val_recall: 0.7500 - val_f1_score: 0.8571\n",
            "Epoch 851/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.2722 - precision: 1.0000 - recall: 0.7733 - f1_score: 0.8716 - val_loss: 0.3006 - val_precision: 1.0000 - val_recall: 0.7500 - val_f1_score: 0.8571\n",
            "Epoch 852/2000\n",
            "300/300 [==============================] - 0s 106us/step - loss: 0.2722 - precision: 1.0000 - recall: 0.7833 - f1_score: 0.8769 - val_loss: 0.3003 - val_precision: 1.0000 - val_recall: 0.7500 - val_f1_score: 0.8571\n",
            "Epoch 853/2000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.2721 - precision: 1.0000 - recall: 0.7833 - f1_score: 0.8778 - val_loss: 0.2998 - val_precision: 1.0000 - val_recall: 0.7833 - val_f1_score: 0.8785\n",
            "Epoch 854/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.2718 - precision: 1.0000 - recall: 0.7900 - f1_score: 0.8818 - val_loss: 0.2998 - val_precision: 1.0000 - val_recall: 0.7833 - val_f1_score: 0.8785\n",
            "Epoch 855/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.2717 - precision: 1.0000 - recall: 0.7867 - f1_score: 0.8799 - val_loss: 0.2995 - val_precision: 1.0000 - val_recall: 0.7833 - val_f1_score: 0.8785\n",
            "Epoch 856/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.2718 - precision: 1.0000 - recall: 0.7900 - f1_score: 0.8809 - val_loss: 0.2995 - val_precision: 1.0000 - val_recall: 0.7667 - val_f1_score: 0.8679\n",
            "Epoch 857/2000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.2714 - precision: 1.0000 - recall: 0.7833 - f1_score: 0.8784 - val_loss: 0.2994 - val_precision: 1.0000 - val_recall: 0.7667 - val_f1_score: 0.8679\n",
            "Epoch 858/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.2713 - precision: 1.0000 - recall: 0.7800 - f1_score: 0.8753 - val_loss: 0.2991 - val_precision: 1.0000 - val_recall: 0.7833 - val_f1_score: 0.8785\n",
            "Epoch 859/2000\n",
            "300/300 [==============================] - 0s 108us/step - loss: 0.2712 - precision: 1.0000 - recall: 0.7867 - f1_score: 0.8802 - val_loss: 0.2986 - val_precision: 1.0000 - val_recall: 0.7667 - val_f1_score: 0.8679\n",
            "Epoch 860/2000\n",
            "300/300 [==============================] - 0s 80us/step - loss: 0.2711 - precision: 1.0000 - recall: 0.7900 - f1_score: 0.8822 - val_loss: 0.2986 - val_precision: 1.0000 - val_recall: 0.7833 - val_f1_score: 0.8785\n",
            "Epoch 861/2000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.2714 - precision: 1.0000 - recall: 0.7900 - f1_score: 0.8801 - val_loss: 0.2986 - val_precision: 1.0000 - val_recall: 0.7833 - val_f1_score: 0.8785\n",
            "Epoch 862/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.2709 - precision: 1.0000 - recall: 0.7800 - f1_score: 0.8748 - val_loss: 0.2984 - val_precision: 1.0000 - val_recall: 0.7833 - val_f1_score: 0.8785\n",
            "Epoch 863/2000\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.2707 - precision: 1.0000 - recall: 0.7900 - f1_score: 0.8816 - val_loss: 0.2981 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 864/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.2705 - precision: 1.0000 - recall: 0.7933 - f1_score: 0.8846 - val_loss: 0.2979 - val_precision: 1.0000 - val_recall: 0.7833 - val_f1_score: 0.8785\n",
            "Epoch 865/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.2703 - precision: 1.0000 - recall: 0.7933 - f1_score: 0.8843 - val_loss: 0.2980 - val_precision: 1.0000 - val_recall: 0.7833 - val_f1_score: 0.8785\n",
            "Epoch 866/2000\n",
            "300/300 [==============================] - 0s 103us/step - loss: 0.2702 - precision: 1.0000 - recall: 0.7867 - f1_score: 0.8775 - val_loss: 0.2978 - val_precision: 1.0000 - val_recall: 0.7833 - val_f1_score: 0.8785\n",
            "Epoch 867/2000\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.2700 - precision: 1.0000 - recall: 0.7900 - f1_score: 0.8818 - val_loss: 0.2977 - val_precision: 1.0000 - val_recall: 0.7833 - val_f1_score: 0.8785\n",
            "Epoch 868/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.2701 - precision: 1.0000 - recall: 0.7900 - f1_score: 0.8819 - val_loss: 0.2974 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 869/2000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.2697 - precision: 1.0000 - recall: 0.7833 - f1_score: 0.8785 - val_loss: 0.2974 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 870/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.2696 - precision: 1.0000 - recall: 0.7900 - f1_score: 0.8819 - val_loss: 0.2972 - val_precision: 1.0000 - val_recall: 0.7833 - val_f1_score: 0.8785\n",
            "Epoch 871/2000\n",
            "300/300 [==============================] - 0s 101us/step - loss: 0.2697 - precision: 1.0000 - recall: 0.7900 - f1_score: 0.8824 - val_loss: 0.2971 - val_precision: 1.0000 - val_recall: 0.7833 - val_f1_score: 0.8785\n",
            "Epoch 872/2000\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.2693 - precision: 1.0000 - recall: 0.7900 - f1_score: 0.8826 - val_loss: 0.2971 - val_precision: 1.0000 - val_recall: 0.7833 - val_f1_score: 0.8785\n",
            "Epoch 873/2000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.2692 - precision: 1.0000 - recall: 0.7900 - f1_score: 0.8823 - val_loss: 0.2971 - val_precision: 1.0000 - val_recall: 0.7833 - val_f1_score: 0.8785\n",
            "Epoch 874/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.2692 - precision: 1.0000 - recall: 0.7933 - f1_score: 0.8825 - val_loss: 0.2973 - val_precision: 1.0000 - val_recall: 0.7833 - val_f1_score: 0.8785\n",
            "Epoch 875/2000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.2690 - precision: 1.0000 - recall: 0.7933 - f1_score: 0.8829 - val_loss: 0.2971 - val_precision: 1.0000 - val_recall: 0.7833 - val_f1_score: 0.8785\n",
            "Epoch 876/2000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.2689 - precision: 1.0000 - recall: 0.7867 - f1_score: 0.8803 - val_loss: 0.2967 - val_precision: 1.0000 - val_recall: 0.7833 - val_f1_score: 0.8785\n",
            "Epoch 877/2000\n",
            "300/300 [==============================] - 0s 102us/step - loss: 0.2688 - precision: 1.0000 - recall: 0.7867 - f1_score: 0.8801 - val_loss: 0.2965 - val_precision: 1.0000 - val_recall: 0.7833 - val_f1_score: 0.8785\n",
            "Epoch 878/2000\n",
            "300/300 [==============================] - 0s 101us/step - loss: 0.2686 - precision: 1.0000 - recall: 0.7933 - f1_score: 0.8843 - val_loss: 0.2960 - val_precision: 1.0000 - val_recall: 0.7833 - val_f1_score: 0.8785\n",
            "Epoch 879/2000\n",
            "300/300 [==============================] - 0s 101us/step - loss: 0.2684 - precision: 1.0000 - recall: 0.7967 - f1_score: 0.8863 - val_loss: 0.2961 - val_precision: 1.0000 - val_recall: 0.7833 - val_f1_score: 0.8785\n",
            "Epoch 880/2000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.2684 - precision: 1.0000 - recall: 0.7933 - f1_score: 0.8842 - val_loss: 0.2956 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 881/2000\n",
            "300/300 [==============================] - 0s 111us/step - loss: 0.2684 - precision: 1.0000 - recall: 0.7967 - f1_score: 0.8865 - val_loss: 0.2958 - val_precision: 1.0000 - val_recall: 0.7833 - val_f1_score: 0.8785\n",
            "Epoch 882/2000\n",
            "300/300 [==============================] - 0s 106us/step - loss: 0.2681 - precision: 1.0000 - recall: 0.7900 - f1_score: 0.8824 - val_loss: 0.2956 - val_precision: 1.0000 - val_recall: 0.7833 - val_f1_score: 0.8785\n",
            "Epoch 883/2000\n",
            "300/300 [==============================] - 0s 102us/step - loss: 0.2680 - precision: 1.0000 - recall: 0.7967 - f1_score: 0.8865 - val_loss: 0.2953 - val_precision: 1.0000 - val_recall: 0.7833 - val_f1_score: 0.8785\n",
            "Epoch 884/2000\n",
            "300/300 [==============================] - 0s 109us/step - loss: 0.2679 - precision: 1.0000 - recall: 0.7900 - f1_score: 0.8825 - val_loss: 0.2954 - val_precision: 1.0000 - val_recall: 0.7833 - val_f1_score: 0.8785\n",
            "Epoch 885/2000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.2677 - precision: 1.0000 - recall: 0.7967 - f1_score: 0.8866 - val_loss: 0.2953 - val_precision: 1.0000 - val_recall: 0.7833 - val_f1_score: 0.8785\n",
            "Epoch 886/2000\n",
            "300/300 [==============================] - 0s 102us/step - loss: 0.2675 - precision: 1.0000 - recall: 0.7967 - f1_score: 0.8865 - val_loss: 0.2950 - val_precision: 1.0000 - val_recall: 0.7833 - val_f1_score: 0.8785\n",
            "Epoch 887/2000\n",
            "300/300 [==============================] - 0s 101us/step - loss: 0.2674 - precision: 1.0000 - recall: 0.7967 - f1_score: 0.8863 - val_loss: 0.2947 - val_precision: 1.0000 - val_recall: 0.7833 - val_f1_score: 0.8785\n",
            "Epoch 888/2000\n",
            "300/300 [==============================] - 0s 104us/step - loss: 0.2672 - precision: 1.0000 - recall: 0.7933 - f1_score: 0.8837 - val_loss: 0.2944 - val_precision: 1.0000 - val_recall: 0.7833 - val_f1_score: 0.8785\n",
            "Epoch 889/2000\n",
            "300/300 [==============================] - 0s 104us/step - loss: 0.2670 - precision: 1.0000 - recall: 0.7933 - f1_score: 0.8840 - val_loss: 0.2943 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 890/2000\n",
            "300/300 [==============================] - 0s 114us/step - loss: 0.2671 - precision: 1.0000 - recall: 0.7967 - f1_score: 0.8864 - val_loss: 0.2941 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 891/2000\n",
            "300/300 [==============================] - 0s 109us/step - loss: 0.2667 - precision: 1.0000 - recall: 0.7933 - f1_score: 0.8843 - val_loss: 0.2940 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 892/2000\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.2666 - precision: 1.0000 - recall: 0.7900 - f1_score: 0.8815 - val_loss: 0.2938 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 893/2000\n",
            "300/300 [==============================] - 0s 102us/step - loss: 0.2667 - precision: 1.0000 - recall: 0.7933 - f1_score: 0.8846 - val_loss: 0.2937 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 894/2000\n",
            "300/300 [==============================] - 0s 106us/step - loss: 0.2664 - precision: 1.0000 - recall: 0.7933 - f1_score: 0.8844 - val_loss: 0.2937 - val_precision: 1.0000 - val_recall: 0.7833 - val_f1_score: 0.8785\n",
            "Epoch 895/2000\n",
            "300/300 [==============================] - 0s 108us/step - loss: 0.2663 - precision: 1.0000 - recall: 0.7967 - f1_score: 0.8860 - val_loss: 0.2934 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 896/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.2662 - precision: 1.0000 - recall: 0.8000 - f1_score: 0.8870 - val_loss: 0.2932 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 897/2000\n",
            "300/300 [==============================] - 0s 104us/step - loss: 0.2659 - precision: 1.0000 - recall: 0.7933 - f1_score: 0.8845 - val_loss: 0.2931 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 898/2000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.2658 - precision: 1.0000 - recall: 0.7967 - f1_score: 0.8860 - val_loss: 0.2931 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 899/2000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.2659 - precision: 1.0000 - recall: 0.8000 - f1_score: 0.8883 - val_loss: 0.2930 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 900/2000\n",
            "300/300 [==============================] - 0s 114us/step - loss: 0.2657 - precision: 1.0000 - recall: 0.7967 - f1_score: 0.8848 - val_loss: 0.2932 - val_precision: 1.0000 - val_recall: 0.7833 - val_f1_score: 0.8785\n",
            "Epoch 901/2000\n",
            "300/300 [==============================] - 0s 110us/step - loss: 0.2654 - precision: 1.0000 - recall: 0.7967 - f1_score: 0.8860 - val_loss: 0.2931 - val_precision: 1.0000 - val_recall: 0.7833 - val_f1_score: 0.8785\n",
            "Epoch 902/2000\n",
            "300/300 [==============================] - 0s 118us/step - loss: 0.2653 - precision: 1.0000 - recall: 0.7933 - f1_score: 0.8842 - val_loss: 0.2929 - val_precision: 1.0000 - val_recall: 0.7833 - val_f1_score: 0.8785\n",
            "Epoch 903/2000\n",
            "300/300 [==============================] - 0s 111us/step - loss: 0.2654 - precision: 1.0000 - recall: 0.7867 - f1_score: 0.8804 - val_loss: 0.2926 - val_precision: 1.0000 - val_recall: 0.7833 - val_f1_score: 0.8785\n",
            "Epoch 904/2000\n",
            "300/300 [==============================] - 0s 101us/step - loss: 0.2650 - precision: 1.0000 - recall: 0.7933 - f1_score: 0.8843 - val_loss: 0.2926 - val_precision: 1.0000 - val_recall: 0.7833 - val_f1_score: 0.8785\n",
            "Epoch 905/2000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.2649 - precision: 1.0000 - recall: 0.8000 - f1_score: 0.8879 - val_loss: 0.2924 - val_precision: 1.0000 - val_recall: 0.7833 - val_f1_score: 0.8785\n",
            "Epoch 906/2000\n",
            "300/300 [==============================] - 0s 117us/step - loss: 0.2649 - precision: 1.0000 - recall: 0.7933 - f1_score: 0.8843 - val_loss: 0.2921 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 907/2000\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.2648 - precision: 1.0000 - recall: 0.7967 - f1_score: 0.8860 - val_loss: 0.2921 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 908/2000\n",
            "300/300 [==============================] - 0s 114us/step - loss: 0.2645 - precision: 1.0000 - recall: 0.8000 - f1_score: 0.8882 - val_loss: 0.2918 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 909/2000\n",
            "300/300 [==============================] - 0s 110us/step - loss: 0.2645 - precision: 1.0000 - recall: 0.8000 - f1_score: 0.8878 - val_loss: 0.2917 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 910/2000\n",
            "300/300 [==============================] - 0s 115us/step - loss: 0.2643 - precision: 1.0000 - recall: 0.7967 - f1_score: 0.8866 - val_loss: 0.2913 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 911/2000\n",
            "300/300 [==============================] - 0s 101us/step - loss: 0.2642 - precision: 1.0000 - recall: 0.8033 - f1_score: 0.8902 - val_loss: 0.2909 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 912/2000\n",
            "300/300 [==============================] - 0s 110us/step - loss: 0.2644 - precision: 1.0000 - recall: 0.7900 - f1_score: 0.8816 - val_loss: 0.2908 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 913/2000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.2638 - precision: 1.0000 - recall: 0.8033 - f1_score: 0.8903 - val_loss: 0.2907 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 914/2000\n",
            "300/300 [==============================] - 0s 113us/step - loss: 0.2637 - precision: 1.0000 - recall: 0.8033 - f1_score: 0.8906 - val_loss: 0.2906 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 915/2000\n",
            "300/300 [==============================] - 0s 107us/step - loss: 0.2636 - precision: 1.0000 - recall: 0.8067 - f1_score: 0.8920 - val_loss: 0.2904 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 916/2000\n",
            "300/300 [==============================] - 0s 104us/step - loss: 0.2635 - precision: 1.0000 - recall: 0.7967 - f1_score: 0.8861 - val_loss: 0.2902 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 917/2000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.2633 - precision: 1.0000 - recall: 0.8000 - f1_score: 0.8883 - val_loss: 0.2901 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 918/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.2634 - precision: 1.0000 - recall: 0.8033 - f1_score: 0.8903 - val_loss: 0.2900 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 919/2000\n",
            "300/300 [==============================] - 0s 105us/step - loss: 0.2632 - precision: 1.0000 - recall: 0.8033 - f1_score: 0.8902 - val_loss: 0.2901 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 920/2000\n",
            "300/300 [==============================] - 0s 105us/step - loss: 0.2629 - precision: 1.0000 - recall: 0.8067 - f1_score: 0.8917 - val_loss: 0.2899 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 921/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.2631 - precision: 1.0000 - recall: 0.8000 - f1_score: 0.8871 - val_loss: 0.2897 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 922/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.2627 - precision: 1.0000 - recall: 0.8033 - f1_score: 0.8905 - val_loss: 0.2895 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 923/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.2625 - precision: 1.0000 - recall: 0.8033 - f1_score: 0.8908 - val_loss: 0.2894 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 924/2000\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.2625 - precision: 1.0000 - recall: 0.8100 - f1_score: 0.8949 - val_loss: 0.2890 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 925/2000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.2623 - precision: 1.0000 - recall: 0.8033 - f1_score: 0.8905 - val_loss: 0.2890 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 926/2000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.2623 - precision: 1.0000 - recall: 0.8033 - f1_score: 0.8905 - val_loss: 0.2890 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 927/2000\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.2621 - precision: 1.0000 - recall: 0.8000 - f1_score: 0.8887 - val_loss: 0.2888 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 928/2000\n",
            "300/300 [==============================] - 0s 105us/step - loss: 0.2622 - precision: 1.0000 - recall: 0.8033 - f1_score: 0.8894 - val_loss: 0.2886 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 929/2000\n",
            "300/300 [==============================] - 0s 103us/step - loss: 0.2618 - precision: 1.0000 - recall: 0.8067 - f1_score: 0.8925 - val_loss: 0.2886 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 930/2000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.2617 - precision: 1.0000 - recall: 0.8067 - f1_score: 0.8925 - val_loss: 0.2885 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 931/2000\n",
            "300/300 [==============================] - 0s 108us/step - loss: 0.2616 - precision: 1.0000 - recall: 0.8033 - f1_score: 0.8901 - val_loss: 0.2884 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 932/2000\n",
            "300/300 [==============================] - 0s 112us/step - loss: 0.2615 - precision: 1.0000 - recall: 0.8067 - f1_score: 0.8926 - val_loss: 0.2884 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 933/2000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.2613 - precision: 1.0000 - recall: 0.8033 - f1_score: 0.8905 - val_loss: 0.2884 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 934/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.2612 - precision: 1.0000 - recall: 0.8133 - f1_score: 0.8965 - val_loss: 0.2879 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 935/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.2611 - precision: 1.0000 - recall: 0.8033 - f1_score: 0.8907 - val_loss: 0.2880 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 936/2000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.2609 - precision: 1.0000 - recall: 0.8067 - f1_score: 0.8912 - val_loss: 0.2878 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 937/2000\n",
            "300/300 [==============================] - 0s 117us/step - loss: 0.2610 - precision: 1.0000 - recall: 0.7967 - f1_score: 0.8858 - val_loss: 0.2878 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 938/2000\n",
            "300/300 [==============================] - 0s 112us/step - loss: 0.2608 - precision: 1.0000 - recall: 0.8133 - f1_score: 0.8960 - val_loss: 0.2877 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 939/2000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.2608 - precision: 1.0000 - recall: 0.8100 - f1_score: 0.8945 - val_loss: 0.2875 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 940/2000\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.2604 - precision: 1.0000 - recall: 0.8100 - f1_score: 0.8931 - val_loss: 0.2874 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 941/2000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.2605 - precision: 1.0000 - recall: 0.8133 - f1_score: 0.8960 - val_loss: 0.2872 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 942/2000\n",
            "300/300 [==============================] - 0s 101us/step - loss: 0.2602 - precision: 1.0000 - recall: 0.8067 - f1_score: 0.8927 - val_loss: 0.2871 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 943/2000\n",
            "300/300 [==============================] - 0s 101us/step - loss: 0.2602 - precision: 1.0000 - recall: 0.8100 - f1_score: 0.8949 - val_loss: 0.2873 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 944/2000\n",
            "300/300 [==============================] - 0s 115us/step - loss: 0.2600 - precision: 1.0000 - recall: 0.8133 - f1_score: 0.8964 - val_loss: 0.2872 - val_precision: 1.0000 - val_recall: 0.7833 - val_f1_score: 0.8785\n",
            "Epoch 945/2000\n",
            "300/300 [==============================] - 0s 109us/step - loss: 0.2598 - precision: 1.0000 - recall: 0.8167 - f1_score: 0.8979 - val_loss: 0.2868 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 946/2000\n",
            "300/300 [==============================] - 0s 113us/step - loss: 0.2599 - precision: 1.0000 - recall: 0.8267 - f1_score: 0.9042 - val_loss: 0.2865 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 947/2000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.2596 - precision: 1.0000 - recall: 0.8133 - f1_score: 0.8969 - val_loss: 0.2864 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 948/2000\n",
            "300/300 [==============================] - 0s 107us/step - loss: 0.2594 - precision: 1.0000 - recall: 0.8200 - f1_score: 0.9005 - val_loss: 0.2862 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 949/2000\n",
            "300/300 [==============================] - 0s 101us/step - loss: 0.2593 - precision: 1.0000 - recall: 0.8100 - f1_score: 0.8948 - val_loss: 0.2860 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 950/2000\n",
            "300/300 [==============================] - 0s 103us/step - loss: 0.2592 - precision: 1.0000 - recall: 0.8233 - f1_score: 0.9026 - val_loss: 0.2859 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 951/2000\n",
            "300/300 [==============================] - 0s 104us/step - loss: 0.2593 - precision: 1.0000 - recall: 0.8067 - f1_score: 0.8928 - val_loss: 0.2857 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 952/2000\n",
            "300/300 [==============================] - 0s 105us/step - loss: 0.2591 - precision: 1.0000 - recall: 0.8100 - f1_score: 0.8935 - val_loss: 0.2857 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 953/2000\n",
            "300/300 [==============================] - 0s 122us/step - loss: 0.2588 - precision: 1.0000 - recall: 0.8233 - f1_score: 0.9024 - val_loss: 0.2856 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 954/2000\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.2587 - precision: 1.0000 - recall: 0.8200 - f1_score: 0.8984 - val_loss: 0.2853 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 955/2000\n",
            "300/300 [==============================] - 0s 105us/step - loss: 0.2587 - precision: 1.0000 - recall: 0.8167 - f1_score: 0.8970 - val_loss: 0.2849 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 956/2000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.2587 - precision: 1.0000 - recall: 0.8067 - f1_score: 0.8927 - val_loss: 0.2847 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 957/2000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.2582 - precision: 1.0000 - recall: 0.8067 - f1_score: 0.8924 - val_loss: 0.2847 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 958/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.2582 - precision: 1.0000 - recall: 0.8100 - f1_score: 0.8940 - val_loss: 0.2845 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 959/2000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.2583 - precision: 1.0000 - recall: 0.8100 - f1_score: 0.8950 - val_loss: 0.2847 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 960/2000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.2583 - precision: 1.0000 - recall: 0.8233 - f1_score: 0.9023 - val_loss: 0.2843 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 961/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.2578 - precision: 1.0000 - recall: 0.8233 - f1_score: 0.9028 - val_loss: 0.2841 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 962/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.2578 - precision: 1.0000 - recall: 0.8100 - f1_score: 0.8940 - val_loss: 0.2841 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 963/2000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.2579 - precision: 1.0000 - recall: 0.8133 - f1_score: 0.8967 - val_loss: 0.2838 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 964/2000\n",
            "300/300 [==============================] - 0s 110us/step - loss: 0.2575 - precision: 1.0000 - recall: 0.8067 - f1_score: 0.8922 - val_loss: 0.2838 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 965/2000\n",
            "300/300 [==============================] - 0s 108us/step - loss: 0.2573 - precision: 1.0000 - recall: 0.8233 - f1_score: 0.9031 - val_loss: 0.2836 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 966/2000\n",
            "300/300 [==============================] - 0s 104us/step - loss: 0.2574 - precision: 1.0000 - recall: 0.8100 - f1_score: 0.8942 - val_loss: 0.2838 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 967/2000\n",
            "300/300 [==============================] - 0s 114us/step - loss: 0.2570 - precision: 1.0000 - recall: 0.8267 - f1_score: 0.9050 - val_loss: 0.2836 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 968/2000\n",
            "300/300 [==============================] - 0s 131us/step - loss: 0.2569 - precision: 1.0000 - recall: 0.8267 - f1_score: 0.9045 - val_loss: 0.2833 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 969/2000\n",
            "300/300 [==============================] - 0s 104us/step - loss: 0.2570 - precision: 1.0000 - recall: 0.8200 - f1_score: 0.9004 - val_loss: 0.2833 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 970/2000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.2568 - precision: 1.0000 - recall: 0.8133 - f1_score: 0.8960 - val_loss: 0.2834 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 971/2000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.2566 - precision: 1.0000 - recall: 0.8233 - f1_score: 0.9023 - val_loss: 0.2832 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 972/2000\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.2565 - precision: 1.0000 - recall: 0.8233 - f1_score: 0.9030 - val_loss: 0.2829 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 973/2000\n",
            "300/300 [==============================] - 0s 110us/step - loss: 0.2564 - precision: 1.0000 - recall: 0.8200 - f1_score: 0.8994 - val_loss: 0.2826 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 974/2000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.2562 - precision: 1.0000 - recall: 0.8233 - f1_score: 0.9025 - val_loss: 0.2823 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 975/2000\n",
            "300/300 [==============================] - 0s 110us/step - loss: 0.2561 - precision: 1.0000 - recall: 0.8167 - f1_score: 0.8985 - val_loss: 0.2823 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 976/2000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.2559 - precision: 1.0000 - recall: 0.8167 - f1_score: 0.8985 - val_loss: 0.2821 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 977/2000\n",
            "300/300 [==============================] - 0s 114us/step - loss: 0.2558 - precision: 1.0000 - recall: 0.8200 - f1_score: 0.9009 - val_loss: 0.2818 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 978/2000\n",
            "300/300 [==============================] - 0s 117us/step - loss: 0.2558 - precision: 1.0000 - recall: 0.8200 - f1_score: 0.9002 - val_loss: 0.2816 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 979/2000\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.2557 - precision: 1.0000 - recall: 0.8167 - f1_score: 0.8980 - val_loss: 0.2816 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 980/2000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.2556 - precision: 1.0000 - recall: 0.8133 - f1_score: 0.8968 - val_loss: 0.2817 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 981/2000\n",
            "300/300 [==============================] - 0s 109us/step - loss: 0.2555 - precision: 1.0000 - recall: 0.8200 - f1_score: 0.8999 - val_loss: 0.2815 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 982/2000\n",
            "300/300 [==============================] - 0s 116us/step - loss: 0.2552 - precision: 1.0000 - recall: 0.8233 - f1_score: 0.9030 - val_loss: 0.2813 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 983/2000\n",
            "300/300 [==============================] - 0s 103us/step - loss: 0.2552 - precision: 1.0000 - recall: 0.8200 - f1_score: 0.9009 - val_loss: 0.2813 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 984/2000\n",
            "300/300 [==============================] - 0s 102us/step - loss: 0.2552 - precision: 1.0000 - recall: 0.8233 - f1_score: 0.9029 - val_loss: 0.2809 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 985/2000\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.2550 - precision: 1.0000 - recall: 0.8300 - f1_score: 0.9064 - val_loss: 0.2806 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 986/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.2548 - precision: 1.0000 - recall: 0.8267 - f1_score: 0.9043 - val_loss: 0.2803 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 987/2000\n",
            "300/300 [==============================] - 0s 108us/step - loss: 0.2547 - precision: 1.0000 - recall: 0.8100 - f1_score: 0.8947 - val_loss: 0.2804 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 988/2000\n",
            "300/300 [==============================] - 0s 106us/step - loss: 0.2545 - precision: 1.0000 - recall: 0.8100 - f1_score: 0.8949 - val_loss: 0.2806 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 989/2000\n",
            "300/300 [==============================] - 0s 104us/step - loss: 0.2544 - precision: 1.0000 - recall: 0.8200 - f1_score: 0.9001 - val_loss: 0.2805 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 990/2000\n",
            "300/300 [==============================] - 0s 117us/step - loss: 0.2543 - precision: 1.0000 - recall: 0.8267 - f1_score: 0.9048 - val_loss: 0.2803 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 991/2000\n",
            "300/300 [==============================] - 0s 102us/step - loss: 0.2541 - precision: 1.0000 - recall: 0.8267 - f1_score: 0.9041 - val_loss: 0.2803 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 992/2000\n",
            "300/300 [==============================] - 0s 109us/step - loss: 0.2541 - precision: 1.0000 - recall: 0.8333 - f1_score: 0.9086 - val_loss: 0.2799 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 993/2000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.2539 - precision: 1.0000 - recall: 0.8267 - f1_score: 0.9044 - val_loss: 0.2798 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 994/2000\n",
            "300/300 [==============================] - 0s 108us/step - loss: 0.2538 - precision: 1.0000 - recall: 0.8200 - f1_score: 0.9001 - val_loss: 0.2797 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 995/2000\n",
            "300/300 [==============================] - 0s 117us/step - loss: 0.2537 - precision: 1.0000 - recall: 0.8167 - f1_score: 0.8988 - val_loss: 0.2797 - val_precision: 1.0000 - val_recall: 0.8167 - val_f1_score: 0.8991\n",
            "Epoch 996/2000\n",
            "300/300 [==============================] - 0s 112us/step - loss: 0.2535 - precision: 1.0000 - recall: 0.8300 - f1_score: 0.9068 - val_loss: 0.2795 - val_precision: 1.0000 - val_recall: 0.8167 - val_f1_score: 0.8991\n",
            "Epoch 997/2000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.2534 - precision: 1.0000 - recall: 0.8300 - f1_score: 0.9064 - val_loss: 0.2795 - val_precision: 1.0000 - val_recall: 0.8167 - val_f1_score: 0.8991\n",
            "Epoch 998/2000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.2536 - precision: 1.0000 - recall: 0.8400 - f1_score: 0.9125 - val_loss: 0.2791 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 999/2000\n",
            "300/300 [==============================] - 0s 101us/step - loss: 0.2533 - precision: 1.0000 - recall: 0.8200 - f1_score: 0.9009 - val_loss: 0.2791 - val_precision: 1.0000 - val_recall: 0.8167 - val_f1_score: 0.8991\n",
            "Epoch 1000/2000\n",
            "300/300 [==============================] - 0s 106us/step - loss: 0.2531 - precision: 1.0000 - recall: 0.8333 - f1_score: 0.9083 - val_loss: 0.2789 - val_precision: 1.0000 - val_recall: 0.8167 - val_f1_score: 0.8991\n",
            "Epoch 1001/2000\n",
            "300/300 [==============================] - 0s 103us/step - loss: 0.2533 - precision: 1.0000 - recall: 0.8233 - f1_score: 0.9031 - val_loss: 0.2792 - val_precision: 1.0000 - val_recall: 0.8333 - val_f1_score: 0.9091\n",
            "Epoch 1002/2000\n",
            "300/300 [==============================] - 0s 107us/step - loss: 0.2530 - precision: 1.0000 - recall: 0.8400 - f1_score: 0.9109 - val_loss: 0.2788 - val_precision: 1.0000 - val_recall: 0.8333 - val_f1_score: 0.9091\n",
            "Epoch 1003/2000\n",
            "300/300 [==============================] - 0s 117us/step - loss: 0.2527 - precision: 1.0000 - recall: 0.8300 - f1_score: 0.9064 - val_loss: 0.2787 - val_precision: 1.0000 - val_recall: 0.8333 - val_f1_score: 0.9091\n",
            "Epoch 1004/2000\n",
            "300/300 [==============================] - 0s 103us/step - loss: 0.2527 - precision: 1.0000 - recall: 0.8333 - f1_score: 0.9089 - val_loss: 0.2786 - val_precision: 1.0000 - val_recall: 0.8333 - val_f1_score: 0.9091\n",
            "Epoch 1005/2000\n",
            "300/300 [==============================] - 0s 113us/step - loss: 0.2526 - precision: 1.0000 - recall: 0.8400 - f1_score: 0.9125 - val_loss: 0.2782 - val_precision: 1.0000 - val_recall: 0.8167 - val_f1_score: 0.8991\n",
            "Epoch 1006/2000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.2525 - precision: 1.0000 - recall: 0.8267 - f1_score: 0.9049 - val_loss: 0.2782 - val_precision: 1.0000 - val_recall: 0.8333 - val_f1_score: 0.9091\n",
            "Epoch 1007/2000\n",
            "300/300 [==============================] - 0s 103us/step - loss: 0.2523 - precision: 1.0000 - recall: 0.8367 - f1_score: 0.9104 - val_loss: 0.2781 - val_precision: 1.0000 - val_recall: 0.8333 - val_f1_score: 0.9091\n",
            "Epoch 1008/2000\n",
            "300/300 [==============================] - 0s 106us/step - loss: 0.2522 - precision: 1.0000 - recall: 0.8333 - f1_score: 0.9082 - val_loss: 0.2781 - val_precision: 1.0000 - val_recall: 0.8333 - val_f1_score: 0.9091\n",
            "Epoch 1009/2000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.2521 - precision: 1.0000 - recall: 0.8300 - f1_score: 0.9061 - val_loss: 0.2781 - val_precision: 1.0000 - val_recall: 0.8333 - val_f1_score: 0.9091\n",
            "Epoch 1010/2000\n",
            "300/300 [==============================] - 0s 103us/step - loss: 0.2519 - precision: 1.0000 - recall: 0.8333 - f1_score: 0.9088 - val_loss: 0.2777 - val_precision: 1.0000 - val_recall: 0.8333 - val_f1_score: 0.9091\n",
            "Epoch 1011/2000\n",
            "300/300 [==============================] - 0s 115us/step - loss: 0.2518 - precision: 1.0000 - recall: 0.8300 - f1_score: 0.9064 - val_loss: 0.2775 - val_precision: 1.0000 - val_recall: 0.8167 - val_f1_score: 0.8991\n",
            "Epoch 1012/2000\n",
            "300/300 [==============================] - 0s 108us/step - loss: 0.2517 - precision: 1.0000 - recall: 0.8300 - f1_score: 0.9066 - val_loss: 0.2774 - val_precision: 1.0000 - val_recall: 0.8167 - val_f1_score: 0.8991\n",
            "Epoch 1013/2000\n",
            "300/300 [==============================] - 0s 102us/step - loss: 0.2516 - precision: 1.0000 - recall: 0.8367 - f1_score: 0.9102 - val_loss: 0.2772 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 1014/2000\n",
            "300/300 [==============================] - 0s 106us/step - loss: 0.2516 - precision: 1.0000 - recall: 0.8267 - f1_score: 0.9036 - val_loss: 0.2771 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 1015/2000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.2518 - precision: 1.0000 - recall: 0.8267 - f1_score: 0.9048 - val_loss: 0.2766 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 1016/2000\n",
            "300/300 [==============================] - 0s 113us/step - loss: 0.2513 - precision: 1.0000 - recall: 0.8233 - f1_score: 0.9024 - val_loss: 0.2767 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 1017/2000\n",
            "300/300 [==============================] - 0s 114us/step - loss: 0.2511 - precision: 1.0000 - recall: 0.8300 - f1_score: 0.9065 - val_loss: 0.2765 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 1018/2000\n",
            "300/300 [==============================] - 0s 102us/step - loss: 0.2511 - precision: 1.0000 - recall: 0.8200 - f1_score: 0.9006 - val_loss: 0.2766 - val_precision: 1.0000 - val_recall: 0.8167 - val_f1_score: 0.8991\n",
            "Epoch 1019/2000\n",
            "300/300 [==============================] - 0s 114us/step - loss: 0.2510 - precision: 1.0000 - recall: 0.8367 - f1_score: 0.9102 - val_loss: 0.2764 - val_precision: 1.0000 - val_recall: 0.8167 - val_f1_score: 0.8991\n",
            "Epoch 1020/2000\n",
            "300/300 [==============================] - 0s 107us/step - loss: 0.2510 - precision: 1.0000 - recall: 0.8400 - f1_score: 0.9125 - val_loss: 0.2761 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 1021/2000\n",
            "300/300 [==============================] - 0s 108us/step - loss: 0.2506 - precision: 1.0000 - recall: 0.8267 - f1_score: 0.9045 - val_loss: 0.2760 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 1022/2000\n",
            "300/300 [==============================] - 0s 107us/step - loss: 0.2505 - precision: 1.0000 - recall: 0.8333 - f1_score: 0.9083 - val_loss: 0.2759 - val_precision: 1.0000 - val_recall: 0.8167 - val_f1_score: 0.8991\n",
            "Epoch 1023/2000\n",
            "300/300 [==============================] - 0s 106us/step - loss: 0.2504 - precision: 1.0000 - recall: 0.8333 - f1_score: 0.9085 - val_loss: 0.2758 - val_precision: 1.0000 - val_recall: 0.8167 - val_f1_score: 0.8991\n",
            "Epoch 1024/2000\n",
            "300/300 [==============================] - 0s 112us/step - loss: 0.2503 - precision: 1.0000 - recall: 0.8300 - f1_score: 0.9070 - val_loss: 0.2757 - val_precision: 1.0000 - val_recall: 0.8167 - val_f1_score: 0.8991\n",
            "Epoch 1025/2000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.2502 - precision: 1.0000 - recall: 0.8367 - f1_score: 0.9103 - val_loss: 0.2755 - val_precision: 1.0000 - val_recall: 0.8167 - val_f1_score: 0.8991\n",
            "Epoch 1026/2000\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.2501 - precision: 1.0000 - recall: 0.8333 - f1_score: 0.9090 - val_loss: 0.2754 - val_precision: 1.0000 - val_recall: 0.8167 - val_f1_score: 0.8991\n",
            "Epoch 1027/2000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.2501 - precision: 1.0000 - recall: 0.8333 - f1_score: 0.9084 - val_loss: 0.2753 - val_precision: 1.0000 - val_recall: 0.8167 - val_f1_score: 0.8991\n",
            "Epoch 1028/2000\n",
            "300/300 [==============================] - 0s 110us/step - loss: 0.2498 - precision: 1.0000 - recall: 0.8400 - f1_score: 0.9128 - val_loss: 0.2751 - val_precision: 1.0000 - val_recall: 0.8167 - val_f1_score: 0.8991\n",
            "Epoch 1029/2000\n",
            "300/300 [==============================] - 0s 102us/step - loss: 0.2498 - precision: 1.0000 - recall: 0.8333 - f1_score: 0.9085 - val_loss: 0.2751 - val_precision: 1.0000 - val_recall: 0.8167 - val_f1_score: 0.8991\n",
            "Epoch 1030/2000\n",
            "300/300 [==============================] - 0s 106us/step - loss: 0.2498 - precision: 1.0000 - recall: 0.8400 - f1_score: 0.9128 - val_loss: 0.2747 - val_precision: 1.0000 - val_recall: 0.8167 - val_f1_score: 0.8991\n",
            "Epoch 1031/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.2496 - precision: 1.0000 - recall: 0.8400 - f1_score: 0.9126 - val_loss: 0.2745 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 1032/2000\n",
            "300/300 [==============================] - 0s 112us/step - loss: 0.2495 - precision: 1.0000 - recall: 0.8267 - f1_score: 0.9047 - val_loss: 0.2746 - val_precision: 1.0000 - val_recall: 0.8167 - val_f1_score: 0.8991\n",
            "Epoch 1033/2000\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.2493 - precision: 1.0000 - recall: 0.8367 - f1_score: 0.9104 - val_loss: 0.2746 - val_precision: 1.0000 - val_recall: 0.8333 - val_f1_score: 0.9091\n",
            "Epoch 1034/2000\n",
            "300/300 [==============================] - 0s 125us/step - loss: 0.2492 - precision: 1.0000 - recall: 0.8367 - f1_score: 0.9100 - val_loss: 0.2744 - val_precision: 1.0000 - val_recall: 0.8167 - val_f1_score: 0.8991\n",
            "Epoch 1035/2000\n",
            "300/300 [==============================] - 0s 148us/step - loss: 0.2491 - precision: 1.0000 - recall: 0.8300 - f1_score: 0.9068 - val_loss: 0.2745 - val_precision: 1.0000 - val_recall: 0.8333 - val_f1_score: 0.9091\n",
            "Epoch 1036/2000\n",
            "300/300 [==============================] - 0s 102us/step - loss: 0.2490 - precision: 1.0000 - recall: 0.8333 - f1_score: 0.9088 - val_loss: 0.2745 - val_precision: 1.0000 - val_recall: 0.8333 - val_f1_score: 0.9091\n",
            "Epoch 1037/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.2488 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9208 - val_loss: 0.2741 - val_precision: 1.0000 - val_recall: 0.8333 - val_f1_score: 0.9091\n",
            "Epoch 1038/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.2489 - precision: 1.0000 - recall: 0.8433 - f1_score: 0.9140 - val_loss: 0.2737 - val_precision: 1.0000 - val_recall: 0.8167 - val_f1_score: 0.8991\n",
            "Epoch 1039/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.2489 - precision: 1.0000 - recall: 0.8300 - f1_score: 0.9060 - val_loss: 0.2737 - val_precision: 1.0000 - val_recall: 0.8167 - val_f1_score: 0.8991\n",
            "Epoch 1040/2000\n",
            "300/300 [==============================] - 0s 106us/step - loss: 0.2485 - precision: 1.0000 - recall: 0.8300 - f1_score: 0.9069 - val_loss: 0.2736 - val_precision: 1.0000 - val_recall: 0.8333 - val_f1_score: 0.9091\n",
            "Epoch 1041/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.2486 - precision: 1.0000 - recall: 0.8500 - f1_score: 0.9188 - val_loss: 0.2734 - val_precision: 1.0000 - val_recall: 0.8167 - val_f1_score: 0.8991\n",
            "Epoch 1042/2000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.2483 - precision: 1.0000 - recall: 0.8367 - f1_score: 0.9104 - val_loss: 0.2734 - val_precision: 1.0000 - val_recall: 0.8333 - val_f1_score: 0.9091\n",
            "Epoch 1043/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.2484 - precision: 1.0000 - recall: 0.8467 - f1_score: 0.9164 - val_loss: 0.2730 - val_precision: 1.0000 - val_recall: 0.8167 - val_f1_score: 0.8991\n",
            "Epoch 1044/2000\n",
            "300/300 [==============================] - 0s 103us/step - loss: 0.2481 - precision: 1.0000 - recall: 0.8333 - f1_score: 0.9086 - val_loss: 0.2729 - val_precision: 1.0000 - val_recall: 0.8333 - val_f1_score: 0.9091\n",
            "Epoch 1045/2000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.2480 - precision: 1.0000 - recall: 0.8300 - f1_score: 0.9058 - val_loss: 0.2727 - val_precision: 1.0000 - val_recall: 0.8167 - val_f1_score: 0.8991\n",
            "Epoch 1046/2000\n",
            "300/300 [==============================] - 0s 104us/step - loss: 0.2478 - precision: 1.0000 - recall: 0.8333 - f1_score: 0.9088 - val_loss: 0.2726 - val_precision: 1.0000 - val_recall: 0.8167 - val_f1_score: 0.8991\n",
            "Epoch 1047/2000\n",
            "300/300 [==============================] - 0s 106us/step - loss: 0.2477 - precision: 1.0000 - recall: 0.8367 - f1_score: 0.9110 - val_loss: 0.2724 - val_precision: 1.0000 - val_recall: 0.8167 - val_f1_score: 0.8991\n",
            "Epoch 1048/2000\n",
            "300/300 [==============================] - 0s 101us/step - loss: 0.2476 - precision: 1.0000 - recall: 0.8433 - f1_score: 0.9139 - val_loss: 0.2722 - val_precision: 1.0000 - val_recall: 0.8167 - val_f1_score: 0.8991\n",
            "Epoch 1049/2000\n",
            "300/300 [==============================] - 0s 109us/step - loss: 0.2477 - precision: 1.0000 - recall: 0.8267 - f1_score: 0.9041 - val_loss: 0.2721 - val_precision: 1.0000 - val_recall: 0.8167 - val_f1_score: 0.8991\n",
            "Epoch 1050/2000\n",
            "300/300 [==============================] - 0s 109us/step - loss: 0.2476 - precision: 1.0000 - recall: 0.8467 - f1_score: 0.9158 - val_loss: 0.2718 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 1051/2000\n",
            "300/300 [==============================] - 0s 119us/step - loss: 0.2474 - precision: 1.0000 - recall: 0.8367 - f1_score: 0.9107 - val_loss: 0.2716 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 1052/2000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.2473 - precision: 1.0000 - recall: 0.8300 - f1_score: 0.9066 - val_loss: 0.2715 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 1053/2000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.2471 - precision: 1.0000 - recall: 0.8267 - f1_score: 0.9049 - val_loss: 0.2715 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1_score: 0.8889\n",
            "Epoch 1054/2000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.2470 - precision: 1.0000 - recall: 0.8367 - f1_score: 0.9109 - val_loss: 0.2714 - val_precision: 1.0000 - val_recall: 0.8167 - val_f1_score: 0.8991\n",
            "Epoch 1055/2000\n",
            "300/300 [==============================] - 0s 119us/step - loss: 0.2468 - precision: 1.0000 - recall: 0.8333 - f1_score: 0.9086 - val_loss: 0.2715 - val_precision: 1.0000 - val_recall: 0.8333 - val_f1_score: 0.9091\n",
            "Epoch 1056/2000\n",
            "300/300 [==============================] - 0s 117us/step - loss: 0.2470 - precision: 1.0000 - recall: 0.8400 - f1_score: 0.9119 - val_loss: 0.2715 - val_precision: 1.0000 - val_recall: 0.8333 - val_f1_score: 0.9091\n",
            "Epoch 1057/2000\n",
            "300/300 [==============================] - 0s 103us/step - loss: 0.2467 - precision: 1.0000 - recall: 0.8433 - f1_score: 0.9146 - val_loss: 0.2712 - val_precision: 1.0000 - val_recall: 0.8167 - val_f1_score: 0.8991\n",
            "Epoch 1058/2000\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.2465 - precision: 1.0000 - recall: 0.8367 - f1_score: 0.9107 - val_loss: 0.2710 - val_precision: 1.0000 - val_recall: 0.8167 - val_f1_score: 0.8991\n",
            "Epoch 1059/2000\n",
            "300/300 [==============================] - 0s 107us/step - loss: 0.2464 - precision: 1.0000 - recall: 0.8333 - f1_score: 0.9087 - val_loss: 0.2710 - val_precision: 1.0000 - val_recall: 0.8333 - val_f1_score: 0.9091\n",
            "Epoch 1060/2000\n",
            "300/300 [==============================] - 0s 114us/step - loss: 0.2463 - precision: 1.0000 - recall: 0.8367 - f1_score: 0.9108 - val_loss: 0.2711 - val_precision: 1.0000 - val_recall: 0.8333 - val_f1_score: 0.9091\n",
            "Epoch 1061/2000\n",
            "300/300 [==============================] - 0s 105us/step - loss: 0.2462 - precision: 1.0000 - recall: 0.8433 - f1_score: 0.9146 - val_loss: 0.2712 - val_precision: 1.0000 - val_recall: 0.8333 - val_f1_score: 0.9091\n",
            "Epoch 1062/2000\n",
            "300/300 [==============================] - 0s 101us/step - loss: 0.2462 - precision: 1.0000 - recall: 0.8467 - f1_score: 0.9168 - val_loss: 0.2712 - val_precision: 1.0000 - val_recall: 0.8500 - val_f1_score: 0.9189\n",
            "Epoch 1063/2000\n",
            "300/300 [==============================] - 0s 102us/step - loss: 0.2460 - precision: 1.0000 - recall: 0.8567 - f1_score: 0.9220 - val_loss: 0.2710 - val_precision: 1.0000 - val_recall: 0.8500 - val_f1_score: 0.9189\n",
            "Epoch 1064/2000\n",
            "300/300 [==============================] - 0s 102us/step - loss: 0.2458 - precision: 1.0000 - recall: 0.8633 - f1_score: 0.9260 - val_loss: 0.2707 - val_precision: 1.0000 - val_recall: 0.8333 - val_f1_score: 0.9091\n",
            "Epoch 1065/2000\n",
            "300/300 [==============================] - 0s 103us/step - loss: 0.2462 - precision: 1.0000 - recall: 0.8600 - f1_score: 0.9243 - val_loss: 0.2709 - val_precision: 1.0000 - val_recall: 0.8500 - val_f1_score: 0.9189\n",
            "Epoch 1066/2000\n",
            "300/300 [==============================] - 0s 121us/step - loss: 0.2457 - precision: 1.0000 - recall: 0.8500 - f1_score: 0.9184 - val_loss: 0.2707 - val_precision: 1.0000 - val_recall: 0.8667 - val_f1_score: 0.9286\n",
            "Epoch 1067/2000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.2456 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9204 - val_loss: 0.2709 - val_precision: 1.0000 - val_recall: 0.8667 - val_f1_score: 0.9286\n",
            "Epoch 1068/2000\n",
            "300/300 [==============================] - 0s 112us/step - loss: 0.2454 - precision: 1.0000 - recall: 0.8633 - f1_score: 0.9257 - val_loss: 0.2706 - val_precision: 1.0000 - val_recall: 0.8667 - val_f1_score: 0.9286\n",
            "Epoch 1069/2000\n",
            "300/300 [==============================] - 0s 110us/step - loss: 0.2453 - precision: 1.0000 - recall: 0.8633 - f1_score: 0.9266 - val_loss: 0.2703 - val_precision: 1.0000 - val_recall: 0.8500 - val_f1_score: 0.9189\n",
            "Epoch 1070/2000\n",
            "300/300 [==============================] - 0s 102us/step - loss: 0.2453 - precision: 1.0000 - recall: 0.8567 - f1_score: 0.9224 - val_loss: 0.2702 - val_precision: 1.0000 - val_recall: 0.8667 - val_f1_score: 0.9286\n",
            "Epoch 1071/2000\n",
            "300/300 [==============================] - 0s 108us/step - loss: 0.2451 - precision: 1.0000 - recall: 0.8600 - f1_score: 0.9239 - val_loss: 0.2699 - val_precision: 1.0000 - val_recall: 0.8500 - val_f1_score: 0.9189\n",
            "Epoch 1072/2000\n",
            "300/300 [==============================] - 0s 106us/step - loss: 0.2450 - precision: 1.0000 - recall: 0.8500 - f1_score: 0.9184 - val_loss: 0.2700 - val_precision: 1.0000 - val_recall: 0.8667 - val_f1_score: 0.9286\n",
            "Epoch 1073/2000\n",
            "300/300 [==============================] - 0s 103us/step - loss: 0.2449 - precision: 1.0000 - recall: 0.8567 - f1_score: 0.9220 - val_loss: 0.2699 - val_precision: 1.0000 - val_recall: 0.8667 - val_f1_score: 0.9286\n",
            "Epoch 1074/2000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.2448 - precision: 1.0000 - recall: 0.8633 - f1_score: 0.9260 - val_loss: 0.2697 - val_precision: 1.0000 - val_recall: 0.8667 - val_f1_score: 0.9286\n",
            "Epoch 1075/2000\n",
            "300/300 [==============================] - 0s 115us/step - loss: 0.2448 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9205 - val_loss: 0.2696 - val_precision: 1.0000 - val_recall: 0.8667 - val_f1_score: 0.9286\n",
            "Epoch 1076/2000\n",
            "300/300 [==============================] - 0s 109us/step - loss: 0.2446 - precision: 1.0000 - recall: 0.8600 - f1_score: 0.9247 - val_loss: 0.2695 - val_precision: 1.0000 - val_recall: 0.8667 - val_f1_score: 0.9286\n",
            "Epoch 1077/2000\n",
            "300/300 [==============================] - 0s 109us/step - loss: 0.2447 - precision: 1.0000 - recall: 0.8500 - f1_score: 0.9188 - val_loss: 0.2694 - val_precision: 1.0000 - val_recall: 0.8667 - val_f1_score: 0.9286\n",
            "Epoch 1078/2000\n",
            "300/300 [==============================] - 0s 105us/step - loss: 0.2444 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9208 - val_loss: 0.2691 - val_precision: 1.0000 - val_recall: 0.8500 - val_f1_score: 0.9189\n",
            "Epoch 1079/2000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.2443 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9202 - val_loss: 0.2688 - val_precision: 1.0000 - val_recall: 0.8333 - val_f1_score: 0.9091\n",
            "Epoch 1080/2000\n",
            "300/300 [==============================] - 0s 104us/step - loss: 0.2441 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9206 - val_loss: 0.2687 - val_precision: 1.0000 - val_recall: 0.8500 - val_f1_score: 0.9189\n",
            "Epoch 1081/2000\n",
            "300/300 [==============================] - 0s 116us/step - loss: 0.2441 - precision: 1.0000 - recall: 0.8633 - f1_score: 0.9261 - val_loss: 0.2685 - val_precision: 1.0000 - val_recall: 0.8500 - val_f1_score: 0.9189\n",
            "Epoch 1082/2000\n",
            "300/300 [==============================] - 0s 102us/step - loss: 0.2440 - precision: 1.0000 - recall: 0.8500 - f1_score: 0.9186 - val_loss: 0.2684 - val_precision: 1.0000 - val_recall: 0.8500 - val_f1_score: 0.9189\n",
            "Epoch 1083/2000\n",
            "300/300 [==============================] - 0s 106us/step - loss: 0.2438 - precision: 1.0000 - recall: 0.8600 - f1_score: 0.9239 - val_loss: 0.2682 - val_precision: 1.0000 - val_recall: 0.8500 - val_f1_score: 0.9189\n",
            "Epoch 1084/2000\n",
            "300/300 [==============================] - 0s 118us/step - loss: 0.2440 - precision: 1.0000 - recall: 0.8633 - f1_score: 0.9265 - val_loss: 0.2679 - val_precision: 1.0000 - val_recall: 0.8333 - val_f1_score: 0.9091\n",
            "Epoch 1085/2000\n",
            "300/300 [==============================] - 0s 108us/step - loss: 0.2435 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9207 - val_loss: 0.2678 - val_precision: 1.0000 - val_recall: 0.8333 - val_f1_score: 0.9091\n",
            "Epoch 1086/2000\n",
            "300/300 [==============================] - 0s 106us/step - loss: 0.2434 - precision: 1.0000 - recall: 0.8500 - f1_score: 0.9174 - val_loss: 0.2677 - val_precision: 1.0000 - val_recall: 0.8333 - val_f1_score: 0.9091\n",
            "Epoch 1087/2000\n",
            "300/300 [==============================] - 0s 113us/step - loss: 0.2433 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9197 - val_loss: 0.2676 - val_precision: 1.0000 - val_recall: 0.8500 - val_f1_score: 0.9189\n",
            "Epoch 1088/2000\n",
            "300/300 [==============================] - 0s 104us/step - loss: 0.2433 - precision: 1.0000 - recall: 0.8500 - f1_score: 0.9180 - val_loss: 0.2674 - val_precision: 1.0000 - val_recall: 0.8333 - val_f1_score: 0.9091\n",
            "Epoch 1089/2000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.2433 - precision: 1.0000 - recall: 0.8500 - f1_score: 0.9182 - val_loss: 0.2675 - val_precision: 1.0000 - val_recall: 0.8500 - val_f1_score: 0.9189\n",
            "Epoch 1090/2000\n",
            "300/300 [==============================] - 0s 107us/step - loss: 0.2431 - precision: 1.0000 - recall: 0.8633 - f1_score: 0.9263 - val_loss: 0.2672 - val_precision: 1.0000 - val_recall: 0.8333 - val_f1_score: 0.9091\n",
            "Epoch 1091/2000\n",
            "300/300 [==============================] - 0s 104us/step - loss: 0.2430 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9206 - val_loss: 0.2670 - val_precision: 1.0000 - val_recall: 0.8333 - val_f1_score: 0.9091\n",
            "Epoch 1092/2000\n",
            "300/300 [==============================] - 0s 110us/step - loss: 0.2429 - precision: 1.0000 - recall: 0.8600 - f1_score: 0.9243 - val_loss: 0.2668 - val_precision: 1.0000 - val_recall: 0.8333 - val_f1_score: 0.9091\n",
            "Epoch 1093/2000\n",
            "300/300 [==============================] - 0s 106us/step - loss: 0.2429 - precision: 1.0000 - recall: 0.8367 - f1_score: 0.9107 - val_loss: 0.2667 - val_precision: 1.0000 - val_recall: 0.8333 - val_f1_score: 0.9091\n",
            "Epoch 1094/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.2426 - precision: 1.0000 - recall: 0.8433 - f1_score: 0.9144 - val_loss: 0.2667 - val_precision: 1.0000 - val_recall: 0.8333 - val_f1_score: 0.9091\n",
            "Epoch 1095/2000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.2425 - precision: 1.0000 - recall: 0.8500 - f1_score: 0.9179 - val_loss: 0.2667 - val_precision: 1.0000 - val_recall: 0.8500 - val_f1_score: 0.9189\n",
            "Epoch 1096/2000\n",
            "300/300 [==============================] - 0s 113us/step - loss: 0.2425 - precision: 1.0000 - recall: 0.8567 - f1_score: 0.9226 - val_loss: 0.2668 - val_precision: 1.0000 - val_recall: 0.8667 - val_f1_score: 0.9286\n",
            "Epoch 1097/2000\n",
            "300/300 [==============================] - 0s 124us/step - loss: 0.2424 - precision: 1.0000 - recall: 0.8633 - f1_score: 0.9262 - val_loss: 0.2666 - val_precision: 1.0000 - val_recall: 0.8667 - val_f1_score: 0.9286\n",
            "Epoch 1098/2000\n",
            "300/300 [==============================] - 0s 125us/step - loss: 0.2422 - precision: 1.0000 - recall: 0.8633 - f1_score: 0.9264 - val_loss: 0.2666 - val_precision: 1.0000 - val_recall: 0.8667 - val_f1_score: 0.9286\n",
            "Epoch 1099/2000\n",
            "300/300 [==============================] - 0s 114us/step - loss: 0.2421 - precision: 1.0000 - recall: 0.8600 - f1_score: 0.9244 - val_loss: 0.2665 - val_precision: 1.0000 - val_recall: 0.8667 - val_f1_score: 0.9286\n",
            "Epoch 1100/2000\n",
            "300/300 [==============================] - 0s 118us/step - loss: 0.2420 - precision: 1.0000 - recall: 0.8567 - f1_score: 0.9225 - val_loss: 0.2665 - val_precision: 1.0000 - val_recall: 0.8667 - val_f1_score: 0.9286\n",
            "Epoch 1101/2000\n",
            "300/300 [==============================] - 0s 105us/step - loss: 0.2419 - precision: 1.0000 - recall: 0.8667 - f1_score: 0.9282 - val_loss: 0.2663 - val_precision: 1.0000 - val_recall: 0.8667 - val_f1_score: 0.9286\n",
            "Epoch 1102/2000\n",
            "300/300 [==============================] - 0s 105us/step - loss: 0.2417 - precision: 1.0000 - recall: 0.8633 - f1_score: 0.9255 - val_loss: 0.2662 - val_precision: 1.0000 - val_recall: 0.8667 - val_f1_score: 0.9286\n",
            "Epoch 1103/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.2416 - precision: 1.0000 - recall: 0.8633 - f1_score: 0.9244 - val_loss: 0.2661 - val_precision: 1.0000 - val_recall: 0.8667 - val_f1_score: 0.9286\n",
            "Epoch 1104/2000\n",
            "300/300 [==============================] - 0s 109us/step - loss: 0.2416 - precision: 1.0000 - recall: 0.8633 - f1_score: 0.9265 - val_loss: 0.2661 - val_precision: 1.0000 - val_recall: 0.8667 - val_f1_score: 0.9286\n",
            "Epoch 1105/2000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.2418 - precision: 1.0000 - recall: 0.8567 - f1_score: 0.9223 - val_loss: 0.2661 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1106/2000\n",
            "300/300 [==============================] - 0s 104us/step - loss: 0.2413 - precision: 1.0000 - recall: 0.8700 - f1_score: 0.9301 - val_loss: 0.2658 - val_precision: 1.0000 - val_recall: 0.8667 - val_f1_score: 0.9286\n",
            "Epoch 1107/2000\n",
            "300/300 [==============================] - 0s 105us/step - loss: 0.2413 - precision: 1.0000 - recall: 0.8633 - f1_score: 0.9264 - val_loss: 0.2656 - val_precision: 1.0000 - val_recall: 0.8667 - val_f1_score: 0.9286\n",
            "Epoch 1108/2000\n",
            "300/300 [==============================] - 0s 104us/step - loss: 0.2412 - precision: 1.0000 - recall: 0.8667 - f1_score: 0.9280 - val_loss: 0.2655 - val_precision: 1.0000 - val_recall: 0.8667 - val_f1_score: 0.9286\n",
            "Epoch 1109/2000\n",
            "300/300 [==============================] - 0s 119us/step - loss: 0.2412 - precision: 1.0000 - recall: 0.8633 - f1_score: 0.9261 - val_loss: 0.2653 - val_precision: 1.0000 - val_recall: 0.8667 - val_f1_score: 0.9286\n",
            "Epoch 1110/2000\n",
            "300/300 [==============================] - 0s 118us/step - loss: 0.2410 - precision: 1.0000 - recall: 0.8633 - f1_score: 0.9261 - val_loss: 0.2650 - val_precision: 1.0000 - val_recall: 0.8667 - val_f1_score: 0.9286\n",
            "Epoch 1111/2000\n",
            "300/300 [==============================] - 0s 112us/step - loss: 0.2408 - precision: 1.0000 - recall: 0.8633 - f1_score: 0.9256 - val_loss: 0.2649 - val_precision: 1.0000 - val_recall: 0.8667 - val_f1_score: 0.9286\n",
            "Epoch 1112/2000\n",
            "300/300 [==============================] - 0s 110us/step - loss: 0.2409 - precision: 1.0000 - recall: 0.8500 - f1_score: 0.9187 - val_loss: 0.2648 - val_precision: 1.0000 - val_recall: 0.8667 - val_f1_score: 0.9286\n",
            "Epoch 1113/2000\n",
            "300/300 [==============================] - 0s 108us/step - loss: 0.2408 - precision: 1.0000 - recall: 0.8567 - f1_score: 0.9218 - val_loss: 0.2649 - val_precision: 1.0000 - val_recall: 0.8833 - val_f1_score: 0.9381\n",
            "Epoch 1114/2000\n",
            "300/300 [==============================] - 0s 109us/step - loss: 0.2406 - precision: 1.0000 - recall: 0.8733 - f1_score: 0.9320 - val_loss: 0.2648 - val_precision: 1.0000 - val_recall: 0.8833 - val_f1_score: 0.9381\n",
            "Epoch 1115/2000\n",
            "300/300 [==============================] - 0s 107us/step - loss: 0.2405 - precision: 1.0000 - recall: 0.8600 - f1_score: 0.9242 - val_loss: 0.2645 - val_precision: 1.0000 - val_recall: 0.8667 - val_f1_score: 0.9286\n",
            "Epoch 1116/2000\n",
            "300/300 [==============================] - 0s 101us/step - loss: 0.2404 - precision: 1.0000 - recall: 0.8633 - f1_score: 0.9264 - val_loss: 0.2642 - val_precision: 1.0000 - val_recall: 0.8667 - val_f1_score: 0.9286\n",
            "Epoch 1117/2000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.2403 - precision: 1.0000 - recall: 0.8667 - f1_score: 0.9269 - val_loss: 0.2640 - val_precision: 1.0000 - val_recall: 0.8667 - val_f1_score: 0.9286\n",
            "Epoch 1118/2000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.2402 - precision: 1.0000 - recall: 0.8567 - f1_score: 0.9226 - val_loss: 0.2640 - val_precision: 1.0000 - val_recall: 0.8667 - val_f1_score: 0.9286\n",
            "Epoch 1119/2000\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.2402 - precision: 1.0000 - recall: 0.8567 - f1_score: 0.9225 - val_loss: 0.2638 - val_precision: 1.0000 - val_recall: 0.8667 - val_f1_score: 0.9286\n",
            "Epoch 1120/2000\n",
            "300/300 [==============================] - 0s 108us/step - loss: 0.2402 - precision: 1.0000 - recall: 0.8633 - f1_score: 0.9264 - val_loss: 0.2633 - val_precision: 1.0000 - val_recall: 0.8333 - val_f1_score: 0.9091\n",
            "Epoch 1121/2000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.2398 - precision: 1.0000 - recall: 0.8567 - f1_score: 0.9217 - val_loss: 0.2633 - val_precision: 1.0000 - val_recall: 0.8333 - val_f1_score: 0.9091\n",
            "Epoch 1122/2000\n",
            "300/300 [==============================] - 0s 114us/step - loss: 0.2397 - precision: 1.0000 - recall: 0.8567 - f1_score: 0.9225 - val_loss: 0.2631 - val_precision: 1.0000 - val_recall: 0.8333 - val_f1_score: 0.9091\n",
            "Epoch 1123/2000\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.2396 - precision: 1.0000 - recall: 0.8600 - f1_score: 0.9245 - val_loss: 0.2631 - val_precision: 1.0000 - val_recall: 0.8500 - val_f1_score: 0.9189\n",
            "Epoch 1124/2000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.2397 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9205 - val_loss: 0.2630 - val_precision: 1.0000 - val_recall: 0.8500 - val_f1_score: 0.9189\n",
            "Epoch 1125/2000\n",
            "300/300 [==============================] - 0s 119us/step - loss: 0.2396 - precision: 1.0000 - recall: 0.8600 - f1_score: 0.9246 - val_loss: 0.2629 - val_precision: 1.0000 - val_recall: 0.8500 - val_f1_score: 0.9189\n",
            "Epoch 1126/2000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.2394 - precision: 1.0000 - recall: 0.8633 - f1_score: 0.9256 - val_loss: 0.2626 - val_precision: 1.0000 - val_recall: 0.8333 - val_f1_score: 0.9091\n",
            "Epoch 1127/2000\n",
            "300/300 [==============================] - 0s 110us/step - loss: 0.2392 - precision: 1.0000 - recall: 0.8567 - f1_score: 0.9224 - val_loss: 0.2625 - val_precision: 1.0000 - val_recall: 0.8333 - val_f1_score: 0.9091\n",
            "Epoch 1128/2000\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.2393 - precision: 1.0000 - recall: 0.8567 - f1_score: 0.9226 - val_loss: 0.2625 - val_precision: 1.0000 - val_recall: 0.8500 - val_f1_score: 0.9189\n",
            "Epoch 1129/2000\n",
            "300/300 [==============================] - 0s 119us/step - loss: 0.2394 - precision: 1.0000 - recall: 0.8633 - f1_score: 0.9265 - val_loss: 0.2623 - val_precision: 1.0000 - val_recall: 0.8333 - val_f1_score: 0.9091\n",
            "Epoch 1130/2000\n",
            "300/300 [==============================] - 0s 101us/step - loss: 0.2389 - precision: 1.0000 - recall: 0.8600 - f1_score: 0.9244 - val_loss: 0.2623 - val_precision: 1.0000 - val_recall: 0.8500 - val_f1_score: 0.9189\n",
            "Epoch 1131/2000\n",
            "300/300 [==============================] - 0s 112us/step - loss: 0.2389 - precision: 1.0000 - recall: 0.8500 - f1_score: 0.9187 - val_loss: 0.2622 - val_precision: 1.0000 - val_recall: 0.8500 - val_f1_score: 0.9189\n",
            "Epoch 1132/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.2389 - precision: 1.0000 - recall: 0.8700 - f1_score: 0.9295 - val_loss: 0.2619 - val_precision: 1.0000 - val_recall: 0.8333 - val_f1_score: 0.9091\n",
            "Epoch 1133/2000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.2386 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9207 - val_loss: 0.2620 - val_precision: 1.0000 - val_recall: 0.8500 - val_f1_score: 0.9189\n",
            "Epoch 1134/2000\n",
            "300/300 [==============================] - 0s 103us/step - loss: 0.2387 - precision: 1.0000 - recall: 0.8633 - f1_score: 0.9264 - val_loss: 0.2618 - val_precision: 1.0000 - val_recall: 0.8333 - val_f1_score: 0.9091\n",
            "Epoch 1135/2000\n",
            "300/300 [==============================] - 0s 114us/step - loss: 0.2384 - precision: 1.0000 - recall: 0.8600 - f1_score: 0.9242 - val_loss: 0.2618 - val_precision: 1.0000 - val_recall: 0.8667 - val_f1_score: 0.9286\n",
            "Epoch 1136/2000\n",
            "300/300 [==============================] - 0s 123us/step - loss: 0.2384 - precision: 1.0000 - recall: 0.8633 - f1_score: 0.9255 - val_loss: 0.2619 - val_precision: 1.0000 - val_recall: 0.8667 - val_f1_score: 0.9286\n",
            "Epoch 1137/2000\n",
            "300/300 [==============================] - 0s 101us/step - loss: 0.2381 - precision: 1.0000 - recall: 0.8633 - f1_score: 0.9264 - val_loss: 0.2618 - val_precision: 1.0000 - val_recall: 0.8667 - val_f1_score: 0.9286\n",
            "Epoch 1138/2000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.2382 - precision: 1.0000 - recall: 0.8633 - f1_score: 0.9260 - val_loss: 0.2617 - val_precision: 1.0000 - val_recall: 0.8833 - val_f1_score: 0.9381\n",
            "Epoch 1139/2000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.2380 - precision: 1.0000 - recall: 0.8667 - f1_score: 0.9276 - val_loss: 0.2615 - val_precision: 1.0000 - val_recall: 0.8667 - val_f1_score: 0.9286\n",
            "Epoch 1140/2000\n",
            "300/300 [==============================] - 0s 113us/step - loss: 0.2380 - precision: 1.0000 - recall: 0.8667 - f1_score: 0.9284 - val_loss: 0.2612 - val_precision: 1.0000 - val_recall: 0.8667 - val_f1_score: 0.9286\n",
            "Epoch 1141/2000\n",
            "300/300 [==============================] - 0s 104us/step - loss: 0.2377 - precision: 1.0000 - recall: 0.8633 - f1_score: 0.9265 - val_loss: 0.2610 - val_precision: 1.0000 - val_recall: 0.8667 - val_f1_score: 0.9286\n",
            "Epoch 1142/2000\n",
            "300/300 [==============================] - 0s 116us/step - loss: 0.2379 - precision: 1.0000 - recall: 0.8633 - f1_score: 0.9262 - val_loss: 0.2610 - val_precision: 1.0000 - val_recall: 0.8667 - val_f1_score: 0.9286\n",
            "Epoch 1143/2000\n",
            "300/300 [==============================] - 0s 102us/step - loss: 0.2376 - precision: 1.0000 - recall: 0.8667 - f1_score: 0.9281 - val_loss: 0.2608 - val_precision: 1.0000 - val_recall: 0.8667 - val_f1_score: 0.9286\n",
            "Epoch 1144/2000\n",
            "300/300 [==============================] - 0s 119us/step - loss: 0.2375 - precision: 1.0000 - recall: 0.8600 - f1_score: 0.9241 - val_loss: 0.2606 - val_precision: 1.0000 - val_recall: 0.8500 - val_f1_score: 0.9189\n",
            "Epoch 1145/2000\n",
            "300/300 [==============================] - 0s 111us/step - loss: 0.2374 - precision: 1.0000 - recall: 0.8633 - f1_score: 0.9264 - val_loss: 0.2606 - val_precision: 1.0000 - val_recall: 0.8667 - val_f1_score: 0.9286\n",
            "Epoch 1146/2000\n",
            "300/300 [==============================] - 0s 112us/step - loss: 0.2373 - precision: 1.0000 - recall: 0.8667 - f1_score: 0.9280 - val_loss: 0.2605 - val_precision: 1.0000 - val_recall: 0.8667 - val_f1_score: 0.9286\n",
            "Epoch 1147/2000\n",
            "300/300 [==============================] - 0s 107us/step - loss: 0.2372 - precision: 1.0000 - recall: 0.8667 - f1_score: 0.9279 - val_loss: 0.2603 - val_precision: 1.0000 - val_recall: 0.8667 - val_f1_score: 0.9286\n",
            "Epoch 1148/2000\n",
            "300/300 [==============================] - 0s 130us/step - loss: 0.2373 - precision: 1.0000 - recall: 0.8567 - f1_score: 0.9227 - val_loss: 0.2604 - val_precision: 1.0000 - val_recall: 0.8667 - val_f1_score: 0.9286\n",
            "Epoch 1149/2000\n",
            "300/300 [==============================] - 0s 102us/step - loss: 0.2371 - precision: 1.0000 - recall: 0.8600 - f1_score: 0.9242 - val_loss: 0.2605 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1150/2000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.2370 - precision: 1.0000 - recall: 0.8633 - f1_score: 0.9243 - val_loss: 0.2604 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1151/2000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.2368 - precision: 1.0000 - recall: 0.8700 - f1_score: 0.9297 - val_loss: 0.2602 - val_precision: 1.0000 - val_recall: 0.8833 - val_f1_score: 0.9381\n",
            "Epoch 1152/2000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.2367 - precision: 1.0000 - recall: 0.8667 - f1_score: 0.9277 - val_loss: 0.2600 - val_precision: 1.0000 - val_recall: 0.8833 - val_f1_score: 0.9381\n",
            "Epoch 1153/2000\n",
            "300/300 [==============================] - 0s 109us/step - loss: 0.2365 - precision: 1.0000 - recall: 0.8667 - f1_score: 0.9283 - val_loss: 0.2599 - val_precision: 1.0000 - val_recall: 0.8833 - val_f1_score: 0.9381\n",
            "Epoch 1154/2000\n",
            "300/300 [==============================] - 0s 107us/step - loss: 0.2365 - precision: 1.0000 - recall: 0.8667 - f1_score: 0.9279 - val_loss: 0.2598 - val_precision: 1.0000 - val_recall: 0.8833 - val_f1_score: 0.9381\n",
            "Epoch 1155/2000\n",
            "300/300 [==============================] - 0s 104us/step - loss: 0.2364 - precision: 1.0000 - recall: 0.8633 - f1_score: 0.9263 - val_loss: 0.2599 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1156/2000\n",
            "300/300 [==============================] - 0s 111us/step - loss: 0.2365 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9356 - val_loss: 0.2594 - val_precision: 1.0000 - val_recall: 0.8667 - val_f1_score: 0.9286\n",
            "Epoch 1157/2000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.2363 - precision: 1.0000 - recall: 0.8700 - f1_score: 0.9303 - val_loss: 0.2593 - val_precision: 1.0000 - val_recall: 0.8667 - val_f1_score: 0.9286\n",
            "Epoch 1158/2000\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.2362 - precision: 1.0000 - recall: 0.8667 - f1_score: 0.9283 - val_loss: 0.2594 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1159/2000\n",
            "300/300 [==============================] - 0s 108us/step - loss: 0.2360 - precision: 1.0000 - recall: 0.8700 - f1_score: 0.9301 - val_loss: 0.2594 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1160/2000\n",
            "300/300 [==============================] - 0s 108us/step - loss: 0.2358 - precision: 1.0000 - recall: 0.8700 - f1_score: 0.9300 - val_loss: 0.2593 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1161/2000\n",
            "300/300 [==============================] - 0s 113us/step - loss: 0.2357 - precision: 1.0000 - recall: 0.8700 - f1_score: 0.9302 - val_loss: 0.2592 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1162/2000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.2358 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9337 - val_loss: 0.2589 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1163/2000\n",
            "300/300 [==============================] - 0s 126us/step - loss: 0.2357 - precision: 1.0000 - recall: 0.8667 - f1_score: 0.9276 - val_loss: 0.2587 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1164/2000\n",
            "300/300 [==============================] - 0s 101us/step - loss: 0.2355 - precision: 1.0000 - recall: 0.8700 - f1_score: 0.9301 - val_loss: 0.2584 - val_precision: 1.0000 - val_recall: 0.8667 - val_f1_score: 0.9286\n",
            "Epoch 1165/2000\n",
            "300/300 [==============================] - 0s 107us/step - loss: 0.2354 - precision: 1.0000 - recall: 0.8633 - f1_score: 0.9266 - val_loss: 0.2585 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1166/2000\n",
            "300/300 [==============================] - 0s 106us/step - loss: 0.2354 - precision: 1.0000 - recall: 0.8700 - f1_score: 0.9304 - val_loss: 0.2582 - val_precision: 1.0000 - val_recall: 0.8833 - val_f1_score: 0.9381\n",
            "Epoch 1167/2000\n",
            "300/300 [==============================] - 0s 106us/step - loss: 0.2352 - precision: 1.0000 - recall: 0.8700 - f1_score: 0.9303 - val_loss: 0.2581 - val_precision: 1.0000 - val_recall: 0.8667 - val_f1_score: 0.9286\n",
            "Epoch 1168/2000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.2351 - precision: 1.0000 - recall: 0.8700 - f1_score: 0.9298 - val_loss: 0.2579 - val_precision: 1.0000 - val_recall: 0.8667 - val_f1_score: 0.9286\n",
            "Epoch 1169/2000\n",
            "300/300 [==============================] - 0s 103us/step - loss: 0.2351 - precision: 1.0000 - recall: 0.8700 - f1_score: 0.9304 - val_loss: 0.2581 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1170/2000\n",
            "300/300 [==============================] - 0s 107us/step - loss: 0.2349 - precision: 1.0000 - recall: 0.8700 - f1_score: 0.9294 - val_loss: 0.2579 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1171/2000\n",
            "300/300 [==============================] - 0s 122us/step - loss: 0.2348 - precision: 1.0000 - recall: 0.8667 - f1_score: 0.9281 - val_loss: 0.2578 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1172/2000\n",
            "300/300 [==============================] - 0s 111us/step - loss: 0.2348 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9340 - val_loss: 0.2576 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1173/2000\n",
            "300/300 [==============================] - 0s 104us/step - loss: 0.2346 - precision: 1.0000 - recall: 0.8700 - f1_score: 0.9298 - val_loss: 0.2576 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1174/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.2345 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9335 - val_loss: 0.2574 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1175/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.2344 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9341 - val_loss: 0.2575 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1176/2000\n",
            "300/300 [==============================] - 0s 104us/step - loss: 0.2344 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9356 - val_loss: 0.2574 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1177/2000\n",
            "300/300 [==============================] - 0s 117us/step - loss: 0.2342 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9332 - val_loss: 0.2572 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1178/2000\n",
            "300/300 [==============================] - 0s 121us/step - loss: 0.2342 - precision: 1.0000 - recall: 0.8733 - f1_score: 0.9318 - val_loss: 0.2571 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1179/2000\n",
            "300/300 [==============================] - 0s 102us/step - loss: 0.2340 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9336 - val_loss: 0.2570 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1180/2000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.2339 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9342 - val_loss: 0.2567 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1181/2000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.2338 - precision: 1.0000 - recall: 0.8733 - f1_score: 0.9313 - val_loss: 0.2568 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1182/2000\n",
            "300/300 [==============================] - 0s 105us/step - loss: 0.2337 - precision: 1.0000 - recall: 0.8733 - f1_score: 0.9322 - val_loss: 0.2567 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1183/2000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.2338 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9346 - val_loss: 0.2567 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1184/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.2336 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9330 - val_loss: 0.2566 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1185/2000\n",
            "300/300 [==============================] - 0s 104us/step - loss: 0.2335 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9356 - val_loss: 0.2564 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1186/2000\n",
            "300/300 [==============================] - 0s 114us/step - loss: 0.2333 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9340 - val_loss: 0.2561 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1187/2000\n",
            "300/300 [==============================] - 0s 108us/step - loss: 0.2332 - precision: 1.0000 - recall: 0.8733 - f1_score: 0.9314 - val_loss: 0.2560 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1188/2000\n",
            "300/300 [==============================] - 0s 107us/step - loss: 0.2331 - precision: 1.0000 - recall: 0.8733 - f1_score: 0.9318 - val_loss: 0.2558 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1189/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.2330 - precision: 1.0000 - recall: 0.8733 - f1_score: 0.9323 - val_loss: 0.2557 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1190/2000\n",
            "300/300 [==============================] - 0s 106us/step - loss: 0.2329 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9361 - val_loss: 0.2556 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1191/2000\n",
            "300/300 [==============================] - 0s 112us/step - loss: 0.2328 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9338 - val_loss: 0.2554 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1192/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.2329 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9360 - val_loss: 0.2553 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1193/2000\n",
            "300/300 [==============================] - 0s 112us/step - loss: 0.2326 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9377 - val_loss: 0.2552 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1194/2000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.2326 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9340 - val_loss: 0.2552 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1195/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.2326 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9358 - val_loss: 0.2552 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1196/2000\n",
            "300/300 [==============================] - 0s 108us/step - loss: 0.2324 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9335 - val_loss: 0.2550 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1197/2000\n",
            "300/300 [==============================] - 0s 113us/step - loss: 0.2324 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9334 - val_loss: 0.2550 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1198/2000\n",
            "300/300 [==============================] - 0s 103us/step - loss: 0.2321 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9337 - val_loss: 0.2548 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1199/2000\n",
            "300/300 [==============================] - 0s 103us/step - loss: 0.2321 - precision: 1.0000 - recall: 0.8733 - f1_score: 0.9316 - val_loss: 0.2548 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1200/2000\n",
            "300/300 [==============================] - 0s 109us/step - loss: 0.2321 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9354 - val_loss: 0.2545 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1201/2000\n",
            "300/300 [==============================] - 0s 111us/step - loss: 0.2321 - precision: 1.0000 - recall: 0.8733 - f1_score: 0.9303 - val_loss: 0.2543 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1202/2000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.2319 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9380 - val_loss: 0.2542 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1203/2000\n",
            "300/300 [==============================] - 0s 112us/step - loss: 0.2319 - precision: 1.0000 - recall: 0.8733 - f1_score: 0.9318 - val_loss: 0.2541 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1204/2000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.2317 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9360 - val_loss: 0.2540 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1205/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.2315 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9379 - val_loss: 0.2540 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1206/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.2314 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9380 - val_loss: 0.2539 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1207/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.2313 - precision: 1.0000 - recall: 0.8867 - f1_score: 0.9396 - val_loss: 0.2537 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1208/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.2314 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9378 - val_loss: 0.2536 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1209/2000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.2314 - precision: 1.0000 - recall: 0.8900 - f1_score: 0.9410 - val_loss: 0.2535 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1210/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.2311 - precision: 1.0000 - recall: 0.8900 - f1_score: 0.9414 - val_loss: 0.2535 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1211/2000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.2309 - precision: 1.0000 - recall: 0.8900 - f1_score: 0.9414 - val_loss: 0.2535 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1212/2000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.2308 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9354 - val_loss: 0.2533 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1213/2000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.2307 - precision: 1.0000 - recall: 0.8900 - f1_score: 0.9411 - val_loss: 0.2533 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1214/2000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.2307 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9360 - val_loss: 0.2530 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1215/2000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.2306 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9355 - val_loss: 0.2529 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1216/2000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.2305 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9377 - val_loss: 0.2528 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1217/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.2303 - precision: 1.0000 - recall: 0.8867 - f1_score: 0.9395 - val_loss: 0.2527 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1218/2000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.2304 - precision: 1.0000 - recall: 0.8867 - f1_score: 0.9396 - val_loss: 0.2527 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1219/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.2302 - precision: 1.0000 - recall: 0.8867 - f1_score: 0.9396 - val_loss: 0.2528 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1220/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.2302 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9360 - val_loss: 0.2526 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1221/2000\n",
            "300/300 [==============================] - 0s 105us/step - loss: 0.2301 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9375 - val_loss: 0.2527 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1222/2000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.2300 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9338 - val_loss: 0.2524 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1223/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.2298 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9377 - val_loss: 0.2521 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1224/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.2299 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9373 - val_loss: 0.2518 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1225/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.2296 - precision: 1.0000 - recall: 0.8867 - f1_score: 0.9397 - val_loss: 0.2518 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1226/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.2296 - precision: 1.0000 - recall: 0.8933 - f1_score: 0.9431 - val_loss: 0.2517 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1227/2000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.2295 - precision: 1.0000 - recall: 0.8900 - f1_score: 0.9417 - val_loss: 0.2518 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1228/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.2295 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9341 - val_loss: 0.2516 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1229/2000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.2293 - precision: 1.0000 - recall: 0.8867 - f1_score: 0.9394 - val_loss: 0.2515 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1230/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.2292 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9356 - val_loss: 0.2515 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1231/2000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.2292 - precision: 1.0000 - recall: 0.8867 - f1_score: 0.9399 - val_loss: 0.2513 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1232/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.2291 - precision: 1.0000 - recall: 0.8933 - f1_score: 0.9433 - val_loss: 0.2513 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1233/2000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.2289 - precision: 1.0000 - recall: 0.8933 - f1_score: 0.9432 - val_loss: 0.2512 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1234/2000\n",
            "300/300 [==============================] - 0s 82us/step - loss: 0.2289 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9380 - val_loss: 0.2509 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1235/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.2288 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9377 - val_loss: 0.2507 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1236/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.2286 - precision: 1.0000 - recall: 0.8933 - f1_score: 0.9434 - val_loss: 0.2506 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1237/2000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.2288 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9378 - val_loss: 0.2504 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1238/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.2285 - precision: 1.0000 - recall: 0.8900 - f1_score: 0.9409 - val_loss: 0.2505 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1239/2000\n",
            "300/300 [==============================] - 0s 81us/step - loss: 0.2284 - precision: 1.0000 - recall: 0.8933 - f1_score: 0.9433 - val_loss: 0.2505 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1240/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.2283 - precision: 1.0000 - recall: 0.8867 - f1_score: 0.9387 - val_loss: 0.2504 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1241/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.2285 - precision: 1.0000 - recall: 0.8867 - f1_score: 0.9391 - val_loss: 0.2505 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1242/2000\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.2282 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9443 - val_loss: 0.2506 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1243/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.2280 - precision: 1.0000 - recall: 0.8867 - f1_score: 0.9396 - val_loss: 0.2504 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1244/2000\n",
            "300/300 [==============================] - 0s 103us/step - loss: 0.2279 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9379 - val_loss: 0.2502 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1245/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.2279 - precision: 1.0000 - recall: 0.8867 - f1_score: 0.9386 - val_loss: 0.2499 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1246/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.2277 - precision: 1.0000 - recall: 0.8933 - f1_score: 0.9432 - val_loss: 0.2496 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1247/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.2276 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9380 - val_loss: 0.2494 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1248/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.2277 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9449 - val_loss: 0.2493 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1249/2000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.2275 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9451 - val_loss: 0.2493 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1250/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.2273 - precision: 1.0000 - recall: 0.8867 - f1_score: 0.9397 - val_loss: 0.2491 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1251/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.2272 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9452 - val_loss: 0.2489 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1252/2000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.2274 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9376 - val_loss: 0.2490 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1253/2000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.2273 - precision: 1.0000 - recall: 0.8933 - f1_score: 0.9435 - val_loss: 0.2491 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1254/2000\n",
            "300/300 [==============================] - 0s 103us/step - loss: 0.2270 - precision: 1.0000 - recall: 0.8867 - f1_score: 0.9398 - val_loss: 0.2488 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1255/2000\n",
            "300/300 [==============================] - 0s 103us/step - loss: 0.2268 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9448 - val_loss: 0.2487 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1256/2000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.2271 - precision: 1.0000 - recall: 0.8933 - f1_score: 0.9432 - val_loss: 0.2488 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1257/2000\n",
            "300/300 [==============================] - 0s 102us/step - loss: 0.2267 - precision: 1.0000 - recall: 0.8867 - f1_score: 0.9394 - val_loss: 0.2485 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1258/2000\n",
            "300/300 [==============================] - 0s 125us/step - loss: 0.2267 - precision: 1.0000 - recall: 0.8933 - f1_score: 0.9434 - val_loss: 0.2487 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1259/2000\n",
            "300/300 [==============================] - 0s 116us/step - loss: 0.2266 - precision: 1.0000 - recall: 0.8867 - f1_score: 0.9393 - val_loss: 0.2483 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1260/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.2266 - precision: 1.0000 - recall: 0.8933 - f1_score: 0.9434 - val_loss: 0.2484 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1261/2000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.2265 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9453 - val_loss: 0.2482 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1262/2000\n",
            "300/300 [==============================] - 0s 107us/step - loss: 0.2264 - precision: 1.0000 - recall: 0.8867 - f1_score: 0.9390 - val_loss: 0.2480 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1263/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.2263 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9452 - val_loss: 0.2478 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1264/2000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.2260 - precision: 1.0000 - recall: 0.8933 - f1_score: 0.9434 - val_loss: 0.2477 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1265/2000\n",
            "300/300 [==============================] - 0s 101us/step - loss: 0.2261 - precision: 1.0000 - recall: 0.8867 - f1_score: 0.9392 - val_loss: 0.2474 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1266/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.2259 - precision: 1.0000 - recall: 0.9000 - f1_score: 0.9472 - val_loss: 0.2473 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1267/2000\n",
            "300/300 [==============================] - 0s 101us/step - loss: 0.2258 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9451 - val_loss: 0.2472 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1268/2000\n",
            "300/300 [==============================] - 0s 123us/step - loss: 0.2258 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9453 - val_loss: 0.2474 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1269/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.2258 - precision: 1.0000 - recall: 0.8900 - f1_score: 0.9416 - val_loss: 0.2471 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1270/2000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.2257 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9453 - val_loss: 0.2471 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1271/2000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.2255 - precision: 1.0000 - recall: 0.9000 - f1_score: 0.9467 - val_loss: 0.2472 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1272/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.2254 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9450 - val_loss: 0.2472 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1273/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.2253 - precision: 1.0000 - recall: 0.8900 - f1_score: 0.9416 - val_loss: 0.2469 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1274/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.2251 - precision: 1.0000 - recall: 0.9000 - f1_score: 0.9472 - val_loss: 0.2468 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1275/2000\n",
            "300/300 [==============================] - 0s 102us/step - loss: 0.2251 - precision: 1.0000 - recall: 0.8933 - f1_score: 0.9434 - val_loss: 0.2466 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1276/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.2250 - precision: 1.0000 - recall: 0.9000 - f1_score: 0.9468 - val_loss: 0.2466 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1277/2000\n",
            "300/300 [==============================] - 0s 105us/step - loss: 0.2249 - precision: 1.0000 - recall: 0.9000 - f1_score: 0.9471 - val_loss: 0.2463 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1278/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.2249 - precision: 1.0000 - recall: 0.8900 - f1_score: 0.9414 - val_loss: 0.2462 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1279/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.2248 - precision: 1.0000 - recall: 0.9000 - f1_score: 0.9471 - val_loss: 0.2462 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1280/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.2246 - precision: 1.0000 - recall: 0.9000 - f1_score: 0.9468 - val_loss: 0.2461 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1281/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.2247 - precision: 1.0000 - recall: 0.9000 - f1_score: 0.9469 - val_loss: 0.2460 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1282/2000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.2245 - precision: 1.0000 - recall: 0.9000 - f1_score: 0.9471 - val_loss: 0.2459 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1283/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.2244 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9453 - val_loss: 0.2458 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1284/2000\n",
            "300/300 [==============================] - 0s 101us/step - loss: 0.2244 - precision: 1.0000 - recall: 0.9000 - f1_score: 0.9473 - val_loss: 0.2458 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1285/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.2243 - precision: 1.0000 - recall: 0.8867 - f1_score: 0.9389 - val_loss: 0.2457 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1286/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.2243 - precision: 1.0000 - recall: 0.8933 - f1_score: 0.9430 - val_loss: 0.2457 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1287/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.2240 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9448 - val_loss: 0.2456 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1288/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.2241 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9491 - val_loss: 0.2456 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1289/2000\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.2240 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9454 - val_loss: 0.2453 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1290/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.2238 - precision: 1.0000 - recall: 0.9000 - f1_score: 0.9470 - val_loss: 0.2452 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1291/2000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.2238 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9448 - val_loss: 0.2454 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1292/2000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.2236 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9452 - val_loss: 0.2453 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1293/2000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.2237 - precision: 1.0000 - recall: 0.8933 - f1_score: 0.9435 - val_loss: 0.2450 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1294/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.2236 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9453 - val_loss: 0.2449 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1295/2000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.2234 - precision: 1.0000 - recall: 0.9000 - f1_score: 0.9465 - val_loss: 0.2447 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1296/2000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.2233 - precision: 1.0000 - recall: 0.9000 - f1_score: 0.9472 - val_loss: 0.2446 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1297/2000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.2231 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9490 - val_loss: 0.2444 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1298/2000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.2231 - precision: 1.0000 - recall: 0.9000 - f1_score: 0.9472 - val_loss: 0.2443 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1299/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.2230 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9508 - val_loss: 0.2442 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1300/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.2229 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9490 - val_loss: 0.2441 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1301/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.2229 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9450 - val_loss: 0.2441 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1302/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.2229 - precision: 1.0000 - recall: 0.9000 - f1_score: 0.9473 - val_loss: 0.2439 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1303/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.2228 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9491 - val_loss: 0.2436 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1304/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.2226 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9455 - val_loss: 0.2436 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1305/2000\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.2225 - precision: 1.0000 - recall: 0.9000 - f1_score: 0.9473 - val_loss: 0.2435 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1306/2000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.2225 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9490 - val_loss: 0.2435 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1307/2000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.2224 - precision: 1.0000 - recall: 0.9000 - f1_score: 0.9472 - val_loss: 0.2435 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1308/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.2223 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9508 - val_loss: 0.2434 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1309/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.2221 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9490 - val_loss: 0.2433 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1310/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.2220 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9492 - val_loss: 0.2432 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1311/2000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.2220 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9490 - val_loss: 0.2430 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1312/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.2220 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9490 - val_loss: 0.2427 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1313/2000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.2218 - precision: 1.0000 - recall: 0.9000 - f1_score: 0.9473 - val_loss: 0.2426 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1314/2000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.2220 - precision: 1.0000 - recall: 0.9000 - f1_score: 0.9471 - val_loss: 0.2424 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1315/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.2218 - precision: 1.0000 - recall: 0.9000 - f1_score: 0.9473 - val_loss: 0.2423 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1316/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.2216 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9491 - val_loss: 0.2421 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1317/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.2214 - precision: 1.0000 - recall: 0.9000 - f1_score: 0.9473 - val_loss: 0.2421 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1318/2000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.2214 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9489 - val_loss: 0.2420 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1319/2000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.2213 - precision: 1.0000 - recall: 0.9000 - f1_score: 0.9469 - val_loss: 0.2421 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1320/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.2214 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9489 - val_loss: 0.2418 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1321/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.2211 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9490 - val_loss: 0.2417 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1322/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.2211 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9490 - val_loss: 0.2417 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1323/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.2211 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9510 - val_loss: 0.2415 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1324/2000\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.2210 - precision: 1.0000 - recall: 0.9000 - f1_score: 0.9464 - val_loss: 0.2415 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1325/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.2208 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9490 - val_loss: 0.2416 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1326/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.2208 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9488 - val_loss: 0.2415 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1327/2000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.2207 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9502 - val_loss: 0.2413 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1328/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.2207 - precision: 1.0000 - recall: 0.9000 - f1_score: 0.9467 - val_loss: 0.2414 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1329/2000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.2205 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9526 - val_loss: 0.2413 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1330/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.2204 - precision: 1.0000 - recall: 0.9000 - f1_score: 0.9472 - val_loss: 0.2413 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1331/2000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.2202 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9488 - val_loss: 0.2412 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1332/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.2201 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9487 - val_loss: 0.2411 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1333/2000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.2202 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9507 - val_loss: 0.2409 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1334/2000\n",
            "300/300 [==============================] - 0s 101us/step - loss: 0.2201 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9504 - val_loss: 0.2408 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1335/2000\n",
            "300/300 [==============================] - 0s 102us/step - loss: 0.2200 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9526 - val_loss: 0.2408 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1336/2000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.2199 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9500 - val_loss: 0.2408 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1337/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.2197 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9527 - val_loss: 0.2406 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1338/2000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.2197 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9509 - val_loss: 0.2405 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1339/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.2197 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9485 - val_loss: 0.2402 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1340/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.2196 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9491 - val_loss: 0.2401 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1341/2000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.2195 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9522 - val_loss: 0.2400 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1342/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.2193 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9525 - val_loss: 0.2400 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1343/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.2195 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9524 - val_loss: 0.2400 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1344/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.2193 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9498 - val_loss: 0.2398 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1345/2000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.2191 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9502 - val_loss: 0.2397 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1346/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.2190 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9509 - val_loss: 0.2397 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1347/2000\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.2190 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9507 - val_loss: 0.2396 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1348/2000\n",
            "300/300 [==============================] - 0s 114us/step - loss: 0.2189 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9528 - val_loss: 0.2396 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1349/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.2187 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9526 - val_loss: 0.2396 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1350/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.2189 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9505 - val_loss: 0.2397 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1351/2000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.2186 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9528 - val_loss: 0.2395 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1352/2000\n",
            "300/300 [==============================] - 0s 103us/step - loss: 0.2186 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9503 - val_loss: 0.2393 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1353/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.2186 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9525 - val_loss: 0.2393 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1354/2000\n",
            "300/300 [==============================] - 0s 105us/step - loss: 0.2183 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9504 - val_loss: 0.2391 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1355/2000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.2184 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9527 - val_loss: 0.2390 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1356/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.2183 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9490 - val_loss: 0.2390 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1357/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.2181 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9526 - val_loss: 0.2388 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1358/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.2180 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9527 - val_loss: 0.2387 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1359/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.2180 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9521 - val_loss: 0.2386 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1360/2000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.2180 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9523 - val_loss: 0.2383 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1361/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.2177 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9522 - val_loss: 0.2383 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1362/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.2176 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9522 - val_loss: 0.2381 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1363/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.2176 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9546 - val_loss: 0.2379 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1364/2000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.2175 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9514 - val_loss: 0.2377 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1365/2000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.2175 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9508 - val_loss: 0.2377 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1366/2000\n",
            "300/300 [==============================] - 0s 103us/step - loss: 0.2176 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9544 - val_loss: 0.2376 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1367/2000\n",
            "300/300 [==============================] - 0s 108us/step - loss: 0.2173 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9527 - val_loss: 0.2375 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1368/2000\n",
            "300/300 [==============================] - 0s 111us/step - loss: 0.2174 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9490 - val_loss: 0.2376 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1369/2000\n",
            "300/300 [==============================] - 0s 103us/step - loss: 0.2171 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9528 - val_loss: 0.2374 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1370/2000\n",
            "300/300 [==============================] - 0s 115us/step - loss: 0.2172 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9523 - val_loss: 0.2376 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1371/2000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.2169 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9527 - val_loss: 0.2374 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1372/2000\n",
            "300/300 [==============================] - 0s 102us/step - loss: 0.2169 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9527 - val_loss: 0.2371 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1373/2000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.2167 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9527 - val_loss: 0.2371 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1374/2000\n",
            "300/300 [==============================] - 0s 111us/step - loss: 0.2168 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9527 - val_loss: 0.2370 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1375/2000\n",
            "300/300 [==============================] - 0s 106us/step - loss: 0.2166 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9546 - val_loss: 0.2368 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1376/2000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.2166 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9522 - val_loss: 0.2367 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1377/2000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.2165 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9545 - val_loss: 0.2366 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1378/2000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.2164 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9544 - val_loss: 0.2365 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1379/2000\n",
            "300/300 [==============================] - 0s 117us/step - loss: 0.2164 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9529 - val_loss: 0.2365 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1380/2000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.2163 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9524 - val_loss: 0.2364 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1381/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.2162 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9542 - val_loss: 0.2362 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1382/2000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.2162 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9544 - val_loss: 0.2364 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1383/2000\n",
            "300/300 [==============================] - 0s 107us/step - loss: 0.2160 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9546 - val_loss: 0.2362 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1384/2000\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.2160 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9540 - val_loss: 0.2362 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1385/2000\n",
            "300/300 [==============================] - 0s 109us/step - loss: 0.2158 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9525 - val_loss: 0.2362 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1386/2000\n",
            "300/300 [==============================] - 0s 106us/step - loss: 0.2158 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9543 - val_loss: 0.2360 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1387/2000\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.2157 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9546 - val_loss: 0.2359 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1388/2000\n",
            "300/300 [==============================] - 0s 103us/step - loss: 0.2157 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9527 - val_loss: 0.2357 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1389/2000\n",
            "300/300 [==============================] - 0s 103us/step - loss: 0.2155 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9546 - val_loss: 0.2357 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1390/2000\n",
            "300/300 [==============================] - 0s 120us/step - loss: 0.2156 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9529 - val_loss: 0.2356 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1391/2000\n",
            "300/300 [==============================] - 0s 107us/step - loss: 0.2154 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9510 - val_loss: 0.2354 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1392/2000\n",
            "300/300 [==============================] - 0s 108us/step - loss: 0.2153 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9547 - val_loss: 0.2353 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1393/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.2153 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9524 - val_loss: 0.2354 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1394/2000\n",
            "300/300 [==============================] - 0s 108us/step - loss: 0.2151 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9546 - val_loss: 0.2353 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1395/2000\n",
            "300/300 [==============================] - 0s 107us/step - loss: 0.2155 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9509 - val_loss: 0.2350 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1396/2000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.2150 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9544 - val_loss: 0.2350 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1397/2000\n",
            "300/300 [==============================] - 0s 121us/step - loss: 0.2149 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9504 - val_loss: 0.2348 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1398/2000\n",
            "300/300 [==============================] - 0s 101us/step - loss: 0.2148 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9544 - val_loss: 0.2347 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1399/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.2147 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9545 - val_loss: 0.2346 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1400/2000\n",
            "300/300 [==============================] - 0s 111us/step - loss: 0.2147 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9545 - val_loss: 0.2344 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1401/2000\n",
            "300/300 [==============================] - 0s 106us/step - loss: 0.2146 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9542 - val_loss: 0.2343 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1402/2000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.2144 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9526 - val_loss: 0.2343 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1403/2000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.2145 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9524 - val_loss: 0.2340 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1404/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.2143 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9525 - val_loss: 0.2340 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1405/2000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.2146 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9526 - val_loss: 0.2340 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1406/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.2142 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9541 - val_loss: 0.2340 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1407/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.2140 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9546 - val_loss: 0.2338 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1408/2000\n",
            "300/300 [==============================] - 0s 102us/step - loss: 0.2140 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9542 - val_loss: 0.2337 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1409/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.2139 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9546 - val_loss: 0.2335 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1410/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.2140 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9545 - val_loss: 0.2335 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1411/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.2138 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9525 - val_loss: 0.2334 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1412/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.2136 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9528 - val_loss: 0.2335 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1413/2000\n",
            "300/300 [==============================] - 0s 103us/step - loss: 0.2136 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9544 - val_loss: 0.2333 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1414/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.2137 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9545 - val_loss: 0.2331 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1415/2000\n",
            "300/300 [==============================] - 0s 103us/step - loss: 0.2135 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9527 - val_loss: 0.2330 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1416/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.2134 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9543 - val_loss: 0.2329 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1417/2000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.2134 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9560 - val_loss: 0.2329 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1418/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.2132 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9527 - val_loss: 0.2330 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1419/2000\n",
            "300/300 [==============================] - 0s 105us/step - loss: 0.2131 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9539 - val_loss: 0.2328 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1420/2000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.2131 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9544 - val_loss: 0.2326 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1421/2000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.2130 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9544 - val_loss: 0.2325 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1422/2000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.2130 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9544 - val_loss: 0.2326 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1423/2000\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.2128 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9542 - val_loss: 0.2323 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1424/2000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.2128 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9544 - val_loss: 0.2323 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1425/2000\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.2126 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9543 - val_loss: 0.2322 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1426/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.2127 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9544 - val_loss: 0.2321 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1427/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.2125 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9544 - val_loss: 0.2321 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1428/2000\n",
            "300/300 [==============================] - 0s 114us/step - loss: 0.2124 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9535 - val_loss: 0.2320 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1429/2000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.2124 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9546 - val_loss: 0.2319 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1430/2000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.2123 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9547 - val_loss: 0.2318 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1431/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.2122 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9542 - val_loss: 0.2317 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1432/2000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.2122 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9538 - val_loss: 0.2317 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1433/2000\n",
            "300/300 [==============================] - 0s 102us/step - loss: 0.2121 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9545 - val_loss: 0.2315 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1434/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.2120 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9545 - val_loss: 0.2313 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1435/2000\n",
            "300/300 [==============================] - 0s 101us/step - loss: 0.2121 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9556 - val_loss: 0.2312 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1436/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.2118 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9543 - val_loss: 0.2311 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1437/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.2118 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9545 - val_loss: 0.2310 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1438/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.2118 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9527 - val_loss: 0.2311 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1439/2000\n",
            "300/300 [==============================] - 0s 107us/step - loss: 0.2118 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9540 - val_loss: 0.2311 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1440/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.2117 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9545 - val_loss: 0.2312 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1441/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.2116 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9505 - val_loss: 0.2309 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1442/2000\n",
            "300/300 [==============================] - 0s 106us/step - loss: 0.2115 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9547 - val_loss: 0.2308 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1443/2000\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.2115 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9545 - val_loss: 0.2306 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1444/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.2113 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9542 - val_loss: 0.2305 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1445/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.2112 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9544 - val_loss: 0.2303 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1446/2000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.2111 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9543 - val_loss: 0.2301 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1447/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.2110 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9546 - val_loss: 0.2300 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1448/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.2110 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9542 - val_loss: 0.2299 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1449/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.2109 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9544 - val_loss: 0.2300 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1450/2000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.2109 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9545 - val_loss: 0.2298 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1451/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.2107 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9545 - val_loss: 0.2296 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1452/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.2106 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9541 - val_loss: 0.2298 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1453/2000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.2106 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9545 - val_loss: 0.2296 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1454/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.2106 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9541 - val_loss: 0.2294 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1455/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.2104 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9543 - val_loss: 0.2293 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1456/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.2104 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9547 - val_loss: 0.2291 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1457/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.2104 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9544 - val_loss: 0.2291 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1458/2000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.2103 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9547 - val_loss: 0.2293 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1459/2000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.2101 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9542 - val_loss: 0.2292 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1460/2000\n",
            "300/300 [==============================] - 0s 101us/step - loss: 0.2101 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9563 - val_loss: 0.2290 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1461/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.2101 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9546 - val_loss: 0.2287 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1462/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.2100 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9538 - val_loss: 0.2285 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1463/2000\n",
            "300/300 [==============================] - 0s 109us/step - loss: 0.2098 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9565 - val_loss: 0.2287 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1464/2000\n",
            "300/300 [==============================] - 0s 102us/step - loss: 0.2099 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9542 - val_loss: 0.2287 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1465/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.2097 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9542 - val_loss: 0.2285 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1466/2000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.2096 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9544 - val_loss: 0.2285 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1467/2000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.2097 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9538 - val_loss: 0.2282 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1468/2000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.2095 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9539 - val_loss: 0.2282 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1469/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.2094 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9563 - val_loss: 0.2282 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1470/2000\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.2095 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9562 - val_loss: 0.2282 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1471/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.2092 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9545 - val_loss: 0.2280 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1472/2000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.2091 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9565 - val_loss: 0.2280 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1473/2000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.2092 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9537 - val_loss: 0.2278 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1474/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.2092 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9544 - val_loss: 0.2278 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1475/2000\n",
            "300/300 [==============================] - 0s 101us/step - loss: 0.2089 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9546 - val_loss: 0.2277 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1476/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.2089 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9564 - val_loss: 0.2276 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1477/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.2087 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9544 - val_loss: 0.2275 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1478/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.2088 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9563 - val_loss: 0.2275 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1479/2000\n",
            "300/300 [==============================] - 0s 103us/step - loss: 0.2088 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9544 - val_loss: 0.2274 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1480/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.2086 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9541 - val_loss: 0.2272 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1481/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.2085 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9562 - val_loss: 0.2272 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1482/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.2084 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9543 - val_loss: 0.2270 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1483/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.2083 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9562 - val_loss: 0.2271 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1484/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.2083 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9542 - val_loss: 0.2271 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1485/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.2082 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9542 - val_loss: 0.2268 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1486/2000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.2082 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9543 - val_loss: 0.2266 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1487/2000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.2081 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9563 - val_loss: 0.2266 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1488/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.2079 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9546 - val_loss: 0.2265 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1489/2000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.2079 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9563 - val_loss: 0.2263 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1490/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.2078 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9562 - val_loss: 0.2263 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1491/2000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.2077 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9564 - val_loss: 0.2264 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1492/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.2077 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9543 - val_loss: 0.2263 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1493/2000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.2077 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9561 - val_loss: 0.2261 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1494/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.2076 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9582 - val_loss: 0.2260 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1495/2000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.2074 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9543 - val_loss: 0.2259 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1496/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.2073 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9561 - val_loss: 0.2259 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1497/2000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.2074 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9562 - val_loss: 0.2258 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1498/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.2072 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9563 - val_loss: 0.2257 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1499/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.2075 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9544 - val_loss: 0.2259 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1500/2000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.2071 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9560 - val_loss: 0.2256 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1501/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.2070 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9545 - val_loss: 0.2254 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1502/2000\n",
            "300/300 [==============================] - 0s 131us/step - loss: 0.2070 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9581 - val_loss: 0.2254 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1503/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.2069 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9545 - val_loss: 0.2254 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1504/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.2068 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9563 - val_loss: 0.2255 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1505/2000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.2068 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9580 - val_loss: 0.2256 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1506/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.2068 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9542 - val_loss: 0.2254 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1507/2000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.2068 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9565 - val_loss: 0.2254 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1508/2000\n",
            "300/300 [==============================] - 0s 104us/step - loss: 0.2067 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9581 - val_loss: 0.2250 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1509/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.2065 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9581 - val_loss: 0.2249 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1510/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.2064 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9564 - val_loss: 0.2247 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1511/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.2062 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9564 - val_loss: 0.2248 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1512/2000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.2063 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9563 - val_loss: 0.2245 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1513/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.2061 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9564 - val_loss: 0.2245 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1514/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.2061 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9564 - val_loss: 0.2246 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1515/2000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.2059 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9545 - val_loss: 0.2245 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1516/2000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.2059 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9582 - val_loss: 0.2245 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1517/2000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.2058 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9564 - val_loss: 0.2243 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1518/2000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.2058 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9579 - val_loss: 0.2243 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1519/2000\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.2057 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9565 - val_loss: 0.2243 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1520/2000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.2057 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9564 - val_loss: 0.2241 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1521/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.2056 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9561 - val_loss: 0.2241 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1522/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.2057 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9563 - val_loss: 0.2239 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1523/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.2057 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9546 - val_loss: 0.2239 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1524/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.2055 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9541 - val_loss: 0.2236 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1525/2000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.2054 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9582 - val_loss: 0.2235 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1526/2000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.2054 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9563 - val_loss: 0.2236 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1527/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.2051 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9580 - val_loss: 0.2236 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1528/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.2052 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9560 - val_loss: 0.2235 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1529/2000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.2050 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9559 - val_loss: 0.2233 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1530/2000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.2050 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9579 - val_loss: 0.2231 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1531/2000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.2049 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9581 - val_loss: 0.2229 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1532/2000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.2049 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9562 - val_loss: 0.2230 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1533/2000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.2047 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9581 - val_loss: 0.2230 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1534/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.2047 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9580 - val_loss: 0.2228 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1535/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.2046 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9563 - val_loss: 0.2228 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1536/2000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.2044 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9580 - val_loss: 0.2227 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1537/2000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.2045 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9563 - val_loss: 0.2225 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1538/2000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.2043 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9580 - val_loss: 0.2224 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1539/2000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.2043 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9582 - val_loss: 0.2224 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1540/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.2042 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9562 - val_loss: 0.2223 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1541/2000\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.2043 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9572 - val_loss: 0.2224 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1542/2000\n",
            "300/300 [==============================] - 0s 82us/step - loss: 0.2041 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9581 - val_loss: 0.2223 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1543/2000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.2040 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9560 - val_loss: 0.2221 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1544/2000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.2039 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9581 - val_loss: 0.2222 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1545/2000\n",
            "300/300 [==============================] - 0s 110us/step - loss: 0.2040 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9578 - val_loss: 0.2219 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1546/2000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.2039 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9581 - val_loss: 0.2221 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1547/2000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.2038 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9578 - val_loss: 0.2219 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1548/2000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.2038 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9578 - val_loss: 0.2217 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1549/2000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.2037 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9561 - val_loss: 0.2216 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1550/2000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.2036 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9564 - val_loss: 0.2214 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1551/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.2035 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9559 - val_loss: 0.2213 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1552/2000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.2034 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9582 - val_loss: 0.2213 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1553/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.2033 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9582 - val_loss: 0.2213 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1554/2000\n",
            "300/300 [==============================] - 0s 82us/step - loss: 0.2033 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9582 - val_loss: 0.2212 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1555/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.2031 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9583 - val_loss: 0.2212 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1556/2000\n",
            "300/300 [==============================] - 0s 82us/step - loss: 0.2031 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9582 - val_loss: 0.2209 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1557/2000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.2032 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9564 - val_loss: 0.2210 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1558/2000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.2030 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9582 - val_loss: 0.2209 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1559/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.2031 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9582 - val_loss: 0.2208 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1560/2000\n",
            "300/300 [==============================] - 0s 104us/step - loss: 0.2029 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9581 - val_loss: 0.2206 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1561/2000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.2028 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9582 - val_loss: 0.2204 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1562/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.2027 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9581 - val_loss: 0.2203 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1563/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.2028 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9581 - val_loss: 0.2202 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1564/2000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.2026 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9564 - val_loss: 0.2202 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1565/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.2026 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9578 - val_loss: 0.2201 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1566/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.2026 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9582 - val_loss: 0.2199 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1567/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.2023 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9579 - val_loss: 0.2198 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1568/2000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.2023 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9580 - val_loss: 0.2197 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1569/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.2024 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9580 - val_loss: 0.2195 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1570/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.2022 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9582 - val_loss: 0.2197 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1571/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.2021 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9580 - val_loss: 0.2195 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1572/2000\n",
            "300/300 [==============================] - 0s 103us/step - loss: 0.2021 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9579 - val_loss: 0.2193 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1573/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.2021 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9561 - val_loss: 0.2194 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1574/2000\n",
            "300/300 [==============================] - 0s 82us/step - loss: 0.2019 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9583 - val_loss: 0.2192 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1575/2000\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.2017 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9581 - val_loss: 0.2192 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1576/2000\n",
            "300/300 [==============================] - 0s 82us/step - loss: 0.2018 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9581 - val_loss: 0.2191 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1577/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.2017 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9562 - val_loss: 0.2190 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1578/2000\n",
            "300/300 [==============================] - 0s 103us/step - loss: 0.2015 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9582 - val_loss: 0.2190 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1579/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.2016 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9579 - val_loss: 0.2190 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1580/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.2015 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9581 - val_loss: 0.2189 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1581/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.2014 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9583 - val_loss: 0.2188 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1582/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.2014 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9581 - val_loss: 0.2189 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1583/2000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.2013 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9580 - val_loss: 0.2188 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1584/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.2013 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9577 - val_loss: 0.2187 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1585/2000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.2013 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9564 - val_loss: 0.2188 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1586/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.2012 - precision: 1.0000 - recall: 0.9233 - f1_score: 0.9597 - val_loss: 0.2187 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1587/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.2010 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9582 - val_loss: 0.2186 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1588/2000\n",
            "300/300 [==============================] - 0s 103us/step - loss: 0.2010 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9582 - val_loss: 0.2185 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1589/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.2014 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9564 - val_loss: 0.2186 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1590/2000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.2008 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9583 - val_loss: 0.2186 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1591/2000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.2008 - precision: 1.0000 - recall: 0.9233 - f1_score: 0.9598 - val_loss: 0.2184 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1592/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.2006 - precision: 1.0000 - recall: 0.9233 - f1_score: 0.9600 - val_loss: 0.2182 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1593/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.2005 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9583 - val_loss: 0.2182 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1594/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.2009 - precision: 1.0000 - recall: 0.9233 - f1_score: 0.9600 - val_loss: 0.2179 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1595/2000\n",
            "300/300 [==============================] - 0s 105us/step - loss: 0.2005 - precision: 1.0000 - recall: 0.9233 - f1_score: 0.9599 - val_loss: 0.2178 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1596/2000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.2004 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9581 - val_loss: 0.2178 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1597/2000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.2004 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9580 - val_loss: 0.2177 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1598/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.2003 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9582 - val_loss: 0.2177 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1599/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.2002 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9581 - val_loss: 0.2175 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1600/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.2002 - precision: 1.0000 - recall: 0.9233 - f1_score: 0.9600 - val_loss: 0.2174 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1601/2000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.2000 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9582 - val_loss: 0.2174 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1602/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.2001 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9581 - val_loss: 0.2172 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1603/2000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.1999 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9581 - val_loss: 0.2171 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1604/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.2000 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9580 - val_loss: 0.2169 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1605/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.1998 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9581 - val_loss: 0.2168 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1606/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.1997 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9581 - val_loss: 0.2169 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1607/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.1996 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9582 - val_loss: 0.2167 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1608/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.1997 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9581 - val_loss: 0.2168 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1609/2000\n",
            "300/300 [==============================] - 0s 101us/step - loss: 0.1998 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9578 - val_loss: 0.2170 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1610/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.1996 - precision: 1.0000 - recall: 0.9233 - f1_score: 0.9599 - val_loss: 0.2168 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1611/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.1995 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9581 - val_loss: 0.2167 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1612/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.1993 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9581 - val_loss: 0.2166 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1613/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.1993 - precision: 1.0000 - recall: 0.9233 - f1_score: 0.9598 - val_loss: 0.2166 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1614/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.1992 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9583 - val_loss: 0.2164 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1615/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.1991 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9580 - val_loss: 0.2163 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1616/2000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.1991 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9580 - val_loss: 0.2163 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1617/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.1989 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9576 - val_loss: 0.2161 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1618/2000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.1989 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9575 - val_loss: 0.2160 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1619/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.1988 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9582 - val_loss: 0.2160 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1620/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.1989 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9613 - val_loss: 0.2157 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1621/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.1987 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9582 - val_loss: 0.2156 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1622/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.1988 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9580 - val_loss: 0.2156 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1623/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.1988 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9558 - val_loss: 0.2156 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1624/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.1987 - precision: 1.0000 - recall: 0.9233 - f1_score: 0.9600 - val_loss: 0.2154 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1625/2000\n",
            "300/300 [==============================] - 0s 81us/step - loss: 0.1985 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9577 - val_loss: 0.2153 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1626/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.1985 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9577 - val_loss: 0.2153 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1627/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.1983 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9579 - val_loss: 0.2152 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1628/2000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.1984 - precision: 1.0000 - recall: 0.9233 - f1_score: 0.9599 - val_loss: 0.2151 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1629/2000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.1983 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9581 - val_loss: 0.2152 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1630/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.1986 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9582 - val_loss: 0.2156 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1631/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.1981 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9615 - val_loss: 0.2154 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1632/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.1980 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9619 - val_loss: 0.2153 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1633/2000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.1982 - precision: 1.0000 - recall: 0.9233 - f1_score: 0.9597 - val_loss: 0.2151 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1634/2000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.1980 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9617 - val_loss: 0.2150 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1635/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.1979 - precision: 1.0000 - recall: 0.9233 - f1_score: 0.9596 - val_loss: 0.2148 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1636/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.1980 - precision: 1.0000 - recall: 0.9233 - f1_score: 0.9600 - val_loss: 0.2150 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1637/2000\n",
            "300/300 [==============================] - 0s 101us/step - loss: 0.1977 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9619 - val_loss: 0.2148 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1638/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.1976 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.2147 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1639/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.1975 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9616 - val_loss: 0.2144 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1640/2000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.1974 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.2143 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1641/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.1975 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9582 - val_loss: 0.2143 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1642/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.1974 - precision: 1.0000 - recall: 0.9233 - f1_score: 0.9596 - val_loss: 0.2143 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1643/2000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.1974 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9577 - val_loss: 0.2142 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1644/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.1973 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9617 - val_loss: 0.2141 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1645/2000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.1972 - precision: 1.0000 - recall: 0.9233 - f1_score: 0.9597 - val_loss: 0.2140 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1646/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.1971 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9582 - val_loss: 0.2140 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1647/2000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.1971 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.2137 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1648/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.1970 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9582 - val_loss: 0.2136 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1649/2000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.1972 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9582 - val_loss: 0.2135 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1650/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.1969 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9583 - val_loss: 0.2135 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1651/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.1968 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9581 - val_loss: 0.2135 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1652/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.1968 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9582 - val_loss: 0.2135 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1653/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.1968 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.2134 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1654/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.1966 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9582 - val_loss: 0.2133 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1655/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.1965 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9616 - val_loss: 0.2131 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1656/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.1964 - precision: 1.0000 - recall: 0.9233 - f1_score: 0.9599 - val_loss: 0.2131 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1657/2000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.1965 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9581 - val_loss: 0.2129 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1658/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.1963 - precision: 1.0000 - recall: 0.9233 - f1_score: 0.9600 - val_loss: 0.2128 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1659/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.1963 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9575 - val_loss: 0.2127 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1660/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.1962 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9579 - val_loss: 0.2127 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1661/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.1962 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9580 - val_loss: 0.2126 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1662/2000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.1960 - precision: 1.0000 - recall: 0.9233 - f1_score: 0.9600 - val_loss: 0.2126 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1663/2000\n",
            "300/300 [==============================] - 0s 82us/step - loss: 0.1960 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9583 - val_loss: 0.2126 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1664/2000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.1960 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9582 - val_loss: 0.2125 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1665/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.1960 - precision: 1.0000 - recall: 0.9233 - f1_score: 0.9600 - val_loss: 0.2124 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1666/2000\n",
            "300/300 [==============================] - 0s 82us/step - loss: 0.1959 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9583 - val_loss: 0.2123 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1667/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.1957 - precision: 1.0000 - recall: 0.9233 - f1_score: 0.9600 - val_loss: 0.2122 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1668/2000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.1957 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9580 - val_loss: 0.2121 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1669/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.1956 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9581 - val_loss: 0.2122 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1670/2000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.1955 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9619 - val_loss: 0.2121 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1671/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.1955 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.2119 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1672/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.1955 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9582 - val_loss: 0.2121 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1673/2000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.1953 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.2119 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1674/2000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.1954 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.2118 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1675/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.1954 - precision: 1.0000 - recall: 0.9233 - f1_score: 0.9600 - val_loss: 0.2116 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1676/2000\n",
            "300/300 [==============================] - 0s 107us/step - loss: 0.1952 - precision: 1.0000 - recall: 0.9233 - f1_score: 0.9601 - val_loss: 0.2116 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1677/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.1951 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9612 - val_loss: 0.2116 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1678/2000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.1950 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9617 - val_loss: 0.2116 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1679/2000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.1951 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9615 - val_loss: 0.2115 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1680/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.1949 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9616 - val_loss: 0.2115 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1681/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.1949 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9619 - val_loss: 0.2114 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1682/2000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.1950 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9616 - val_loss: 0.2113 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1683/2000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.1948 - precision: 1.0000 - recall: 0.9233 - f1_score: 0.9600 - val_loss: 0.2112 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1684/2000\n",
            "300/300 [==============================] - 0s 111us/step - loss: 0.1947 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9613 - val_loss: 0.2112 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1685/2000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.1946 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.2111 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1686/2000\n",
            "300/300 [==============================] - 0s 103us/step - loss: 0.1945 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9616 - val_loss: 0.2110 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1687/2000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.1945 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9616 - val_loss: 0.2110 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1688/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.1944 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9616 - val_loss: 0.2109 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1689/2000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.1943 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9619 - val_loss: 0.2109 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1690/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.1946 - precision: 1.0000 - recall: 0.9233 - f1_score: 0.9599 - val_loss: 0.2110 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1691/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.1942 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9619 - val_loss: 0.2109 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1692/2000\n",
            "300/300 [==============================] - 0s 80us/step - loss: 0.1941 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9616 - val_loss: 0.2108 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1693/2000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.1945 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.2107 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1694/2000\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.1940 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9619 - val_loss: 0.2105 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1695/2000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.1940 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9617 - val_loss: 0.2105 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1696/2000\n",
            "300/300 [==============================] - 0s 103us/step - loss: 0.1939 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9619 - val_loss: 0.2103 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1697/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.1938 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9615 - val_loss: 0.2102 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1698/2000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.1938 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.2100 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1699/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.1937 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9617 - val_loss: 0.2101 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1700/2000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.1937 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9619 - val_loss: 0.2100 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1701/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.1936 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9619 - val_loss: 0.2099 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1702/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.1938 - precision: 1.0000 - recall: 0.9233 - f1_score: 0.9600 - val_loss: 0.2099 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1703/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.1937 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9619 - val_loss: 0.2096 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1704/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.1935 - precision: 1.0000 - recall: 0.9233 - f1_score: 0.9601 - val_loss: 0.2096 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1705/2000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.1934 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.2097 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1706/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.1933 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.2097 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1707/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.1932 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.2095 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1708/2000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.1933 - precision: 1.0000 - recall: 0.9233 - f1_score: 0.9601 - val_loss: 0.2094 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1709/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.1931 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.2094 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1710/2000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.1932 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9582 - val_loss: 0.2094 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1711/2000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.1930 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.2091 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1712/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.1929 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9615 - val_loss: 0.2090 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1713/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.1929 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9619 - val_loss: 0.2089 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1714/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.1928 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.2087 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1715/2000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.1927 - precision: 1.0000 - recall: 0.9233 - f1_score: 0.9599 - val_loss: 0.2087 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1716/2000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.1926 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9580 - val_loss: 0.2087 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1717/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.1926 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9617 - val_loss: 0.2087 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1718/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.1925 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.2087 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1719/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.1925 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.2086 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1720/2000\n",
            "300/300 [==============================] - 0s 106us/step - loss: 0.1926 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9617 - val_loss: 0.2084 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1721/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.1925 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9616 - val_loss: 0.2084 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1722/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.1924 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.2085 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1723/2000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.1922 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.2085 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1724/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.1923 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.2082 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1725/2000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.1923 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9581 - val_loss: 0.2082 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1726/2000\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.1920 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9617 - val_loss: 0.2081 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1727/2000\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.1921 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9616 - val_loss: 0.2080 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1728/2000\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.1921 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9616 - val_loss: 0.2078 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1729/2000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.1920 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9614 - val_loss: 0.2077 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1730/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.1918 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9614 - val_loss: 0.2077 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1731/2000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.1919 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9616 - val_loss: 0.2075 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1732/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.1917 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9615 - val_loss: 0.2075 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1733/2000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.1916 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9619 - val_loss: 0.2074 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1734/2000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.1917 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9578 - val_loss: 0.2075 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1735/2000\n",
            "300/300 [==============================] - 0s 109us/step - loss: 0.1915 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9614 - val_loss: 0.2074 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1736/2000\n",
            "300/300 [==============================] - 0s 82us/step - loss: 0.1914 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.2074 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1737/2000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.1916 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9613 - val_loss: 0.2074 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1738/2000\n",
            "300/300 [==============================] - 0s 80us/step - loss: 0.1914 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9617 - val_loss: 0.2071 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1739/2000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.1914 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.2073 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1740/2000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.1913 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.2070 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1741/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.1912 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9617 - val_loss: 0.2068 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1742/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.1911 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9619 - val_loss: 0.2066 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1743/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.1910 - precision: 1.0000 - recall: 0.9233 - f1_score: 0.9600 - val_loss: 0.2066 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1744/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.1910 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9582 - val_loss: 0.2067 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1745/2000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.1908 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.2066 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1746/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.1909 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9617 - val_loss: 0.2065 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1747/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.1908 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9616 - val_loss: 0.2064 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1748/2000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.1909 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9617 - val_loss: 0.2063 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1749/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.1907 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9581 - val_loss: 0.2062 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1750/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.1907 - precision: 1.0000 - recall: 0.9233 - f1_score: 0.9600 - val_loss: 0.2063 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1751/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.1906 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.2062 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1752/2000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.1904 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9617 - val_loss: 0.2062 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1753/2000\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.1904 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9615 - val_loss: 0.2061 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1754/2000\n",
            "300/300 [==============================] - 0s 103us/step - loss: 0.1904 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9619 - val_loss: 0.2059 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1755/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.1904 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.2059 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1756/2000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.1902 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.2059 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1757/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.1902 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9615 - val_loss: 0.2059 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1758/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.1902 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9617 - val_loss: 0.2059 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1759/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.1902 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9617 - val_loss: 0.2057 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1760/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.1902 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9615 - val_loss: 0.2057 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1761/2000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.1899 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.2056 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1762/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.1899 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.2055 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1763/2000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.1898 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9619 - val_loss: 0.2055 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1764/2000\n",
            "300/300 [==============================] - 0s 82us/step - loss: 0.1899 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9616 - val_loss: 0.2053 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1765/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.1896 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.2052 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1766/2000\n",
            "300/300 [==============================] - 0s 82us/step - loss: 0.1897 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.2053 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1767/2000\n",
            "300/300 [==============================] - 0s 121us/step - loss: 0.1896 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9617 - val_loss: 0.2053 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1768/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.1896 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.2051 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1769/2000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.1897 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9617 - val_loss: 0.2049 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1770/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.1894 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.2049 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1771/2000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.1894 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9619 - val_loss: 0.2048 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1772/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.1894 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.2049 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1773/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.1892 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9617 - val_loss: 0.2048 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1774/2000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.1891 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.2047 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1775/2000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.1891 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9612 - val_loss: 0.2046 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1776/2000\n",
            "300/300 [==============================] - 0s 81us/step - loss: 0.1890 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9617 - val_loss: 0.2046 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1777/2000\n",
            "300/300 [==============================] - 0s 80us/step - loss: 0.1891 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9616 - val_loss: 0.2047 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1778/2000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.1889 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9615 - val_loss: 0.2046 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1779/2000\n",
            "300/300 [==============================] - 0s 78us/step - loss: 0.1889 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9614 - val_loss: 0.2044 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1780/2000\n",
            "300/300 [==============================] - 0s 82us/step - loss: 0.1888 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.2043 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1781/2000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.1889 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9613 - val_loss: 0.2042 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1782/2000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.1887 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9616 - val_loss: 0.2040 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1783/2000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.1887 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.2039 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1784/2000\n",
            "300/300 [==============================] - 0s 82us/step - loss: 0.1887 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9619 - val_loss: 0.2039 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1785/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.1885 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.2038 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1786/2000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.1887 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9619 - val_loss: 0.2039 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1787/2000\n",
            "300/300 [==============================] - 0s 103us/step - loss: 0.1885 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9615 - val_loss: 0.2038 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1788/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.1884 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.2038 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1789/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.1883 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9617 - val_loss: 0.2037 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1790/2000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.1883 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.2037 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1791/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.1881 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9617 - val_loss: 0.2036 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1792/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.1882 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9615 - val_loss: 0.2034 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1793/2000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.1881 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9619 - val_loss: 0.2033 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1794/2000\n",
            "300/300 [==============================] - 0s 81us/step - loss: 0.1881 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9617 - val_loss: 0.2033 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1795/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.1879 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9619 - val_loss: 0.2032 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1796/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.1881 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9619 - val_loss: 0.2029 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1797/2000\n",
            "300/300 [==============================] - 0s 104us/step - loss: 0.1879 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9617 - val_loss: 0.2029 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1798/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.1879 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9617 - val_loss: 0.2029 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1799/2000\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.1877 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.2029 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1800/2000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.1878 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9615 - val_loss: 0.2028 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1801/2000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.1876 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9619 - val_loss: 0.2027 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1802/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.1877 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9614 - val_loss: 0.2026 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1803/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.1874 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9619 - val_loss: 0.2026 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1804/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.1875 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9616 - val_loss: 0.2026 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1805/2000\n",
            "300/300 [==============================] - 0s 79us/step - loss: 0.1873 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.2025 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1806/2000\n",
            "300/300 [==============================] - 0s 81us/step - loss: 0.1873 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.2025 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1807/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.1873 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9617 - val_loss: 0.2024 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1808/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.1874 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9617 - val_loss: 0.2024 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1809/2000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.1871 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.2024 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1810/2000\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.1872 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9619 - val_loss: 0.2022 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1811/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.1870 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9615 - val_loss: 0.2021 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1812/2000\n",
            "300/300 [==============================] - 0s 79us/step - loss: 0.1870 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.2020 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1813/2000\n",
            "300/300 [==============================] - 0s 82us/step - loss: 0.1869 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9616 - val_loss: 0.2019 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1814/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.1870 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9616 - val_loss: 0.2018 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1815/2000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.1868 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9616 - val_loss: 0.2018 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1816/2000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.1867 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9615 - val_loss: 0.2017 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1817/2000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.1867 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9619 - val_loss: 0.2017 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1818/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.1867 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9615 - val_loss: 0.2016 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1819/2000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.1865 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9616 - val_loss: 0.2015 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1820/2000\n",
            "300/300 [==============================] - 0s 82us/step - loss: 0.1865 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9619 - val_loss: 0.2015 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1821/2000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.1866 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9613 - val_loss: 0.2013 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1822/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.1865 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9617 - val_loss: 0.2013 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1823/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.1864 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9616 - val_loss: 0.2013 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1824/2000\n",
            "300/300 [==============================] - 0s 103us/step - loss: 0.1863 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9619 - val_loss: 0.2013 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1825/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.1865 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9617 - val_loss: 0.2012 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1826/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.1863 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.2012 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1827/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.1864 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9613 - val_loss: 0.2011 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1828/2000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.1862 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9614 - val_loss: 0.2010 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1829/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.1860 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9615 - val_loss: 0.2009 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1830/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.1861 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9619 - val_loss: 0.2008 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1831/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.1859 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9617 - val_loss: 0.2007 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1832/2000\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.1860 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9617 - val_loss: 0.2005 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1833/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.1858 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9617 - val_loss: 0.2004 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1834/2000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.1858 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.2004 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1835/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.1858 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.2003 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1836/2000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.1856 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9614 - val_loss: 0.2003 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1837/2000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.1857 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9619 - val_loss: 0.2002 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1838/2000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.1858 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9614 - val_loss: 0.2001 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1839/2000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.1855 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9619 - val_loss: 0.2000 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1840/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.1855 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9617 - val_loss: 0.2000 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1841/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.1853 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9615 - val_loss: 0.1999 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1842/2000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.1857 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9617 - val_loss: 0.1997 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1843/2000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.1854 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9619 - val_loss: 0.1998 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1844/2000\n",
            "300/300 [==============================] - 0s 82us/step - loss: 0.1851 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9617 - val_loss: 0.1998 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1845/2000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.1851 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9616 - val_loss: 0.1997 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1846/2000\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.1852 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9617 - val_loss: 0.1996 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1847/2000\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.1850 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9619 - val_loss: 0.1996 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1848/2000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.1851 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9614 - val_loss: 0.1994 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1849/2000\n",
            "300/300 [==============================] - 0s 82us/step - loss: 0.1849 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9616 - val_loss: 0.1993 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1850/2000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.1849 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.1993 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1851/2000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.1848 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9619 - val_loss: 0.1992 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1852/2000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.1847 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9617 - val_loss: 0.1992 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1853/2000\n",
            "300/300 [==============================] - 0s 105us/step - loss: 0.1846 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9617 - val_loss: 0.1992 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1854/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.1846 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9619 - val_loss: 0.1992 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1855/2000\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.1846 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9617 - val_loss: 0.1993 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1856/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.1846 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9616 - val_loss: 0.1993 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1857/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.1844 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9617 - val_loss: 0.1992 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1858/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.1845 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9614 - val_loss: 0.1991 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1859/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.1844 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9614 - val_loss: 0.1991 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1860/2000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.1844 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9619 - val_loss: 0.1989 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1861/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.1842 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9615 - val_loss: 0.1989 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1862/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.1843 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9613 - val_loss: 0.1987 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1863/2000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.1841 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9617 - val_loss: 0.1987 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1864/2000\n",
            "300/300 [==============================] - 0s 82us/step - loss: 0.1841 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.1986 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1865/2000\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.1840 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9616 - val_loss: 0.1986 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1866/2000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.1839 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.1984 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1867/2000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.1838 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9619 - val_loss: 0.1983 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1868/2000\n",
            "300/300 [==============================] - 0s 81us/step - loss: 0.1841 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9616 - val_loss: 0.1983 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1869/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.1838 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.1982 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1870/2000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.1837 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9617 - val_loss: 0.1981 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1871/2000\n",
            "300/300 [==============================] - 0s 106us/step - loss: 0.1837 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.1982 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1872/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.1836 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9619 - val_loss: 0.1980 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1873/2000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.1835 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9615 - val_loss: 0.1979 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1874/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.1838 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.1981 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1875/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.1835 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9617 - val_loss: 0.1979 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1876/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.1834 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9619 - val_loss: 0.1979 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1877/2000\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.1834 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9616 - val_loss: 0.1978 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1878/2000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.1833 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.1976 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1879/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.1833 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9617 - val_loss: 0.1974 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1880/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.1831 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.1974 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1881/2000\n",
            "300/300 [==============================] - 0s 103us/step - loss: 0.1831 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9616 - val_loss: 0.1974 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1882/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.1832 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.1974 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1883/2000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.1831 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9609 - val_loss: 0.1972 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1884/2000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.1830 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9619 - val_loss: 0.1970 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1885/2000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.1829 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9619 - val_loss: 0.1971 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1886/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.1830 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9616 - val_loss: 0.1971 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1887/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.1827 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.1971 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1888/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.1827 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.1970 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1889/2000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.1829 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9617 - val_loss: 0.1972 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1890/2000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.1827 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9617 - val_loss: 0.1970 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1891/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.1825 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9619 - val_loss: 0.1969 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1892/2000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.1825 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9616 - val_loss: 0.1969 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1893/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.1825 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9613 - val_loss: 0.1969 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1894/2000\n",
            "300/300 [==============================] - 0s 80us/step - loss: 0.1824 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9619 - val_loss: 0.1968 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1895/2000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.1823 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9613 - val_loss: 0.1967 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1896/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.1823 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9619 - val_loss: 0.1966 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1897/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.1822 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9617 - val_loss: 0.1966 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1898/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.1823 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9617 - val_loss: 0.1965 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1899/2000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.1821 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9615 - val_loss: 0.1965 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1900/2000\n",
            "300/300 [==============================] - 0s 82us/step - loss: 0.1821 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.1964 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1901/2000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.1820 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.1964 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1902/2000\n",
            "300/300 [==============================] - 0s 80us/step - loss: 0.1819 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9612 - val_loss: 0.1963 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1903/2000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.1819 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9616 - val_loss: 0.1962 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1904/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.1820 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.1962 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1905/2000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.1819 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9617 - val_loss: 0.1959 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1906/2000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.1818 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9617 - val_loss: 0.1958 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1907/2000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.1818 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9613 - val_loss: 0.1957 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1908/2000\n",
            "300/300 [==============================] - 0s 101us/step - loss: 0.1816 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9617 - val_loss: 0.1955 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1909/2000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.1816 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.1955 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1910/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.1815 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9617 - val_loss: 0.1955 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1911/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.1815 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9617 - val_loss: 0.1955 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1912/2000\n",
            "300/300 [==============================] - 0s 82us/step - loss: 0.1815 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9617 - val_loss: 0.1955 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1913/2000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.1814 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9619 - val_loss: 0.1953 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1914/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.1813 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9617 - val_loss: 0.1952 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1915/2000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.1814 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9617 - val_loss: 0.1951 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1916/2000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.1812 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9617 - val_loss: 0.1950 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1917/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.1812 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9617 - val_loss: 0.1949 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1918/2000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.1813 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9619 - val_loss: 0.1949 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1919/2000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.1811 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.1948 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1920/2000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.1810 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.1947 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1921/2000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.1809 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9617 - val_loss: 0.1948 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1922/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.1809 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.1948 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1923/2000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.1810 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9619 - val_loss: 0.1948 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1924/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.1809 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9617 - val_loss: 0.1947 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1925/2000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.1808 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9619 - val_loss: 0.1946 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1926/2000\n",
            "300/300 [==============================] - 0s 82us/step - loss: 0.1807 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9613 - val_loss: 0.1945 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1927/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.1806 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9619 - val_loss: 0.1944 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1928/2000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.1806 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.1944 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1929/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.1805 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9617 - val_loss: 0.1944 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1930/2000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.1806 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9615 - val_loss: 0.1943 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1931/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.1804 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9616 - val_loss: 0.1943 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1932/2000\n",
            "300/300 [==============================] - 0s 102us/step - loss: 0.1805 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9615 - val_loss: 0.1941 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1933/2000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.1804 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9616 - val_loss: 0.1940 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1934/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.1802 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9615 - val_loss: 0.1940 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1935/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.1802 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9617 - val_loss: 0.1939 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1936/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.1803 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9616 - val_loss: 0.1938 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1937/2000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.1802 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9612 - val_loss: 0.1937 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1938/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.1801 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9617 - val_loss: 0.1938 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1939/2000\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.1801 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9615 - val_loss: 0.1936 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1940/2000\n",
            "300/300 [==============================] - 0s 103us/step - loss: 0.1800 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.1936 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1941/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.1799 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9617 - val_loss: 0.1937 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1942/2000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.1799 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9616 - val_loss: 0.1937 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1943/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.1798 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9616 - val_loss: 0.1937 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1944/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.1798 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.1937 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1945/2000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.1797 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9610 - val_loss: 0.1936 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1946/2000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.1796 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.1935 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1947/2000\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.1795 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9617 - val_loss: 0.1933 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1948/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.1796 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9619 - val_loss: 0.1933 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1949/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.1796 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9613 - val_loss: 0.1934 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1950/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.1794 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9617 - val_loss: 0.1933 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1951/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.1794 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9617 - val_loss: 0.1932 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1952/2000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.1794 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9617 - val_loss: 0.1933 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1953/2000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.1795 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9616 - val_loss: 0.1933 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1954/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.1794 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9615 - val_loss: 0.1931 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1955/2000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.1792 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9615 - val_loss: 0.1929 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1956/2000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.1792 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.1930 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1957/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.1790 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.1930 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1958/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.1790 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9617 - val_loss: 0.1929 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1959/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.1790 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9617 - val_loss: 0.1928 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1960/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.1790 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9614 - val_loss: 0.1928 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1961/2000\n",
            "300/300 [==============================] - 0s 81us/step - loss: 0.1791 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9616 - val_loss: 0.1926 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1962/2000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.1790 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.1925 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1963/2000\n",
            "300/300 [==============================] - 0s 79us/step - loss: 0.1787 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9619 - val_loss: 0.1924 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1964/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.1788 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.1923 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1965/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.1786 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.1922 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1966/2000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.1786 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.1921 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1967/2000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.1785 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9612 - val_loss: 0.1921 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1968/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.1785 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.1920 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1969/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.1784 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.1921 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1970/2000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.1784 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9619 - val_loss: 0.1920 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1971/2000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.1783 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9617 - val_loss: 0.1920 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1972/2000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.1783 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9614 - val_loss: 0.1918 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1973/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.1782 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9616 - val_loss: 0.1918 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1974/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.1783 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9616 - val_loss: 0.1917 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1975/2000\n",
            "300/300 [==============================] - 0s 80us/step - loss: 0.1781 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9615 - val_loss: 0.1917 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1976/2000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.1781 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9614 - val_loss: 0.1916 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1977/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.1780 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9617 - val_loss: 0.1916 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1978/2000\n",
            "300/300 [==============================] - 0s 105us/step - loss: 0.1779 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9616 - val_loss: 0.1916 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1979/2000\n",
            "300/300 [==============================] - 0s 105us/step - loss: 0.1779 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.1915 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1980/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.1779 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9619 - val_loss: 0.1914 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1981/2000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.1778 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9617 - val_loss: 0.1914 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1982/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.1778 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.1914 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1983/2000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.1778 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9616 - val_loss: 0.1912 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1984/2000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.1777 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.1910 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1985/2000\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.1777 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.1908 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1986/2000\n",
            "300/300 [==============================] - 0s 104us/step - loss: 0.1776 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9617 - val_loss: 0.1909 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1987/2000\n",
            "300/300 [==============================] - 0s 104us/step - loss: 0.1779 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9615 - val_loss: 0.1909 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1988/2000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.1774 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.1909 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1989/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.1777 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.1910 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1990/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.1774 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9616 - val_loss: 0.1910 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1991/2000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.1773 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9619 - val_loss: 0.1909 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1992/2000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.1772 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.1907 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1993/2000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.1773 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9619 - val_loss: 0.1906 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1994/2000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.1772 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.1906 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1995/2000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.1773 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9615 - val_loss: 0.1906 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1996/2000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.1772 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9619 - val_loss: 0.1906 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1997/2000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.1770 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9619 - val_loss: 0.1906 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1998/2000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.1770 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.1905 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 1999/2000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.1771 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9619 - val_loss: 0.1903 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2000/2000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.1769 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9619 - val_loss: 0.1901 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "v18B9tYZAPEN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We now plot the training history."
      ]
    },
    {
      "metadata": {
        "id": "01kabwyOALRx",
        "colab_type": "code",
        "outputId": "0899ee36-1556-4346-ef05-7acfa116d6f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        }
      },
      "cell_type": "code",
      "source": [
        "plt.plot(history_sgd.history['f1_score'])\n",
        "plt.plot(history_sgd.history['val_f1_score'])\n",
        "plt.title('model f1 score')\n",
        "plt.ylabel('f1 score')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history_sgd.history['loss'])\n",
        "plt.plot(history_sgd.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEVCAYAAADpbDJPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxmSo/wd6Xq9SYAD7eAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fbc4e103cc0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEVCAYAAADpbDJPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fbc4e067e48>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "PIxsNwI74erS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Adam optimizer\n",
        "We train our model with Adam optimizer"
      ]
    },
    {
      "metadata": {
        "id": "5Om6YXQD4ghf",
        "colab_type": "code",
        "outputId": "0461c8bf-b41e-4ab6-a952-384ce5fef255",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3607
        }
      },
      "cell_type": "code",
      "source": [
        "optimizer = Adam(0.001)\n",
        "loss = 'binary_crossentropy'\n",
        "metrics = [get_metrics(0.5)['precision'], get_metrics(0.5)['recall'], get_metrics(0.5)['f1_score']]\n",
        "\n",
        "model_adam = get_model(optimizer, loss, metrics)\n",
        "\n",
        "history_adam = model_adam.fit(X_train, Y_train,\n",
        "          epochs=100,\n",
        "          batch_size=32,\n",
        "          validation_data=(X_valid, Y_valid)\n",
        "         )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_2 (Dense)              (None, 3)                 15555     \n",
            "=================================================================\n",
            "Total params: 15,555\n",
            "Trainable params: 15,555\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 300 samples, validate on 60 samples\n",
            "Epoch 1/100\n",
            "300/300 [==============================] - 0s 741us/step - loss: 1.4209 - precision: 0.3658 - recall: 0.3633 - f1_score: 0.3645 - val_loss: 1.2316 - val_precision: 0.3333 - val_recall: 0.3333 - val_f1_score: 0.3333\n",
            "Epoch 2/100\n",
            "300/300 [==============================] - 0s 131us/step - loss: 0.7036 - precision: 0.4657 - recall: 0.4167 - f1_score: 0.4367 - val_loss: 0.4515 - val_precision: 0.7563 - val_recall: 0.5167 - val_f1_score: 0.6139\n",
            "Epoch 3/100\n",
            "300/300 [==============================] - 0s 128us/step - loss: 0.4080 - precision: 0.7472 - recall: 0.6733 - f1_score: 0.7068 - val_loss: 0.3091 - val_precision: 0.9395 - val_recall: 0.7833 - val_f1_score: 0.8542\n",
            "Epoch 4/100\n",
            "300/300 [==============================] - 0s 112us/step - loss: 0.3074 - precision: 0.8710 - recall: 0.7367 - f1_score: 0.7957 - val_loss: 0.3625 - val_precision: 0.6778 - val_recall: 0.6667 - val_f1_score: 0.6721\n",
            "Epoch 5/100\n",
            "300/300 [==============================] - 0s 115us/step - loss: 0.2615 - precision: 0.8969 - recall: 0.8233 - f1_score: 0.8578 - val_loss: 0.2318 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9472\n",
            "Epoch 6/100\n",
            "300/300 [==============================] - 0s 123us/step - loss: 0.2193 - precision: 0.9421 - recall: 0.8667 - f1_score: 0.9021 - val_loss: 0.1993 - val_precision: 1.0000 - val_recall: 0.9833 - val_f1_score: 0.9915\n",
            "Epoch 7/100\n",
            "300/300 [==============================] - 0s 119us/step - loss: 0.1850 - precision: 0.9930 - recall: 0.9500 - f1_score: 0.9702 - val_loss: 0.1950 - val_precision: 0.9822 - val_recall: 0.9167 - val_f1_score: 0.9483\n",
            "Epoch 8/100\n",
            "300/300 [==============================] - 0s 115us/step - loss: 0.1741 - precision: 0.9587 - recall: 0.9033 - f1_score: 0.9300 - val_loss: 0.1627 - val_precision: 1.0000 - val_recall: 0.9833 - val_f1_score: 0.9915\n",
            "Epoch 9/100\n",
            "300/300 [==============================] - 0s 125us/step - loss: 0.1963 - precision: 0.8900 - recall: 0.8800 - f1_score: 0.8849 - val_loss: 0.1946 - val_precision: 0.8167 - val_recall: 0.8167 - val_f1_score: 0.8167\n",
            "Epoch 10/100\n",
            "300/300 [==============================] - 0s 108us/step - loss: 0.1528 - precision: 0.9220 - recall: 0.9000 - f1_score: 0.9107 - val_loss: 0.1841 - val_precision: 0.8000 - val_recall: 0.8000 - val_f1_score: 0.8000\n",
            "Epoch 11/100\n",
            "300/300 [==============================] - 0s 111us/step - loss: 0.1357 - precision: 0.9457 - recall: 0.9267 - f1_score: 0.9360 - val_loss: 0.1224 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 12/100\n",
            "300/300 [==============================] - 0s 116us/step - loss: 0.1216 - precision: 0.9595 - recall: 0.9500 - f1_score: 0.9547 - val_loss: 0.1030 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 13/100\n",
            "300/300 [==============================] - 0s 117us/step - loss: 0.1013 - precision: 0.9967 - recall: 0.9867 - f1_score: 0.9915 - val_loss: 0.1095 - val_precision: 1.0000 - val_recall: 0.9833 - val_f1_score: 0.9915\n",
            "Epoch 14/100\n",
            "300/300 [==============================] - 0s 115us/step - loss: 0.0962 - precision: 0.9829 - recall: 0.9767 - f1_score: 0.9797 - val_loss: 0.0894 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 15/100\n",
            "300/300 [==============================] - 0s 114us/step - loss: 0.1156 - precision: 0.9625 - recall: 0.9500 - f1_score: 0.9561 - val_loss: 0.0908 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 16/100\n",
            "300/300 [==============================] - 0s 128us/step - loss: 0.0850 - precision: 0.9933 - recall: 0.9933 - f1_score: 0.9933 - val_loss: 0.0742 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 17/100\n",
            "300/300 [==============================] - 0s 145us/step - loss: 0.0684 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0743 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 18/100\n",
            "300/300 [==============================] - 0s 123us/step - loss: 0.0695 - precision: 0.9967 - recall: 0.9933 - f1_score: 0.9950 - val_loss: 0.0771 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 19/100\n",
            "300/300 [==============================] - 0s 131us/step - loss: 0.0873 - precision: 0.9796 - recall: 0.9667 - f1_score: 0.9729 - val_loss: 0.0929 - val_precision: 0.9661 - val_recall: 0.9500 - val_f1_score: 0.9579\n",
            "Epoch 20/100\n",
            "300/300 [==============================] - 0s 117us/step - loss: 0.0678 - precision: 0.9967 - recall: 0.9967 - f1_score: 0.9967 - val_loss: 0.0565 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 21/100\n",
            "300/300 [==============================] - 0s 115us/step - loss: 0.0602 - precision: 0.9967 - recall: 0.9967 - f1_score: 0.9967 - val_loss: 0.0523 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 22/100\n",
            "300/300 [==============================] - 0s 116us/step - loss: 0.0566 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0467 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 23/100\n",
            "300/300 [==============================] - 0s 131us/step - loss: 0.0530 - precision: 0.9967 - recall: 0.9967 - f1_score: 0.9967 - val_loss: 0.0466 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 24/100\n",
            "300/300 [==============================] - 0s 122us/step - loss: 0.0466 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0412 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 25/100\n",
            "300/300 [==============================] - 0s 133us/step - loss: 0.0437 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0478 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 26/100\n",
            "300/300 [==============================] - 0s 127us/step - loss: 0.0412 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0387 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 27/100\n",
            "300/300 [==============================] - 0s 133us/step - loss: 0.0412 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0364 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 28/100\n",
            "300/300 [==============================] - 0s 140us/step - loss: 0.0383 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0357 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 29/100\n",
            "300/300 [==============================] - 0s 128us/step - loss: 0.0334 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0357 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 30/100\n",
            "300/300 [==============================] - 0s 141us/step - loss: 0.0330 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0352 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 31/100\n",
            "300/300 [==============================] - 0s 118us/step - loss: 0.0314 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0329 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 32/100\n",
            "300/300 [==============================] - 0s 129us/step - loss: 0.0287 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0341 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 33/100\n",
            "300/300 [==============================] - 0s 130us/step - loss: 0.0315 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0351 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 34/100\n",
            "300/300 [==============================] - 0s 115us/step - loss: 0.0408 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0297 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 35/100\n",
            "300/300 [==============================] - 0s 134us/step - loss: 0.0422 - precision: 0.9967 - recall: 0.9967 - f1_score: 0.9967 - val_loss: 0.0245 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 36/100\n",
            "300/300 [==============================] - 0s 136us/step - loss: 0.0290 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0241 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 37/100\n",
            "300/300 [==============================] - 0s 121us/step - loss: 0.0252 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0226 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 38/100\n",
            "300/300 [==============================] - 0s 128us/step - loss: 0.0255 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0218 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 39/100\n",
            "300/300 [==============================] - 0s 121us/step - loss: 0.0217 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0209 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 40/100\n",
            "300/300 [==============================] - 0s 138us/step - loss: 0.0213 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0214 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 41/100\n",
            "300/300 [==============================] - 0s 124us/step - loss: 0.0216 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0223 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 42/100\n",
            "300/300 [==============================] - 0s 113us/step - loss: 0.0194 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0194 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 43/100\n",
            "300/300 [==============================] - 0s 112us/step - loss: 0.0198 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0197 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 44/100\n",
            "300/300 [==============================] - 0s 116us/step - loss: 0.0191 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0217 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 45/100\n",
            "300/300 [==============================] - 0s 107us/step - loss: 0.0176 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0176 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 46/100\n",
            "300/300 [==============================] - 0s 125us/step - loss: 0.0170 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0167 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 47/100\n",
            "300/300 [==============================] - 0s 126us/step - loss: 0.0169 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0164 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 48/100\n",
            "300/300 [==============================] - 0s 128us/step - loss: 0.0159 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0159 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 49/100\n",
            "300/300 [==============================] - 0s 139us/step - loss: 0.0153 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0154 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 50/100\n",
            "300/300 [==============================] - 0s 134us/step - loss: 0.0149 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0171 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 51/100\n",
            "300/300 [==============================] - 0s 118us/step - loss: 0.0156 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0148 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 52/100\n",
            "300/300 [==============================] - 0s 122us/step - loss: 0.0141 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0144 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 53/100\n",
            "300/300 [==============================] - 0s 119us/step - loss: 0.0138 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0141 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 54/100\n",
            "300/300 [==============================] - 0s 143us/step - loss: 0.0139 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0137 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 55/100\n",
            "300/300 [==============================] - 0s 157us/step - loss: 0.0132 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0146 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 56/100\n",
            "300/300 [==============================] - 0s 128us/step - loss: 0.0137 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0131 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 57/100\n",
            "300/300 [==============================] - 0s 118us/step - loss: 0.0123 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0127 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 58/100\n",
            "300/300 [==============================] - 0s 109us/step - loss: 0.0120 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0136 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 59/100\n",
            "300/300 [==============================] - 0s 139us/step - loss: 0.0136 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0118 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 60/100\n",
            "300/300 [==============================] - 0s 113us/step - loss: 0.0113 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0116 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 61/100\n",
            "300/300 [==============================] - 0s 121us/step - loss: 0.0111 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0112 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 62/100\n",
            "300/300 [==============================] - 0s 111us/step - loss: 0.0108 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0110 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 63/100\n",
            "300/300 [==============================] - 0s 117us/step - loss: 0.0107 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0113 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 64/100\n",
            "300/300 [==============================] - 0s 109us/step - loss: 0.0107 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0105 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 65/100\n",
            "300/300 [==============================] - 0s 107us/step - loss: 0.0101 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0102 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 66/100\n",
            "300/300 [==============================] - 0s 117us/step - loss: 0.0103 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0105 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 67/100\n",
            "300/300 [==============================] - 0s 120us/step - loss: 0.0097 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0098 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 68/100\n",
            "300/300 [==============================] - 0s 111us/step - loss: 0.0094 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0096 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 69/100\n",
            "300/300 [==============================] - 0s 116us/step - loss: 0.0095 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0103 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 70/100\n",
            "300/300 [==============================] - 0s 127us/step - loss: 0.0092 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0093 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 71/100\n",
            "300/300 [==============================] - 0s 114us/step - loss: 0.0090 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0090 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 72/100\n",
            "300/300 [==============================] - 0s 119us/step - loss: 0.0088 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0089 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 73/100\n",
            "300/300 [==============================] - 0s 119us/step - loss: 0.0089 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0089 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 74/100\n",
            "300/300 [==============================] - 0s 120us/step - loss: 0.0086 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0094 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 75/100\n",
            "300/300 [==============================] - 0s 122us/step - loss: 0.0084 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0084 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 76/100\n",
            "300/300 [==============================] - 0s 119us/step - loss: 0.0081 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0082 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 77/100\n",
            "300/300 [==============================] - 0s 122us/step - loss: 0.0078 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0080 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 78/100\n",
            "300/300 [==============================] - 0s 127us/step - loss: 0.0077 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0079 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 79/100\n",
            "300/300 [==============================] - 0s 140us/step - loss: 0.0077 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0079 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 80/100\n",
            "300/300 [==============================] - 0s 131us/step - loss: 0.0075 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0077 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 81/100\n",
            "300/300 [==============================] - 0s 141us/step - loss: 0.0073 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0074 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 82/100\n",
            "300/300 [==============================] - 0s 124us/step - loss: 0.0071 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0073 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 83/100\n",
            "300/300 [==============================] - 0s 121us/step - loss: 0.0070 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0071 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 84/100\n",
            "300/300 [==============================] - 0s 124us/step - loss: 0.0068 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0070 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 85/100\n",
            "300/300 [==============================] - 0s 119us/step - loss: 0.0068 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0069 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 86/100\n",
            "300/300 [==============================] - 0s 117us/step - loss: 0.0065 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0067 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 87/100\n",
            "300/300 [==============================] - 0s 107us/step - loss: 0.0065 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0067 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 88/100\n",
            "300/300 [==============================] - 0s 104us/step - loss: 0.0066 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0070 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 89/100\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.0063 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0065 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 90/100\n",
            "300/300 [==============================] - 0s 105us/step - loss: 0.0061 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0066 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 91/100\n",
            "300/300 [==============================] - 0s 115us/step - loss: 0.0064 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0062 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 92/100\n",
            "300/300 [==============================] - 0s 127us/step - loss: 0.0059 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0061 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 93/100\n",
            "300/300 [==============================] - 0s 115us/step - loss: 0.0059 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0060 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 94/100\n",
            "300/300 [==============================] - 0s 110us/step - loss: 0.0057 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0059 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 95/100\n",
            "300/300 [==============================] - 0s 113us/step - loss: 0.0056 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0058 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 96/100\n",
            "300/300 [==============================] - 0s 107us/step - loss: 0.0056 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0057 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 97/100\n",
            "300/300 [==============================] - 0s 106us/step - loss: 0.0055 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0056 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 98/100\n",
            "300/300 [==============================] - 0s 117us/step - loss: 0.0055 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0055 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 99/100\n",
            "300/300 [==============================] - 0s 129us/step - loss: 0.0053 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0054 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 100/100\n",
            "300/300 [==============================] - 0s 121us/step - loss: 0.0053 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0054 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "ny-RqSHuB41C"
      },
      "cell_type": "markdown",
      "source": [
        "We now plot the training history."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "BlCWcUl7B41D",
        "outputId": "faa1ed34-5736-4df0-cc32-efbbba43f762",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        }
      },
      "cell_type": "code",
      "source": [
        "plt.plot(history_adam.history['f1_score'])\n",
        "plt.plot(history_adam.history['val_f1_score'])\n",
        "plt.title('model f1 score')\n",
        "plt.ylabel('f1 score')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'valid'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history_adam.history['loss'])\n",
        "plt.plot(history_adam.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'valid'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEVCAYAAADpbDJPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRNT/D1TBEDk3MuWNAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fbc4dc1a278>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEVCAYAAADpbDJPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niIgk1P8Hclfug+MSzFEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fbc4dc399e8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "ZjtCfj465HoA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Visualization of solution"
      ]
    },
    {
      "metadata": {
        "id": "VI3ZCWZGnsRZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### SGD"
      ]
    },
    {
      "metadata": {
        "id": "OjxbuPKW5KWS",
        "colab_type": "code",
        "outputId": "4368c932-7e44-4aba-c403-a5aad2a06607",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        }
      },
      "cell_type": "code",
      "source": [
        "weights = model_sgd.get_weights()[0]\n",
        "weights = weights.reshape(IMAGE_SIZE, IMAGE_SIZE, weights.shape[1])\n",
        "_, [ax0, ax1, ax2] = plt.subplots(1, 3)\n",
        "ax0.imshow(weights[:,:,0], cmap='gray')\n",
        "ax1.imshow(weights[:,:,1], cmap='gray')\n",
        "ax2.imshow(weights[:,:,2], cmap='gray')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fbc4daa4320>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW8AAACFCAYAAACUlHlEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCyEZbwkSJEh4CyEZbwkSJEh4C/HfdYw5BUrYGuUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fbc4dc09da0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "L7263erinwAh"
      },
      "cell_type": "markdown",
      "source": [
        "#### Adam"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "df0dpCmGnwAh",
        "outputId": "413362c7-afac-48da-dec9-cb562e1d5bee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        }
      },
      "cell_type": "code",
      "source": [
        "weights = model_adam.get_weights()[0]\n",
        "weights = weights.reshape(IMAGE_SIZE, IMAGE_SIZE, weights.shape[1])\n",
        "_, [ax0, ax1, ax2] = plt.subplots(1, 3)\n",
        "ax0.imshow(weights[:,:,0], cmap='gray')\n",
        "ax1.imshow(weights[:,:,1], cmap='gray')\n",
        "ax2.imshow(weights[:,:,2], cmap='gray')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fbc4d98c4a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW8AAACFCAYAAACUlHlEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fbc4daecba8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "vhU0Og7RA_Oi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## A More Difficult Classification Problem"
      ]
    },
    {
      "metadata": {
        "id": "3kaahExhBIhT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Train and validation data\n",
        "We generate training and validation sets with shapes of different size and positions."
      ]
    },
    {
      "metadata": {
        "id": "YESUnKbSBAof",
        "colab_type": "code",
        "outputId": "a7f0a1d2-1cf5-424f-e89a-ad7f16cb14cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        }
      },
      "cell_type": "code",
      "source": [
        "[X_train, Y_train] = generate_dataset_classification(300, 20, True)\n",
        "[X_valid, Y_valid] = generate_dataset_classification(60, 20, True)\n",
        "Y_train = np_utils.to_categorical(Y_train)\n",
        "Y_valid = np_utils.to_categorical(Y_valid)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating data:\n",
            "0\n",
            "10\n",
            "20\n",
            "30\n",
            "40\n",
            "50\n",
            "60\n",
            "70\n",
            "80\n",
            "90\n",
            "100\n",
            "110\n",
            "120\n",
            "130\n",
            "140\n",
            "150\n",
            "160\n",
            "170\n",
            "180\n",
            "190\n",
            "200\n",
            "210\n",
            "220\n",
            "230\n",
            "240\n",
            "250\n",
            "260\n",
            "270\n",
            "280\n",
            "290\n",
            "Creating data:\n",
            "0\n",
            "10\n",
            "20\n",
            "30\n",
            "40\n",
            "50\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KMpQXKMvLaWV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Test Data\n",
        "We generate a test dataset to compare the models."
      ]
    },
    {
      "metadata": {
        "id": "Np7MGsSyLcRy",
        "colab_type": "code",
        "outputId": "09bbb714-8fac-4e8e-f911-b21f7f8bb5b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "cell_type": "code",
      "source": [
        "[X_test, Y_test] = generate_test_set_classification()\n",
        "X_test = X_test.reshape(X_test.shape[0], IMAGE_SIZE*IMAGE_SIZE,)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating data:\n",
            "0\n",
            "10\n",
            "20\n",
            "30\n",
            "40\n",
            "50\n",
            "60\n",
            "70\n",
            "80\n",
            "90\n",
            "100\n",
            "110\n",
            "120\n",
            "130\n",
            "140\n",
            "150\n",
            "160\n",
            "170\n",
            "180\n",
            "190\n",
            "200\n",
            "210\n",
            "220\n",
            "230\n",
            "240\n",
            "250\n",
            "260\n",
            "270\n",
            "280\n",
            "290\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yvvk8IUDLiZt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Dense model train on moving shapes\n",
        "Lets train the previous models on this new data"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "f--PtPhFRhy8"
      },
      "cell_type": "markdown",
      "source": [
        "#### Stochastic gradient descent\n",
        "We train our model with SGD"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "NPoNUiuPRhy8",
        "outputId": "563e6e7c-5f3b-40c9-fe8b-33b0ca822664",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17207
        }
      },
      "cell_type": "code",
      "source": [
        "optimizer = SGD(lr=0.001, momentum=0.0, decay=0.0, nesterov=False) # 0.001 learning rate without modifications during gradient descent\n",
        "loss = 'binary_crossentropy'\n",
        "metrics = [get_metrics(0.5)['precision'], get_metrics(0.5)['recall'], get_metrics(0.5)['f1_score']]\n",
        "\n",
        "model_sgd = get_model(optimizer, loss, metrics)\n",
        "\n",
        "history_sgd = model_sgd.fit(X_train, Y_train,\n",
        "          epochs=500,\n",
        "          batch_size=64,\n",
        "          validation_data=(X_valid, Y_valid)\n",
        "         )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_3 (Dense)              (None, 3)                 15555     \n",
            "=================================================================\n",
            "Total params: 15,555\n",
            "Trainable params: 15,555\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 300 samples, validate on 60 samples\n",
            "Epoch 1/500\n",
            "300/300 [==============================] - 0s 779us/step - loss: 0.6651 - precision: 0.1201 - recall: 0.0667 - f1_score: 0.0822 - val_loss: 0.6179 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00\n",
            "Epoch 2/500\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.6393 - precision: 0.2533 - recall: 0.0167 - f1_score: 0.0289 - val_loss: 0.6244 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00\n",
            "Epoch 3/500\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.6320 - precision: 0.2974 - recall: 0.0167 - f1_score: 0.0295 - val_loss: 0.6421 - val_precision: 0.2500 - val_recall: 0.0167 - val_f1_score: 0.0312\n",
            "Epoch 4/500\n",
            "300/300 [==============================] - 0s 78us/step - loss: 0.6331 - precision: 0.4844 - recall: 0.0200 - f1_score: 0.0379 - val_loss: 0.6242 - val_precision: 0.3333 - val_recall: 0.0167 - val_f1_score: 0.0317\n",
            "Epoch 5/500\n",
            "300/300 [==============================] - 0s 81us/step - loss: 0.6271 - precision: 0.5356 - recall: 0.0167 - f1_score: 0.0321 - val_loss: 0.6556 - val_precision: 0.2632 - val_recall: 0.0833 - val_f1_score: 0.1266\n",
            "Epoch 6/500\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.6256 - precision: 0.5914 - recall: 0.0367 - f1_score: 0.0649 - val_loss: 0.6134 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00\n",
            "Epoch 7/500\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.6259 - precision: 0.3804 - recall: 0.0200 - f1_score: 0.0378 - val_loss: 0.6165 - val_precision: 0.5000 - val_recall: 0.0167 - val_f1_score: 0.0323\n",
            "Epoch 8/500\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.6165 - precision: 0.7987 - recall: 0.0300 - f1_score: 0.0573 - val_loss: 0.6145 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00\n",
            "Epoch 9/500\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.6177 - precision: 0.7562 - recall: 0.0333 - f1_score: 0.0620 - val_loss: 0.6146 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00\n",
            "Epoch 10/500\n",
            "300/300 [==============================] - 0s 82us/step - loss: 0.6099 - precision: 0.8222 - recall: 0.0300 - f1_score: 0.0574 - val_loss: 0.6176 - val_precision: 0.3333 - val_recall: 0.0167 - val_f1_score: 0.0317\n",
            "Epoch 11/500\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.6119 - precision: 0.7175 - recall: 0.0567 - f1_score: 0.1027 - val_loss: 0.5974 - val_precision: 0.5556 - val_recall: 0.0833 - val_f1_score: 0.1449\n",
            "Epoch 12/500\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.6123 - precision: 0.7453 - recall: 0.0333 - f1_score: 0.0632 - val_loss: 0.6034 - val_precision: 0.2500 - val_recall: 0.0167 - val_f1_score: 0.0312\n",
            "Epoch 13/500\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.6030 - precision: 0.7947 - recall: 0.0500 - f1_score: 0.0923 - val_loss: 0.6058 - val_precision: 0.4000 - val_recall: 0.0333 - val_f1_score: 0.0615\n",
            "Epoch 14/500\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.6027 - precision: 0.7253 - recall: 0.0600 - f1_score: 0.1108 - val_loss: 0.6466 - val_precision: 0.2963 - val_recall: 0.1333 - val_f1_score: 0.1839\n",
            "Epoch 15/500\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.6032 - precision: 0.5756 - recall: 0.1033 - f1_score: 0.1655 - val_loss: 0.6174 - val_precision: 0.4286 - val_recall: 0.0500 - val_f1_score: 0.0896\n",
            "Epoch 16/500\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.6016 - precision: 0.6679 - recall: 0.0933 - f1_score: 0.1635 - val_loss: 0.6120 - val_precision: 0.4286 - val_recall: 0.0500 - val_f1_score: 0.0896\n",
            "Epoch 17/500\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.5969 - precision: 0.7415 - recall: 0.1033 - f1_score: 0.1805 - val_loss: 0.6018 - val_precision: 0.6667 - val_recall: 0.0667 - val_f1_score: 0.1212\n",
            "Epoch 18/500\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.5906 - precision: 0.8213 - recall: 0.0967 - f1_score: 0.1682 - val_loss: 0.5930 - val_precision: 0.5000 - val_recall: 0.0667 - val_f1_score: 0.1176\n",
            "Epoch 19/500\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.5907 - precision: 0.7947 - recall: 0.0900 - f1_score: 0.1613 - val_loss: 0.6087 - val_precision: 0.3333 - val_recall: 0.0333 - val_f1_score: 0.0606\n",
            "Epoch 20/500\n",
            "300/300 [==============================] - 0s 102us/step - loss: 0.5889 - precision: 0.7972 - recall: 0.1033 - f1_score: 0.1796 - val_loss: 0.6321 - val_precision: 0.3043 - val_recall: 0.1167 - val_f1_score: 0.1687\n",
            "Epoch 21/500\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.5969 - precision: 0.6631 - recall: 0.1233 - f1_score: 0.1973 - val_loss: 0.5952 - val_precision: 0.4286 - val_recall: 0.0500 - val_f1_score: 0.0896\n",
            "Epoch 22/500\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.5836 - precision: 0.7268 - recall: 0.1067 - f1_score: 0.1841 - val_loss: 0.5974 - val_precision: 0.6667 - val_recall: 0.1000 - val_f1_score: 0.1739\n",
            "Epoch 23/500\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.5805 - precision: 0.8517 - recall: 0.1367 - f1_score: 0.2331 - val_loss: 0.6021 - val_precision: 0.5000 - val_recall: 0.0500 - val_f1_score: 0.0909\n",
            "Epoch 24/500\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.5834 - precision: 0.7655 - recall: 0.1100 - f1_score: 0.1923 - val_loss: 0.6389 - val_precision: 0.3056 - val_recall: 0.1833 - val_f1_score: 0.2292\n",
            "Epoch 25/500\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.5741 - precision: 0.7489 - recall: 0.2167 - f1_score: 0.3091 - val_loss: 0.5919 - val_precision: 0.7000 - val_recall: 0.1167 - val_f1_score: 0.2000\n",
            "Epoch 26/500\n",
            "300/300 [==============================] - 0s 101us/step - loss: 0.5799 - precision: 0.7783 - recall: 0.1167 - f1_score: 0.2026 - val_loss: 0.5997 - val_precision: 0.7000 - val_recall: 0.1167 - val_f1_score: 0.2000\n",
            "Epoch 27/500\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.5758 - precision: 0.8128 - recall: 0.1467 - f1_score: 0.2476 - val_loss: 0.6055 - val_precision: 0.4444 - val_recall: 0.0667 - val_f1_score: 0.1159\n",
            "Epoch 28/500\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.5781 - precision: 0.7513 - recall: 0.1500 - f1_score: 0.2493 - val_loss: 0.6125 - val_precision: 0.5000 - val_recall: 0.1167 - val_f1_score: 0.1892\n",
            "Epoch 29/500\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.5706 - precision: 0.7916 - recall: 0.1567 - f1_score: 0.2576 - val_loss: 0.6211 - val_precision: 0.4583 - val_recall: 0.1833 - val_f1_score: 0.2619\n",
            "Epoch 30/500\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.5693 - precision: 0.7355 - recall: 0.1767 - f1_score: 0.2783 - val_loss: 0.5953 - val_precision: 0.7000 - val_recall: 0.1167 - val_f1_score: 0.2000\n",
            "Epoch 31/500\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.5700 - precision: 0.8055 - recall: 0.1633 - f1_score: 0.2698 - val_loss: 0.5985 - val_precision: 0.6364 - val_recall: 0.1167 - val_f1_score: 0.1972\n",
            "Epoch 32/500\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.5633 - precision: 0.8251 - recall: 0.1467 - f1_score: 0.2478 - val_loss: 0.5991 - val_precision: 0.5000 - val_recall: 0.0667 - val_f1_score: 0.1176\n",
            "Epoch 33/500\n",
            "300/300 [==============================] - 0s 81us/step - loss: 0.5668 - precision: 0.7106 - recall: 0.1633 - f1_score: 0.2644 - val_loss: 0.5920 - val_precision: 0.6667 - val_recall: 0.1000 - val_f1_score: 0.1739\n",
            "Epoch 34/500\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.5702 - precision: 0.7686 - recall: 0.1700 - f1_score: 0.2744 - val_loss: 0.6425 - val_precision: 0.3721 - val_recall: 0.2667 - val_f1_score: 0.3107\n",
            "Epoch 35/500\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.5672 - precision: 0.7175 - recall: 0.1967 - f1_score: 0.2872 - val_loss: 0.6105 - val_precision: 0.5238 - val_recall: 0.1833 - val_f1_score: 0.2716\n",
            "Epoch 36/500\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.5614 - precision: 0.8523 - recall: 0.1800 - f1_score: 0.2911 - val_loss: 0.6072 - val_precision: 0.4545 - val_recall: 0.0833 - val_f1_score: 0.1408\n",
            "Epoch 37/500\n",
            "300/300 [==============================] - 0s 103us/step - loss: 0.5632 - precision: 0.7709 - recall: 0.1667 - f1_score: 0.2687 - val_loss: 0.6154 - val_precision: 0.4400 - val_recall: 0.1833 - val_f1_score: 0.2588\n",
            "Epoch 38/500\n",
            "300/300 [==============================] - 0s 82us/step - loss: 0.5616 - precision: 0.8017 - recall: 0.1800 - f1_score: 0.2873 - val_loss: 0.6040 - val_precision: 0.5000 - val_recall: 0.1333 - val_f1_score: 0.2105\n",
            "Epoch 39/500\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.5535 - precision: 0.8279 - recall: 0.1867 - f1_score: 0.3013 - val_loss: 0.5965 - val_precision: 0.5385 - val_recall: 0.1167 - val_f1_score: 0.1918\n",
            "Epoch 40/500\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.5534 - precision: 0.8075 - recall: 0.1767 - f1_score: 0.2878 - val_loss: 0.5923 - val_precision: 0.6923 - val_recall: 0.1500 - val_f1_score: 0.2466\n",
            "Epoch 41/500\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.5531 - precision: 0.7697 - recall: 0.1967 - f1_score: 0.3095 - val_loss: 0.5810 - val_precision: 0.6923 - val_recall: 0.1500 - val_f1_score: 0.2466\n",
            "Epoch 42/500\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.5574 - precision: 0.7753 - recall: 0.1967 - f1_score: 0.3091 - val_loss: 0.5879 - val_precision: 0.6667 - val_recall: 0.1000 - val_f1_score: 0.1739\n",
            "Epoch 43/500\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.5517 - precision: 0.7573 - recall: 0.1933 - f1_score: 0.3025 - val_loss: 0.5812 - val_precision: 0.7143 - val_recall: 0.1667 - val_f1_score: 0.2703\n",
            "Epoch 44/500\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.5503 - precision: 0.8243 - recall: 0.1733 - f1_score: 0.2846 - val_loss: 0.5846 - val_precision: 0.6364 - val_recall: 0.1167 - val_f1_score: 0.1972\n",
            "Epoch 45/500\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.5494 - precision: 0.8219 - recall: 0.1733 - f1_score: 0.2796 - val_loss: 0.5833 - val_precision: 0.7500 - val_recall: 0.1500 - val_f1_score: 0.2500\n",
            "Epoch 46/500\n",
            "300/300 [==============================] - 0s 102us/step - loss: 0.5448 - precision: 0.8402 - recall: 0.1867 - f1_score: 0.3041 - val_loss: 0.5838 - val_precision: 0.7692 - val_recall: 0.1667 - val_f1_score: 0.2740\n",
            "Epoch 47/500\n",
            "300/300 [==============================] - 0s 82us/step - loss: 0.5483 - precision: 0.7809 - recall: 0.1867 - f1_score: 0.2978 - val_loss: 0.5964 - val_precision: 0.5000 - val_recall: 0.1333 - val_f1_score: 0.2105\n",
            "Epoch 48/500\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.5430 - precision: 0.7669 - recall: 0.2067 - f1_score: 0.3230 - val_loss: 0.5940 - val_precision: 0.5625 - val_recall: 0.1500 - val_f1_score: 0.2368\n",
            "Epoch 49/500\n",
            "300/300 [==============================] - 0s 80us/step - loss: 0.5421 - precision: 0.8162 - recall: 0.2067 - f1_score: 0.3273 - val_loss: 0.5833 - val_precision: 0.6667 - val_recall: 0.1667 - val_f1_score: 0.2667\n",
            "Epoch 50/500\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.5427 - precision: 0.8043 - recall: 0.2200 - f1_score: 0.3453 - val_loss: 0.5914 - val_precision: 0.6471 - val_recall: 0.1833 - val_f1_score: 0.2857\n",
            "Epoch 51/500\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.5427 - precision: 0.8480 - recall: 0.2133 - f1_score: 0.3402 - val_loss: 0.6351 - val_precision: 0.4419 - val_recall: 0.3167 - val_f1_score: 0.3689\n",
            "Epoch 52/500\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.5396 - precision: 0.7389 - recall: 0.3000 - f1_score: 0.4090 - val_loss: 0.5830 - val_precision: 0.6667 - val_recall: 0.1667 - val_f1_score: 0.2667\n",
            "Epoch 53/500\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.5411 - precision: 0.7564 - recall: 0.2100 - f1_score: 0.3275 - val_loss: 0.6048 - val_precision: 0.5238 - val_recall: 0.1833 - val_f1_score: 0.2716\n",
            "Epoch 54/500\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.5426 - precision: 0.8064 - recall: 0.2400 - f1_score: 0.3677 - val_loss: 0.5865 - val_precision: 0.7059 - val_recall: 0.2000 - val_f1_score: 0.3117\n",
            "Epoch 55/500\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.5395 - precision: 0.8191 - recall: 0.2300 - f1_score: 0.3565 - val_loss: 0.5887 - val_precision: 0.6250 - val_recall: 0.1667 - val_f1_score: 0.2632\n",
            "Epoch 56/500\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.5359 - precision: 0.8171 - recall: 0.2167 - f1_score: 0.3411 - val_loss: 0.6079 - val_precision: 0.4815 - val_recall: 0.2167 - val_f1_score: 0.2989\n",
            "Epoch 57/500\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.5366 - precision: 0.7556 - recall: 0.2433 - f1_score: 0.3671 - val_loss: 0.5866 - val_precision: 0.6250 - val_recall: 0.1667 - val_f1_score: 0.2632\n",
            "Epoch 58/500\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.5356 - precision: 0.7524 - recall: 0.2400 - f1_score: 0.3545 - val_loss: 0.5803 - val_precision: 0.6667 - val_recall: 0.1667 - val_f1_score: 0.2667\n",
            "Epoch 59/500\n",
            "300/300 [==============================] - 0s 82us/step - loss: 0.5352 - precision: 0.8303 - recall: 0.2367 - f1_score: 0.3663 - val_loss: 0.5910 - val_precision: 0.6000 - val_recall: 0.2000 - val_f1_score: 0.3000\n",
            "Epoch 60/500\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.5360 - precision: 0.7963 - recall: 0.2167 - f1_score: 0.3349 - val_loss: 0.6115 - val_precision: 0.4444 - val_recall: 0.2000 - val_f1_score: 0.2759\n",
            "Epoch 61/500\n",
            "300/300 [==============================] - 0s 80us/step - loss: 0.5357 - precision: 0.7327 - recall: 0.3000 - f1_score: 0.4226 - val_loss: 0.5885 - val_precision: 0.6316 - val_recall: 0.2000 - val_f1_score: 0.3038\n",
            "Epoch 62/500\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.5353 - precision: 0.7573 - recall: 0.2567 - f1_score: 0.3792 - val_loss: 0.5778 - val_precision: 0.6111 - val_recall: 0.3667 - val_f1_score: 0.4583\n",
            "Epoch 63/500\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.5406 - precision: 0.6956 - recall: 0.2800 - f1_score: 0.3844 - val_loss: 0.5868 - val_precision: 0.6111 - val_recall: 0.1833 - val_f1_score: 0.2821\n",
            "Epoch 64/500\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.5288 - precision: 0.8085 - recall: 0.2633 - f1_score: 0.3947 - val_loss: 0.5845 - val_precision: 0.6667 - val_recall: 0.2000 - val_f1_score: 0.3077\n",
            "Epoch 65/500\n",
            "300/300 [==============================] - 0s 107us/step - loss: 0.5300 - precision: 0.8106 - recall: 0.2567 - f1_score: 0.3830 - val_loss: 0.6072 - val_precision: 0.5000 - val_recall: 0.1500 - val_f1_score: 0.2308\n",
            "Epoch 66/500\n",
            "300/300 [==============================] - 0s 119us/step - loss: 0.5336 - precision: 0.7257 - recall: 0.2833 - f1_score: 0.4062 - val_loss: 0.5778 - val_precision: 0.7000 - val_recall: 0.2333 - val_f1_score: 0.3500\n",
            "Epoch 67/500\n",
            "300/300 [==============================] - 0s 80us/step - loss: 0.5249 - precision: 0.7858 - recall: 0.2400 - f1_score: 0.3620 - val_loss: 0.5842 - val_precision: 0.6667 - val_recall: 0.2000 - val_f1_score: 0.3077\n",
            "Epoch 68/500\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.5244 - precision: 0.8275 - recall: 0.2800 - f1_score: 0.4141 - val_loss: 0.5837 - val_precision: 0.6316 - val_recall: 0.2000 - val_f1_score: 0.3038\n",
            "Epoch 69/500\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.5214 - precision: 0.7997 - recall: 0.2700 - f1_score: 0.4009 - val_loss: 0.6165 - val_precision: 0.4737 - val_recall: 0.3000 - val_f1_score: 0.3673\n",
            "Epoch 70/500\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.5309 - precision: 0.7025 - recall: 0.3200 - f1_score: 0.4183 - val_loss: 0.5756 - val_precision: 0.7500 - val_recall: 0.2500 - val_f1_score: 0.3750\n",
            "Epoch 71/500\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.5210 - precision: 0.7860 - recall: 0.2600 - f1_score: 0.3903 - val_loss: 0.6032 - val_precision: 0.5357 - val_recall: 0.2500 - val_f1_score: 0.3409\n",
            "Epoch 72/500\n",
            "300/300 [==============================] - 0s 82us/step - loss: 0.5236 - precision: 0.8040 - recall: 0.2933 - f1_score: 0.4235 - val_loss: 0.5732 - val_precision: 0.6296 - val_recall: 0.2833 - val_f1_score: 0.3908\n",
            "Epoch 73/500\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.5221 - precision: 0.7826 - recall: 0.2833 - f1_score: 0.4126 - val_loss: 0.5751 - val_precision: 0.6364 - val_recall: 0.2333 - val_f1_score: 0.3415\n",
            "Epoch 74/500\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.5218 - precision: 0.7913 - recall: 0.2967 - f1_score: 0.4300 - val_loss: 0.5806 - val_precision: 0.6667 - val_recall: 0.2000 - val_f1_score: 0.3077\n",
            "Epoch 75/500\n",
            "300/300 [==============================] - 0s 101us/step - loss: 0.5204 - precision: 0.7925 - recall: 0.2733 - f1_score: 0.4049 - val_loss: 0.5806 - val_precision: 0.6471 - val_recall: 0.1833 - val_f1_score: 0.2857\n",
            "Epoch 76/500\n",
            "300/300 [==============================] - 0s 101us/step - loss: 0.5233 - precision: 0.7849 - recall: 0.2967 - f1_score: 0.4239 - val_loss: 0.6129 - val_precision: 0.4865 - val_recall: 0.3000 - val_f1_score: 0.3711\n",
            "Epoch 77/500\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.5188 - precision: 0.6947 - recall: 0.3667 - f1_score: 0.4665 - val_loss: 0.5728 - val_precision: 0.6333 - val_recall: 0.3167 - val_f1_score: 0.4222\n",
            "Epoch 78/500\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.5221 - precision: 0.7812 - recall: 0.2900 - f1_score: 0.4208 - val_loss: 0.5774 - val_precision: 0.7059 - val_recall: 0.2000 - val_f1_score: 0.3117\n",
            "Epoch 79/500\n",
            "300/300 [==============================] - 0s 101us/step - loss: 0.5181 - precision: 0.7768 - recall: 0.2767 - f1_score: 0.4065 - val_loss: 0.5751 - val_precision: 0.7143 - val_recall: 0.2500 - val_f1_score: 0.3704\n",
            "Epoch 80/500\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.5167 - precision: 0.8166 - recall: 0.2633 - f1_score: 0.3957 - val_loss: 0.5841 - val_precision: 0.6111 - val_recall: 0.1833 - val_f1_score: 0.2821\n",
            "Epoch 81/500\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.5175 - precision: 0.7902 - recall: 0.2633 - f1_score: 0.3917 - val_loss: 0.5885 - val_precision: 0.6000 - val_recall: 0.2000 - val_f1_score: 0.3000\n",
            "Epoch 82/500\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.5150 - precision: 0.7897 - recall: 0.2933 - f1_score: 0.4270 - val_loss: 0.5817 - val_precision: 0.6667 - val_recall: 0.2000 - val_f1_score: 0.3077\n",
            "Epoch 83/500\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.5164 - precision: 0.7854 - recall: 0.2800 - f1_score: 0.4108 - val_loss: 0.5746 - val_precision: 0.7143 - val_recall: 0.2500 - val_f1_score: 0.3704\n",
            "Epoch 84/500\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.5117 - precision: 0.7726 - recall: 0.2767 - f1_score: 0.4064 - val_loss: 0.5731 - val_precision: 0.6522 - val_recall: 0.2500 - val_f1_score: 0.3614\n",
            "Epoch 85/500\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.5096 - precision: 0.7936 - recall: 0.3033 - f1_score: 0.4384 - val_loss: 0.6096 - val_precision: 0.5143 - val_recall: 0.3000 - val_f1_score: 0.3789\n",
            "Epoch 86/500\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.5144 - precision: 0.7896 - recall: 0.3233 - f1_score: 0.4513 - val_loss: 0.5910 - val_precision: 0.6190 - val_recall: 0.2167 - val_f1_score: 0.3210\n",
            "Epoch 87/500\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.5117 - precision: 0.8063 - recall: 0.3100 - f1_score: 0.4439 - val_loss: 0.5797 - val_precision: 0.6364 - val_recall: 0.2333 - val_f1_score: 0.3415\n",
            "Epoch 88/500\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.5183 - precision: 0.7434 - recall: 0.3100 - f1_score: 0.4369 - val_loss: 0.5814 - val_precision: 0.6667 - val_recall: 0.2000 - val_f1_score: 0.3077\n",
            "Epoch 89/500\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.5108 - precision: 0.7979 - recall: 0.2767 - f1_score: 0.4054 - val_loss: 0.5781 - val_precision: 0.6316 - val_recall: 0.2000 - val_f1_score: 0.3038\n",
            "Epoch 90/500\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.5157 - precision: 0.7226 - recall: 0.3600 - f1_score: 0.4749 - val_loss: 0.5787 - val_precision: 0.6667 - val_recall: 0.2000 - val_f1_score: 0.3077\n",
            "Epoch 91/500\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.5102 - precision: 0.8047 - recall: 0.3133 - f1_score: 0.4427 - val_loss: 0.5762 - val_precision: 0.6667 - val_recall: 0.2000 - val_f1_score: 0.3077\n",
            "Epoch 92/500\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.5153 - precision: 0.7461 - recall: 0.3167 - f1_score: 0.4404 - val_loss: 0.6109 - val_precision: 0.5429 - val_recall: 0.3167 - val_f1_score: 0.4000\n",
            "Epoch 93/500\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.5123 - precision: 0.7004 - recall: 0.4000 - f1_score: 0.5064 - val_loss: 0.5732 - val_precision: 0.6667 - val_recall: 0.2667 - val_f1_score: 0.3810\n",
            "Epoch 94/500\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.5145 - precision: 0.7776 - recall: 0.3233 - f1_score: 0.4478 - val_loss: 0.5879 - val_precision: 0.5909 - val_recall: 0.2167 - val_f1_score: 0.3171\n",
            "Epoch 95/500\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.5109 - precision: 0.7540 - recall: 0.3167 - f1_score: 0.4356 - val_loss: 0.5841 - val_precision: 0.6190 - val_recall: 0.2167 - val_f1_score: 0.3210\n",
            "Epoch 96/500\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.5105 - precision: 0.7927 - recall: 0.3400 - f1_score: 0.4745 - val_loss: 0.6026 - val_precision: 0.5333 - val_recall: 0.2667 - val_f1_score: 0.3556\n",
            "Epoch 97/500\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.5113 - precision: 0.7415 - recall: 0.3467 - f1_score: 0.4672 - val_loss: 0.5900 - val_precision: 0.6364 - val_recall: 0.2333 - val_f1_score: 0.3415\n",
            "Epoch 98/500\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.5018 - precision: 0.8020 - recall: 0.3200 - f1_score: 0.4558 - val_loss: 0.5754 - val_precision: 0.7143 - val_recall: 0.2500 - val_f1_score: 0.3704\n",
            "Epoch 99/500\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.5054 - precision: 0.8091 - recall: 0.3167 - f1_score: 0.4530 - val_loss: 0.5966 - val_precision: 0.5769 - val_recall: 0.2500 - val_f1_score: 0.3488\n",
            "Epoch 100/500\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.5092 - precision: 0.7692 - recall: 0.3400 - f1_score: 0.4677 - val_loss: 0.5966 - val_precision: 0.5000 - val_recall: 0.1667 - val_f1_score: 0.2500\n",
            "Epoch 101/500\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.5033 - precision: 0.7770 - recall: 0.3400 - f1_score: 0.4712 - val_loss: 0.5784 - val_precision: 0.6818 - val_recall: 0.2500 - val_f1_score: 0.3659\n",
            "Epoch 102/500\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.5038 - precision: 0.7917 - recall: 0.3167 - f1_score: 0.4509 - val_loss: 0.5993 - val_precision: 0.5333 - val_recall: 0.2667 - val_f1_score: 0.3556\n",
            "Epoch 103/500\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.5027 - precision: 0.7787 - recall: 0.3167 - f1_score: 0.4437 - val_loss: 0.6156 - val_precision: 0.5000 - val_recall: 0.3667 - val_f1_score: 0.4231\n",
            "Epoch 104/500\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.5058 - precision: 0.7379 - recall: 0.3333 - f1_score: 0.4499 - val_loss: 0.5875 - val_precision: 0.5714 - val_recall: 0.2000 - val_f1_score: 0.2963\n",
            "Epoch 105/500\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.5009 - precision: 0.7648 - recall: 0.3267 - f1_score: 0.4558 - val_loss: 0.5840 - val_precision: 0.6190 - val_recall: 0.2167 - val_f1_score: 0.3210\n",
            "Epoch 106/500\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.4972 - precision: 0.7786 - recall: 0.3333 - f1_score: 0.4645 - val_loss: 0.5806 - val_precision: 0.5385 - val_recall: 0.3500 - val_f1_score: 0.4242\n",
            "Epoch 107/500\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.5048 - precision: 0.7434 - recall: 0.3133 - f1_score: 0.4315 - val_loss: 0.5771 - val_precision: 0.6071 - val_recall: 0.2833 - val_f1_score: 0.3864\n",
            "Epoch 108/500\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.5042 - precision: 0.7226 - recall: 0.3167 - f1_score: 0.4385 - val_loss: 0.5757 - val_precision: 0.6818 - val_recall: 0.2500 - val_f1_score: 0.3659\n",
            "Epoch 109/500\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.4966 - precision: 0.8177 - recall: 0.3200 - f1_score: 0.4577 - val_loss: 0.5760 - val_precision: 0.6364 - val_recall: 0.2333 - val_f1_score: 0.3415\n",
            "Epoch 110/500\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.4978 - precision: 0.8051 - recall: 0.3433 - f1_score: 0.4737 - val_loss: 0.5732 - val_precision: 0.6522 - val_recall: 0.2500 - val_f1_score: 0.3614\n",
            "Epoch 111/500\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.5032 - precision: 0.7193 - recall: 0.3600 - f1_score: 0.4748 - val_loss: 0.5954 - val_precision: 0.5926 - val_recall: 0.2667 - val_f1_score: 0.3678\n",
            "Epoch 112/500\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.4954 - precision: 0.7656 - recall: 0.3233 - f1_score: 0.4515 - val_loss: 0.5730 - val_precision: 0.6522 - val_recall: 0.2500 - val_f1_score: 0.3614\n",
            "Epoch 113/500\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.4972 - precision: 0.8085 - recall: 0.3300 - f1_score: 0.4679 - val_loss: 0.5836 - val_precision: 0.6190 - val_recall: 0.2167 - val_f1_score: 0.3210\n",
            "Epoch 114/500\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.4945 - precision: 0.8020 - recall: 0.3400 - f1_score: 0.4760 - val_loss: 0.5888 - val_precision: 0.6190 - val_recall: 0.2167 - val_f1_score: 0.3210\n",
            "Epoch 115/500\n",
            "300/300 [==============================] - 0s 101us/step - loss: 0.4972 - precision: 0.7818 - recall: 0.3467 - f1_score: 0.4706 - val_loss: 0.5758 - val_precision: 0.6000 - val_recall: 0.2500 - val_f1_score: 0.3529\n",
            "Epoch 116/500\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.4964 - precision: 0.7938 - recall: 0.3667 - f1_score: 0.4988 - val_loss: 0.5892 - val_precision: 0.6364 - val_recall: 0.2333 - val_f1_score: 0.3415\n",
            "Epoch 117/500\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.4952 - precision: 0.7997 - recall: 0.3400 - f1_score: 0.4764 - val_loss: 0.5747 - val_precision: 0.6429 - val_recall: 0.3000 - val_f1_score: 0.4091\n",
            "Epoch 118/500\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.4971 - precision: 0.7829 - recall: 0.3500 - f1_score: 0.4812 - val_loss: 0.5877 - val_precision: 0.5500 - val_recall: 0.1833 - val_f1_score: 0.2750\n",
            "Epoch 119/500\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.4971 - precision: 0.7338 - recall: 0.3600 - f1_score: 0.4783 - val_loss: 0.5743 - val_precision: 0.6818 - val_recall: 0.2500 - val_f1_score: 0.3659\n",
            "Epoch 120/500\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.4983 - precision: 0.7741 - recall: 0.3833 - f1_score: 0.5049 - val_loss: 0.5827 - val_precision: 0.6190 - val_recall: 0.2167 - val_f1_score: 0.3210\n",
            "Epoch 121/500\n",
            "300/300 [==============================] - 0s 105us/step - loss: 0.4926 - precision: 0.7637 - recall: 0.3567 - f1_score: 0.4831 - val_loss: 0.6069 - val_precision: 0.5135 - val_recall: 0.3167 - val_f1_score: 0.3918\n",
            "Epoch 122/500\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.4995 - precision: 0.7513 - recall: 0.3700 - f1_score: 0.4924 - val_loss: 0.5784 - val_precision: 0.6190 - val_recall: 0.2167 - val_f1_score: 0.3210\n",
            "Epoch 123/500\n",
            "300/300 [==============================] - 0s 82us/step - loss: 0.4930 - precision: 0.8038 - recall: 0.3300 - f1_score: 0.4656 - val_loss: 0.5865 - val_precision: 0.6190 - val_recall: 0.2167 - val_f1_score: 0.3210\n",
            "Epoch 124/500\n",
            "300/300 [==============================] - 0s 79us/step - loss: 0.4902 - precision: 0.8023 - recall: 0.3600 - f1_score: 0.4949 - val_loss: 0.5827 - val_precision: 0.6190 - val_recall: 0.2167 - val_f1_score: 0.3210\n",
            "Epoch 125/500\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.4897 - precision: 0.7805 - recall: 0.3567 - f1_score: 0.4885 - val_loss: 0.5861 - val_precision: 0.6190 - val_recall: 0.2167 - val_f1_score: 0.3210\n",
            "Epoch 126/500\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.4883 - precision: 0.7937 - recall: 0.3600 - f1_score: 0.4936 - val_loss: 0.5829 - val_precision: 0.6000 - val_recall: 0.2000 - val_f1_score: 0.3000\n",
            "Epoch 127/500\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.4886 - precision: 0.8068 - recall: 0.3467 - f1_score: 0.4778 - val_loss: 0.6280 - val_precision: 0.4889 - val_recall: 0.3667 - val_f1_score: 0.4190\n",
            "Epoch 128/500\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.4888 - precision: 0.7649 - recall: 0.4133 - f1_score: 0.5237 - val_loss: 0.5852 - val_precision: 0.6190 - val_recall: 0.2167 - val_f1_score: 0.3210\n",
            "Epoch 129/500\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.4940 - precision: 0.7680 - recall: 0.3700 - f1_score: 0.4931 - val_loss: 0.5802 - val_precision: 0.6250 - val_recall: 0.2500 - val_f1_score: 0.3571\n",
            "Epoch 130/500\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.4881 - precision: 0.8033 - recall: 0.3367 - f1_score: 0.4712 - val_loss: 0.5861 - val_precision: 0.5714 - val_recall: 0.2000 - val_f1_score: 0.2963\n",
            "Epoch 131/500\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.4897 - precision: 0.7588 - recall: 0.3567 - f1_score: 0.4804 - val_loss: 0.5810 - val_precision: 0.6087 - val_recall: 0.2333 - val_f1_score: 0.3373\n",
            "Epoch 132/500\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.4909 - precision: 0.7621 - recall: 0.3667 - f1_score: 0.4914 - val_loss: 0.6083 - val_precision: 0.5500 - val_recall: 0.3667 - val_f1_score: 0.4400\n",
            "Epoch 133/500\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.4929 - precision: 0.7796 - recall: 0.3467 - f1_score: 0.4763 - val_loss: 0.5787 - val_precision: 0.6087 - val_recall: 0.2333 - val_f1_score: 0.3373\n",
            "Epoch 134/500\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.4916 - precision: 0.8093 - recall: 0.3433 - f1_score: 0.4782 - val_loss: 0.6041 - val_precision: 0.5714 - val_recall: 0.3333 - val_f1_score: 0.4211\n",
            "Epoch 135/500\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.4883 - precision: 0.7787 - recall: 0.3700 - f1_score: 0.4912 - val_loss: 0.5731 - val_precision: 0.6400 - val_recall: 0.2667 - val_f1_score: 0.3765\n",
            "Epoch 136/500\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.4849 - precision: 0.7917 - recall: 0.3500 - f1_score: 0.4843 - val_loss: 0.5857 - val_precision: 0.6364 - val_recall: 0.2333 - val_f1_score: 0.3415\n",
            "Epoch 137/500\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.4887 - precision: 0.7407 - recall: 0.3800 - f1_score: 0.4983 - val_loss: 0.5849 - val_precision: 0.5909 - val_recall: 0.2167 - val_f1_score: 0.3171\n",
            "Epoch 138/500\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.4835 - precision: 0.7756 - recall: 0.3533 - f1_score: 0.4819 - val_loss: 0.5774 - val_precision: 0.6522 - val_recall: 0.2500 - val_f1_score: 0.3614\n",
            "Epoch 139/500\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.4822 - precision: 0.8095 - recall: 0.3800 - f1_score: 0.5165 - val_loss: 0.5794 - val_precision: 0.6000 - val_recall: 0.2000 - val_f1_score: 0.3000\n",
            "Epoch 140/500\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.4829 - precision: 0.7956 - recall: 0.3233 - f1_score: 0.4582 - val_loss: 0.5994 - val_precision: 0.5172 - val_recall: 0.2500 - val_f1_score: 0.3371\n",
            "Epoch 141/500\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.4825 - precision: 0.7770 - recall: 0.3733 - f1_score: 0.5006 - val_loss: 0.6039 - val_precision: 0.5588 - val_recall: 0.3167 - val_f1_score: 0.4043\n",
            "Epoch 142/500\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.4858 - precision: 0.7465 - recall: 0.3867 - f1_score: 0.5039 - val_loss: 0.5730 - val_precision: 0.6000 - val_recall: 0.2500 - val_f1_score: 0.3529\n",
            "Epoch 143/500\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.4842 - precision: 0.7721 - recall: 0.3700 - f1_score: 0.4978 - val_loss: 0.6064 - val_precision: 0.5385 - val_recall: 0.3500 - val_f1_score: 0.4242\n",
            "Epoch 144/500\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.4829 - precision: 0.7518 - recall: 0.4267 - f1_score: 0.5416 - val_loss: 0.5740 - val_precision: 0.5938 - val_recall: 0.3167 - val_f1_score: 0.4130\n",
            "Epoch 145/500\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.4833 - precision: 0.7539 - recall: 0.3833 - f1_score: 0.5054 - val_loss: 0.5919 - val_precision: 0.6154 - val_recall: 0.2667 - val_f1_score: 0.3721\n",
            "Epoch 146/500\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.4848 - precision: 0.7610 - recall: 0.3933 - f1_score: 0.5164 - val_loss: 0.5774 - val_precision: 0.6364 - val_recall: 0.2333 - val_f1_score: 0.3415\n",
            "Epoch 147/500\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.4934 - precision: 0.7529 - recall: 0.3700 - f1_score: 0.4910 - val_loss: 0.5946 - val_precision: 0.5000 - val_recall: 0.2333 - val_f1_score: 0.3182\n",
            "Epoch 148/500\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.4781 - precision: 0.7869 - recall: 0.3833 - f1_score: 0.5124 - val_loss: 0.5738 - val_precision: 0.5556 - val_recall: 0.2500 - val_f1_score: 0.3448\n",
            "Epoch 149/500\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.4789 - precision: 0.7833 - recall: 0.4067 - f1_score: 0.5340 - val_loss: 0.5742 - val_precision: 0.6538 - val_recall: 0.2833 - val_f1_score: 0.3953\n",
            "Epoch 150/500\n",
            "300/300 [==============================] - 0s 118us/step - loss: 0.4796 - precision: 0.7785 - recall: 0.3400 - f1_score: 0.4721 - val_loss: 0.5894 - val_precision: 0.5652 - val_recall: 0.2167 - val_f1_score: 0.3133\n",
            "Epoch 151/500\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.4763 - precision: 0.7906 - recall: 0.3767 - f1_score: 0.5060 - val_loss: 0.5841 - val_precision: 0.6250 - val_recall: 0.2500 - val_f1_score: 0.3571\n",
            "Epoch 152/500\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.4762 - precision: 0.7957 - recall: 0.3567 - f1_score: 0.4899 - val_loss: 0.5823 - val_precision: 0.6000 - val_recall: 0.2000 - val_f1_score: 0.3000\n",
            "Epoch 153/500\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.4772 - precision: 0.8054 - recall: 0.3800 - f1_score: 0.5130 - val_loss: 0.6045 - val_precision: 0.5135 - val_recall: 0.3167 - val_f1_score: 0.3918\n",
            "Epoch 154/500\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.4747 - precision: 0.7855 - recall: 0.4333 - f1_score: 0.5545 - val_loss: 0.5713 - val_precision: 0.6176 - val_recall: 0.3500 - val_f1_score: 0.4468\n",
            "Epoch 155/500\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.4763 - precision: 0.7882 - recall: 0.4000 - f1_score: 0.5279 - val_loss: 0.5919 - val_precision: 0.6000 - val_recall: 0.2500 - val_f1_score: 0.3529\n",
            "Epoch 156/500\n",
            "300/300 [==============================] - 0s 82us/step - loss: 0.4764 - precision: 0.7994 - recall: 0.3700 - f1_score: 0.4996 - val_loss: 0.5810 - val_precision: 0.6190 - val_recall: 0.2167 - val_f1_score: 0.3210\n",
            "Epoch 157/500\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.4795 - precision: 0.7717 - recall: 0.3767 - f1_score: 0.5044 - val_loss: 0.5721 - val_precision: 0.5938 - val_recall: 0.3167 - val_f1_score: 0.4130\n",
            "Epoch 158/500\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.4745 - precision: 0.7594 - recall: 0.4533 - f1_score: 0.5654 - val_loss: 0.5840 - val_precision: 0.5909 - val_recall: 0.2167 - val_f1_score: 0.3171\n",
            "Epoch 159/500\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.4735 - precision: 0.7952 - recall: 0.3900 - f1_score: 0.5191 - val_loss: 0.5717 - val_precision: 0.5758 - val_recall: 0.3167 - val_f1_score: 0.4086\n",
            "Epoch 160/500\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.4805 - precision: 0.7791 - recall: 0.3967 - f1_score: 0.5204 - val_loss: 0.6007 - val_precision: 0.5455 - val_recall: 0.3000 - val_f1_score: 0.3871\n",
            "Epoch 161/500\n",
            "300/300 [==============================] - 0s 79us/step - loss: 0.4803 - precision: 0.7317 - recall: 0.4233 - f1_score: 0.5341 - val_loss: 0.5856 - val_precision: 0.6154 - val_recall: 0.2667 - val_f1_score: 0.3721\n",
            "Epoch 162/500\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.4730 - precision: 0.7930 - recall: 0.3767 - f1_score: 0.5104 - val_loss: 0.5887 - val_precision: 0.6400 - val_recall: 0.2667 - val_f1_score: 0.3765\n",
            "Epoch 163/500\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.4723 - precision: 0.7588 - recall: 0.4000 - f1_score: 0.5221 - val_loss: 0.5848 - val_precision: 0.6087 - val_recall: 0.2333 - val_f1_score: 0.3373\n",
            "Epoch 164/500\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.4738 - precision: 0.7996 - recall: 0.3900 - f1_score: 0.5208 - val_loss: 0.5853 - val_precision: 0.5909 - val_recall: 0.2167 - val_f1_score: 0.3171\n",
            "Epoch 165/500\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.4724 - precision: 0.7847 - recall: 0.3933 - f1_score: 0.5206 - val_loss: 0.5790 - val_precision: 0.6000 - val_recall: 0.2500 - val_f1_score: 0.3529\n",
            "Epoch 166/500\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.4758 - precision: 0.7357 - recall: 0.3733 - f1_score: 0.4941 - val_loss: 0.5793 - val_precision: 0.6190 - val_recall: 0.2167 - val_f1_score: 0.3210\n",
            "Epoch 167/500\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.4757 - precision: 0.7645 - recall: 0.3700 - f1_score: 0.4983 - val_loss: 0.6033 - val_precision: 0.5405 - val_recall: 0.3333 - val_f1_score: 0.4124\n",
            "Epoch 168/500\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.4773 - precision: 0.7664 - recall: 0.3967 - f1_score: 0.5196 - val_loss: 0.5861 - val_precision: 0.6154 - val_recall: 0.2667 - val_f1_score: 0.3721\n",
            "Epoch 169/500\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.4718 - precision: 0.7821 - recall: 0.3833 - f1_score: 0.5107 - val_loss: 0.5829 - val_precision: 0.5714 - val_recall: 0.2000 - val_f1_score: 0.2963\n",
            "Epoch 170/500\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.4709 - precision: 0.7893 - recall: 0.3833 - f1_score: 0.5146 - val_loss: 0.5786 - val_precision: 0.6000 - val_recall: 0.2500 - val_f1_score: 0.3529\n",
            "Epoch 171/500\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.4758 - precision: 0.7268 - recall: 0.4533 - f1_score: 0.5476 - val_loss: 0.5731 - val_precision: 0.5641 - val_recall: 0.3667 - val_f1_score: 0.4444\n",
            "Epoch 172/500\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.4719 - precision: 0.7620 - recall: 0.4267 - f1_score: 0.5440 - val_loss: 0.6129 - val_precision: 0.5238 - val_recall: 0.3667 - val_f1_score: 0.4314\n",
            "Epoch 173/500\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.4702 - precision: 0.7602 - recall: 0.4400 - f1_score: 0.5523 - val_loss: 0.5857 - val_precision: 0.5909 - val_recall: 0.2167 - val_f1_score: 0.3171\n",
            "Epoch 174/500\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.4725 - precision: 0.7517 - recall: 0.4067 - f1_score: 0.5260 - val_loss: 0.5992 - val_precision: 0.5588 - val_recall: 0.3167 - val_f1_score: 0.4043\n",
            "Epoch 175/500\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.4723 - precision: 0.7455 - recall: 0.4100 - f1_score: 0.5265 - val_loss: 0.5868 - val_precision: 0.5926 - val_recall: 0.2667 - val_f1_score: 0.3678\n",
            "Epoch 176/500\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.4681 - precision: 0.7684 - recall: 0.4300 - f1_score: 0.5488 - val_loss: 0.5756 - val_precision: 0.5926 - val_recall: 0.2667 - val_f1_score: 0.3678\n",
            "Epoch 177/500\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.4738 - precision: 0.7741 - recall: 0.3967 - f1_score: 0.5198 - val_loss: 0.5798 - val_precision: 0.5909 - val_recall: 0.2167 - val_f1_score: 0.3171\n",
            "Epoch 178/500\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.4688 - precision: 0.7733 - recall: 0.3967 - f1_score: 0.5228 - val_loss: 0.5773 - val_precision: 0.6190 - val_recall: 0.2167 - val_f1_score: 0.3210\n",
            "Epoch 179/500\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.4699 - precision: 0.7921 - recall: 0.4033 - f1_score: 0.5321 - val_loss: 0.5760 - val_precision: 0.6250 - val_recall: 0.2500 - val_f1_score: 0.3571\n",
            "Epoch 180/500\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.4681 - precision: 0.7829 - recall: 0.3733 - f1_score: 0.5052 - val_loss: 0.6104 - val_precision: 0.5349 - val_recall: 0.3833 - val_f1_score: 0.4466\n",
            "Epoch 181/500\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.4657 - precision: 0.7735 - recall: 0.4400 - f1_score: 0.5535 - val_loss: 0.5725 - val_precision: 0.5714 - val_recall: 0.3333 - val_f1_score: 0.4211\n",
            "Epoch 182/500\n",
            "300/300 [==============================] - 0s 82us/step - loss: 0.4655 - precision: 0.7696 - recall: 0.4300 - f1_score: 0.5505 - val_loss: 0.5833 - val_precision: 0.5833 - val_recall: 0.2333 - val_f1_score: 0.3333\n",
            "Epoch 183/500\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.4648 - precision: 0.7892 - recall: 0.4233 - f1_score: 0.5482 - val_loss: 0.5739 - val_precision: 0.6429 - val_recall: 0.3000 - val_f1_score: 0.4091\n",
            "Epoch 184/500\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.4659 - precision: 0.7896 - recall: 0.3833 - f1_score: 0.5146 - val_loss: 0.5760 - val_precision: 0.5588 - val_recall: 0.3167 - val_f1_score: 0.4043\n",
            "Epoch 185/500\n",
            "300/300 [==============================] - 0s 78us/step - loss: 0.4660 - precision: 0.8018 - recall: 0.4167 - f1_score: 0.5467 - val_loss: 0.5800 - val_precision: 0.6000 - val_recall: 0.2500 - val_f1_score: 0.3529\n",
            "Epoch 186/500\n",
            "300/300 [==============================] - 0s 79us/step - loss: 0.4670 - precision: 0.7790 - recall: 0.3833 - f1_score: 0.5125 - val_loss: 0.5773 - val_precision: 0.6250 - val_recall: 0.2500 - val_f1_score: 0.3571\n",
            "Epoch 187/500\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.4663 - precision: 0.7611 - recall: 0.4167 - f1_score: 0.5340 - val_loss: 0.5830 - val_precision: 0.6000 - val_recall: 0.2500 - val_f1_score: 0.3529\n",
            "Epoch 188/500\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.4666 - precision: 0.7878 - recall: 0.4167 - f1_score: 0.5434 - val_loss: 0.5955 - val_precision: 0.5484 - val_recall: 0.2833 - val_f1_score: 0.3736\n",
            "Epoch 189/500\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.4629 - precision: 0.7867 - recall: 0.3967 - f1_score: 0.5227 - val_loss: 0.5764 - val_precision: 0.6154 - val_recall: 0.2667 - val_f1_score: 0.3721\n",
            "Epoch 190/500\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.4689 - precision: 0.7716 - recall: 0.4233 - f1_score: 0.5432 - val_loss: 0.5742 - val_precision: 0.6552 - val_recall: 0.3167 - val_f1_score: 0.4270\n",
            "Epoch 191/500\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.4652 - precision: 0.8010 - recall: 0.4033 - f1_score: 0.5351 - val_loss: 0.5723 - val_precision: 0.5517 - val_recall: 0.2667 - val_f1_score: 0.3596\n",
            "Epoch 192/500\n",
            "300/300 [==============================] - 0s 82us/step - loss: 0.4648 - precision: 0.7766 - recall: 0.3933 - f1_score: 0.5210 - val_loss: 0.5773 - val_precision: 0.6000 - val_recall: 0.2500 - val_f1_score: 0.3529\n",
            "Epoch 193/500\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.4638 - precision: 0.7948 - recall: 0.4167 - f1_score: 0.5459 - val_loss: 0.5718 - val_precision: 0.5526 - val_recall: 0.3500 - val_f1_score: 0.4286\n",
            "Epoch 194/500\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.4643 - precision: 0.7902 - recall: 0.4400 - f1_score: 0.5613 - val_loss: 0.6230 - val_precision: 0.5000 - val_recall: 0.3833 - val_f1_score: 0.4340\n",
            "Epoch 195/500\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.4717 - precision: 0.7364 - recall: 0.4533 - f1_score: 0.5586 - val_loss: 0.5707 - val_precision: 0.5641 - val_recall: 0.3667 - val_f1_score: 0.4444\n",
            "Epoch 196/500\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.4662 - precision: 0.7296 - recall: 0.4400 - f1_score: 0.5456 - val_loss: 0.5936 - val_precision: 0.5714 - val_recall: 0.3333 - val_f1_score: 0.4211\n",
            "Epoch 197/500\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.4642 - precision: 0.7675 - recall: 0.4367 - f1_score: 0.5515 - val_loss: 0.5797 - val_precision: 0.5909 - val_recall: 0.2167 - val_f1_score: 0.3171\n",
            "Epoch 198/500\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.4619 - precision: 0.7828 - recall: 0.4133 - f1_score: 0.5378 - val_loss: 0.5739 - val_precision: 0.5429 - val_recall: 0.3167 - val_f1_score: 0.4000\n",
            "Epoch 199/500\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.4716 - precision: 0.7447 - recall: 0.4300 - f1_score: 0.5401 - val_loss: 0.5894 - val_precision: 0.5769 - val_recall: 0.2500 - val_f1_score: 0.3488\n",
            "Epoch 200/500\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.4599 - precision: 0.7734 - recall: 0.4367 - f1_score: 0.5573 - val_loss: 0.5730 - val_precision: 0.6071 - val_recall: 0.2833 - val_f1_score: 0.3864\n",
            "Epoch 201/500\n",
            "300/300 [==============================] - 0s 103us/step - loss: 0.4598 - precision: 0.7971 - recall: 0.3833 - f1_score: 0.5171 - val_loss: 0.5761 - val_precision: 0.5667 - val_recall: 0.2833 - val_f1_score: 0.3778\n",
            "Epoch 202/500\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.4644 - precision: 0.7793 - recall: 0.4300 - f1_score: 0.5511 - val_loss: 0.5744 - val_precision: 0.5806 - val_recall: 0.3000 - val_f1_score: 0.3956\n",
            "Epoch 203/500\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.4612 - precision: 0.7942 - recall: 0.4133 - f1_score: 0.5403 - val_loss: 0.5739 - val_precision: 0.6207 - val_recall: 0.3000 - val_f1_score: 0.4045\n",
            "Epoch 204/500\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.4663 - precision: 0.7611 - recall: 0.4200 - f1_score: 0.5365 - val_loss: 0.5871 - val_precision: 0.5769 - val_recall: 0.2500 - val_f1_score: 0.3488\n",
            "Epoch 205/500\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.4669 - precision: 0.7584 - recall: 0.4500 - f1_score: 0.5645 - val_loss: 0.5840 - val_precision: 0.5652 - val_recall: 0.2167 - val_f1_score: 0.3133\n",
            "Epoch 206/500\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.4713 - precision: 0.7536 - recall: 0.4400 - f1_score: 0.5510 - val_loss: 0.5859 - val_precision: 0.6000 - val_recall: 0.2500 - val_f1_score: 0.3529\n",
            "Epoch 207/500\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.4593 - precision: 0.8062 - recall: 0.4367 - f1_score: 0.5627 - val_loss: 0.6054 - val_precision: 0.5238 - val_recall: 0.3667 - val_f1_score: 0.4314\n",
            "Epoch 208/500\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.4618 - precision: 0.7818 - recall: 0.4533 - f1_score: 0.5711 - val_loss: 0.5979 - val_precision: 0.5429 - val_recall: 0.3167 - val_f1_score: 0.4000\n",
            "Epoch 209/500\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.4601 - precision: 0.7874 - recall: 0.4233 - f1_score: 0.5488 - val_loss: 0.5865 - val_precision: 0.6000 - val_recall: 0.2500 - val_f1_score: 0.3529\n",
            "Epoch 210/500\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.4587 - precision: 0.7919 - recall: 0.4233 - f1_score: 0.5510 - val_loss: 0.5741 - val_precision: 0.5455 - val_recall: 0.3000 - val_f1_score: 0.3871\n",
            "Epoch 211/500\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.4582 - precision: 0.7981 - recall: 0.4333 - f1_score: 0.5615 - val_loss: 0.5928 - val_precision: 0.5172 - val_recall: 0.2500 - val_f1_score: 0.3371\n",
            "Epoch 212/500\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.4570 - precision: 0.7433 - recall: 0.4800 - f1_score: 0.5826 - val_loss: 0.5718 - val_precision: 0.6364 - val_recall: 0.3500 - val_f1_score: 0.4516\n",
            "Epoch 213/500\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.4595 - precision: 0.7945 - recall: 0.3867 - f1_score: 0.5176 - val_loss: 0.5756 - val_precision: 0.5667 - val_recall: 0.2833 - val_f1_score: 0.3778\n",
            "Epoch 214/500\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.4591 - precision: 0.7878 - recall: 0.4467 - f1_score: 0.5673 - val_loss: 0.5713 - val_precision: 0.5556 - val_recall: 0.3333 - val_f1_score: 0.4167\n",
            "Epoch 215/500\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.4626 - precision: 0.7524 - recall: 0.4533 - f1_score: 0.5647 - val_loss: 0.5777 - val_precision: 0.5909 - val_recall: 0.2167 - val_f1_score: 0.3171\n",
            "Epoch 216/500\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.4556 - precision: 0.8176 - recall: 0.4367 - f1_score: 0.5666 - val_loss: 0.5947 - val_precision: 0.5625 - val_recall: 0.3000 - val_f1_score: 0.3913\n",
            "Epoch 217/500\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.4703 - precision: 0.7623 - recall: 0.4233 - f1_score: 0.5388 - val_loss: 0.5818 - val_precision: 0.5909 - val_recall: 0.2167 - val_f1_score: 0.3171\n",
            "Epoch 218/500\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.4612 - precision: 0.7777 - recall: 0.4333 - f1_score: 0.5558 - val_loss: 0.5795 - val_precision: 0.5833 - val_recall: 0.2333 - val_f1_score: 0.3333\n",
            "Epoch 219/500\n",
            "300/300 [==============================] - 0s 103us/step - loss: 0.4593 - precision: 0.7722 - recall: 0.4433 - f1_score: 0.5591 - val_loss: 0.5770 - val_precision: 0.6400 - val_recall: 0.2667 - val_f1_score: 0.3765\n",
            "Epoch 220/500\n",
            "300/300 [==============================] - 0s 104us/step - loss: 0.4602 - precision: 0.7936 - recall: 0.4333 - f1_score: 0.5576 - val_loss: 0.5816 - val_precision: 0.5833 - val_recall: 0.2333 - val_f1_score: 0.3333\n",
            "Epoch 221/500\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.4599 - precision: 0.7497 - recall: 0.4467 - f1_score: 0.5573 - val_loss: 0.5926 - val_precision: 0.5455 - val_recall: 0.3000 - val_f1_score: 0.3871\n",
            "Epoch 222/500\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.4574 - precision: 0.7567 - recall: 0.4500 - f1_score: 0.5621 - val_loss: 0.5734 - val_precision: 0.6207 - val_recall: 0.3000 - val_f1_score: 0.4045\n",
            "Epoch 223/500\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.4552 - precision: 0.8012 - recall: 0.4267 - f1_score: 0.5562 - val_loss: 0.5808 - val_precision: 0.5909 - val_recall: 0.2167 - val_f1_score: 0.3171\n",
            "Epoch 224/500\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.4562 - precision: 0.7864 - recall: 0.4400 - f1_score: 0.5632 - val_loss: 0.5786 - val_precision: 0.5833 - val_recall: 0.2333 - val_f1_score: 0.3333\n",
            "Epoch 225/500\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.4544 - precision: 0.7785 - recall: 0.4300 - f1_score: 0.5528 - val_loss: 0.5728 - val_precision: 0.5952 - val_recall: 0.4167 - val_f1_score: 0.4902\n",
            "Epoch 226/500\n",
            "300/300 [==============================] - 0s 81us/step - loss: 0.4571 - precision: 0.7851 - recall: 0.4300 - f1_score: 0.5511 - val_loss: 0.6093 - val_precision: 0.5349 - val_recall: 0.3833 - val_f1_score: 0.4466\n",
            "Epoch 227/500\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.4572 - precision: 0.7661 - recall: 0.4933 - f1_score: 0.5956 - val_loss: 0.5740 - val_precision: 0.5897 - val_recall: 0.3833 - val_f1_score: 0.4646\n",
            "Epoch 228/500\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.4544 - precision: 0.7932 - recall: 0.4467 - f1_score: 0.5669 - val_loss: 0.5876 - val_precision: 0.5833 - val_recall: 0.2333 - val_f1_score: 0.3333\n",
            "Epoch 229/500\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.4543 - precision: 0.7900 - recall: 0.4433 - f1_score: 0.5660 - val_loss: 0.5886 - val_precision: 0.5833 - val_recall: 0.2333 - val_f1_score: 0.3333\n",
            "Epoch 230/500\n",
            "300/300 [==============================] - 0s 102us/step - loss: 0.4538 - precision: 0.7901 - recall: 0.4400 - f1_score: 0.5637 - val_loss: 0.5740 - val_precision: 0.5806 - val_recall: 0.3000 - val_f1_score: 0.3956\n",
            "Epoch 231/500\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.4530 - precision: 0.8010 - recall: 0.4667 - f1_score: 0.5886 - val_loss: 0.5757 - val_precision: 0.5676 - val_recall: 0.3500 - val_f1_score: 0.4330\n",
            "Epoch 232/500\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.4600 - precision: 0.7168 - recall: 0.4633 - f1_score: 0.5609 - val_loss: 0.5847 - val_precision: 0.6000 - val_recall: 0.2500 - val_f1_score: 0.3529\n",
            "Epoch 233/500\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.4521 - precision: 0.8129 - recall: 0.4567 - f1_score: 0.5842 - val_loss: 0.5903 - val_precision: 0.5312 - val_recall: 0.2833 - val_f1_score: 0.3696\n",
            "Epoch 234/500\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.4544 - precision: 0.7470 - recall: 0.4700 - f1_score: 0.5726 - val_loss: 0.5789 - val_precision: 0.6000 - val_recall: 0.2500 - val_f1_score: 0.3529\n",
            "Epoch 235/500\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.4551 - precision: 0.7839 - recall: 0.4533 - f1_score: 0.5701 - val_loss: 0.5857 - val_precision: 0.5769 - val_recall: 0.2500 - val_f1_score: 0.3488\n",
            "Epoch 236/500\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.4496 - precision: 0.8013 - recall: 0.4767 - f1_score: 0.5965 - val_loss: 0.5739 - val_precision: 0.5897 - val_recall: 0.3833 - val_f1_score: 0.4646\n",
            "Epoch 237/500\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.4540 - precision: 0.7898 - recall: 0.4500 - f1_score: 0.5671 - val_loss: 0.5795 - val_precision: 0.5833 - val_recall: 0.2333 - val_f1_score: 0.3333\n",
            "Epoch 238/500\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.4560 - precision: 0.7828 - recall: 0.4500 - f1_score: 0.5709 - val_loss: 0.6007 - val_precision: 0.5500 - val_recall: 0.3667 - val_f1_score: 0.4400\n",
            "Epoch 239/500\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.4664 - precision: 0.7246 - recall: 0.4900 - f1_score: 0.5824 - val_loss: 0.5824 - val_precision: 0.5909 - val_recall: 0.2167 - val_f1_score: 0.3171\n",
            "Epoch 240/500\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.4513 - precision: 0.8242 - recall: 0.4400 - f1_score: 0.5718 - val_loss: 0.5832 - val_precision: 0.5625 - val_recall: 0.3000 - val_f1_score: 0.3913\n",
            "Epoch 241/500\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.4582 - precision: 0.7552 - recall: 0.4400 - f1_score: 0.5545 - val_loss: 0.6164 - val_precision: 0.5217 - val_recall: 0.4000 - val_f1_score: 0.4528\n",
            "Epoch 242/500\n",
            "300/300 [==============================] - 0s 80us/step - loss: 0.4531 - precision: 0.7616 - recall: 0.4600 - f1_score: 0.5697 - val_loss: 0.5885 - val_precision: 0.5172 - val_recall: 0.2500 - val_f1_score: 0.3371\n",
            "Epoch 243/500\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.4551 - precision: 0.7692 - recall: 0.4533 - f1_score: 0.5683 - val_loss: 0.5849 - val_precision: 0.5833 - val_recall: 0.2333 - val_f1_score: 0.3333\n",
            "Epoch 244/500\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.4521 - precision: 0.7858 - recall: 0.4567 - f1_score: 0.5756 - val_loss: 0.6062 - val_precision: 0.5333 - val_recall: 0.4000 - val_f1_score: 0.4571\n",
            "Epoch 245/500\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.4514 - precision: 0.7955 - recall: 0.4467 - f1_score: 0.5666 - val_loss: 0.5809 - val_precision: 0.6087 - val_recall: 0.2333 - val_f1_score: 0.3373\n",
            "Epoch 246/500\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.4484 - precision: 0.8164 - recall: 0.4467 - f1_score: 0.5746 - val_loss: 0.5769 - val_precision: 0.6000 - val_recall: 0.2500 - val_f1_score: 0.3529\n",
            "Epoch 247/500\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.4469 - precision: 0.8096 - recall: 0.4433 - f1_score: 0.5723 - val_loss: 0.5752 - val_precision: 0.5294 - val_recall: 0.3000 - val_f1_score: 0.3830\n",
            "Epoch 248/500\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.4519 - precision: 0.7820 - recall: 0.4733 - f1_score: 0.5861 - val_loss: 0.5777 - val_precision: 0.5667 - val_recall: 0.2833 - val_f1_score: 0.3778\n",
            "Epoch 249/500\n",
            "300/300 [==============================] - 0s 82us/step - loss: 0.4523 - precision: 0.7809 - recall: 0.4700 - f1_score: 0.5831 - val_loss: 0.5733 - val_precision: 0.5758 - val_recall: 0.3167 - val_f1_score: 0.4086\n",
            "Epoch 250/500\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.4484 - precision: 0.7990 - recall: 0.4833 - f1_score: 0.6002 - val_loss: 0.5740 - val_precision: 0.6071 - val_recall: 0.2833 - val_f1_score: 0.3864\n",
            "Epoch 251/500\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.4473 - precision: 0.8170 - recall: 0.4567 - f1_score: 0.5831 - val_loss: 0.5901 - val_precision: 0.5161 - val_recall: 0.2667 - val_f1_score: 0.3516\n",
            "Epoch 252/500\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.4490 - precision: 0.7618 - recall: 0.4867 - f1_score: 0.5888 - val_loss: 0.5776 - val_precision: 0.5758 - val_recall: 0.3167 - val_f1_score: 0.4086\n",
            "Epoch 253/500\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.4480 - precision: 0.7934 - recall: 0.4533 - f1_score: 0.5759 - val_loss: 0.5811 - val_precision: 0.5833 - val_recall: 0.2333 - val_f1_score: 0.3333\n",
            "Epoch 254/500\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.4461 - precision: 0.8030 - recall: 0.4700 - f1_score: 0.5892 - val_loss: 0.5859 - val_precision: 0.5769 - val_recall: 0.2500 - val_f1_score: 0.3488\n",
            "Epoch 255/500\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.4494 - precision: 0.7972 - recall: 0.4667 - f1_score: 0.5878 - val_loss: 0.5792 - val_precision: 0.5833 - val_recall: 0.2333 - val_f1_score: 0.3333\n",
            "Epoch 256/500\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.4456 - precision: 0.8063 - recall: 0.4500 - f1_score: 0.5757 - val_loss: 0.5753 - val_precision: 0.5926 - val_recall: 0.2667 - val_f1_score: 0.3678\n",
            "Epoch 257/500\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.4486 - precision: 0.7919 - recall: 0.4533 - f1_score: 0.5742 - val_loss: 0.5767 - val_precision: 0.6154 - val_recall: 0.2667 - val_f1_score: 0.3721\n",
            "Epoch 258/500\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.4454 - precision: 0.8353 - recall: 0.4533 - f1_score: 0.5866 - val_loss: 0.5849 - val_precision: 0.6207 - val_recall: 0.3000 - val_f1_score: 0.4045\n",
            "Epoch 259/500\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.4479 - precision: 0.8011 - recall: 0.4667 - f1_score: 0.5892 - val_loss: 0.5752 - val_precision: 0.6538 - val_recall: 0.2833 - val_f1_score: 0.3953\n",
            "Epoch 260/500\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.4461 - precision: 0.8194 - recall: 0.4533 - f1_score: 0.5832 - val_loss: 0.5831 - val_precision: 0.5600 - val_recall: 0.2333 - val_f1_score: 0.3294\n",
            "Epoch 261/500\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.4446 - precision: 0.8078 - recall: 0.4667 - f1_score: 0.5903 - val_loss: 0.5728 - val_precision: 0.6250 - val_recall: 0.3333 - val_f1_score: 0.4348\n",
            "Epoch 262/500\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.4467 - precision: 0.8189 - recall: 0.4533 - f1_score: 0.5814 - val_loss: 0.5876 - val_precision: 0.5333 - val_recall: 0.2667 - val_f1_score: 0.3556\n",
            "Epoch 263/500\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.4457 - precision: 0.7785 - recall: 0.4667 - f1_score: 0.5830 - val_loss: 0.5907 - val_precision: 0.5294 - val_recall: 0.3000 - val_f1_score: 0.3830\n",
            "Epoch 264/500\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.4477 - precision: 0.7593 - recall: 0.4900 - f1_score: 0.5926 - val_loss: 0.5893 - val_precision: 0.5455 - val_recall: 0.3000 - val_f1_score: 0.3871\n",
            "Epoch 265/500\n",
            "300/300 [==============================] - 0s 101us/step - loss: 0.4503 - precision: 0.7554 - recall: 0.4967 - f1_score: 0.5983 - val_loss: 0.5933 - val_precision: 0.5676 - val_recall: 0.3500 - val_f1_score: 0.4330\n",
            "Epoch 266/500\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.4448 - precision: 0.7694 - recall: 0.4567 - f1_score: 0.5722 - val_loss: 0.5716 - val_precision: 0.5135 - val_recall: 0.3167 - val_f1_score: 0.3918\n",
            "Epoch 267/500\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.4460 - precision: 0.7781 - recall: 0.4967 - f1_score: 0.6059 - val_loss: 0.5713 - val_precision: 0.5758 - val_recall: 0.3167 - val_f1_score: 0.4086\n",
            "Epoch 268/500\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.4471 - precision: 0.8078 - recall: 0.4667 - f1_score: 0.5882 - val_loss: 0.5710 - val_precision: 0.5676 - val_recall: 0.3500 - val_f1_score: 0.4330\n",
            "Epoch 269/500\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.4462 - precision: 0.8152 - recall: 0.4867 - f1_score: 0.6057 - val_loss: 0.5790 - val_precision: 0.5833 - val_recall: 0.2333 - val_f1_score: 0.3333\n",
            "Epoch 270/500\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.4459 - precision: 0.7818 - recall: 0.4833 - f1_score: 0.5963 - val_loss: 0.5921 - val_precision: 0.5714 - val_recall: 0.3333 - val_f1_score: 0.4211\n",
            "Epoch 271/500\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.4428 - precision: 0.8048 - recall: 0.4867 - f1_score: 0.6032 - val_loss: 0.5828 - val_precision: 0.6071 - val_recall: 0.2833 - val_f1_score: 0.3864\n",
            "Epoch 272/500\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.4455 - precision: 0.7605 - recall: 0.4633 - f1_score: 0.5739 - val_loss: 0.5906 - val_precision: 0.5714 - val_recall: 0.3333 - val_f1_score: 0.4211\n",
            "Epoch 273/500\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.4424 - precision: 0.7816 - recall: 0.4700 - f1_score: 0.5849 - val_loss: 0.5782 - val_precision: 0.6071 - val_recall: 0.2833 - val_f1_score: 0.3864\n",
            "Epoch 274/500\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.4456 - precision: 0.7800 - recall: 0.4500 - f1_score: 0.5681 - val_loss: 0.5702 - val_precision: 0.5882 - val_recall: 0.3333 - val_f1_score: 0.4255\n",
            "Epoch 275/500\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.4419 - precision: 0.8104 - recall: 0.4767 - f1_score: 0.5985 - val_loss: 0.5881 - val_precision: 0.5588 - val_recall: 0.3167 - val_f1_score: 0.4043\n",
            "Epoch 276/500\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.4426 - precision: 0.7866 - recall: 0.4633 - f1_score: 0.5814 - val_loss: 0.5773 - val_precision: 0.5926 - val_recall: 0.2667 - val_f1_score: 0.3678\n",
            "Epoch 277/500\n",
            "300/300 [==============================] - 0s 119us/step - loss: 0.4507 - precision: 0.7853 - recall: 0.5033 - f1_score: 0.6102 - val_loss: 0.5689 - val_precision: 0.5750 - val_recall: 0.3833 - val_f1_score: 0.4600\n",
            "Epoch 278/500\n",
            "300/300 [==============================] - 0s 102us/step - loss: 0.4444 - precision: 0.8228 - recall: 0.4800 - f1_score: 0.6042 - val_loss: 0.5751 - val_precision: 0.5758 - val_recall: 0.3167 - val_f1_score: 0.4086\n",
            "Epoch 279/500\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.4403 - precision: 0.7938 - recall: 0.5267 - f1_score: 0.6299 - val_loss: 0.5871 - val_precision: 0.5333 - val_recall: 0.2667 - val_f1_score: 0.3556\n",
            "Epoch 280/500\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.4413 - precision: 0.7825 - recall: 0.4600 - f1_score: 0.5790 - val_loss: 0.5967 - val_precision: 0.5263 - val_recall: 0.3333 - val_f1_score: 0.4082\n",
            "Epoch 281/500\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.4487 - precision: 0.7528 - recall: 0.4733 - f1_score: 0.5781 - val_loss: 0.5942 - val_precision: 0.4865 - val_recall: 0.3000 - val_f1_score: 0.3711\n",
            "Epoch 282/500\n",
            "300/300 [==============================] - 0s 101us/step - loss: 0.4466 - precision: 0.7779 - recall: 0.4800 - f1_score: 0.5911 - val_loss: 0.5868 - val_precision: 0.5161 - val_recall: 0.2667 - val_f1_score: 0.3516\n",
            "Epoch 283/500\n",
            "300/300 [==============================] - 0s 105us/step - loss: 0.4452 - precision: 0.7747 - recall: 0.4733 - f1_score: 0.5872 - val_loss: 0.5841 - val_precision: 0.6071 - val_recall: 0.2833 - val_f1_score: 0.3864\n",
            "Epoch 284/500\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.4421 - precision: 0.8053 - recall: 0.4767 - f1_score: 0.5973 - val_loss: 0.5912 - val_precision: 0.5405 - val_recall: 0.3333 - val_f1_score: 0.4124\n",
            "Epoch 285/500\n",
            "300/300 [==============================] - 0s 102us/step - loss: 0.4437 - precision: 0.7927 - recall: 0.4800 - f1_score: 0.5958 - val_loss: 0.6205 - val_precision: 0.5208 - val_recall: 0.4167 - val_f1_score: 0.4630\n",
            "Epoch 286/500\n",
            "300/300 [==============================] - 0s 101us/step - loss: 0.4464 - precision: 0.7499 - recall: 0.4967 - f1_score: 0.5942 - val_loss: 0.5707 - val_precision: 0.6061 - val_recall: 0.3333 - val_f1_score: 0.4301\n",
            "Epoch 287/500\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.4404 - precision: 0.8129 - recall: 0.4967 - f1_score: 0.6128 - val_loss: 0.5698 - val_precision: 0.5714 - val_recall: 0.4000 - val_f1_score: 0.4706\n",
            "Epoch 288/500\n",
            "300/300 [==============================] - 0s 105us/step - loss: 0.4351 - precision: 0.7870 - recall: 0.5667 - f1_score: 0.6571 - val_loss: 0.6099 - val_precision: 0.5227 - val_recall: 0.3833 - val_f1_score: 0.4423\n",
            "Epoch 289/500\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.4401 - precision: 0.7949 - recall: 0.4867 - f1_score: 0.6003 - val_loss: 0.5840 - val_precision: 0.5769 - val_recall: 0.2500 - val_f1_score: 0.3488\n",
            "Epoch 290/500\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.4404 - precision: 0.7905 - recall: 0.5133 - f1_score: 0.6198 - val_loss: 0.5782 - val_precision: 0.5600 - val_recall: 0.2333 - val_f1_score: 0.3294\n",
            "Epoch 291/500\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.4394 - precision: 0.8055 - recall: 0.4733 - f1_score: 0.5958 - val_loss: 0.6027 - val_precision: 0.5435 - val_recall: 0.4167 - val_f1_score: 0.4717\n",
            "Epoch 292/500\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.4402 - precision: 0.7932 - recall: 0.4933 - f1_score: 0.6072 - val_loss: 0.5784 - val_precision: 0.6071 - val_recall: 0.2833 - val_f1_score: 0.3864\n",
            "Epoch 293/500\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.4379 - precision: 0.8181 - recall: 0.4800 - f1_score: 0.6044 - val_loss: 0.5777 - val_precision: 0.6154 - val_recall: 0.2667 - val_f1_score: 0.3721\n",
            "Epoch 294/500\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.4435 - precision: 0.7865 - recall: 0.5000 - f1_score: 0.6090 - val_loss: 0.5691 - val_precision: 0.5714 - val_recall: 0.4000 - val_f1_score: 0.4706\n",
            "Epoch 295/500\n",
            "300/300 [==============================] - 0s 103us/step - loss: 0.4402 - precision: 0.8157 - recall: 0.5067 - f1_score: 0.6245 - val_loss: 0.5785 - val_precision: 0.6000 - val_recall: 0.2500 - val_f1_score: 0.3529\n",
            "Epoch 296/500\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.4393 - precision: 0.7997 - recall: 0.4933 - f1_score: 0.6086 - val_loss: 0.5781 - val_precision: 0.6000 - val_recall: 0.2500 - val_f1_score: 0.3529\n",
            "Epoch 297/500\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.4376 - precision: 0.8027 - recall: 0.4900 - f1_score: 0.6071 - val_loss: 0.5739 - val_precision: 0.5405 - val_recall: 0.3333 - val_f1_score: 0.4124\n",
            "Epoch 298/500\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.4402 - precision: 0.7443 - recall: 0.5233 - f1_score: 0.6119 - val_loss: 0.5852 - val_precision: 0.6000 - val_recall: 0.3000 - val_f1_score: 0.4000\n",
            "Epoch 299/500\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.4376 - precision: 0.8014 - recall: 0.4767 - f1_score: 0.5960 - val_loss: 0.5836 - val_precision: 0.5385 - val_recall: 0.2333 - val_f1_score: 0.3256\n",
            "Epoch 300/500\n",
            "300/300 [==============================] - 0s 115us/step - loss: 0.4353 - precision: 0.7888 - recall: 0.5133 - f1_score: 0.6195 - val_loss: 0.6039 - val_precision: 0.5333 - val_recall: 0.4000 - val_f1_score: 0.4571\n",
            "Epoch 301/500\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.4352 - precision: 0.7794 - recall: 0.5000 - f1_score: 0.6048 - val_loss: 0.5708 - val_precision: 0.5882 - val_recall: 0.3333 - val_f1_score: 0.4255\n",
            "Epoch 302/500\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.4417 - precision: 0.7795 - recall: 0.4667 - f1_score: 0.5825 - val_loss: 0.5774 - val_precision: 0.6000 - val_recall: 0.2500 - val_f1_score: 0.3529\n",
            "Epoch 303/500\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.4356 - precision: 0.8237 - recall: 0.4900 - f1_score: 0.6140 - val_loss: 0.5942 - val_precision: 0.5000 - val_recall: 0.3000 - val_f1_score: 0.3750\n",
            "Epoch 304/500\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.4368 - precision: 0.8162 - recall: 0.5000 - f1_score: 0.6194 - val_loss: 0.5892 - val_precision: 0.5556 - val_recall: 0.3333 - val_f1_score: 0.4167\n",
            "Epoch 305/500\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.4373 - precision: 0.7759 - recall: 0.4967 - f1_score: 0.6051 - val_loss: 0.5882 - val_precision: 0.5938 - val_recall: 0.3167 - val_f1_score: 0.4130\n",
            "Epoch 306/500\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.4376 - precision: 0.7854 - recall: 0.4900 - f1_score: 0.6023 - val_loss: 0.5922 - val_precision: 0.5000 - val_recall: 0.3000 - val_f1_score: 0.3750\n",
            "Epoch 307/500\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.4392 - precision: 0.7651 - recall: 0.4967 - f1_score: 0.6004 - val_loss: 0.5740 - val_precision: 0.5625 - val_recall: 0.3000 - val_f1_score: 0.3913\n",
            "Epoch 308/500\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.4396 - precision: 0.7981 - recall: 0.5067 - f1_score: 0.6168 - val_loss: 0.5789 - val_precision: 0.6071 - val_recall: 0.2833 - val_f1_score: 0.3864\n",
            "Epoch 309/500\n",
            "300/300 [==============================] - 0s 106us/step - loss: 0.4360 - precision: 0.8201 - recall: 0.5000 - f1_score: 0.6209 - val_loss: 0.5870 - val_precision: 0.5455 - val_recall: 0.3000 - val_f1_score: 0.3871\n",
            "Epoch 310/500\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.4356 - precision: 0.8055 - recall: 0.5000 - f1_score: 0.6137 - val_loss: 0.5733 - val_precision: 0.5882 - val_recall: 0.3333 - val_f1_score: 0.4255\n",
            "Epoch 311/500\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.4347 - precision: 0.8208 - recall: 0.4900 - f1_score: 0.6126 - val_loss: 0.5722 - val_precision: 0.6061 - val_recall: 0.3333 - val_f1_score: 0.4301\n",
            "Epoch 312/500\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.4343 - precision: 0.8133 - recall: 0.4967 - f1_score: 0.6156 - val_loss: 0.5698 - val_precision: 0.5610 - val_recall: 0.3833 - val_f1_score: 0.4554\n",
            "Epoch 313/500\n",
            "300/300 [==============================] - 0s 102us/step - loss: 0.4363 - precision: 0.8177 - recall: 0.4900 - f1_score: 0.6103 - val_loss: 0.5865 - val_precision: 0.6129 - val_recall: 0.3167 - val_f1_score: 0.4176\n",
            "Epoch 314/500\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.4372 - precision: 0.7945 - recall: 0.4833 - f1_score: 0.5988 - val_loss: 0.6069 - val_precision: 0.5319 - val_recall: 0.4167 - val_f1_score: 0.4673\n",
            "Epoch 315/500\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.4357 - precision: 0.7939 - recall: 0.5033 - f1_score: 0.6119 - val_loss: 0.5753 - val_precision: 0.6207 - val_recall: 0.3000 - val_f1_score: 0.4045\n",
            "Epoch 316/500\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.4315 - precision: 0.8402 - recall: 0.4967 - f1_score: 0.6224 - val_loss: 0.5854 - val_precision: 0.5625 - val_recall: 0.3000 - val_f1_score: 0.3913\n",
            "Epoch 317/500\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.4324 - precision: 0.8036 - recall: 0.5200 - f1_score: 0.6307 - val_loss: 0.5832 - val_precision: 0.6071 - val_recall: 0.2833 - val_f1_score: 0.3864\n",
            "Epoch 318/500\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.4317 - precision: 0.8092 - recall: 0.4967 - f1_score: 0.6151 - val_loss: 0.5797 - val_precision: 0.6154 - val_recall: 0.2667 - val_f1_score: 0.3721\n",
            "Epoch 319/500\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.4355 - precision: 0.8123 - recall: 0.4900 - f1_score: 0.6063 - val_loss: 0.5885 - val_precision: 0.5455 - val_recall: 0.3000 - val_f1_score: 0.3871\n",
            "Epoch 320/500\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.4357 - precision: 0.7933 - recall: 0.5067 - f1_score: 0.6180 - val_loss: 0.5705 - val_precision: 0.5526 - val_recall: 0.3500 - val_f1_score: 0.4286\n",
            "Epoch 321/500\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.4350 - precision: 0.8189 - recall: 0.4900 - f1_score: 0.6120 - val_loss: 0.5718 - val_precision: 0.5882 - val_recall: 0.3333 - val_f1_score: 0.4255\n",
            "Epoch 322/500\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.4316 - precision: 0.8210 - recall: 0.4933 - f1_score: 0.6153 - val_loss: 0.5878 - val_precision: 0.5429 - val_recall: 0.3167 - val_f1_score: 0.4000\n",
            "Epoch 323/500\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.4314 - precision: 0.8250 - recall: 0.4867 - f1_score: 0.6102 - val_loss: 0.5835 - val_precision: 0.6207 - val_recall: 0.3000 - val_f1_score: 0.4045\n",
            "Epoch 324/500\n",
            "300/300 [==============================] - 0s 81us/step - loss: 0.4341 - precision: 0.8316 - recall: 0.4967 - f1_score: 0.6198 - val_loss: 0.5919 - val_precision: 0.5128 - val_recall: 0.3333 - val_f1_score: 0.4040\n",
            "Epoch 325/500\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.4318 - precision: 0.8037 - recall: 0.5200 - f1_score: 0.6283 - val_loss: 0.6047 - val_precision: 0.5319 - val_recall: 0.4167 - val_f1_score: 0.4673\n",
            "Epoch 326/500\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.4339 - precision: 0.7957 - recall: 0.4967 - f1_score: 0.6110 - val_loss: 0.5767 - val_precision: 0.5926 - val_recall: 0.2667 - val_f1_score: 0.3678\n",
            "Epoch 327/500\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.4305 - precision: 0.8178 - recall: 0.4933 - f1_score: 0.6142 - val_loss: 0.5758 - val_precision: 0.6000 - val_recall: 0.3000 - val_f1_score: 0.4000\n",
            "Epoch 328/500\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.4311 - precision: 0.7771 - recall: 0.5233 - f1_score: 0.6231 - val_loss: 0.5868 - val_precision: 0.5556 - val_recall: 0.3333 - val_f1_score: 0.4167\n",
            "Epoch 329/500\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.4305 - precision: 0.8063 - recall: 0.5000 - f1_score: 0.6168 - val_loss: 0.5699 - val_precision: 0.5556 - val_recall: 0.3333 - val_f1_score: 0.4167\n",
            "Epoch 330/500\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.4345 - precision: 0.7872 - recall: 0.5067 - f1_score: 0.6140 - val_loss: 0.5756 - val_precision: 0.6154 - val_recall: 0.2667 - val_f1_score: 0.3721\n",
            "Epoch 331/500\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.4298 - precision: 0.8123 - recall: 0.4733 - f1_score: 0.5962 - val_loss: 0.5716 - val_precision: 0.5882 - val_recall: 0.3333 - val_f1_score: 0.4255\n",
            "Epoch 332/500\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.4307 - precision: 0.7891 - recall: 0.5433 - f1_score: 0.6398 - val_loss: 0.6083 - val_precision: 0.5319 - val_recall: 0.4167 - val_f1_score: 0.4673\n",
            "Epoch 333/500\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.4394 - precision: 0.7869 - recall: 0.5133 - f1_score: 0.6173 - val_loss: 0.5704 - val_precision: 0.6000 - val_recall: 0.3500 - val_f1_score: 0.4421\n",
            "Epoch 334/500\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.4332 - precision: 0.7772 - recall: 0.5533 - f1_score: 0.6451 - val_loss: 0.5727 - val_precision: 0.6250 - val_recall: 0.3333 - val_f1_score: 0.4348\n",
            "Epoch 335/500\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.4335 - precision: 0.8149 - recall: 0.4933 - f1_score: 0.6135 - val_loss: 0.5697 - val_precision: 0.6047 - val_recall: 0.4333 - val_f1_score: 0.5049\n",
            "Epoch 336/500\n",
            "300/300 [==============================] - 0s 102us/step - loss: 0.4500 - precision: 0.7005 - recall: 0.4867 - f1_score: 0.5736 - val_loss: 0.5730 - val_precision: 0.5366 - val_recall: 0.3667 - val_f1_score: 0.4356\n",
            "Epoch 337/500\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.4286 - precision: 0.8187 - recall: 0.5767 - f1_score: 0.6752 - val_loss: 0.5916 - val_precision: 0.5128 - val_recall: 0.3333 - val_f1_score: 0.4040\n",
            "Epoch 338/500\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.4300 - precision: 0.8022 - recall: 0.5467 - f1_score: 0.6490 - val_loss: 0.5876 - val_precision: 0.5714 - val_recall: 0.3333 - val_f1_score: 0.4211\n",
            "Epoch 339/500\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.4300 - precision: 0.7944 - recall: 0.5167 - f1_score: 0.6236 - val_loss: 0.5696 - val_precision: 0.5641 - val_recall: 0.3667 - val_f1_score: 0.4444\n",
            "Epoch 340/500\n",
            "300/300 [==============================] - 0s 82us/step - loss: 0.4293 - precision: 0.7978 - recall: 0.4967 - f1_score: 0.6101 - val_loss: 0.5749 - val_precision: 0.6129 - val_recall: 0.3167 - val_f1_score: 0.4176\n",
            "Epoch 341/500\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.4321 - precision: 0.7999 - recall: 0.5033 - f1_score: 0.6152 - val_loss: 0.5693 - val_precision: 0.5526 - val_recall: 0.3500 - val_f1_score: 0.4286\n",
            "Epoch 342/500\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.4324 - precision: 0.7965 - recall: 0.5267 - f1_score: 0.6333 - val_loss: 0.5696 - val_precision: 0.5676 - val_recall: 0.3500 - val_f1_score: 0.4330\n",
            "Epoch 343/500\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.4279 - precision: 0.8195 - recall: 0.5467 - f1_score: 0.6548 - val_loss: 0.5907 - val_precision: 0.5263 - val_recall: 0.3333 - val_f1_score: 0.4082\n",
            "Epoch 344/500\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.4278 - precision: 0.8031 - recall: 0.5200 - f1_score: 0.6291 - val_loss: 0.5916 - val_precision: 0.5128 - val_recall: 0.3333 - val_f1_score: 0.4040\n",
            "Epoch 345/500\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.4281 - precision: 0.7973 - recall: 0.5133 - f1_score: 0.6238 - val_loss: 0.5763 - val_precision: 0.6129 - val_recall: 0.3167 - val_f1_score: 0.4176\n",
            "Epoch 346/500\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.4322 - precision: 0.7790 - recall: 0.5067 - f1_score: 0.6132 - val_loss: 0.5735 - val_precision: 0.6207 - val_recall: 0.3000 - val_f1_score: 0.4045\n",
            "Epoch 347/500\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.4292 - precision: 0.7829 - recall: 0.4933 - f1_score: 0.6037 - val_loss: 0.5689 - val_precision: 0.5610 - val_recall: 0.3833 - val_f1_score: 0.4554\n",
            "Epoch 348/500\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.4287 - precision: 0.8103 - recall: 0.5300 - f1_score: 0.6379 - val_loss: 0.5690 - val_precision: 0.5750 - val_recall: 0.3833 - val_f1_score: 0.4600\n",
            "Epoch 349/500\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.4340 - precision: 0.7592 - recall: 0.5133 - f1_score: 0.6077 - val_loss: 0.5766 - val_precision: 0.5652 - val_recall: 0.4333 - val_f1_score: 0.4906\n",
            "Epoch 350/500\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.4259 - precision: 0.7879 - recall: 0.5500 - f1_score: 0.6445 - val_loss: 0.5939 - val_precision: 0.5250 - val_recall: 0.3500 - val_f1_score: 0.4200\n",
            "Epoch 351/500\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.4290 - precision: 0.8089 - recall: 0.5100 - f1_score: 0.6245 - val_loss: 0.5743 - val_precision: 0.6129 - val_recall: 0.3167 - val_f1_score: 0.4176\n",
            "Epoch 352/500\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.4262 - precision: 0.8306 - recall: 0.5167 - f1_score: 0.6357 - val_loss: 0.5767 - val_precision: 0.6071 - val_recall: 0.2833 - val_f1_score: 0.3864\n",
            "Epoch 353/500\n",
            "300/300 [==============================] - 0s 101us/step - loss: 0.4285 - precision: 0.7996 - recall: 0.5067 - f1_score: 0.6201 - val_loss: 0.5768 - val_precision: 0.5714 - val_recall: 0.2667 - val_f1_score: 0.3636\n",
            "Epoch 354/500\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.4260 - precision: 0.8202 - recall: 0.5033 - f1_score: 0.6229 - val_loss: 0.5808 - val_precision: 0.6071 - val_recall: 0.2833 - val_f1_score: 0.3864\n",
            "Epoch 355/500\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.4268 - precision: 0.8165 - recall: 0.5200 - f1_score: 0.6330 - val_loss: 0.5842 - val_precision: 0.5625 - val_recall: 0.3000 - val_f1_score: 0.3913\n",
            "Epoch 356/500\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.4356 - precision: 0.7738 - recall: 0.5067 - f1_score: 0.6098 - val_loss: 0.5903 - val_precision: 0.5128 - val_recall: 0.3333 - val_f1_score: 0.4040\n",
            "Epoch 357/500\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.4257 - precision: 0.8032 - recall: 0.5033 - f1_score: 0.6188 - val_loss: 0.5698 - val_precision: 0.5714 - val_recall: 0.3333 - val_f1_score: 0.4211\n",
            "Epoch 358/500\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.4318 - precision: 0.8083 - recall: 0.5167 - f1_score: 0.6272 - val_loss: 0.5761 - val_precision: 0.6207 - val_recall: 0.3000 - val_f1_score: 0.4045\n",
            "Epoch 359/500\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.4258 - precision: 0.8234 - recall: 0.5133 - f1_score: 0.6312 - val_loss: 0.5733 - val_precision: 0.5714 - val_recall: 0.3333 - val_f1_score: 0.4211\n",
            "Epoch 360/500\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.4261 - precision: 0.8215 - recall: 0.5133 - f1_score: 0.6283 - val_loss: 0.5868 - val_precision: 0.5263 - val_recall: 0.3333 - val_f1_score: 0.4082\n",
            "Epoch 361/500\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.4247 - precision: 0.8141 - recall: 0.5167 - f1_score: 0.6300 - val_loss: 0.5798 - val_precision: 0.5714 - val_recall: 0.2667 - val_f1_score: 0.3636\n",
            "Epoch 362/500\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.4274 - precision: 0.7970 - recall: 0.4900 - f1_score: 0.6016 - val_loss: 0.5717 - val_precision: 0.5714 - val_recall: 0.3333 - val_f1_score: 0.4211\n",
            "Epoch 363/500\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.4266 - precision: 0.8114 - recall: 0.5167 - f1_score: 0.6305 - val_loss: 0.5795 - val_precision: 0.5714 - val_recall: 0.2667 - val_f1_score: 0.3636\n",
            "Epoch 364/500\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.4244 - precision: 0.8343 - recall: 0.5300 - f1_score: 0.6472 - val_loss: 0.5711 - val_precision: 0.5676 - val_recall: 0.3500 - val_f1_score: 0.4330\n",
            "Epoch 365/500\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.4277 - precision: 0.7893 - recall: 0.5100 - f1_score: 0.6159 - val_loss: 0.5681 - val_precision: 0.6047 - val_recall: 0.4333 - val_f1_score: 0.5049\n",
            "Epoch 366/500\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.4297 - precision: 0.8082 - recall: 0.5133 - f1_score: 0.6250 - val_loss: 0.5753 - val_precision: 0.6129 - val_recall: 0.3167 - val_f1_score: 0.4176\n",
            "Epoch 367/500\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.4271 - precision: 0.7901 - recall: 0.5233 - f1_score: 0.6284 - val_loss: 0.5714 - val_precision: 0.5714 - val_recall: 0.3333 - val_f1_score: 0.4211\n",
            "Epoch 368/500\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.4338 - precision: 0.7713 - recall: 0.5200 - f1_score: 0.6194 - val_loss: 0.5780 - val_precision: 0.5667 - val_recall: 0.2833 - val_f1_score: 0.3778\n",
            "Epoch 369/500\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.4278 - precision: 0.7941 - recall: 0.5300 - f1_score: 0.6334 - val_loss: 0.5792 - val_precision: 0.5517 - val_recall: 0.2667 - val_f1_score: 0.3596\n",
            "Epoch 370/500\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.4235 - precision: 0.8184 - recall: 0.5267 - f1_score: 0.6402 - val_loss: 0.5714 - val_precision: 0.5588 - val_recall: 0.3167 - val_f1_score: 0.4043\n",
            "Epoch 371/500\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.4238 - precision: 0.8289 - recall: 0.4900 - f1_score: 0.6136 - val_loss: 0.5708 - val_precision: 0.5714 - val_recall: 0.3333 - val_f1_score: 0.4211\n",
            "Epoch 372/500\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.4230 - precision: 0.8047 - recall: 0.5333 - f1_score: 0.6410 - val_loss: 0.5697 - val_precision: 0.5833 - val_recall: 0.3500 - val_f1_score: 0.4375\n",
            "Epoch 373/500\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.4218 - precision: 0.8355 - recall: 0.5000 - f1_score: 0.6238 - val_loss: 0.5795 - val_precision: 0.5333 - val_recall: 0.2667 - val_f1_score: 0.3556\n",
            "Epoch 374/500\n",
            "300/300 [==============================] - 0s 81us/step - loss: 0.4228 - precision: 0.8014 - recall: 0.5100 - f1_score: 0.6229 - val_loss: 0.5695 - val_precision: 0.5366 - val_recall: 0.3667 - val_f1_score: 0.4356\n",
            "Epoch 375/500\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.4254 - precision: 0.8128 - recall: 0.5067 - f1_score: 0.6230 - val_loss: 0.5760 - val_precision: 0.5455 - val_recall: 0.3000 - val_f1_score: 0.3871\n",
            "Epoch 376/500\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.4231 - precision: 0.8169 - recall: 0.5167 - f1_score: 0.6324 - val_loss: 0.5869 - val_precision: 0.5263 - val_recall: 0.3333 - val_f1_score: 0.4082\n",
            "Epoch 377/500\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.4219 - precision: 0.8176 - recall: 0.5167 - f1_score: 0.6303 - val_loss: 0.5870 - val_precision: 0.5263 - val_recall: 0.3333 - val_f1_score: 0.4082\n",
            "Epoch 378/500\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.4241 - precision: 0.7948 - recall: 0.5367 - f1_score: 0.6387 - val_loss: 0.6117 - val_precision: 0.5208 - val_recall: 0.4167 - val_f1_score: 0.4630\n",
            "Epoch 379/500\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.4304 - precision: 0.7513 - recall: 0.5500 - f1_score: 0.6323 - val_loss: 0.5738 - val_precision: 0.5758 - val_recall: 0.3167 - val_f1_score: 0.4086\n",
            "Epoch 380/500\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.4217 - precision: 0.8099 - recall: 0.5433 - f1_score: 0.6458 - val_loss: 0.5683 - val_precision: 0.5476 - val_recall: 0.3833 - val_f1_score: 0.4510\n",
            "Epoch 381/500\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.4235 - precision: 0.7894 - recall: 0.5367 - f1_score: 0.6381 - val_loss: 0.5706 - val_precision: 0.6176 - val_recall: 0.3500 - val_f1_score: 0.4468\n",
            "Epoch 382/500\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.4276 - precision: 0.8073 - recall: 0.4933 - f1_score: 0.6091 - val_loss: 0.5708 - val_precision: 0.5833 - val_recall: 0.3500 - val_f1_score: 0.4375\n",
            "Epoch 383/500\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.4224 - precision: 0.8269 - recall: 0.5233 - f1_score: 0.6392 - val_loss: 0.5853 - val_precision: 0.5556 - val_recall: 0.3333 - val_f1_score: 0.4167\n",
            "Epoch 384/500\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.4239 - precision: 0.8189 - recall: 0.5200 - f1_score: 0.6351 - val_loss: 0.5711 - val_precision: 0.5556 - val_recall: 0.3333 - val_f1_score: 0.4167\n",
            "Epoch 385/500\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.4218 - precision: 0.8082 - recall: 0.5767 - f1_score: 0.6685 - val_loss: 0.5956 - val_precision: 0.5238 - val_recall: 0.3667 - val_f1_score: 0.4314\n",
            "Epoch 386/500\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.4203 - precision: 0.8131 - recall: 0.5500 - f1_score: 0.6535 - val_loss: 0.5728 - val_precision: 0.5588 - val_recall: 0.3167 - val_f1_score: 0.4043\n",
            "Epoch 387/500\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.4206 - precision: 0.8214 - recall: 0.5100 - f1_score: 0.6282 - val_loss: 0.5743 - val_precision: 0.5882 - val_recall: 0.3333 - val_f1_score: 0.4255\n",
            "Epoch 388/500\n",
            "300/300 [==============================] - 0s 82us/step - loss: 0.4197 - precision: 0.8428 - recall: 0.5333 - f1_score: 0.6517 - val_loss: 0.5729 - val_precision: 0.6333 - val_recall: 0.3167 - val_f1_score: 0.4222\n",
            "Epoch 389/500\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.4224 - precision: 0.8423 - recall: 0.5133 - f1_score: 0.6372 - val_loss: 0.6021 - val_precision: 0.5217 - val_recall: 0.4000 - val_f1_score: 0.4528\n",
            "Epoch 390/500\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.4253 - precision: 0.7795 - recall: 0.5333 - f1_score: 0.6318 - val_loss: 0.5943 - val_precision: 0.5366 - val_recall: 0.3667 - val_f1_score: 0.4356\n",
            "Epoch 391/500\n",
            "300/300 [==============================] - 0s 81us/step - loss: 0.4202 - precision: 0.7687 - recall: 0.5767 - f1_score: 0.6567 - val_loss: 0.5774 - val_precision: 0.5667 - val_recall: 0.2833 - val_f1_score: 0.3778\n",
            "Epoch 392/500\n",
            "300/300 [==============================] - 0s 80us/step - loss: 0.4256 - precision: 0.8168 - recall: 0.5467 - f1_score: 0.6532 - val_loss: 0.5920 - val_precision: 0.5122 - val_recall: 0.3500 - val_f1_score: 0.4158\n",
            "Epoch 393/500\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.4219 - precision: 0.8138 - recall: 0.5033 - f1_score: 0.6196 - val_loss: 0.5848 - val_precision: 0.5405 - val_recall: 0.3333 - val_f1_score: 0.4124\n",
            "Epoch 394/500\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.4220 - precision: 0.8015 - recall: 0.5267 - f1_score: 0.6347 - val_loss: 0.5990 - val_precision: 0.5333 - val_recall: 0.4000 - val_f1_score: 0.4571\n",
            "Epoch 395/500\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.4206 - precision: 0.7981 - recall: 0.5233 - f1_score: 0.6286 - val_loss: 0.5688 - val_precision: 0.5405 - val_recall: 0.3333 - val_f1_score: 0.4124\n",
            "Epoch 396/500\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.4193 - precision: 0.8400 - recall: 0.5500 - f1_score: 0.6636 - val_loss: 0.5771 - val_precision: 0.6071 - val_recall: 0.2833 - val_f1_score: 0.3864\n",
            "Epoch 397/500\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.4174 - precision: 0.7943 - recall: 0.5467 - f1_score: 0.6444 - val_loss: 0.5674 - val_precision: 0.5778 - val_recall: 0.4333 - val_f1_score: 0.4952\n",
            "Epoch 398/500\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.4325 - precision: 0.7612 - recall: 0.5300 - f1_score: 0.6237 - val_loss: 0.5689 - val_precision: 0.5833 - val_recall: 0.3500 - val_f1_score: 0.4375\n",
            "Epoch 399/500\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.4184 - precision: 0.8507 - recall: 0.5467 - f1_score: 0.6637 - val_loss: 0.5781 - val_precision: 0.5667 - val_recall: 0.2833 - val_f1_score: 0.3778\n",
            "Epoch 400/500\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.4189 - precision: 0.8448 - recall: 0.5467 - f1_score: 0.6617 - val_loss: 0.5775 - val_precision: 0.5484 - val_recall: 0.2833 - val_f1_score: 0.3736\n",
            "Epoch 401/500\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.4175 - precision: 0.8150 - recall: 0.5233 - f1_score: 0.6368 - val_loss: 0.5712 - val_precision: 0.5122 - val_recall: 0.3500 - val_f1_score: 0.4158\n",
            "Epoch 402/500\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.4178 - precision: 0.8407 - recall: 0.5400 - f1_score: 0.6566 - val_loss: 0.5702 - val_precision: 0.5833 - val_recall: 0.3500 - val_f1_score: 0.4375\n",
            "Epoch 403/500\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.4182 - precision: 0.8248 - recall: 0.5167 - f1_score: 0.6350 - val_loss: 0.5669 - val_precision: 0.5714 - val_recall: 0.4000 - val_f1_score: 0.4706\n",
            "Epoch 404/500\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.4203 - precision: 0.8137 - recall: 0.5533 - f1_score: 0.6566 - val_loss: 0.5796 - val_precision: 0.5625 - val_recall: 0.3000 - val_f1_score: 0.3913\n",
            "Epoch 405/500\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.4166 - precision: 0.8382 - recall: 0.5300 - f1_score: 0.6484 - val_loss: 0.5891 - val_precision: 0.5000 - val_recall: 0.3333 - val_f1_score: 0.4000\n",
            "Epoch 406/500\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.4178 - precision: 0.8085 - recall: 0.5567 - f1_score: 0.6586 - val_loss: 0.5736 - val_precision: 0.5882 - val_recall: 0.3333 - val_f1_score: 0.4255\n",
            "Epoch 407/500\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.4162 - precision: 0.8510 - recall: 0.5333 - f1_score: 0.6549 - val_loss: 0.5947 - val_precision: 0.5238 - val_recall: 0.3667 - val_f1_score: 0.4314\n",
            "Epoch 408/500\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.4195 - precision: 0.8138 - recall: 0.5767 - f1_score: 0.6718 - val_loss: 0.5772 - val_precision: 0.5926 - val_recall: 0.2667 - val_f1_score: 0.3678\n",
            "Epoch 409/500\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.4151 - precision: 0.8364 - recall: 0.5100 - f1_score: 0.6322 - val_loss: 0.5690 - val_precision: 0.5789 - val_recall: 0.3667 - val_f1_score: 0.4490\n",
            "Epoch 410/500\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.4235 - precision: 0.8162 - recall: 0.5333 - f1_score: 0.6445 - val_loss: 0.5786 - val_precision: 0.5862 - val_recall: 0.2833 - val_f1_score: 0.3820\n",
            "Epoch 411/500\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.4157 - precision: 0.8521 - recall: 0.5067 - f1_score: 0.6349 - val_loss: 0.5891 - val_precision: 0.5128 - val_recall: 0.3333 - val_f1_score: 0.4040\n",
            "Epoch 412/500\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.4169 - precision: 0.8144 - recall: 0.5400 - f1_score: 0.6475 - val_loss: 0.6175 - val_precision: 0.5102 - val_recall: 0.4167 - val_f1_score: 0.4587\n",
            "Epoch 413/500\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.4265 - precision: 0.7774 - recall: 0.5367 - f1_score: 0.6312 - val_loss: 0.5726 - val_precision: 0.5714 - val_recall: 0.3333 - val_f1_score: 0.4211\n",
            "Epoch 414/500\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.4149 - precision: 0.8249 - recall: 0.5333 - f1_score: 0.6473 - val_loss: 0.5692 - val_precision: 0.6000 - val_recall: 0.3500 - val_f1_score: 0.4421\n",
            "Epoch 415/500\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.4161 - precision: 0.8565 - recall: 0.5267 - f1_score: 0.6512 - val_loss: 0.5760 - val_precision: 0.5667 - val_recall: 0.2833 - val_f1_score: 0.3778\n",
            "Epoch 416/500\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.4173 - precision: 0.8077 - recall: 0.5767 - f1_score: 0.6715 - val_loss: 0.5686 - val_precision: 0.6000 - val_recall: 0.3500 - val_f1_score: 0.4421\n",
            "Epoch 417/500\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.4170 - precision: 0.8361 - recall: 0.5300 - f1_score: 0.6487 - val_loss: 0.5733 - val_precision: 0.5676 - val_recall: 0.3500 - val_f1_score: 0.4330\n",
            "Epoch 418/500\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.4149 - precision: 0.8347 - recall: 0.5467 - f1_score: 0.6577 - val_loss: 0.5816 - val_precision: 0.5588 - val_recall: 0.3167 - val_f1_score: 0.4043\n",
            "Epoch 419/500\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.4149 - precision: 0.8098 - recall: 0.5733 - f1_score: 0.6707 - val_loss: 0.5668 - val_precision: 0.5778 - val_recall: 0.4333 - val_f1_score: 0.4952\n",
            "Epoch 420/500\n",
            "300/300 [==============================] - 0s 102us/step - loss: 0.4243 - precision: 0.7903 - recall: 0.5167 - f1_score: 0.6236 - val_loss: 0.5672 - val_precision: 0.5581 - val_recall: 0.4000 - val_f1_score: 0.4660\n",
            "Epoch 421/500\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.4170 - precision: 0.8242 - recall: 0.5433 - f1_score: 0.6529 - val_loss: 0.5712 - val_precision: 0.5429 - val_recall: 0.3167 - val_f1_score: 0.4000\n",
            "Epoch 422/500\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.4166 - precision: 0.8074 - recall: 0.5333 - f1_score: 0.6413 - val_loss: 0.5681 - val_precision: 0.5385 - val_recall: 0.3500 - val_f1_score: 0.4242\n",
            "Epoch 423/500\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.4191 - precision: 0.7970 - recall: 0.5467 - f1_score: 0.6477 - val_loss: 0.5741 - val_precision: 0.5714 - val_recall: 0.2667 - val_f1_score: 0.3636\n",
            "Epoch 424/500\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.4156 - precision: 0.8126 - recall: 0.5267 - f1_score: 0.6361 - val_loss: 0.5754 - val_precision: 0.6071 - val_recall: 0.2833 - val_f1_score: 0.3864\n",
            "Epoch 425/500\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.4262 - precision: 0.7843 - recall: 0.5433 - f1_score: 0.6385 - val_loss: 0.5701 - val_precision: 0.5676 - val_recall: 0.3500 - val_f1_score: 0.4330\n",
            "Epoch 426/500\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.4215 - precision: 0.8140 - recall: 0.5267 - f1_score: 0.6383 - val_loss: 0.5887 - val_precision: 0.5000 - val_recall: 0.3333 - val_f1_score: 0.4000\n",
            "Epoch 427/500\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.4185 - precision: 0.8285 - recall: 0.5467 - f1_score: 0.6558 - val_loss: 0.6061 - val_precision: 0.5208 - val_recall: 0.4167 - val_f1_score: 0.4630\n",
            "Epoch 428/500\n",
            "300/300 [==============================] - 0s 81us/step - loss: 0.4180 - precision: 0.7984 - recall: 0.5367 - f1_score: 0.6402 - val_loss: 0.5797 - val_precision: 0.5484 - val_recall: 0.2833 - val_f1_score: 0.3736\n",
            "Epoch 429/500\n",
            "300/300 [==============================] - 0s 80us/step - loss: 0.4137 - precision: 0.8445 - recall: 0.5433 - f1_score: 0.6593 - val_loss: 0.5922 - val_precision: 0.5000 - val_recall: 0.3333 - val_f1_score: 0.4000\n",
            "Epoch 430/500\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.4158 - precision: 0.8001 - recall: 0.5733 - f1_score: 0.6663 - val_loss: 0.6120 - val_precision: 0.5217 - val_recall: 0.4000 - val_f1_score: 0.4528\n",
            "Epoch 431/500\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.4239 - precision: 0.7525 - recall: 0.5500 - f1_score: 0.6341 - val_loss: 0.5720 - val_precision: 0.5758 - val_recall: 0.3167 - val_f1_score: 0.4086\n",
            "Epoch 432/500\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.4130 - precision: 0.8336 - recall: 0.5600 - f1_score: 0.6692 - val_loss: 0.5952 - val_precision: 0.5116 - val_recall: 0.3667 - val_f1_score: 0.4272\n",
            "Epoch 433/500\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.4168 - precision: 0.7815 - recall: 0.5400 - f1_score: 0.6370 - val_loss: 0.5770 - val_precision: 0.5625 - val_recall: 0.3000 - val_f1_score: 0.3913\n",
            "Epoch 434/500\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.4133 - precision: 0.8453 - recall: 0.5900 - f1_score: 0.6924 - val_loss: 0.5906 - val_precision: 0.5000 - val_recall: 0.3333 - val_f1_score: 0.4000\n",
            "Epoch 435/500\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.4167 - precision: 0.8031 - recall: 0.5700 - f1_score: 0.6657 - val_loss: 0.6021 - val_precision: 0.5435 - val_recall: 0.4167 - val_f1_score: 0.4717\n",
            "Epoch 436/500\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.4159 - precision: 0.7728 - recall: 0.5633 - f1_score: 0.6484 - val_loss: 0.5824 - val_precision: 0.5405 - val_recall: 0.3333 - val_f1_score: 0.4124\n",
            "Epoch 437/500\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.4118 - precision: 0.8171 - recall: 0.5700 - f1_score: 0.6703 - val_loss: 0.5844 - val_precision: 0.5263 - val_recall: 0.3333 - val_f1_score: 0.4082\n",
            "Epoch 438/500\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.4209 - precision: 0.7825 - recall: 0.5400 - f1_score: 0.6365 - val_loss: 0.5718 - val_precision: 0.5556 - val_recall: 0.3333 - val_f1_score: 0.4167\n",
            "Epoch 439/500\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.4118 - precision: 0.8491 - recall: 0.5433 - f1_score: 0.6622 - val_loss: 0.5788 - val_precision: 0.5625 - val_recall: 0.3000 - val_f1_score: 0.3913\n",
            "Epoch 440/500\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.4143 - precision: 0.8308 - recall: 0.5100 - f1_score: 0.6311 - val_loss: 0.5796 - val_precision: 0.5625 - val_recall: 0.3000 - val_f1_score: 0.3913\n",
            "Epoch 441/500\n",
            "300/300 [==============================] - 0s 79us/step - loss: 0.4106 - precision: 0.8216 - recall: 0.5400 - f1_score: 0.6505 - val_loss: 0.5681 - val_precision: 0.5476 - val_recall: 0.3833 - val_f1_score: 0.4510\n",
            "Epoch 442/500\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.4111 - precision: 0.8394 - recall: 0.5633 - f1_score: 0.6728 - val_loss: 0.5797 - val_precision: 0.5625 - val_recall: 0.3000 - val_f1_score: 0.3913\n",
            "Epoch 443/500\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.4119 - precision: 0.8583 - recall: 0.5567 - f1_score: 0.6735 - val_loss: 0.5920 - val_precision: 0.5000 - val_recall: 0.3333 - val_f1_score: 0.4000\n",
            "Epoch 444/500\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.4116 - precision: 0.8367 - recall: 0.5433 - f1_score: 0.6571 - val_loss: 0.5825 - val_precision: 0.5385 - val_recall: 0.3500 - val_f1_score: 0.4242\n",
            "Epoch 445/500\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.4124 - precision: 0.8280 - recall: 0.5533 - f1_score: 0.6630 - val_loss: 0.5970 - val_precision: 0.5227 - val_recall: 0.3833 - val_f1_score: 0.4423\n",
            "Epoch 446/500\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.4255 - precision: 0.7431 - recall: 0.5433 - f1_score: 0.6265 - val_loss: 0.5782 - val_precision: 0.6000 - val_recall: 0.3000 - val_f1_score: 0.4000\n",
            "Epoch 447/500\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.4124 - precision: 0.8340 - recall: 0.5133 - f1_score: 0.6352 - val_loss: 0.5711 - val_precision: 0.5588 - val_recall: 0.3167 - val_f1_score: 0.4043\n",
            "Epoch 448/500\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.4132 - precision: 0.8183 - recall: 0.5467 - f1_score: 0.6529 - val_loss: 0.5715 - val_precision: 0.5758 - val_recall: 0.3167 - val_f1_score: 0.4086\n",
            "Epoch 449/500\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.4098 - precision: 0.8636 - recall: 0.5433 - f1_score: 0.6656 - val_loss: 0.5856 - val_precision: 0.5385 - val_recall: 0.3500 - val_f1_score: 0.4242\n",
            "Epoch 450/500\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.4102 - precision: 0.8385 - recall: 0.5767 - f1_score: 0.6826 - val_loss: 0.5883 - val_precision: 0.5250 - val_recall: 0.3500 - val_f1_score: 0.4200\n",
            "Epoch 451/500\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.4110 - precision: 0.8393 - recall: 0.5533 - f1_score: 0.6637 - val_loss: 0.5959 - val_precision: 0.5116 - val_recall: 0.3667 - val_f1_score: 0.4272\n",
            "Epoch 452/500\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.4149 - precision: 0.8263 - recall: 0.5667 - f1_score: 0.6716 - val_loss: 0.5781 - val_precision: 0.5625 - val_recall: 0.3000 - val_f1_score: 0.3913\n",
            "Epoch 453/500\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.4095 - precision: 0.8281 - recall: 0.5600 - f1_score: 0.6673 - val_loss: 0.5804 - val_precision: 0.5484 - val_recall: 0.2833 - val_f1_score: 0.3736\n",
            "Epoch 454/500\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.4128 - precision: 0.7959 - recall: 0.5733 - f1_score: 0.6655 - val_loss: 0.5711 - val_precision: 0.5938 - val_recall: 0.3167 - val_f1_score: 0.4130\n",
            "Epoch 455/500\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.4087 - precision: 0.8538 - recall: 0.5433 - f1_score: 0.6632 - val_loss: 0.5740 - val_precision: 0.5806 - val_recall: 0.3000 - val_f1_score: 0.3956\n",
            "Epoch 456/500\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.4101 - precision: 0.8330 - recall: 0.5500 - f1_score: 0.6613 - val_loss: 0.5670 - val_precision: 0.5581 - val_recall: 0.4000 - val_f1_score: 0.4660\n",
            "Epoch 457/500\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.4153 - precision: 0.7875 - recall: 0.5867 - f1_score: 0.6716 - val_loss: 0.6126 - val_precision: 0.5417 - val_recall: 0.4333 - val_f1_score: 0.4815\n",
            "Epoch 458/500\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.4185 - precision: 0.7952 - recall: 0.5433 - f1_score: 0.6414 - val_loss: 0.5950 - val_precision: 0.5000 - val_recall: 0.3500 - val_f1_score: 0.4118\n",
            "Epoch 459/500\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.4205 - precision: 0.7734 - recall: 0.5567 - f1_score: 0.6452 - val_loss: 0.6155 - val_precision: 0.5200 - val_recall: 0.4333 - val_f1_score: 0.4727\n",
            "Epoch 460/500\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.4124 - precision: 0.7979 - recall: 0.5733 - f1_score: 0.6620 - val_loss: 0.5752 - val_precision: 0.5667 - val_recall: 0.2833 - val_f1_score: 0.3778\n",
            "Epoch 461/500\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.4106 - precision: 0.8037 - recall: 0.5200 - f1_score: 0.6301 - val_loss: 0.5684 - val_precision: 0.5789 - val_recall: 0.3667 - val_f1_score: 0.4490\n",
            "Epoch 462/500\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.4112 - precision: 0.8158 - recall: 0.5567 - f1_score: 0.6601 - val_loss: 0.5812 - val_precision: 0.5429 - val_recall: 0.3167 - val_f1_score: 0.4000\n",
            "Epoch 463/500\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.4084 - precision: 0.8422 - recall: 0.5500 - f1_score: 0.6652 - val_loss: 0.5813 - val_precision: 0.5294 - val_recall: 0.3000 - val_f1_score: 0.3830\n",
            "Epoch 464/500\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.4078 - precision: 0.8277 - recall: 0.5600 - f1_score: 0.6667 - val_loss: 0.5716 - val_precision: 0.6000 - val_recall: 0.3000 - val_f1_score: 0.4000\n",
            "Epoch 465/500\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.4096 - precision: 0.8295 - recall: 0.5600 - f1_score: 0.6648 - val_loss: 0.5716 - val_precision: 0.5641 - val_recall: 0.3667 - val_f1_score: 0.4444\n",
            "Epoch 466/500\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.4082 - precision: 0.8249 - recall: 0.5700 - f1_score: 0.6720 - val_loss: 0.5691 - val_precision: 0.5500 - val_recall: 0.3667 - val_f1_score: 0.4400\n",
            "Epoch 467/500\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.4072 - precision: 0.8430 - recall: 0.5900 - f1_score: 0.6940 - val_loss: 0.5745 - val_precision: 0.5455 - val_recall: 0.3000 - val_f1_score: 0.3871\n",
            "Epoch 468/500\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.4069 - precision: 0.8489 - recall: 0.5600 - f1_score: 0.6729 - val_loss: 0.5760 - val_precision: 0.5625 - val_recall: 0.3000 - val_f1_score: 0.3913\n",
            "Epoch 469/500\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.4101 - precision: 0.8301 - recall: 0.5367 - f1_score: 0.6503 - val_loss: 0.5784 - val_precision: 0.5625 - val_recall: 0.3000 - val_f1_score: 0.3913\n",
            "Epoch 470/500\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.4109 - precision: 0.7803 - recall: 0.5867 - f1_score: 0.6693 - val_loss: 0.5714 - val_precision: 0.5714 - val_recall: 0.3333 - val_f1_score: 0.4211\n",
            "Epoch 471/500\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.4081 - precision: 0.8324 - recall: 0.5533 - f1_score: 0.6626 - val_loss: 0.5662 - val_precision: 0.5476 - val_recall: 0.3833 - val_f1_score: 0.4510\n",
            "Epoch 472/500\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.4080 - precision: 0.8568 - recall: 0.5633 - f1_score: 0.6789 - val_loss: 0.5945 - val_precision: 0.5116 - val_recall: 0.3667 - val_f1_score: 0.4272\n",
            "Epoch 473/500\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.4085 - precision: 0.7918 - recall: 0.6000 - f1_score: 0.6818 - val_loss: 0.5716 - val_precision: 0.5676 - val_recall: 0.3500 - val_f1_score: 0.4330\n",
            "Epoch 474/500\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.4082 - precision: 0.8226 - recall: 0.5733 - f1_score: 0.6731 - val_loss: 0.5668 - val_precision: 0.5455 - val_recall: 0.4000 - val_f1_score: 0.4615\n",
            "Epoch 475/500\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.4157 - precision: 0.7986 - recall: 0.5700 - f1_score: 0.6644 - val_loss: 0.5746 - val_precision: 0.5455 - val_recall: 0.3000 - val_f1_score: 0.3871\n",
            "Epoch 476/500\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.4047 - precision: 0.8656 - recall: 0.5633 - f1_score: 0.6792 - val_loss: 0.5766 - val_precision: 0.5625 - val_recall: 0.3000 - val_f1_score: 0.3913\n",
            "Epoch 477/500\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.4074 - precision: 0.8356 - recall: 0.5667 - f1_score: 0.6720 - val_loss: 0.5808 - val_precision: 0.5263 - val_recall: 0.3333 - val_f1_score: 0.4082\n",
            "Epoch 478/500\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.4050 - precision: 0.8375 - recall: 0.5400 - f1_score: 0.6553 - val_loss: 0.5815 - val_precision: 0.5526 - val_recall: 0.3500 - val_f1_score: 0.4286\n",
            "Epoch 479/500\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.4086 - precision: 0.8377 - recall: 0.5733 - f1_score: 0.6799 - val_loss: 0.5715 - val_precision: 0.5714 - val_recall: 0.3333 - val_f1_score: 0.4211\n",
            "Epoch 480/500\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.4100 - precision: 0.8341 - recall: 0.5600 - f1_score: 0.6662 - val_loss: 0.5662 - val_precision: 0.5652 - val_recall: 0.4333 - val_f1_score: 0.4906\n",
            "Epoch 481/500\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.4063 - precision: 0.8313 - recall: 0.6133 - f1_score: 0.7034 - val_loss: 0.5729 - val_precision: 0.5405 - val_recall: 0.3333 - val_f1_score: 0.4124\n",
            "Epoch 482/500\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.4042 - precision: 0.8239 - recall: 0.5733 - f1_score: 0.6742 - val_loss: 0.5703 - val_precision: 0.5758 - val_recall: 0.3167 - val_f1_score: 0.4086\n",
            "Epoch 483/500\n",
            "300/300 [==============================] - 0s 101us/step - loss: 0.4073 - precision: 0.8273 - recall: 0.5567 - f1_score: 0.6640 - val_loss: 0.5706 - val_precision: 0.5714 - val_recall: 0.3333 - val_f1_score: 0.4211\n",
            "Epoch 484/500\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.4044 - precision: 0.8552 - recall: 0.5567 - f1_score: 0.6737 - val_loss: 0.5786 - val_precision: 0.5625 - val_recall: 0.3000 - val_f1_score: 0.3913\n",
            "Epoch 485/500\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.4131 - precision: 0.8150 - recall: 0.5633 - f1_score: 0.6647 - val_loss: 0.5989 - val_precision: 0.5319 - val_recall: 0.4167 - val_f1_score: 0.4673\n",
            "Epoch 486/500\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.4088 - precision: 0.7784 - recall: 0.5533 - f1_score: 0.6445 - val_loss: 0.5790 - val_precision: 0.5455 - val_recall: 0.3000 - val_f1_score: 0.3871\n",
            "Epoch 487/500\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.4063 - precision: 0.8217 - recall: 0.5800 - f1_score: 0.6796 - val_loss: 0.5758 - val_precision: 0.5625 - val_recall: 0.3000 - val_f1_score: 0.3913\n",
            "Epoch 488/500\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.4120 - precision: 0.8045 - recall: 0.5533 - f1_score: 0.6523 - val_loss: 0.5657 - val_precision: 0.5476 - val_recall: 0.3833 - val_f1_score: 0.4510\n",
            "Epoch 489/500\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.4076 - precision: 0.8416 - recall: 0.5600 - f1_score: 0.6690 - val_loss: 0.5695 - val_precision: 0.5676 - val_recall: 0.3500 - val_f1_score: 0.4330\n",
            "Epoch 490/500\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.4049 - precision: 0.8435 - recall: 0.6133 - f1_score: 0.7096 - val_loss: 0.5673 - val_precision: 0.5526 - val_recall: 0.3500 - val_f1_score: 0.4286\n",
            "Epoch 491/500\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.4087 - precision: 0.8173 - recall: 0.5800 - f1_score: 0.6783 - val_loss: 0.5901 - val_precision: 0.4762 - val_recall: 0.3333 - val_f1_score: 0.3922\n",
            "Epoch 492/500\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.4098 - precision: 0.7899 - recall: 0.5833 - f1_score: 0.6680 - val_loss: 0.5676 - val_precision: 0.5676 - val_recall: 0.3500 - val_f1_score: 0.4330\n",
            "Epoch 493/500\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.4065 - precision: 0.8517 - recall: 0.5700 - f1_score: 0.6818 - val_loss: 0.5661 - val_precision: 0.5610 - val_recall: 0.3833 - val_f1_score: 0.4554\n",
            "Epoch 494/500\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.4053 - precision: 0.8412 - recall: 0.5533 - f1_score: 0.6655 - val_loss: 0.5731 - val_precision: 0.5263 - val_recall: 0.3333 - val_f1_score: 0.4082\n",
            "Epoch 495/500\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.4039 - precision: 0.8480 - recall: 0.5500 - f1_score: 0.6661 - val_loss: 0.5725 - val_precision: 0.5429 - val_recall: 0.3167 - val_f1_score: 0.4000\n",
            "Epoch 496/500\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.4056 - precision: 0.8465 - recall: 0.5633 - f1_score: 0.6763 - val_loss: 0.5913 - val_precision: 0.5116 - val_recall: 0.3667 - val_f1_score: 0.4272\n",
            "Epoch 497/500\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.4011 - precision: 0.7842 - recall: 0.6033 - f1_score: 0.6805 - val_loss: 0.5666 - val_precision: 0.5227 - val_recall: 0.3833 - val_f1_score: 0.4423\n",
            "Epoch 498/500\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.4054 - precision: 0.8282 - recall: 0.5600 - f1_score: 0.6665 - val_loss: 0.5703 - val_precision: 0.5429 - val_recall: 0.3167 - val_f1_score: 0.4000\n",
            "Epoch 499/500\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.4058 - precision: 0.8295 - recall: 0.5800 - f1_score: 0.6818 - val_loss: 0.5882 - val_precision: 0.5000 - val_recall: 0.3333 - val_f1_score: 0.4000\n",
            "Epoch 500/500\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.4083 - precision: 0.7922 - recall: 0.5733 - f1_score: 0.6641 - val_loss: 0.5744 - val_precision: 0.5588 - val_recall: 0.3167 - val_f1_score: 0.4043\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "s0u1rWuECaAi"
      },
      "cell_type": "markdown",
      "source": [
        "We now plot the training history."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Azy4air5CaAj",
        "outputId": "65dbf207-7e83-44fa-c289-e0eed1d463bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        }
      },
      "cell_type": "code",
      "source": [
        "plt.plot(history_sgd.history['f1_score'])\n",
        "plt.plot(history_sgd.history['val_f1_score'])\n",
        "plt.title('model f1 score')\n",
        "plt.ylabel('f1 score')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'valid'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history_sgd.history['loss'])\n",
        "plt.plot(history_sgd.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'valid'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEVCAYAAADpbDJPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fbc54405c18>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEVCAYAAAAPRfkLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRYKCEEIIiwQFIYQQlv8HdG5JZAbKaCAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fbc543c5cf8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "VX-zJoQORhzC"
      },
      "cell_type": "markdown",
      "source": [
        "#### Adam optimizer\n",
        "We train our model with Adam optimizer."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Oj3Up3P9RhzC",
        "outputId": "763d2f09-5d59-4c0f-d45c-246307611c73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1567
        }
      },
      "cell_type": "code",
      "source": [
        "optimizer = Adam(0.001)\n",
        "loss = 'binary_crossentropy'\n",
        "metrics = [get_metrics(0.5)['precision'], get_metrics(0.5)['recall'], get_metrics(0.5)['f1_score']]\n",
        "\n",
        "model_adam = get_model(optimizer, loss, metrics)\n",
        "\n",
        "history_adam = model_adam.fit(X_train, Y_train,\n",
        "          epochs=40,\n",
        "          batch_size=32,\n",
        "          validation_data=(X_valid, Y_valid)\n",
        "         )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_4 (Dense)              (None, 3)                 15555     \n",
            "=================================================================\n",
            "Total params: 15,555\n",
            "Trainable params: 15,555\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 300 samples, validate on 60 samples\n",
            "Epoch 1/40\n",
            "300/300 [==============================] - 0s 984us/step - loss: 1.7461 - precision: 0.4079 - recall: 0.3867 - f1_score: 0.3953 - val_loss: 1.0268 - val_precision: 0.5167 - val_recall: 0.5167 - val_f1_score: 0.5167\n",
            "Epoch 2/40\n",
            "300/300 [==============================] - 0s 109us/step - loss: 1.0423 - precision: 0.4228 - recall: 0.3500 - f1_score: 0.3717 - val_loss: 1.0777 - val_precision: 0.3811 - val_recall: 0.3667 - val_f1_score: 0.3737\n",
            "Epoch 3/40\n",
            "300/300 [==============================] - 0s 114us/step - loss: 0.7920 - precision: 0.4175 - recall: 0.3400 - f1_score: 0.3658 - val_loss: 0.7358 - val_precision: 0.4000 - val_recall: 0.3333 - val_f1_score: 0.3632\n",
            "Epoch 4/40\n",
            "300/300 [==============================] - 0s 105us/step - loss: 0.6293 - precision: 0.5591 - recall: 0.3467 - f1_score: 0.4172 - val_loss: 0.6392 - val_precision: 0.5330 - val_recall: 0.3333 - val_f1_score: 0.4095\n",
            "Epoch 5/40\n",
            "300/300 [==============================] - 0s 117us/step - loss: 0.5702 - precision: 0.5609 - recall: 0.4100 - f1_score: 0.4721 - val_loss: 0.7898 - val_precision: 0.4275 - val_recall: 0.4000 - val_f1_score: 0.4131\n",
            "Epoch 6/40\n",
            "300/300 [==============================] - 0s 110us/step - loss: 0.5684 - precision: 0.5620 - recall: 0.4367 - f1_score: 0.4782 - val_loss: 0.8076 - val_precision: 0.4106 - val_recall: 0.3833 - val_f1_score: 0.3965\n",
            "Epoch 7/40\n",
            "300/300 [==============================] - 0s 121us/step - loss: 0.5648 - precision: 0.5659 - recall: 0.4367 - f1_score: 0.4817 - val_loss: 0.6407 - val_precision: 0.6292 - val_recall: 0.3333 - val_f1_score: 0.4354\n",
            "Epoch 8/40\n",
            "300/300 [==============================] - 0s 109us/step - loss: 0.5296 - precision: 0.6578 - recall: 0.4733 - f1_score: 0.5324 - val_loss: 0.6456 - val_precision: 0.6032 - val_recall: 0.5333 - val_f1_score: 0.5652\n",
            "Epoch 9/40\n",
            "300/300 [==============================] - 0s 121us/step - loss: 0.5508 - precision: 0.6221 - recall: 0.4500 - f1_score: 0.5129 - val_loss: 0.6244 - val_precision: 0.6489 - val_recall: 0.2833 - val_f1_score: 0.3918\n",
            "Epoch 10/40\n",
            "300/300 [==============================] - 0s 113us/step - loss: 0.5467 - precision: 0.6292 - recall: 0.4800 - f1_score: 0.5392 - val_loss: 0.7678 - val_precision: 0.4574 - val_recall: 0.4500 - val_f1_score: 0.4536\n",
            "Epoch 11/40\n",
            "300/300 [==============================] - 0s 113us/step - loss: 0.4723 - precision: 0.7110 - recall: 0.5767 - f1_score: 0.6331 - val_loss: 0.6184 - val_precision: 0.4975 - val_recall: 0.3000 - val_f1_score: 0.3741\n",
            "Epoch 12/40\n",
            "300/300 [==============================] - 0s 114us/step - loss: 0.4874 - precision: 0.7150 - recall: 0.4433 - f1_score: 0.5357 - val_loss: 0.6000 - val_precision: 0.5662 - val_recall: 0.4667 - val_f1_score: 0.5115\n",
            "Epoch 13/40\n",
            "300/300 [==============================] - 0s 116us/step - loss: 0.5822 - precision: 0.6126 - recall: 0.5133 - f1_score: 0.5541 - val_loss: 0.6650 - val_precision: 0.4825 - val_recall: 0.4667 - val_f1_score: 0.4745\n",
            "Epoch 14/40\n",
            "300/300 [==============================] - 0s 110us/step - loss: 0.4835 - precision: 0.6865 - recall: 0.4700 - f1_score: 0.5484 - val_loss: 0.6925 - val_precision: 0.4279 - val_recall: 0.3500 - val_f1_score: 0.3849\n",
            "Epoch 15/40\n",
            "300/300 [==============================] - 0s 115us/step - loss: 0.4838 - precision: 0.6609 - recall: 0.5333 - f1_score: 0.5860 - val_loss: 0.6089 - val_precision: 0.5731 - val_recall: 0.5167 - val_f1_score: 0.5434\n",
            "Epoch 16/40\n",
            "300/300 [==============================] - 0s 109us/step - loss: 0.5462 - precision: 0.6505 - recall: 0.5200 - f1_score: 0.5704 - val_loss: 0.5883 - val_precision: 0.5559 - val_recall: 0.4333 - val_f1_score: 0.4866\n",
            "Epoch 17/40\n",
            "300/300 [==============================] - 0s 107us/step - loss: 0.5059 - precision: 0.6549 - recall: 0.5400 - f1_score: 0.5887 - val_loss: 1.1738 - val_precision: 0.3622 - val_recall: 0.3500 - val_f1_score: 0.3559\n",
            "Epoch 18/40\n",
            "300/300 [==============================] - 0s 117us/step - loss: 0.6570 - precision: 0.5583 - recall: 0.4567 - f1_score: 0.4973 - val_loss: 0.5961 - val_precision: 0.4996 - val_recall: 0.3333 - val_f1_score: 0.3988\n",
            "Epoch 19/40\n",
            "300/300 [==============================] - 0s 101us/step - loss: 0.4881 - precision: 0.6830 - recall: 0.5533 - f1_score: 0.6082 - val_loss: 0.6633 - val_precision: 0.6122 - val_recall: 0.3500 - val_f1_score: 0.4408\n",
            "Epoch 20/40\n",
            "300/300 [==============================] - 0s 114us/step - loss: 0.4959 - precision: 0.6828 - recall: 0.5500 - f1_score: 0.6028 - val_loss: 0.5997 - val_precision: 0.5752 - val_recall: 0.3000 - val_f1_score: 0.3929\n",
            "Epoch 21/40\n",
            "300/300 [==============================] - 0s 114us/step - loss: 0.4335 - precision: 0.7679 - recall: 0.5733 - f1_score: 0.6543 - val_loss: 0.6313 - val_precision: 0.4386 - val_recall: 0.3833 - val_f1_score: 0.4070\n",
            "Epoch 22/40\n",
            "300/300 [==============================] - 0s 124us/step - loss: 0.4868 - precision: 0.6573 - recall: 0.5467 - f1_score: 0.5916 - val_loss: 0.6016 - val_precision: 0.4919 - val_recall: 0.3667 - val_f1_score: 0.4197\n",
            "Epoch 23/40\n",
            "300/300 [==============================] - 0s 108us/step - loss: 0.4241 - precision: 0.7893 - recall: 0.5633 - f1_score: 0.6528 - val_loss: 0.5957 - val_precision: 0.4893 - val_recall: 0.3333 - val_f1_score: 0.3960\n",
            "Epoch 24/40\n",
            "300/300 [==============================] - 0s 110us/step - loss: 0.4159 - precision: 0.7786 - recall: 0.6000 - f1_score: 0.6760 - val_loss: 0.5960 - val_precision: 0.6122 - val_recall: 0.3333 - val_f1_score: 0.4284\n",
            "Epoch 25/40\n",
            "300/300 [==============================] - 0s 105us/step - loss: 0.4220 - precision: 0.7886 - recall: 0.5867 - f1_score: 0.6698 - val_loss: 0.6361 - val_precision: 0.5773 - val_recall: 0.5167 - val_f1_score: 0.5452\n",
            "Epoch 26/40\n",
            "300/300 [==============================] - 0s 114us/step - loss: 0.4581 - precision: 0.6844 - recall: 0.5967 - f1_score: 0.6364 - val_loss: 0.7086 - val_precision: 0.5407 - val_recall: 0.3500 - val_f1_score: 0.4229\n",
            "Epoch 27/40\n",
            "300/300 [==============================] - 0s 120us/step - loss: 0.4679 - precision: 0.6814 - recall: 0.5433 - f1_score: 0.6017 - val_loss: 0.5871 - val_precision: 0.5378 - val_recall: 0.2667 - val_f1_score: 0.3562\n",
            "Epoch 28/40\n",
            "300/300 [==============================] - 0s 106us/step - loss: 0.4112 - precision: 0.7538 - recall: 0.5900 - f1_score: 0.6606 - val_loss: 0.5919 - val_precision: 0.4865 - val_recall: 0.3167 - val_f1_score: 0.3824\n",
            "Epoch 29/40\n",
            "300/300 [==============================] - 0s 112us/step - loss: 0.4309 - precision: 0.7273 - recall: 0.5700 - f1_score: 0.6323 - val_loss: 0.6399 - val_precision: 0.4518 - val_recall: 0.4000 - val_f1_score: 0.4239\n",
            "Epoch 30/40\n",
            "300/300 [==============================] - 0s 115us/step - loss: 0.4367 - precision: 0.6999 - recall: 0.5933 - f1_score: 0.6399 - val_loss: 0.6300 - val_precision: 0.5190 - val_recall: 0.4333 - val_f1_score: 0.4720\n",
            "Epoch 31/40\n",
            "300/300 [==============================] - 0s 119us/step - loss: 0.3956 - precision: 0.7825 - recall: 0.6367 - f1_score: 0.7010 - val_loss: 0.6273 - val_precision: 0.4822 - val_recall: 0.4000 - val_f1_score: 0.4353\n",
            "Epoch 32/40\n",
            "300/300 [==============================] - 0s 116us/step - loss: 0.3932 - precision: 0.7476 - recall: 0.6267 - f1_score: 0.6784 - val_loss: 0.6080 - val_precision: 0.4767 - val_recall: 0.3667 - val_f1_score: 0.4141\n",
            "Epoch 33/40\n",
            "300/300 [==============================] - 0s 123us/step - loss: 0.4165 - precision: 0.7308 - recall: 0.6267 - f1_score: 0.6716 - val_loss: 0.7726 - val_precision: 0.4833 - val_recall: 0.4833 - val_f1_score: 0.4833\n",
            "Epoch 34/40\n",
            "300/300 [==============================] - 0s 118us/step - loss: 0.5252 - precision: 0.6950 - recall: 0.5733 - f1_score: 0.6213 - val_loss: 0.7719 - val_precision: 0.4733 - val_recall: 0.4333 - val_f1_score: 0.4524\n",
            "Epoch 35/40\n",
            "300/300 [==============================] - 0s 119us/step - loss: 0.5264 - precision: 0.6499 - recall: 0.5500 - f1_score: 0.5899 - val_loss: 0.9060 - val_precision: 0.4821 - val_recall: 0.4500 - val_f1_score: 0.4653\n",
            "Epoch 36/40\n",
            "300/300 [==============================] - 0s 112us/step - loss: 0.6444 - precision: 0.6187 - recall: 0.5300 - f1_score: 0.5634 - val_loss: 1.2004 - val_precision: 0.4667 - val_recall: 0.4667 - val_f1_score: 0.4667\n",
            "Epoch 37/40\n",
            "300/300 [==============================] - 0s 109us/step - loss: 0.5065 - precision: 0.7312 - recall: 0.5867 - f1_score: 0.6463 - val_loss: 0.6390 - val_precision: 0.4917 - val_recall: 0.4500 - val_f1_score: 0.4699\n",
            "Epoch 38/40\n",
            "300/300 [==============================] - 0s 105us/step - loss: 0.3954 - precision: 0.7471 - recall: 0.6267 - f1_score: 0.6787 - val_loss: 0.6016 - val_precision: 0.5528 - val_recall: 0.4667 - val_f1_score: 0.5058\n",
            "Epoch 39/40\n",
            "300/300 [==============================] - 0s 109us/step - loss: 0.3793 - precision: 0.7866 - recall: 0.6933 - f1_score: 0.7364 - val_loss: 0.6215 - val_precision: 0.4909 - val_recall: 0.3500 - val_f1_score: 0.4085\n",
            "Epoch 40/40\n",
            "300/300 [==============================] - 0s 115us/step - loss: 0.3936 - precision: 0.7398 - recall: 0.6433 - f1_score: 0.6870 - val_loss: 0.5969 - val_precision: 0.5753 - val_recall: 0.4667 - val_f1_score: 0.5149\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "c8ZJ3SWAChEd"
      },
      "cell_type": "markdown",
      "source": [
        "We now plot the training history."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "XV-A2El1ChEe",
        "outputId": "aec879af-16f9-4428-b159-cf50290c693c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        }
      },
      "cell_type": "code",
      "source": [
        "plt.plot(history_adam.history['f1_score'])\n",
        "plt.plot(history_adam.history['val_f1_score'])\n",
        "plt.title('model f1 score')\n",
        "plt.ylabel('f1 score')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'valid'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history_adam.history['loss'])\n",
        "plt.plot(history_adam.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'valid'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEVCAYAAAAPRfkLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzsvXl4G9d56P3DyhUkwX0Tqf1osazF\nki1ZtuQ9dhw3dbPHTWI7S9M4aXJ70za9X9Lb3vbePLlfcrN9Tds0t2mdpLGd2HHs2PEuy5K1WrYW\nS9SRSIn7BpIAwRXrfH8MhoIoEgRBDDed3/PoETAzZ/ACBOadd7domoZCoVAoFADWuRZAoVAoFPMH\npRQUCoVCMYZSCgqFQqEYQykFhUKhUIyhlIJCoVAoxlBKQaFQKBRjKKWgUIxDCPETIcTfTnHMg0KI\nVybYbhNCvCaEuCiE2BDb9gkhxKAQ4o9NElmhSBv2uRZAoVhkVAK7gUwpZUgI8TXgRkDOrVgKRXIo\npaBY0AghlgIHge8CnwYswCeBbwCbgBellA/Hjv0Q8N/Rv/ftwGellA1CiCLgl8Aq4AwwDLTG1qwD\n/gmoAALAQ1LKtyaRxQa8jm6BnxJCfATYA3wr9n+i92HIZgNCwJ9JKV8XQiwH/h1d2XiBP5FSvi2E\nqAH+FVgaO/5/SykfjX0eB4DHgS1Syt1CiJ3A9wA30AN8XEp5YYqPVnGVotxHisVAMdAppRTASfQL\n4qeAa4GPCyFWxF1E/1BKuQZ4DviX2Pq/AjxSymXAI8B7AIQQVuBp4FEp5Wrg88BvhRAT3kxJKSPA\n7UBESrlGSnlCSnlYSplM24AfAfdKKdcCXwD+ILb9x8AvpZQrgf8J/Cxu++ux93wv8IOYQjA+j+Mx\nheACngX+W+wc3weeSEIexVWKUgqKxYAd+FXs8SngqJSyR0rZC3Sg32XfCeyRUtbHjvsJcGvsAr+L\n2IVSStkI7I0dswYoBf4ttu9NwIPuDko33cDnhRC1Usr9Uso/F0JkAreiWzEAvwVuEEI4Yu/nRzG5\nmtAtkdtixzmA38Qe3wy0Silfjh37S2BlTEkqFFeg3EeKxUBESjliPAYG4/ehu2RK0N0vAEgp+4UQ\nFvS76kKgP26NcVwBkA3UCSGMfXlAUbrfALpl8HXgmBCiBfgKcB79xq0/JrMGDAohygGLlHK8zKWx\nxxEppT/uPawQQpyNOzaA/nk0m/A+FAscpRQUVwtdwA7jiRDCDUTRfexeID/u2BLgAnrcwR9zN12G\nEOLBdAonpWwAHoq5rD4J/CewHNDQlVBPTImtAJqAqBDCLaU0FFhR7D2Opx2ok1JuTae8isWLch8p\nrhZeBnbFAregxwdeklKG0QPV9wMIIVYAN8WOaQJahRAfjO0rFkL8UgiRk07BhBAlQoiXhRB5Usoo\ncAjQpJQB4CXgwdih7wGel1KGgBeBP4mTeRdwRYoscBioEELcEDt2uRDiZzEFo1BcgVIKiqsCKWUr\n8Bn0QPFZ9Ivon8R2fxOoFUJcBH4IPBVbowEfBb4YW/MG8KqUcijZ1xVCvBhbez3wv4UQZ4UQ94+T\nzQO8ABwVQpwBHkPPpCIm831CiAvAPwAfj23/PHBL7Ny/AT4jpWyZ4H2PAB8EfiiEqIsd+6skg9+K\nqxCLmqegUCgUCgNlKSgUCoViDKUUFAqFQjGGUgoKhUKhGEMpBYVCoVCMYWqdghDiu8B29FzrL0sp\nj8a2VwG/iDt0OfA1wAn8PdAQ2/6ylPJ/JnoNj2cg5Ui5252N1zuc6nJTUbKlhpItNZRsqbGQZSsp\ncU2YlmyaUhBC7AZWSSl3CCHWorcK2AEgpWwDbokdZ0dvIvYMeurc41LKr5olVzx2u202XiYllGyp\noWRLDSVbaixG2cx0H92O3kwMKWUd4BZC5E1w3IPAk1LKwQn2KRQKhWIWMdN9VA4ci3vuiW3zjzvu\nM8Bdcc93CyFeQG/q9VUp5TuJXsTtzp6Rti4pcaW81myUbKmhZEsNJVtqLDbZZrP30RX+KyHEDuBs\nXPOuQ+gtjJ+L7XsU2JDopDPx55WUuPB4BlJebyZKttRQsqWGki01FrJskykMM91H7eiWgUElehvj\neN5HXL8WKeVZKeVzsccHgZLY4BKFQqFQzAJmKoWX0APHCCG2AO1SyvFqaxtwwngihPhLIcTHYo+v\nQbcaIibKqFAoFIo4THMfSSkPCCGOCSEOoLcofiTWbrhfSmkMAKlAHy5i8J/Az4QQn4/J9mkUCoVC\nMWuYGlOQUn5t3KYT4/ZvGPe8FX3SlEKhUCjmAFXRrFAoFPOMYCjCk3sb6O0fnfXXVkrBJF5//dWk\njvv+979De3ubydIoFIqFxJG6bp472MRzBxtn/bWVUjCBjo52XnnlxaSO/fKX/yuVlVUmS6RQKBYS\ndU36lNXj9T1EZ3nmjZrRbAL/5/98i7q609x88zbuuuseOjra+d73fsQ3v/k/8Hi6GRkZ4eGHP8fO\nnTfzxS9+jj//879kz55XGRoapLm5iba2Vr7xja+zbt2WuX4rCoViltE0jbqmPgB8g0GaOgdYVjFR\nMwhzWPRK4YnX6jl6tnvCfTabhUhk+lp425pSPnzbykn3f+xjn+Cpp55g2bIVNDc38qMf/QSvt4/r\nr9/OPfe8L3bR/xo7d9582bru7i6+/e0fcOjQAR5//HH+7u+UUlAorjY6+4bxDQbJzXIwOBLi+Pke\npRQWE2vXrgfA5cqjru40zzzzFBaLFb+//4pjr712EwClpaUMDMzPKkmFQmEuhuvo3h21PLm3geP1\nPdy/a/msvf6iVwofvm3lpHf1s1Gi7nA4AHj55Rfw+/384z/+BL/fz2c+84krjrXZVPG2QnG1U9eo\nK4XNq4o53djHuxf66O0fpSg/c1ZeXwWaTcBqtRKJXF6I7fP5qKioxGq1snfva4RCoTmSTqFQzFei\nmsbZZi9FeRmUFGSxeWUxoAecZwulFEygtnYZUp5laOhSN/BbbrmNAwf28eUv/ylZWVmUlpby05/+\n6xxKqVAo5hstXYMMjYZZW1uIxWJh4xwohUXvPpoL3G43Tz313GXbKioq+Y//eGzs+V133QPAQw99\nFoDlyy+5uJYvX8nPfvazedt9UaFQmIMRT1i71A1AYV4mNWW5nG3yMhIIk5Vh/iVbWQoKhUIxTzgT\nS0VdU+Me27ZpZTGRqMa7F/tmRQalFBQKhWIeEI5EOdfio6IoG7crY2z75lUlABw/PzsuJKUUFAqF\nYh5wod1PMBRlXW3hZdtrynJxuzI42dBDJBo1XQ6lFBQKhWIeYMQT1tS6L9tusVjYtLKYodEw9a1X\n1jelG6UUFAqFYh5Q1+TFYoE1tQVX7JvNLCSlFBQKhWKOCQQjNLT1U1vmIifTccX+tbUFZDhsHK/v\nNV0WpRRMItnW2QbHj7+N1zs72QUKhWJ+cb7VRySqsXac68jAYbdxzbJCuvqG6egdMlUWU5NehRDf\nBbYDGvBlKeXR2PYq4Bdxhy4Hvgb8Cvh3oBaIAA9JKS+YKaMZGK2zb7nl9qTXPPfcM3zsY3+M2104\n9cEKhWJRMb4+YSI2rSrm2DkPx+t7qCjKMU0W05SCEGI3sEpKuUMIsRb4N2AHgJSyDbgldpwdeB14\nBvg44JNSPiCEuAv4JvARs2Q0C6N19r/924+5cKGegYEBIpEIX/nKX7By5Sp+/vN/Z+/ePVitVnbu\nvJm1a9exb9/rXLx4gX/4h/9NeXn5XL8FhWJeEAhF6PPP/vSx2eZMkxeb1cKqqivjCQYbVhRhseip\nqffcUGuaLGZaCrcDTwNIKeuEEG4hRJ6U0j/uuAeBJ6WUg0KI24FHY9tfQVckM+Kp+t/xTvepCffZ\nrBYi0em3zt5cuoE/Wvm+SfcbrbOtVis33HAj9933h1y8eIHvf//bfO97P+Kxx37O00+/gM1m4+mn\nn2Tbtu2sXLmaP//zv1QKQaGI46fP13GioZe/+dRWU++O55Kh0RDNnQOsWlJAhnPypph52U5WVuVT\n39bPwHAQV7bTFHnMVArlwLG4557YtvFK4TPAXXFrPABSyqgQQhNCOKWUwclexO3Oxm6f/IPMbnNi\ns1om3Z9o36TnzHJSUuKadH9BQTYZGQ6kPE1fXx979rwEQCAwQkmJi7vvvpu//Ms/433vex8f//iH\nyM3Nxem043bnXHbeRK8x1yjZUkPJljyRqMbpi30EghEefekc3/rizSn9Xs1mpp9b/al2NGDruvIp\nz7VzYxXnW/tp9Axx29YiU2Sbzd5HV/w1hRA7gLMTWA+TrhmP1zuccP/dVXdxd9VdE+6bSevsROt8\nvmECgRCaZuFLX/qvXHPNtZet++IXv0pTUyOvvfYyH/vYx/nxj/+DYDCM1zs0dt7ZaOudKkq21FCy\nTY+mzgGGRsPYrBZkk5f/fP4Md99QM9diXUY6PrdDJ9sBqCnOnvJcqyr1i/wbb7eyYZKgdLKyTaYw\nzMw+ake/8zeoBDrGHfM+dDfRFWuEEA7AkshKmK8YrbPXrbuGN954HYCLFy/w2GM/Z3BwkJ/+9F+p\nrV3KQw99Fpcrn+HhoQnbbSsUVzOyxQfAg+9bR162g6feuGB65s1cUNfkJcNhY3nl1NPVyguzKXNn\n8e6FPkJhc64XZiqFl4APAgghtgDtUsrxamsbcGLcmg/FHt8H7DFRPtMwWmf7fF7a2lr4whc+w7e+\n9Q9s2rSF3NxcfD4vn/3sJ/mzP/s869dfQ15ePps2beHrX/8rLlxomGvxFYp5gWzWM3Ju3FDJJ94j\nCEei/NvzdURTiAPOV7wDATp6h1m9pAC7berLscViYdOqYgKhCGebfabIZJr7SEp5QAhxTAhxAIgC\njwghHgT6pZS/iR1WAcQPUH4cuFMIsR8IoAehFxwTtc6O57/8l7+8YtvDD3+Ohx/+nJliKRQLhqim\nca7FR1FeJqWF2VwnSrl+bSlH6rp56WjLvHMjpcpZIxV1CldQPJtWFvPikRaOn+9hw/Kp4wrTxdSY\ngpTya+M2nRi3f8O45xHgITNlUigU8592zxBDo+Gx9g4AD9y5mromL7/Zd4GNK4sWRTZSXQpKYWV1\nPjmZdo7X9/DHd63GYklv8F1VNCsUinmHEU8QSy7l7buynXziLkEovDjcSJqmUdfUR06mnSVluUmv\ns1mtXLuiCO9AgLae9MdYlFJQKBTzDkMprK65vJhr6xrdjdTQ5uflt1rmQrS04fGN0OsPsKbWjXWa\nd/t3bath86pi8nPSX6uglIJCoZhXaJrGuWYvBblOSguyrtj/8TtX41oE2UhnYq6jddNwHRnUlrv4\n0geuNaWATSkFhUIxr+jsG8Y/HELUuCf0l+fFuZF++vzZBetGqms0+h3Nr35nSikoFIp5hWy+Mp4w\nnq1rStm2ppT6tn5+u/8i4Yj5E8nSSVTTONvsxe3KoMx9pTU0lyiloFAsAjr7hmdlVONsMBZkrplc\nKQA8cNdq8rIdPHugkb/+l4O8dKSZkUB4NkScMScbehkYDnHNssK0Zw/NlNlsc6FQKEzg9XfaePRF\niduVwe6NlezaVElBbsbUC+chmqYhm73k5TgpL8xOeGxetpNvfGobLxxpZt/Jdh57rZ5n3mzk1i1V\n3HFdNfnz+DN44VATAHduXTLHklyJUgoKxQKmt3+Ux/fUk+G0MRoM8/T+izx7oJEtq0u4bUsVq5cU\nzLs70UR0+0bwDQbZuqY0KbmL8jN54M7VvP+mZbz2diuvHmvluYNNvHikmR3ry7n7hpp5V89Q39bP\nudZ+Niwvoro0+VTU2UIpBYVigaJpGj97SRIIRnjovWvYtqaUQ6e7eO3tVo6e7ebo2W4qi3O4dXMV\nN15TTlbG/P+5JxNPmIjcLAd/sHMZd19fw4F3O3nxSDP7Tnaw72QHD9y5mtuvqzZD3JT4fcxKeO/2\n+VmVPf+/JQqFYkIOn+niZEMv65a6uWlDBRaLhVs2V7F7UyX1bf289nYbb53t5hcvn+O3+y/yjU9t\npWSCFM/5xJhSmCKeMBlOh41bNlexa2Ml75zv4Se/O8PLR1u4bUvVvLCYOnqHeOd8D8sr81g9TcU3\nW6hAs0KxAPEPB/nPV87jdFj55N1rLrvgWSwWVlUX8Cd/sJ5vP7KTu7YtYXAkxAtHmudQ4uQ41+Il\nN8tBZfHMXD5Wq4XrRAnXLCuk2zdCZ1/iFvuzxe8P63+De26omRdKaiKUUlAoFiCPvXKewZEQf3Tz\n8gkLvAzyc5x86NYVFOVl8ubJDgZHQrMo5fToiVX4rl5SMO0K38kweicdr+9Jy/lmgncgwMF3Oykr\nzGbzqpK5FmdSlFJQKBYYJ+p7OHSmi2UVedyRRPaKzWrlzm1LCIaj7Hm7dRYkTI2J+h3NlGtXFGEB\nTtT3pu2cqfLyWy1Eohr33FCDdR5OkDNQSkGhWECMBMI8+qLEZrXw0HvXJH1xufnaCrIy7Lz6dlva\nh7P0+UfTUjw203jCROTlOFlemUd9a/+cWknDoyFef6eN/BwnO9aXzZkcyaCUgkKxgPj16w14BwLc\nu6OW6pLk0xmzMuzcsqkS/1CQg6e70iaPdyDAX//4ED/53ZkZn0u2eMnOsE/rfSXDxpXFRDWNdy/M\nnbWw5502RoMR7ty2BEeCmfLzAaUUFIoFwrkWH3veaaOyOId7dyyd9vrbr6vGZrXw4pFmolp6+gWd\naewjFI5ypK6bix2TjVqfmj7/KB7fqB5PSLNrZa7jCqFwhFfeaiXTaeOWTVVzIsN0UEpBoVgABEMR\nfvp8HRbgoXvW4LBP/6dbmJfJ9WvL6OgdTttd89nYyEyAJ/emPkp2rFW2CWma1SU5FOVlcOpC35z0\nSDrwbif9Q0Fu2VxFdub8rwIwVUIhxHeB7YAGfFlKeTRu3xLgl4ATeFtK+XkhxC3Ar4DTscNOSSm/\nZKaMCsVs8OvXG2jtGeLPPrAhpcyaZ95spMs7wh1bq1lRlZ+yHO+5fgkHT3fy4pEWrl1RPPWCBGia\nxtkmPYW0tiyX041eTjf2sT6Frp9mxBMMLBYL164sZs/bbdS39rMmhVbVqRKNarxwuBm7zTIvW1pM\nhGmWghBiN7BKSrkD+DTwg3GHfAf4jpTyeiAihDDK+/ZKKW+J/VMKQbHgCUeivPZ2Kyfre+hIYVKW\ndyDAC4ebKc7P5I92LZ+RLDVlLtYtdVPX5KWpc2BG5/L0j9LrDyBqCvjgLSsBePL1BrQUXFOyxUem\n00bNNCaQTYdNc+RCeue8hy7vCDvWl+N2zd9eTPGY6T66HXgaQEpZB7iFEHkAQggrcDPwTGz/I1LK\n+V9Zo1CkwPkWH6NBPePnXGv/tNfXNfUR1TRuv66aTOfMjfv3XK/ff714dGY/OWPo/JoaN7XlLq5f\nW0pj5wDHpGda5/ENBujqG2ZldT42qzmXpDU1BWQ4bJxomL1gs6ZpPH+oGQtw9w3zs6XFRJjpPioH\njsU998S2+YESYAD4rhBiC7BPSvnXsePWCSGeAQqBv5NSvpzoRdzubOwziOaXlLhSXms2SrbUmG+y\nPXOwaexxU/fgtOVr9ui++u3XVqXlvd1anMtTb1zgSF03n7t/IyWxfv7TPffFzkEAbtyky/Xp92/g\nLfkav32zkbtuXIbNltwF/myrHqDesqZsUhnS8b43ixIOvdtJEAtVacxwmky2U/U9XOzws/2acq5d\nU56215sOqXxusxn1sIx7XAV8H2gEnhNC3AscB/4OeAJYDuwRQqyUUgYnO6nXm3r5ekmJC49nZia0\nWSjZUmM+ynb43Q6cDiuZTjun6nvo7vZPq8XBiXPdZGXYcDmtaXtvt22p4qfPn+WJl87y4dtWTvtz\n0zSN4+e7yctxkmkFj2cAB7Dr2gpeP97O03vOs2tjZVLnOnq6A4DqouwJZUjX33TNkgIOvdvJniNN\nY9bSTEkk22MvnQXgts1Vc/KdnOpzm0xhmOk+ake3DAwqgY7Y4x6gSUrZIKWMAK8C66WUbVLKx6WU\nmpSyAehEVx4KxYKk2zdCR+8w62oLWb+8CO9AgN7+0aTX+wYDdHlHWFWd3lTN7evKyc9xsvdEW0qD\naTr7hukfDLKm5vLW3PftXIbDbuW3+y8SDCVXJCdbfDgdVpaWm2vhbVxRBOgV4WYTiUapa/JSXZLD\nyhkkBswFZiqFl4APAsRcRO1SygEAKWUYuCCEWBU79jpACiEeEEJ8NbamHCgD2kyUUaEwlVMxH/a1\nK4q4Zrl+UTLSL5Mh1VbSU+GwW7n9umpGAhHeONE+7fVj8YRxmTxuVwZ3bK3GOxDgtben/un6h4O0\n9wyxsiofe5LuplTJz81gWUUe51r6GR41t7q5q2+EUDhKrcmKzgxM+ytIKQ8Ax4QQB9Azjx4RQjwo\nhLg/dshXgJ/G9vcDz6IHnncLIfYBvwX+NJHrSKGY75xo0O9KNywvYl1MKZxvnYZSMPL3TUjVvGVz\nFU6HlVfeapl2/n5dTFmtnSC9873ba8nOsPPcwUaGRxNbIacv9AHpV3qTsXFlEVFN41Tsdc2i1aPH\nW5akuTp7NjA1piCl/Nq4TSfi9tUDN43bPwDcZ6ZMCsVsEQhGONvk04un8jMpLMol02njXEvyGUiy\n2UuGw0ZtWfrvOHOzHNy8oZJX327lzRPtrFuSnJsjGhuZ6XZlTNihNSfTwT3ba3hy7wVeONI8YRpt\ne88Qz7x5kaN13QBjVpTZbFpZzNP7LnKioYcb1pnXg6ilW1cK83Gy2lSoimaFwiTqmr2EI9GxIjGb\n1cLKqnzdHz80tQHsHwrS0TvMyqo801wrd26rxgL8Zm990vUF7Z4hBoZDrKlxTxowv2PrEvJznbx0\ntPmy99rRO8SPnznNN35ymCN13dSUufjKhzayrCIvHW9nSpaU5uJ2ZXCqoZdI1LzqZqUUFArFFZyM\niycYGG0czicRVzg35joyrwK31J3NltUlNLT2cz7JGoq6WGuLiVxHBhkOG3+wcxnBUJTfvdlIV98w\n//rsGb7+k8McOtNFdWkuX/qjDfzNg1sv+3zMxmKxsHFlMUOjYepTqBlJllbPIPm5TvKynaa9hlko\npaCYFk+90cC3Hj069YFXOZqmcbKhh5xMOyuqLt0FG0rhXBJxBbOCzOO5c5vefuHlt1qSOv5SkDmx\nXDdfW0GpO4s977Tx//zrYQ6e7qSqOIdH7r+G//7QNjavLpmT6WNjWUgmFbINjoTo8wdYsgCtBFBK\nQTFN9p/sYP+J9ikDiFc7bT1D9PkDrF9WeFmV7rIKF3abZcwKSIRs8eGwW013rayqzmd5ZT5vn/PQ\n0z+S8NhoVEM2+yjOz6Q4P/G8Z7vNygd3ryCqaZQXZfOnf3gNf/vw9VwnStM2WS0V1ta6cdqtpqWm\nti3gIDMopaCYBsOjYXyDun94vsy8na9M5DoCcNhtLK/Io6V7MGF9wOBIiDbPICsq81LqiDodLBYL\n9928HE2DPVOkkbZ0DzIcCCd0HcWzdU0p3/7CjfyPh69n25q5VQYGToeNdUsL6egdpmsGxa+TsZDj\nCaCUgmIadPRdaubW0Tv9xm5XEyfre7AwcVbNqiUFaBrUt03u0z7f4kMDhInxhHh2ba7Cle3gjRPt\nBIKTF53VTVKfkIjCvMx5N35y40qjkC39LiRDKSj3kWLR09Fz6a5KWQqTMzQaor7Nz/LKvAkDjWNx\nhQQuJDPmFSfC6dAHwAyNhjl4unPS44z5CWtmSVmZhZERZoYLqdUziN1mobwwO+3nng2UUlAkTbx1\n0NmrlMJknL6odzXdMElWzcqqfCyWKZRCsw+7zcLyytlJ1QS4dUsVNquFV461TpieGo5EkS0+yguz\nF0wb6MlwuzKoLXdxrsWX1vhYNKrR5hmisijH9Apts1iYUivmhI6YIrDbrMpSSIDhktg4yRCbrAw7\nNaUuLnb4CYWvdNUMj4Zp7h5gWUUeTsfszfMtyM1g25pS2nuGONPovWJ/U+cAgWBkVofUmMmmlcVE\nohqn0ji7ucs7TDAcXbDxBFBKQTEN2nuHyM1ysKwyjy7vMNFoeub8Lib0Fgq95Oc6Ew6MWbUkn3BE\n42LHlV0sz7f60DRzppBNxR2x6WCvTJCeesl1NPtymcHWNaUAvHKsJaXBQBOx0OMJoJSCIklC4Qge\n3wgVRdlUl+YSjmhTpi9ejVzs8DM4EmLD8qKEOfhGrGCi5niX4gmzf0e+vDKPFZV5nGzovSIzp65p\nccQTDKqKc9i0spiGNn9SKcLJYPQ8UpaCYtHT1TeCpkFFUQ5VsS+8ciFdyckx11HiKt1V1ZNXNstm\n31hLjLngjq1L0IBX32od2xYKR6lv7aeqJIe8nIVXpTsZ9+6oBeB3cYOQZkJrtx53W6g1CqCUgiJJ\n2mNB5sqibKpL9eZsHSrYfAUnL/Ris1pYN8Xw+rwcJ+WF2dS39V/Wg2c0GKapc4Cl5S4ynLMXT4jn\nOlFCQa6T/ac6xmopLnb4CYaji8ZKMFhRlc/aWjenL/ZxscM/4/O1dA+Qn+Nc0IpTKQVFUhgKoKI4\nh+oSZSlMhG8wQFPnAKuXFJCVMXUD4tVLChgNRsb80KDXLkQ1zZRW2clit1m5dUs1o8EI+0/qc7EM\n11GyRWsLCcNaeG6G1sLwaIhef2BBu45AKQVFkhjpqBVF2VQU52CxKEthPKcmqWKejNWxVtXxrbQv\n9Tua24vv7k2V2G1WXj3WSjSqcbbJi4W5CX6bzdpaN8sq8nj7nIe2ntSLMhdDkBmUUlAkSUfvME6H\nlcK8TJwOG8X5mVeVpdDUOcCXvvcG33n8OAfe7WA0eGVu+8kL01QKE8QVZIsPi0XvRzSX5GU72b6+\njG7fCMfOeWho72dJWS45mY45lcsMLBYL77tRtxaen4G10OpZ+PEEUEpBkQTRqEZn3zAVhTljvWsq\ninLwDwVNH2s4X6hr8jI0Gub0xT5+8rs6vvLD/fzLM6c52dBDOBIlHIly+mIfJQWZSVeyFuVnUpiX\nwblWH5qmEQhFuNjup7bMlZT7yWzujKWn/uIlSTiiLUrXkcHGlcVUleRw+EwXHl9qWXULveeRganf\nPCHEd4HtgAZ8WUp5NG7fEuCXgBN4W0r5+anWKOaGHv8ooXCUiuJLF7vywmxONvTS0TfMisqFNZg8\nFbpjF4pH7r+GVs8QB093cvi5LrgCAAAgAElEQVRMF4fPdOHKdrCqWo8P7NxQkXQ7aIvFwurqAg6d\n6aKzbxjfQIBIVBtrgzHXLCnNZU1NAWdjLq3FFmSOx2qxcO/2Wn787Bl+f7iZT75HTPscLd2D2KwW\nKooWZnsLA9MsBSHEbmCVlHIH8Gn0Oc3xfAf4jpTyeiAihKhJYo1iDujoMeIJOWPbymNf/Kul3YUn\nlrO/flkh779pGd/83Ha+/smt3H5dNQBvn/MAU6eijmdVXB+ksfqEeeS3v/063VqwWizzRlmZxba1\npZQUZLL/ZDu+wcC01kajGm09g1Qs4PYWBmZKfzvwNICUsg5wCyHyAIQQVuBm4JnY/keklM2J1ijm\nDiOgXBl3B1QRc5FcLXEFj2+UvGwHmU7duLZY9L5ED9y5mu88spOvfGgjn3yPYP2yxKmo44lvjieb\nfVjits0HNq8qpqY0lw3LC+eFS8tMbFYr92yvJRzReOlIcgOHDLp9IwRD0QUfZAZz3UflwLG4557Y\nNj9QAgwA3xVCbAH2SSn/eoo1E+J2Z2O3p57PXVKS/oHo6WK+yOaNzdhdv6p0TKb1q/UWAX2DwXkj\np0G65YlEovT6R1m1pGDSc1eUJ+dCG7++uDgXV7aTc639+IeCLK3MY+mS6SmWdDHZe/vBX9yG1cKc\nTEkzmK3v2B/euorfHWji9eNtfPK+9biSGKdZUuLiXLvermTNsqJ59XtIRZbZVP2WcY+rgO8DjcBz\nQoh7p1gzId4ZDMkoKXHh8VzZe2Y+MJ9ku9CmV9jatSgezwAlJS5CI0GyMuw0dfjnjZxgzufW7Rsh\nEtVw5zpndO7JZFtZlcc75/UWzisq8ubk85xP37fxzLZsd22t5rHX6nn8xbO8/6ZlCY81ZHu3Xncf\nFuY45s3nONXnNpnCMNN91I5+l29QCXTEHvcATVLKBillBHgVWD/FGsUcoGkaHT3DlLqzLvOVWix6\nQK2rb/iyitzFiJGNUlKQePxkqsS7i+ZTPOFqZdemSnKzHLzyVkvC6XjxtC6SzCMwVym8BHwQIOYi\napdSDgBIKcPABSHEqtix1wEy0RrF3OAfCjIcCF8WZDYoL8wmEtXo6R+dA8lmD4939pTCfIonXK1k\nOu3csbWaodEwe4+3J7Wm1TNIXraD/AXc3sLANKUgpTwAHBNCHEDPInpECPGgEOL+2CFfAX4a298P\nPDvRGrPkUyRHu9HeYoI0O2PbYq9sNtJRS93mKIWaslxyMu3UlOUm5cNWmM/t11WT6bTx4pHmCWde\nxDM8Gqanf3RRBJnB5JiClPJr4zadiNtXD9yUxBrFHNIx1ghvYksBYmmpK2dVrGkTDEX48bNnqC3L\n5b6dif3E4zHbfWSzWvlvn7gO5wwSJhTpJSfTwa1bqvj9oWZePdbG3TfUTHrsYmiXHc/CTqhVmI4x\nl7l8AkuhPKYoOvtS7xczHQaGgxyp65r2cB9N0/j3F87y9jkPb5xIzh0Qj8c7gtNhNdU1UFGUQ1F+\npmnnV0yf926vJSfTzrMHLuKPZeBNxGLpeWSglIIiIe1xjfDGU1qQhcUyewVs//77s/zzb0/z778/\nS3Qak7JeONzModNdAPT6A0kHD0FXKN2+EUoKsuY0JVMx++RkOvjDm5czEojw9L4Lkx43Ziks8J5H\nBkopKBLS0TtEYV7GWNFWPA67lZKCLDpmoYDNOxAYm328/1QHv3j5XFIjFE/U9/Dr1xtwu/T5wzC9\ngrvBkRCjwQilJrmOFPOb3ZsqqSjKZu+J9rEMo/EY7S0qi690sS5ElFJQTMrwaBjfYHDCzCOD8sJs\nBoZDDI6Y2xhv38l2oprGB3Yvp7okhz1vt/HEnvqEiqG9Z4h/eeY0druVL31gw1hDt/ZptEfuNjme\noJjf2G1WPnLbKjQNHnvt/BXft2hUo9UzSEVR9oJvb2GwON6FwhQ6+iZ3HRmUz0K7i2hUY9+JdjKc\nNm7bUs1XP7qZiqJsXjzSwtP7Lk64ZnAkxA+ePMloMMLD713L0vK8sTu56SgFs9NRFfOfa1cUcc3y\nQs40ejkRm5lh0Nk3RDAUXTRBZkhCKQgh3EKIbwshfh57fp8QosR80RRzjRFknijzyKBiFhrjvXux\nj15/gO3rysjKsJOX4+SrH91MSUEmzx5o5LmDjZcdH4lG+effvku3d4R7d9Ryw7oygDGlMJ1BKh6T\n01EVC4OP3LYKq8XC46/VE45cKta82K534FksQWZIzlL4CdAMGHl8GcB/mCaRYt7QkSDIbGBYCh0m\nZiDtPd4G6P5dA7crg7/42GYK8zJ4cu8FXj56qYHZ46/Vc6bRy6aVxdy/a/nY9twsB3nZDuU+Ukyb\nquIcbtlcSVffMHvebhvb3mgohUUSZIbklEKJlPIHQBBASvlrYGE3DFckRfxc5skw4g1mWQpGgLm2\nzMXS8ssb5hbnZ/EXH9tMfq6TX756ntePt/HS4SZeeauVquIcPnvfurGhQAaVxTn09o8SCCYuSDLw\neEewWKBYpYte9bz/pmVkZdj57f6LYzG0i+36KNWrzVJACOFAH3qDEKIMWBxhdkVC2nuHYnfXk+fn\nu7IdZGfYTYspGAHm3ZsrJ9xf5s7mqx/dTG6Wg5+9IPnRr0+Qk2nnSx/YMGGr58riHDSSj4F0+0Yo\ndGUumiCiInVc2U7ev3Mpw4Ewv43Fsho7/LiyHeQtgvYWBsl80/8/4CiwXgjxDHpV8rdNlUox54TC\nETy+kSmnSBmN8bq9I5f5WtNBfID5hrVlkx5XVZzDVz+6iawMOxrwhT+8hlL3xHJPJ9gcDEXwDQYp\nKVBWgkLntuuqKXNnseedNhra++nqG6a6JHdR1bBM2eZCSvlErBfRDiAA/ImUUnUuXeR09Y2gaSRM\nRzUoL8ymod1PT/9o0vOJk8EIMO/eVDnlgJeaMhd/+/A2nJlO8jImbxdhBM2NorxEeGKN/lSQWWFg\nt1n58G0r+eGTp/jnp08Di8t1BEkoBSHE41LKjwC/mgV5FDMkqkV5/uLLbCvbTFlOacrnaR/reTT1\nRT5+NGc6lcJEAeZEFOdnTdlDfjqWgkpHVUzEppXFrK11U9fkBRafUkjGfXRRCPGwEGKNEGK58c90\nyRQpcaG/id83vsretoMzOk8yQWaD8kL9mHRmICUKMM8EV7aD3KzkMpAupaOqvArFJSwWCx+9fRWG\nx2ixKYVkuqR+ZIJtGqAUwzykb1S/exkIzmwMRTLpqAZm1CrsnyLAnCoWi4XKomzOt/UTCkdwJOhM\neikdVcUUFJezpDSX926v5WyLb9G0tzBIJqYwvT7DijnFO+oDYCA4cZ+WZOnoHcbpsFKYN/UFsdSd\nhdViSVsPpGhU440kAsypUlmcw7nWfjp6h6kpm3yG7ZiloNxHign4wO4V83qMaaokE1OoAP4B2IZu\nIRwCvi6l9JgsmyIF+gIxpRBK3ZUTjWp09g1TWZRzRZ7/RNhtVkoKMtNmKUwnwJwKhkusvXdoSqWQ\nk2knO9ORdhkUivlKMjGFHwNvAx8DHgDqgP9rplCK1DEshcEZWAo9/lFC4SgVxcn70ssLsxkcSU9j\nvOkGmKfLpWDz5Eosqml4fKMqyKy46kjmNixbSvmPcc/fFUL8QTInF0J8F9iObmF8WUp5NG5fI9AC\nGKWlDwCr0LOcTse2nZJSfimZ11LoGEphKDRMJBrBZp3+NK+OHiOekLyvtKIohxMNvXT2DrOyOn/C\nY7p9I/zz0+9S6s7ipg0VrFtaiNV6uSViVoA5nqqYUuhIEGz2DQQIR6IqHVVx1ZGMUsgRQlQYtQlC\niGpgSkezEGI3sEpKuUMIsRb4N/Rah3jukVIOxq1ZBeyVUn4w6XeguAxvzH2koTEYGiY/Y3L3yGQY\nmUfJpKMalI/Nax6aUCmMBML88MmTtHmGaOwc4EhdNwW5Tm68poKdG8rHFJBZAeZ48nOcZGfYE9Yq\nmD2CU6GYrySjFP4eOCaE6AQsQAnw6STW3Q48DSClrIt1W82TUvpTllaRkJHwKCPh0bHng6HBlJTC\npWlryVsKiVpoRzWNn/zuDG2eIW7bUsWN11Tw5qkODp/p4vlDTTx/qInllXns3FDBGyc6TAswG1gs\n+kCUC+1+wpHohC0sulWNguIqJZnso+eEECuA1ehuoHNSytEplgGUA8finnti2+KVwj8LIZYC+4G/\njm1bF2unUQj8nZTy5UQv4nZnY5/BwPOSkulfNGeL6crW0n95FoQ1K5LS++vpH8VmtbB+demkPX/G\nn9eZpfd+6RsMXrHv5y/U8c75Hq5dWcyXProFu83KDRurCIYiHD7dyatHm3lHdnMh1nHyPdtrqal2\nT1vuyWSbiOXVBdS39RPEQsUExw/GGuatXlqU1u/IYvq+zSZKttRIRbZkso9uBj4jpfxU7PnLQoi/\nl1K+Mc3XGp/G8jfAC0AfukXxAeAg8HfAE+h1EHuEECullJNOzfZ6U894mc/pZKnI1tCrB2jdGQV4\nAz5aPR4qbNXTOoemaTR3DlBSkIV3kmK0iWTTNI2cTDtNHf7L9h09283jL5+jpCCTz9y79opzrqnK\nY03VNXgHAhw63cn51n5u3VSZ8t8l2c+tMEfPKDp93kO27coMq6ZY90unRUvbd2Suvm/haJjeUS9l\n2ZOPQVlsv4XZYiHLNpnCSMZ99E3gwbjnnwV+Dtw0xbp2dMvAoBIY65kkpXzUeCyEeB7YEGvL/Xhs\nc0PMZVUFTDxeS3EZRpC5Nq8ar8fHQGj6GUj+oSDDgTCipmBa6ywWC+VF2TR2DIy5ZJo6B/i/vztD\nhtPGlz5wLblZk6d2ul0Z3LO9lnsSvMZIeISOoS6W5y+dlmwTMVW7C49vBLvNQoErY8avNde81rKP\nZxpe4Os3/FfKZ9D6RHF1kExKqkVKWW88kVI2Asm0w3wJ+CCAEGIL0C6lHIg9zxdCvCiEMPrN7kbP\nanpACPHV2DHlQBnQduWpFRNhKIUlLt06SKWArd0IMqdQpVlRmEMkquHxjdA/FOSHT50kFI7yufvW\nUZ2GISQvNu7hO8d+RMtA+4zPNdUUtm7vCMX5WUnVacx3Wgba0NBoG1R9LBVTk4yl0CyE+BbwOroS\nuRs9lTQhUsoDQohjsQ6rUeARIcSDQL+U8jcx6+CQEGIEeAf4NZAL/KcQ4v2AE/jTRK4jxeUYhWu1\nM1AK02lvMR4jA6nVM8TLb7XQ5w9w/67lbF6VnumtnpEeAOp6JUtcM8tOcrsyyHDaJkxLHR4NMTQa\nZkXVxKm1C43eWOsTowWKQpGIZJTCQ8BXgS+gB5rfBP4qmZNLKb82btOJuH3fB74/bv8AcF8y51Zc\niXfUhwUL1bELZipKob5N96VPJ/PIoCKWgfSLlyT+4RDXry3lfTtqp32eyfDH+jmd9Z7nrqW3zuhc\neg+kHJq7Bq7IQPL49DyKxZJ51DvSB0BfzJJUKBIxpfsolmn0fSnlfcDngANAMtlHilnGO+ojz5lL\nriMHu9U+7ZhCc9cAh093UVWcQ22C9g+TYVgK/uEQNWW5PPTetWkdPuIP6Eqhob+RYGTmldNVxZfc\nXfEsprnMo+EAg7GWJ32jfXMsjWIhMKVSEEL8EPiwEKIQPXX0i8A/mS2YYnpEtSjeQD/uTDcWiwWX\nI3darS40TeOXr5xHAz56+6orKo2ToaQgiwyHjbxsB3/2gWvJcKSeKjyRfP0xSyEcDXOhv3HG55ws\n2Nwdy2hbDI3w4l1GylJQJEMygebNUsr/C3wY+I/YwJ2V5oqlmC4DwSEiWoQCZz6/fr2BDEsW/uAg\nmqYltf7tcx5ki4+NK4pYv6wwJRnsNit/9cBmvv7JrUl1V50Oo5EAoWgIp03PTZDe+ilWTE1lrLfT\neKUw5j5aBC0ueuOsg97RvqS/D4qrl6Syj2L/vw94NvZ44efpLTK8Af2OMDTq5PlDTXR7IoSiIQKR\nqeP0oXCUx1+rx2a18JHbV81IjqXleRSbcIdtxBM2FK3FZrFxtu/8jM95aTTn5bUuYy0u8hf+HIWe\nWDzBarESiAQZDo9MsUJxtZOMUjgnhDgNuKSUx4UQn0QvOFPMI7yjeoC4v0932QRH9RwCww+fiJff\naqGnf5Tbr6tO6zjNdGK8j5KsIpbl19Ay0MZwaGatugvzM3E6rBO4j0YoyHXiTKP7a64wLAUjI61X\nxRUUU5CMUvgMegfTu2LPTwOfNE0iRUp4Y77jjs4oeTlOSnL14rPfHT2XcF3/YIDfHWgkN8vBH+xc\naraYKeMP6i0wXBkuhHslGhrnvA0zOqfVYqGiKIeO3mGiUd2tEo5E6RsYXRTxBIDeEf17scq9AlBx\nBcXUJJN9FJFSHpdSBmLPj0kp1TdrnmHUKAwNOLh2RRE71+ipoAfONnO8vmfSdU+9cYHRYIT7b142\nr4fJ+GNB8zynizWFuovrbDriCkU5hCPRMZdRb/8omrY44gmgWwZOm5OamKXQN6IsBUVikrEUFAsA\nw32kBTLZuKKIwmx9FoE9I8hPnj0zlmYZT1PnAPtPdlBVksMukwbapAsjppDndFHrWkKmLQPpTUNc\nYVyweTGlo2qaRu9IH8WZhRRl6g0GlaWgmAqlFBYJ3lEfaFZs0QzWLS3E5dTbSmxam8dwIMw//eZd\nQuHI2PGapvHLVy+loNqs8/urYMQU8p152Kw2VhYsp3u4Z8ZVupVxozlhcc1lHgoPMxoJUJTlpjCm\nFHpVVbNiClK6Eggh/t90C6KYGb0jXqKBTNbUuMnKsI8phaJCCzdfW0FT1wC/ePnSnfUx6eFci49N\nK4tZvzS1FNTZpN+IKcTel+FCkn0zcyFVjatVGJujsAjcR0Ylc1FmITmObJxWh2p1oZiSVG8Pr0ur\nFHNAk7+FOs/M3Q/zgVA0zGB4EC2YybUri4FLF8+B4CAP3LmamtJc3jjRzpunOgiFIzyxJ5aCetvC\nKDnxBwfIsDnJtOvZ0MKtyz3TeoXi/CwcduvYvObFNHHNsAqKsgqxWCwUZhUqpaCYkkl7HwkhWtB7\nHY3HAhSbJtEs8cS539IX6OObO/9mrkWZMb5x8QSAXId+BzwQGsLpsPGFP9rA//jpUR59USKbffT0\nj3LXtiWUzdMU1PH4gwPkOy/NbK7IKcPlzOWs9zyapqXcTsNqtVBRmE1H7xBRTW95kem04UrQ5nuh\nEG8pABRmFtA51MVIeJQs+8Kvwbia6Q/4OdL5Nrurd+K0pfe7mshS2I8+S+HmCf69k1Yp5oBMWwb+\nwCDBJIq75jvdQ70A5NhclLr1i7zdaifbnjXW6qK0IIvPvG8doXCU/ac65n0KajxRLcpgcAiX81I/\nJovFwhr3KgaCg3QMdc3o/JXFOQTDUXr6R/H49HTUdPZsmit6YjUJxVm6UjCUg7IWFj772w7xdMPz\ntA6mf7JAIqXwWeBWoFdK2RT3rxEIpF2SWaYgQ2+L7Av0z7EkM6euXZ8vUFt4+QAVlzN3LGsHYNOq\nYu6NdS394C0rTElBfbr+ed5sO5zWcw4EB9HQyBs3bzpdLqSKWFzhbJOXQCiyKFxHAH2xGgUj86gw\nU69dUUph4dMdayOf70x/e/dESiFPSvlhYKIRXHdNsG1BUZChuyJ8Af8UR85/znd3ArC24vK00lxH\nLkOhYaLapZlIH9i9gm9/4UZ2bUx/CmogEuTl5td5sv5ZRsPpa6Qbn44ajyjUlcJMW14Y7S5OxOo5\nFkOQGfQahRxHNpkxV1GRykBaNHiGe7FbbLgz068UEs1TeEYIsRP4mRDiNi6fsRyZZM2CIT9mKfQv\ncKWgaRqd/l5ww7rqyy/0LmcuGhpDoeGxwDOQ9mZ1BobVFYgEOdp1nJurtqflvIZSyB+nFAoz3ZRm\nFXPe10AkGsFmTa0thVGrcLpRd7cshnTUqBald9RLZc6libhGWqphQSgWLp6RHoqyirBa0p9KnuiM\nF4Ah9FGZYSAU+2c8XtBcshQWtvuozTNEwKKnUxZnuS/blxeXgTQbGAFvgH1tB9PWkdOoURhvKQCI\nwlUEIkGaBqYcBjgppe4sbFYLwZBuUS0G95E/OEA4GqYo61K6caGKKcwbItEIj555nGNdJ6Y+eBxD\noWGGwyOUZBWZIFkCSyHmOkII8a9Sys+mcnIhxHeB7ehZTF+WUh6N29eIPtbTsDoekFK2JVqTTvJj\nSmGhWwonGnqwOEdxWjLG3AQGubOtFGIK1m610zbYQaO/hWX5NTM+rzFHYXxMAWCNeyX72g5ytu88\ny/OXpnR+m9VKeVE2bR5duS4G91HvuHgCgMupD19S7qO557jnXQ53HqNv1Mt1ZRuntdYYS1uSbY5S\nSKb3UaoKYTewSkq5A/g08IMJDrtHSnlL7F9bkmvSwmIJNB+v78GSMULROCsBwOUwlMLUnVLTgTf2\nWe6q2gHoGRLp4FJMIe+KfavcK7Bg4ewMi9iMuILNaqEob+F3hje6oRoZR6C3zy7MKFCWwjzgjbYD\nAHQOd097bfewrhRKs8ypDDCzt8HtwNMAUso6wC2EuPJXPfM1KeFy5mK1WBd0oHlgOMiFzl4stsjE\nSsGwFEJXDqc3A0PB3lB+HcVZRRzrPjHj9tYweaAZIMeRzRJXFY3+ZkbDqSfFGZXNRXmZ877lRzKM\n1ShkXV6tXpjpZjA0tChSsRcqbYMd1PsuAroVPxya3owLz4iegl5iklJIFGieKeXAsbjnnti2+Kvw\nPwshlqLXRPx1kmsuw+3Oxm5PLcDozsxnIDxAScn05xHPBlPJdeqtFnDqWT6VBSVXHL+EEgAi9mDa\n3+NE5xs+q7upVlVXc3dwFz8/8RtOD57mvatvm9FrjUSHsFgsLK8sxzrBBXtL9Xqa61rpoZMlFKf0\nXtcsL4b9F6kszTX1+zBb37XBi7oiXV1ZTUnepdesdJfqBX/ZQUryLnc/zNffASwu2Z5u0meVVbhK\n6RjoJpgxRG1R6RSrLjHQoN98ieoaSnITv3Yqn5uZSmE846uB/gZ4AX1gz9PAB5JYcwVeb+p3ooVZ\n+TR4m+nq7jclij8TSkpceDyJ3T7732nF4tTvMrK0nCuOjwzryrLL1zfludIhW7e/F6fVwbAvwjWu\nDdgtz/CC3MvWgq0zKgbrHfKR68iht3dii2dJhh63OHzxJJsrrknpvRZk27FaLJS7s9L6WcWTzN80\nXbR5YwV9w048cYOWctCtx/r2NjIClzLSZlO26bKYZBsJj7C38TDujAJurriRJwaeRrY1URBN/q6/\n1duJ1WJFG3LgGZn8taeSbTKFYeaVsB39Lt+gEugwnkgpH5VSdkspw8DzwIap1qQbd3aBXi07S+6V\ndBKORHn3Yi+uAj1O7868spxkLKYQmp1AszfQT0FmPhaLBZczl02lG+gc7h4zlVNlfIuL8SzPX4rd\nap9REVtpQRZ/+/C2BVPlPRW9o17ynXk4xrVAGEtLVRPY5oRDHccIRoLsqtpBRU4ZMP24gmekl+LM\nwpRTsKfCTKXwEvBBACHEFqBdSjkQe54vhHhRCOGMHbsbeDfRGjMozNIvpAsx2Hy+tZ+RQIQS3UM0\noVLIsmdis9hmJfsoFAkxGBqiIOOSHDcbAef21APOo+EAgUhwwniCgdPmYHn+UtoGO+gfTT1GVF2S\nS6ZzNo1nc4hEI3hHfVfEEyBeKai5CrONpmnsazuI3WJjR+U2yrL1H2/3sCfpcwyHRhgMDVFsUuYR\nmKgUpJQHgGNCiAPoWUSPCCEeFELcL6XsR7cODgkh3kSPHfx6ojVmyQeXlMJCTEs1qm+zXXrJiDvj\nSqVg3LHPhlIwWlu7My5VWK7IX0p5dinvdJ9KWYZEQeZ41sRaXpzuTjx+9GrAG/ChoV2WeWQwVtWs\nJrDNOtJbT9ewhy1lG3E5c8lzusi0ZdI5DaXQY3KQGUyOKUgpvzZu04m4fd8Hvp/EGtO4ZCksQKXQ\n0EuGw0bENowFy1gx3nhcjhy6RiYfx5kujM+wIE4pWCwWbqrazq/PP8Ohjre4s/aWaZ/Xn6BGIZ41\nhat45sILnOw6y6qlYtqvs5joGTEa4V2ZkZafkYfVYlWWwhywt1VPQ91VdSOg/z7KsktoG2xPuiJ/\nrEbBpMI1uMonrxVmGa0uFpb7qLNvmK6+YdYtddMf7Cc/I2/SL1SuM5dgJEjA5BREX+wiE68UAG4o\n34LD6mB/++HLejAlS7KWwhJXFVn2LE51nZ32ayw2JqpRMLBarLgzClRMYZbpG/VyqucMNa4qluYt\nGdtellNCWIskXVDYPaxbCqXZ5lkKV7lSWJiWwsmY62jDikK8gf4JXUcGxsV00GQXklG4Nr5BV7Yj\nm+vKNtIz0ptSIDhZpWC1WKl1VeMZ6jVdAc53xrqjThBTAL1ban9wgFA0PJtizQmj4dGUbkbSzb62\nQ2ho7KreeVkm3nTjCspSMJmFGGgeDYY5dk7/Ai2rySCqRRN2Ssx16kVZfpOVgvEZjrcUgLHGeKlU\nOCfqezQeozW09yp3jfQksBTity/2z2k4NMzXD/wvHpNPzakcoWiYA+1HyLFnc13p5S0tyrL1+oRk\nM5A8I716ZXrmla7BdLHwUy1mQKYjk0xb5rwONA+OhDjf4kO2+Djf6qOpc5CoprGswkXUptdoTJR5\nZGCkpQ6anJaaSCnUupZQnVvJyZ4z+AL9Ex4zGWMdUqeIKQAUGEoh4KM8J/lioMVG74hXdxNNcrMQ\nP1fBTDfEXHOhv4mR8CgH2o9yR80tc/Ze3+k+yWBoiDtqdl8xJS0VS6EwowC71bxL91WtFEDvljqf\nLIVINMrJhl7O773AyfOesYHyoPflWVbpYnV1ATddW0H7qO6OKcyY/K7BNUtN8byBfuwW29gY0HiM\ngPNj8ikOth/lnmV3JH3eZN1HAIUZylIAPaZQmFEwaUFmYdbV0S210d8MgIbGS017+OO1H5oTOfa2\nHsCCZSxFO56SrCIsWOgcmlopjIZHGQgOUl242gwxx1BKISOfzuFugpFQ2medToc+/yj7Tnbwxol2\nvAN6D58Mh431S92sWgfmhbYAACAASURBVFLA6uoCllXmkeG4FFA+3axf/BK5j2ZLKfhGdQtgssrl\nbWWb+E3973iz/QjvWXpb0hXk/uAATquDDNvUTercyn1EMBLCHxxgdSxFdyKKYp/TYu+W2ujX26kX\nZbo53HmMe5beMWGPMDNp9rfS6G/mmqI1Y2NR43HYHBRlupOyFDyxrDIz4wmglMJYC21foH/Wzcto\nVOPdi33sPd7G8foeNA0ynTZu3VLFvTctJz/TlrA5m3HxS+g+cppf1RyJRvAHB1hRsHTSYzLtmWwr\n38L+tkOc7j3LhuJ1SZ3bH/CT53Ql1SbDqJHoC1y9SsHIKipO4HO+GuYqRLUojf5mSrKKuGfpHTxa\n9zivNL/OR8T9syrH3lg31F3VOyc9piynlNO9ZxkODZPtyJ70uNkIMsNVHmiGSz7w2YwrjAbDPHew\nka/9y0G+96sTvHO+h5oyFw/es4b/88WdfOIugagtnLJb55hSSJB9dKl9tnlKwR8cQEObMlZwY8U2\nAE56ziR13qgWZSA0RN4kNRjjMZRj/LCfq42eSbqjxuPOyMeCZWzmwlwSiUboHJp+++ip6B7uYSQ8\nytK8WraWbaI4s5ADHUdn1VU8GBriWNdxSrKKWFu4atLjjLhC1xTWQk8sHbXE5JtXpRTGhu3M3pfl\nidfqeXLvBfzDQXZtrOAbn9rKf39wG7s2Vk6rzYI34MNhtU/oxzeYjUE7Y+moCZQTQFVuBVaLlY6h\nrqTOa8yXTiaeAOC0OXE5c/BexZaC4RKaLPMIwGa1UZCRPy8shZeaXufvD3+bc96GtJ73YiyesDR/\nCTarjbuW3ko4GubV5jfS+jqJONh+lFA0zM1VOxK6Sw2lMFVlc/eYpWCuUlDuI8N9FJwdS0HTNN45\n30NetoP/9bkdZGem/ifoG/XhzixI6FpxWO1k2TNNVQqJMo/isVvtlGaX0DHUhaZpU7qEphNkNijO\nLqTV35nU+Rcjk81RGE9hZgEX+ptmNNs6HRzrPg7A3tY3We1ekbbzGkHmZXl6B90byq/j9xdfZV/b\nIe6qvfWymeXpIBgJ0TLQRqO/Ofavhb5RLw6rgx0VWxOuTTYDyTPSgwXLlH/bmXLVK4XZnsDW5hmi\nfyjIjvVlM1IIwVgDuqrciimPdTlyTY0pjFUzJwh4G1TklNE51IUv0J8wFgKXXHrTUQpF2W4u+loY\nCg8ntKAWK4mqmeMpzCykob8RX6Df9IvMZHQPe8asxlTSlRPR2N+Mw2of+33YrXburL2FJ849zWst\n+3j/inumdT5N0xgOjzAQHMAfHMAfHMQfHGCguZ+zXQ20DnZcViSX68jhmqK13Fy1PWGcAPSYAkDX\nFG40z3Av7swCHCamo4JSCnGB5tmxFN69qP9o1y+b2Q/RF5g6yGzgcubi6e8lqkVNmRtxyX2UnFJ4\nB+gY6ppS9unUKBgUZ18qzLoqlcJIHw6rg7wp7oSL4moV5kopnOzRY0vL85dyob+RA+1HeO+yO2d8\n3kAkSPtQJ0vzllyWz7+jYhsvNL7K3tY3uaNmNzlTXKxP9ZzhxcbX8Ab6GQgOEtEiEx5nt9iodVWz\nNK+GpXlLWJpfQ1FmYdKWqsuRS5Y9K2FMIRAJ0h/0IxJklaWLq14p5DldWC3WWYspnG6MKYWlM/sh\nGg3NCqfw44OuFDQ0hkMjYxXO6SRZ9xEw1kO+Y6iLdUWJG9el4j4qytazbryjPpa4qpJet1joGfVS\nlOme8oJkVMT2jnqZPARqLic8p7Fg4VPrPso3j3xXT1euvW3G7qxmfytRLcrSmOvIwGlzcHvNLn5T\n/xyvt+zn3uV3Tbhe0zT2tOzjqfrnsFgsFGTks8RVNdbZNC/2v8vpYnl5Jdnh/BndvRuN8VoG2iZ1\n513qjmpu5hEopYDVYiXP6ZoVSyEYinCuxceS0lzyc2c2HD6ZdFQDI9jsDw6YphSsFmtSftrKOKUw\nFSnFFHJi8wKuwmDzcGiEkfAIy/Nrpzy2MMuYqzA3wWZ/cICL/U2sKFhKcVYh15dv4Y22g7zbW8fG\nkmtmdG4jnjBeKYA+4+Olpj3saX2T22p2kWXPvGx/JBrhV+efYV/bQfKdLj5/7UPU5FVP+lolRemZ\nCleWXUKjv5ne0T5KYzGGeMbmMs9C2vxVn30EugupP+A3vXHW+dZ+QuHojF1HwFiGTVLuI5NbXXhH\n+8l35iXlmirJKsZmsSWnFALJtc2Ox3CFXI1pqcnGE+ByS2EuONXz/7d35tFtXfed/zysBAgQ4L5K\nFKnlal8t2fIm2U5qu3HiOnZqp2ljJ87uZNImndNMlzl1p2fak0zitJ5O2yyt0ywndprGS9p4txzZ\nlmPtu64kbqJIkeK+AgSxzB8PDwQpEgRAgITE+zlH54jAw8OPF8T7vftbvr9TRIiwqWQdMDGQaW8a\n+lhTiSWZPVc6BbvZxu1LbsUX9PHrqJS1gS/o55+OPcXetn1Uuyr579d9KaFDyCSzlaV2jc5PjwIo\npwDoYY9QJMTIePrznpPhRJPu7TPiFJLoUTDIZldzOBJmIDCYsKs6HrPJTLmzlI5oBVIiBgNDaGgx\np5YMJUb4aBHuFCYqj2bv2jXCjgs1V+FY10kANpbqTqHKVcFyzzJO956lK1qPny7Ng60U2Nwzfjd2\n1ezEYXHweuvemKJun7+fbx38f5zqlawtFnxl6+eTuuHKFLFk80xOYR6G6xgop8BEr0K2Q0gnm3qx\nWkysqpl7hUVvCuGjCaeQ+VnUQ4FhwpFwSlUjlfnl+ENjs164BwND5FudKcWYCx16Y9ZiHCJj3PWX\nJLFTsJqtFNjc9C7ABDZ/0M+ZvvNUuyopibvzvdlQ053D+NY+fz/9YwPUFSydMa/isDjYXXMTw+Mj\nvNX2LhcGL/KNA0/SPtLBrdU38rkNj5A3JayUbWI7hRkqkIydQsnVvlMQQjwhhNgnhHhHCLF9hmP+\nRgixJ/r/3UKILiHEnui/J7Npn4HXlv1hO/3DY1zsGkEs8WK1zL0uvG9sgHyrE7vZNuuxsa7mJMJH\njQPN/Ozsc4TC01daTCWVJLNBZZJ5hcHAUEr5BNB3Ih57waLUP4qFj5KsJirOK6RvbGDe5w2c6j1L\nMBxkYzR0ZLClbCMuaz77Lu1nPDSe1rmbEuQT4tm95CbsZhsvNb/OE4f+kcHAMA+s/BC/u+reBenb\nKHEUY9JMCXcKXrtnXvTZsuYUhBC7gJVSyp3Ao+gzl6cesxa4dcrDb0opd0f/fSlb9sUTr3+ULU5m\nqBQV9OqIPn9fUqEjiN8pzJ4Qe7H5dfZcfDv25ZqNVMpRDZJxCoHQOL6gP/bZpII+RCb7OaJcIxY+\nSmKnAHpeIRQJzbt0/EToaLL+ldVkYWfldkbGRzncdTytc8eSzNPkE+JxWfO5tfpGRoJ6yPgzGz7O\nbUtuXrCGR6vJQnFe4bROIRAap2+sf17yCZDdncIdwLMAUsrTQKEQYuo3/JvAn2XRhqSYj16FWClq\nBpzCaNBHIDyedMwz2fBROBKmob8ZgItD7Umd20joelOIv1YYTmF4ZqeQTuWRQaHdq+c6cnhORjbo\n9vfhsOThtDqSOt5INs9nqC0UDnGi5zSFdi9LXFeWDN9cfT0aGnvb9qV1/uaBC2hoLHXPniC+c9lt\nvH/pbr6y7Qux3MZCUu4sY3h8hOHxyd9TYwc4H/kEyG5JagVwMO7nruhjgwBCiEeAN4HmKa9bK4R4\nHigCHpdSvpLoTQoLnVjmEI4pLXUTsFfBERjTRiktTf0iNBvhcIQzLf0UFdjZvKYi6buRmWwZ6dO/\nxNXesqTsLY7kY9ZM+CO+hMc39l7AH/ID0B3sSnis8dxYuw+AuvJKSkuSW7uiYieW/Ra6AjO/R1+3\nfsdU7i1O+TOpLirj4GWIOAJJ2zRfZOPvCyZ2j5Xu5P4mAGoHKuACBG2+rNoWz7GO0/iCfnbV3UBZ\n2ZW7wFLcbGpaw5GOU4xaB6j11iRtWzAconW4jaWeKpZUJnMBdfPpygdT/RWuIFPrtqykmhM9pwnY\nRigtqYg93hJo1J8vrUr5vdKxbT77FGJXQiFEEfAJ4H1A/O3COeBx4BmgHnhDCLFCSjnj0N2+vvQr\nhkpL9RrjcFB3Kh0DPRmpOZ7Khc4h+ofHuGl9Bd3dyVUAGbZNR0NXGwB5EWfS9rqsLnpHBxIev7/1\nROz/57uaZzw23rb2vmhizGdNae3KHCW0Dlyi8/LAtKWsLV36LsIasqd03tJSN/aQ3qna1NFOUSR3\nJrAl+kznymBgiLFQAI/Vm/R7WMf1HUXT5UvcXEvWbItnb8MBAFblr5rx/XaUbudIxymeP/E6D4n7\nkl63C0MXCYTGqcmvmZffBTL7mRZoegj2TFvLpL/b8x0XAXCGU3uv2WybyWFkM3zUjr4zMKgCLkX/\nfztQCuwFfgFsFUI8IaVsk1I+LaWMSCkbgA4mO42skGfJI89sz1pOIZP5BIiL46cQsnHbXAzPUpJ6\nvr8JAI+tgEsjnQSTGOzePzaAhpZymKcyv5xAKDBjQngwDd0jg9iwnRyaqJdtJvIJyQ+RKZ7nCWyR\nSISjXSdxWhys8NbNeNz64tV47R7e6ziIP+hP+vzNA/pQndmSzLmKMa95qjBe1zx2M0N2ncLLwAMA\nQoitQLuUcghASvnvUsq1UsobgPuAQ1LKPxJCfEwI8cfR11QA5UBbFm2M4bF7shaDNvSO1s5R2sIg\nlR4FA7fNhT80RmCGqo5IJML5/kYK7V7Wl6wmGAnNqu8Oek6hwOZOuWKjMl+/X5gp2TynnEK0ZyLT\nsfLZ+ioWkmTVUeOZyCnMj1NoHWqjf2yA9SVrEv69mE1mbq66nrFQgP2dh5M+f6KmtauBCQntyWWp\nsca1eRoCljWnIKV8BzgohHgHvfLoMSHEI0IkHH30PLBLCLEXeA74fKLQUSbx2gsYCY7OeNFMl7FA\niHMX+1la7qIgf/by0WQwvsRFKewUXLMM2+kYvczI+CgrvPXUuKoA/UuciEgkoitbJtm4Fk+lK3EF\n0lwTzTCh3poJzvU18OU9f8rp3rMZO2cm6U6hR8HAbrbhsubPm1M42q1XHW0qmT2pe2PVDkyaib1t\n7ybtjJsHL5BnzotdXK82XNZ8nBbHNDuFbjw2d1Ll55kgqzkFKeXXpjx0dJpjmoHd0f8PAR/Mpk0z\nYdTZDwYGM9ogIlv7CYYirK/L3Dn7olpDqVww3VHNo+Hx4Wk7Xs/16cmslYV1sZLRi8OJK5CGx0cI\nRkIplaMazFaWmo5CqoHLmo/VZMmo/tGbbfsIRULsa9/PmiwPTk+HdHYKoN9YXEqiuzwTHOs6idVk\nYc0sQoigVwRuKlnH4a7jnOtpopDEF/rR8VE6R7tYXbgyK0rA84EujFdGy1BrTBhvPByk199PvWfZ\nvNlxda5eFshWWWqm8wmgh488toKUQjazSV2c79edwgpvPVX5lWhos5alptO4ZlDqKMZisnBppGPa\n5wfGhrCaLOSZU+8s1TSNQrs3Yw1svqCPE1GZ55M9ZxhPItcy30zoHqU2mL4or4jxcJCBsewmZi+P\ndtM+0sHqopVJ3/EaHc4vn599WlrzoJFPWJK+kTlAubOUcCQcU0Xt9fUSIUKpc37yCaCcQoxsDds5\n2dyLzWpiRXVmhof4gr6kBtRMxR3dVUznFPR8QhNum4syRwl5FjulzmIuDl9KeAc5F6dg0kxRDaTL\n0zaZGd3M6TYTFeZ5GR4fyUg48MjlE4yHgzgsDvyhsYyPjswEPb5e3DYXthRDDEYIsmtkbnpDs3Es\nGjraWJK8AqooXEGZs4R3Wg/SMUv3e1OSTWu5Tnn+5NGc86l5ZKCcQpRsdDX3Dvpp7x5h9dJCrJbM\nLPWBzqNEiLCueHVKr3NHB85MJ3XR7etlIDDICm997CJc46rCF/QljDf3+VPvZo6nMr+cQHj8ivcI\nR8IMBYbTyicYxPIKGQghGcnOj6z8EADHuk4kOnzeCUfC9I71p5RPMDC6n7tGsquBdCw6O2FDyZqk\nX6NpGvfW300wHOSpUz9NWA2XSC77amJqBdJ8Vx6BcgoxDFG8TFYgZWqgTjz72vejoXFD5baUXpco\nfHQuFjqaKBM0uk1bE+QVYjuFNNUkZ6pAGg36CEVCFKQhcWEQK0udo4R2/9gAZ/saqPfUsr1iCy5r\nPse6T+WUhEafX9cvSmeC2nzsFIYCwzQOtFDvqU15NvLmsg3srttJ61Abv2x8edpjIpEILQOtlOQV\nZXz28nwztQKpy2dUHimnMO9kI3yU6XxC2/AlWoZaWVcsUg7ZJHIKRj5hpbc+9li1W69ASpRXmEv4\nCOKSzVPkLmJzFOayUzDKUue4UzjQeYQIEbaXb8WkmdhQspbBwFAshp0L9KYwR2EqRlnqXOWqE2HM\nTkhXSuITW36XEkcxr154c9rQXZevm5Hg6FUfOgJ9R2DSTBM7hVEVPlow3FYXGlrGEs3hSIRTzX0U\nuu1UFieeBZss+9r3A7CzakfKr3UnKEk939+E0+KIXaQBlhhOIcFOwWgOS0e0DiacQvuUncJEOWr6\nd31Fdv1iN9ey1P0dhzFpJraWbQRgU/TCZoi65QIneyTApM8vWQyn0J3F8NFRQwAviVLU6XBY83hk\n7UfRNI0fnPopo1PmnjQNXBuhI9B7NEocRXSOGOGj7ugM5/mT8lZOIYrZZKbA5s6YfHZLxxDDvnHW\n1SU/wDsR4+Eg73Ucwm11saE4+bisgdVsJc+cd0VOoc/fT4+/l+XeukmlfPosWvcsO4V+3FZX2vNp\nSxxFWE0WOqZUIMXKUW1zCR/NvYHt0kgnF4fbWVcsYmNMReFKbCYrR7tO5EQzmy/oY2/bu7htLjan\nMcbSaXXgsORlLXzkD45xpu8cVfkVlM2h+arOs5S7l91B/9gAP5W/mLT2xq7tam1am0q5s4yR4CgD\nY4P0+PvmNXQEyilMwhvtas7El90IHa3PUOjoWNdJRoKj7Kjcmrbeu9uWf4XUhSFtMZ3sQI2rir6x\n/itUGyHauOZPr3HNwKSZqHCW0TE6uQLJyOukMoZzKl67IXWRvlPY36EnmLeXb4k9ZjNbWVssuOzr\npnN0+oEo88lbbb/BH/JzW83NWNPU2i/KK6RrtDcrTu5kz5no7IS1sx88C3fW3k69p5aDl4/yXseh\n2OPNgy1YNDPV0abLqx0jr3Cq9yzhSHheQ0egnMIkvPYCghkay3myqRcNWFObWt34TOy7pIeObqxM\nPXRk4La5GBofmXQBPjdNPsGgJkFewReV7043n2BQkV/BeDhId9wEsLl0MxvkWew4LY609Y/CkTD7\nOw+TZ7azYcoFzRgsfzSDIaRwJJxy8no8HOSN1r3kme2xGcfpUOYowR8cy0pn8/5O/eK9rXzznM9l\nNpl5eO1D5JntPHP2Wbp9vQRC41wcvsQSd3XaO9Zcw6hAOtl9GpjfyiNQTmESngwlm31jQc63DVBb\n4cbtnHtreo+vjzO956j31FKRn77qp9vqIhwJMxr0xR4739+E3WyLSVvEYzw2XV4hneE601E1TWdz\nJpwC6BVIff6+tO6AGwda6PX3sal0/RW1/+uLV2PSTBlzCi2DrfzPd/6WJw9/NyXHsL/jEAOBIW6q\nvj7pGQrTUeepBfTfOZMMBYY52SOpcVVR5aqY/QVJUOIo5iOr7sUfGuMHp35Ky+AFwpHwNZFPMDB2\nCoakinIKC4g3Q70KsrWfUDjC+vrMhI7e7ThAhAg757BLAHBFE7dGCGkoMEzn6GXqPcumDUnFks1D\nl654bq6VRwbTaSANRu2ba3lhod3LWCiALwWlTYP90fDEjoqtVzzntDpZ6a2nZah1zl3Thy8f54lD\n/0TfWD9n+xv4dZLDZcKRMK9eeBOzZub2JbfMyQbDKTQNZtYpHLx8lHAkPO0azoXrK7axtWwjjQPN\n/ET+HLj6m9biMRrY/KExYP6E8AyUU4jDuMDNtVfheIOetMtEf0I4EubdSwewm22xCph0KZhSljqR\nT7gydAT6XZnNbOPi8JXCeLGJa3N1CrGdwkSyeXBskHyrE8scwwETEtqpXbiD4SCHLh/DY3OzqnD5\ntMcY5ZXHo/IXqRKJRHip+XW+d+KHaJrG76/+CE6Lg+cbfpWUoznefYrO0S62V2yZ82ewxF2NxWTJ\n+E5hf8dhNDSuy0DoKB5N0/io+DBeu4fLUQXRa2mn4LLmk2+dqFhUO4UFJBNdzZFIhGMNPTjtFlbU\nTP6y+oJ+Tvac4bmGX/G0fJax0OwCsLLvPL3+PraVbSLPYk/bLpjYKQxFE8fnp2lai8ekmahxVdI5\n2nWFXMTETIe5XZCK8gqxmaxXhI/mGjoCKDKSzSnezZ/skYwGfWwr3zyjuJqh9JlOCGk8HOSHp5/h\n+cYXKbR7+erWL7Czajv3rbiHsVCAp88+mzDkFYlEeKVlDwDvX7or5fefitVkYXnhUtqGLyX1N5kM\nnaNdNA9eYHXRyrRLlhPhtDp5eO2DaGi4ra6UNZ9yHSOvkG9x4rRmpqQ9Wa6NzEyG8GZAFK+9e4Se\nQT871pThC/lo6GnmfH8j5/sbaR1qJ8LEl73H38tnNzycsJpoLr0JUzF6FYyY/bn+RiwmC7UJRMRq\nXNU0DrRwaaRj0nGZCh+ZNBMV+WW0j3QSjoQJRXMeS9xzn63kTbMs1ZC12F6xZcZjCvO8LHVXc7a/\ngdFxX9Ix/eHACN85/gMaBpqpdS/hsxsfjl00d1Zex3sdBznefYqjXSfYXLZh2nM0DDTTNHiBDSVr\nY/Ou58rKknpkTyMtg60z7o5SIVH4LVOsKlzBJ9d/DLvZnpGy71yi3FlK40DzvIeOQO0UJhFLNAfS\n3ykca+hBcwxxsfBX/Mnex/nO8R/weute2oc7qPfUcmft7Ty26VHWFK3iZM8Zfnzm32e8KxweH+Fo\n1wkqnGXUZWB77I7LKYyOj9I+3EFdwdKEVRs17krgygqkTDkF0OUuguEgXb4ehmJJ5rnfXRqNWamE\nj3xBH8e7T1HuLJt2sHw8m0rXE46EOdlzJqlzXxy8xDcOPEnDQDNbyjbyh1s/N+kuWtM0Prr6fiwm\nC8+cfRZfXEFAPK+0vAHAb9XuTu6XSgJRoocQMxFCikQivNdxGJvZFqvUyhZbyzayLgkp7qsNI9k8\n36EjUDuFSTgsedjNtjnlFI429GApb6Ev2MUKbx2icAUrvfXUFizFFldHXu9Zxt8f/g6/6TiIx17A\nvcvvvuJc+zsOE4yE2Fm1PSN3QvFSFw0DzUSIzJhPMDAujFMrkPrGBsi3OFNW5ZyO+NkKRsNagX3u\nGjZGZVQq+kdHLp8gGA6yo2LLrGu+sWQdLzS+xNGuEwl3FQBnes/x/ZM/YnTcx13L7uADde+fNjRV\n7izlrto7+GXTSzzX8CIPTZlJ1T7cwYmeM9R7lmVUY39Vsf530DTQPOdzNQw00+PvZUfF1nkbDHOt\nYVRrGWGk+UTtFKbgtXvSzimM+Mc5f7EfW3EXbquLL2/5LL9d935WFi6f5BBAr6P//KZPUOYo4eWW\nN3ij9a1Jz0ciEfZd2o9JM3F9RWridzPhjsspJGpai6cyvxyTZqJ16k5hjo1rU98DdA2kTJWjgv5Z\namj0jSVff/9eNHR0XXniizzodpc6ijnZKxlPINF95PJx/vHovxAIjfPxNQ/ywfo7Ew6CeX/tLiry\ny9nbto+G/uZJz7164U0gs7sEgEKHh+K8IpoGLsy5iW0+QkfXOmuKVvHxNQ+ye8mN8/7eWXUKQogn\nhBD7hBDvCCG2z3DM3wgh9qTymmzisXsYGR9Na5DKyaZecPUQNo+xqXTdrBOg3DYXj23+FAU2Nz8/\n9wIHO4/Enmvsu0Db8CU2lqzNmPKj0+LApJkYCgxzrr8Rk2aKlSPOhNVspcJZRtvIpVgN/ei4D3/I\nn5HQEUyuQMqExIWBIV2S7E6hf2yAc30N1HuWUZKE4qimaWwsXUcgFED2nZ/2mHcvHeB7J36EyWTm\nT299jOuTULe1mCx8bPX9APxE/jwmGd3r72N/52Eq8stTlk5PhjrPUkaCo1eMg0yF8VjlVgGicEUG\nrVtcmDQT11duw2FJv/8k7ffO1omFELuAlVLKncCj6HOapx6zFrg1lddkm7lIaB9r6MFcpFfRzJQk\nnEqJo4gvbHoUu9nGD049zZnecwC83vg2ADsrM+cXTZoJlzWfHl8PrUNt1Lprktre17irCIQCMW33\nXp8eo8+UUyjM82Iz27g0ktmdgnHu/rGBpJrCJhRRZ98lGGwqmbm7ec/Ft/nh6WdwWPL4b5s/w/ry\n5C/k9Z5l3FK9k46RTl5p0XcHr7fuJRwJ876lu7IyctIIR80lr3Cy+zSjQR/XVcxcuaXIbbL5qd0B\nPAsgpTwNFAohpt7+fRP4sxRfk1XSldAORyIca+zGUnQZp8XBKm/yFRxL3FV8duPDaMB3j/8bDf3N\nvHVhP167h7UZTqK5bS4GAkOEI+FZ8wkGsc7mIb1foXdUdwpz7WY2MGkmKp3lXB7tiqmazkX3KJ7C\nPC+hSGjGMaTxxBRRy5PvB6nzLMVtc3E8bsZCJBLhxebX+NnZ53DbXPzh1s+lJdZ27/K78NjcvNj8\nKk0DLbzd/h5eu4ftGa77N6jPQGezoUmUqZCnYv7JZqK5AjgY93NX9LFBACHEI8CbQHOyr5mOwkIn\nFkt6AnEApaWTLz41/WXQAhF74IrnEiFbehk1dWG3+tlRs5OK8tQGz5SWbsHk+ATffuf7/N2RfyYU\nDnHXmt2Ul2XmwmtQlO+hbVjvUN5Wuy6p33F9eAX/cR56wz2Ulro50ajH6JeUlKe0RomoK66hZaiV\n5mFdBrm+shKXPT+tc8XbVO0t5fBliDgClBbPbOvFgUtcHG5nW9UG6qpSk2TYUbOZ1xrfok/rQpQs\n58fHfsELja9Q6iziL3Z/mQr3RLIwtfVy8+h1D/Gtd77Lk0e+SyAU4MH1H6SyPDs1+ZuWrcR+2E7r\nSGtan+vQ2DAni84/TAAAEKFJREFUes9Q66lmc92qjNqWqb+zbHCt2Taf1UexUg4hRBHwCeB9QKK6\nv1lLbvr60hOva+saxunKo9AxeQnMAT2ccqGrk5WO5IeZv3mgFVOhHjpaXSDo6kp9EPqKvFU8sOpD\n/OzscwBs8mxK6zyJsKPrsmtolGhlSZ3fFdId3NnOZrq6huiJho/M4/aM2Vdo0WP47UOdWDQzowMh\nfFrq5y4tdU+yKS+iO5bGjna84Zlrvl9u0BP9mwo3pPw7rXKt5DXe4o1zv+HlM2/xVvtvKHeW8qXN\nn8bsd9DlH5rWtmSot69gQ8lajnefwmFxsDkLfxOGbb09o9S6ajjb30BL++WU9ZR+fXEfoXCIraWb\nM2pjOus2X1zNts3kMLLpFNrR7/INqgBDROd2oBTYC9iB5UKIJ2Z5TUb58StnaWgf5PFP7qCiaKJj\nMF1RvKMN3VgqOrGb7awuSv8uaXfNTQBY87Ss6KgbsfoaV2XSSax8q5NCu5fWYSN8pO8UMhU+gskD\nYtw2d8aakQwbEw3biUQiHOg8gs1su0IRNRlE4QrsZht7Wt8mQoQaVxVf3PypjBQIaJrGg6t+h46R\nTm6p3kleloet1HtqOdvfQNPghZTr//d3HsqKrIVifslmTuFl4AEAIcRWoF1KOQQgpfx3KeVaKeUN\nwH3AISnlHyV6Taa5bWsN48Ew//bimUkleOkkmvuHx2gdakOz+9hQsmbOEr67a27id9bcOadzzITR\n1ZxsPsFgibuaocAwA2MTO4VMJZphslPIVD4BJvSPEo3lbB5spdvfy6aSdWn1XVjNVtYWryZChHrP\nMr685bMZnRVcmOflL3f+CXcsvXX2g+dITBwvxbxC12gPjQMtiMIVGf27UMw/WXMKUsp3gINCiHfQ\nq4geE0I8IsSUbpxZXpMt+64TpexYW8GZC/3sPTaxGSmwuaNjOZPfKUyqOipNrupooVhaUIOGFhsr\nmSw1rmhn83AbvaN95JnzMnrXWmj3kmfWtZ0yVXkEcaJ4CcpSD8R6E9K/w/1g3W9xT92dfHHzp+Yk\nY73QGGqjqTqF9zpVb8K1QlZzClLKr0156Og0xzQDuxO8JitomsbnPryRo+e7eOb182xaXozHZY/W\ntrtS0j861tCNubATq8ma8y33q4tW8q1df31FM91sxA/c6fH1Z6xxzUDTNCryy2kevIAng07BZc3H\noplnFMULhUMcvHyUfKuTNXMI+5Xnl3F33R1pvz5XcFnzKXeW0TTYQjgSTqqsVJe1OITNZM26rIUi\n+yzqQuLSQgcP7FrO6FiQn7x6Lva4x+5hIJDcWM5gKMypjguYHCOsK16dEdmHbJOqQwBdGA/0csXh\nwEhG8wkGRggpkzsFk2bCm+edUf/oXH8jQ4FhtpRtTHvM6bVGnWcpY6EA7cMdsx8MNA1eoNvXw6bS\n9XNW8lUsPIvaKQDctqWa5VUF7D9zmSPndW12r91DMBxkJDh7ZdPZ1n6CLl0CYss1fJdUlOfFaXHE\nOnezETeOOYUM5hRATzYPBoam7VKPKaKm0LB2rVOf4tAdJWtxbbHonYLJpPHI3asxmzR++JLENxZM\nKdls5BNMmFlXsibb5i4YmqZR46piPKxr/GTDKeyo2MpNVdezZY7DhKZiqKUOTMkTjYfGOXL5BIV2\nb+xCqEits3k8HOTg5aMU2NxK1uIaYdE7BYDqUhe/fUMtfUNj/MevG1MqSz10oQWTc4g1RStxZLlc\ncKEx8gqQ2XJUA7fNxe+tvh+XNb2mtZmYUEudHEI62Svxh/xcl2CYzmKk3FmKw+JIyinsaX2LkfFR\nbqi8ToXfrhHUNyHKPTfWUlHk5PWDFwmM6vn32ZxCZ98o/aZmALakII1wtWLIXQAZTzRnk1hZ6hSn\ncKBDDx1tU3X1kzBpJuoKltLt60koDzIYGOLF5tfItzp5/9Ld82egIqsopxDFajHzyN2riQDvHNYv\nHrNVIB1r6MFc2IGGiY1pND1dbcTvFK6mWvSJWc0TTt4X9HO85zQVzrJYua1igmR0kF5oeAl/aIx7\n6u68qstwFZNRTiGOVUu87NpcRVdUOXhqDHoqB5suYHINUl9QN2nQ9rVKhbMMS7QxLxvho2xRGJvV\nPDFX4WiXPkznuvLZh+ksRmZrYmsdamPfpf1U5VdwUwZGxSpyB+UUpvCR3ctx29xEInDs8mkaZ5hE\n5Q8EaR6VAGyv3DSPFi4cZpOZZQVL8OYVLIjOe7pMt1M4EJ1dsa18cXx2qbKsYAka2rQ7hUgkws/P\nvUCECPev/KDKJVxjKKcwBWeeld+/fR3BiysZGh/imwf+kR8eey426MTgdHMfePU67lS7g69mPrnu\nY/zVHX98Vd1dOyx55JnzYonmwcAQsu88tQVLKFuAwehXA3mWPKpcFVwYar3ib/9I1wnO9TeyoWQt\nq4tWLpCFimyhnMI0bBOl3L/mTmwtNxMO5PFu99t89aWv8+z+Y4z69ZLM/Q2tmFz9VDuWZrTZKtfx\n2AuocJUutBkpUxTXwHbo8jHCkbDqTZiFes8yxsPBSfO5x0Pj/OL8f2LWzHx4xQcW0DpFtlBOYRo0\nTePOHUv5P4/cwyeXfwbP2HKC9n5eHvgJX3n6x3znhZOc6DmJpsEN1apy5WrAm+fBF/TjC/o50HEE\nDY2tGe6HuNaoK9B1kOJDSG+0vkWPv5fdNTdR5rz6bg4Us6OcQgLMJhPbV1Xzv+/+LL+34iFsJhvm\nJac4FPwl4wX6MJgtZdduF/O1RFE02dzQ30TTYAurCpfjsc/rUL+rDqOJzUg2D4wN8WLLa7is+dy1\n7OrXeVJMz3wO2bmquWnpVtaXr+RHp5/hFHqCudpZHUtiKnIb43N65cIeAK5ToaNZKXEU4ba6YjuF\nFxpfZCwU4L4V96gS1GsYtVNIAY/dzRc2fZKHxH24bS5+a1n29e0VmcEoSz3f34RFM7P5GtapyhSa\nplHnqaV/bIBjXSd599IBqvIruLFy+0KbpsgiaqeQIpqmcUv1Tm6p3rnQpihSIH5Ht654tbrTTZJ6\nTy3Huk/yg1NPEyHCAys/pEpQr3HUTkGxKCiKcwrXVajQUbIYTWz+kJ+NJesQRUr07lpH7RQUiwJD\n5NButrG++NpVs800S901mDV9Z3CfKkFdFGTVKQghngBuACLAl6WU++Oe+zTwKBBCn8j2GLAL+Blw\nMnrYcSnll7Jpo2JxYDVZuLP2drx2T1pDhhYrNrOVj4oPYzNbVaPfIiFrTkEIsQtYKaXcKYRYA/wL\nsDP6nBN4CLhFSjkuhHjdeA54U0r5QLbsUixePrT8roU24apkZ5VKLC8msplTuAN4FkBKeRooFEIU\nRH8elVLeEXUITsADJDf7T6FQKBRZI5vhowrgYNzPXdHHYnrUQoivAV8Gvi2lbBRCLAXWCiGeB4qA\nx6WUryR6k8JCJxZL+tUQpaW5K1GhbEsPZVt6KNvS41qzbT4TzVcoqEkp/1YI8XfAfwkh3gLOAY8D\nzwD1wBtCiBVSysBMJ+3rm32O8kyUlrrp6hpK+/XZRNmWHsq29FC2pcfVbNtMDiObTqEdfWdgUAVc\nAhBCFAHrpZS/llL6hBC/Am6SUr4NPB09vkEI0QFUA01ZtFOhUCgUUbKZU3gZeABACLEVaJdSGm7L\nCjwlhHBFf94BSCHEx4QQfxx9TQVQDrRl0UaFQqFQxJG1nYKU8h0hxEEhxDtAGHhMCPEIMCCl/IUQ\n4q/Qw0NB9JLU5wEX8BMhxL2ADfh8otCRQqFQKDJLVnMKUsqvTXnoaNxzTwFPTXl+CPhgNm1SKBQK\nxcwomQuFQqFQxNAikchC26BQKBSKHEHtFBQKhUIRQzkFhUKhUMRQTkGhUCgUMZRTUCgUCkUM5RQU\nCoVCEUM5BYVCoVDEUE5BoVAoFDEW7TjORFPhFhIhxG5ybPqcEGI98BzwhJTy/wohlgA/BMzoIod/\nIKUcyxHbngK2AT3RQ74hpfzPBbLt68At6N+zvwH2kzvrNtW2D5ED6xadr/IUuu5ZHvC/0JUQFnzd\nZrDtAXJg3QyEEA7gRNS210hj3RblTiF+Khz6SNC/X2CTpvKmlHJ39N9CO4R84En0PzCDvwL+QUp5\nC3Ae+GQO2QbwP+LWb6Ecwm3oSsA7gbuAb5M76zadbZAD64Yuc3NASrkL+F3gW+TIus1gG+TGuhn8\nOdAb/X9a67YonQIJpsIprmAM+G10KXSD3egChgAvAO+bZ5sMprMtV/g18JHo//uBfHJn3aazLf1J\nVRlESvm0lPLr0R+XABfJkXWbwbacQQixGlgLGI5pN2ms22INH806FW6BSWn6XDaRUgaBoBAi/uH8\nuG3oZaBy3g1jRtsAviiE+Aq6bV+UUnYvgG0hYCT646PAfwF35si6TWdbiBxYN4OounINcA/wai6s\nm8EU275C7qzbN4EvAg9Hf07re7pYdwpTuWIq3AJiTJ+7F/3D/b4QwrawJiUkl9YO9Bjq16SUtwNH\ngL9cSGOiMvCPon9Z41nwdZtiW06tm5TyRvQ8x4+YvFYLvm5TbMuJdRNCfBzYJ6WcaSBZ0uu2WJ3C\njFPhFhopZVt0mxqRUjYAxvS5XGI4mtAC3bacCd9IKV+TUh6J/vg8sGGhbBFC3An8GXC3lHKAHFq3\nqbblyroJIbZFCxmI2mMBhnJh3Waw7XgurBvwAeBeIcS7wKeAvyDNv7fF6hQSTYVbUK6S6XOvAvdH\n/38/8OIC2jIJIcTPhRD10R93o1diLIQdHuAbwD1SSiPxlxPrNp1tubJuwK3AV6M2laMP3sqJdWN6\n2/45F9ZNSvmglHK7lPIG4Hvo1Udprduilc4WQvwt+occBh6TUh6d5SXzghDCDfwE8KJPn3tcSvlf\nC2jPNvRY5TJgHN1BfQy9NC8PaAE+IaUczxHbngS+BowCw1HbLi+AbZ9BDyWcjXv4YfQv7EKv23S2\n/St6GGmh180BfB89ketAD6UeAP6NhV+36WwbBr7OAq9bPEKIvwSagZdIY90WrVNQKBQKxZUs1vCR\nQqFQKKZBOQWFQqFQxFBOQaFQKBQxlFNQKBQKRQzlFBQKhUIRQzkFhWIBEUI8IoT40ULboVAYKKeg\nUCgUihiqT0GhSAIhxJfQ5ZItwBn0hqVfAr8CNkUPe0hK2SaE+ADwP9EbmkaBz0Qfvx5dpjqALm/8\ncfRO0w+jizGuRW8y+rCUUn0xFQuC2ikoFLMghNgB3AfcGp1B0I8uQ1wP/GtUr34P8NXoIJbvAfdL\nKW9Ddxp/HT3Vj4BPR/X430TXqwFYB3wGfVjLemDrfPxeCsV0LFbpbIUiFXYDK4A3ojLd+egCYz1S\nSkOC/W3gD4FVQKeU0tDa3wN8TghRAnillCcApJTfBj2nAOyXUo5Gf25DlzhRKBYE5RQUitkZA56X\nUsbkr4UQy4BDccdo6KNdp4Z94h+faWcenOY1CsWCoMJHCsXsvA3cLYRwAQghvoA+sKRQCLEleszN\nwDF0kbkyIcTS6OPvA96VUvYA3UKI7dFzfDV6HoUip1BOQaGYBSnlAeAfgD1CiLfQw0kD6Kqsjwgh\nXgduAp6QUvrQB9c8LYTYgz769c+jp/oD4O+EEG+iK/SqUlRFzqGqjxSKNIiGj96SUtYstC0KRSZR\nOwWFQqFQxFA7BYVCoVDEUDsFhUKhUMRQTkGhUCgUMZRTUCgUCkUM5RQUCoVCEUM5BYVCoVDE+P95\neJ2uuaMxugAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fbc53f61908>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEVCAYAAADpbDJPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxkSp/wdGrzq/j4V1zQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fbc53ec7cf8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "677HYTowThsH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Dense models test"
      ]
    },
    {
      "metadata": {
        "id": "2JTtLHcXLl1b",
        "colab_type": "code",
        "outputId": "63b55cd5-7c5d-4a78-9960-6a94f343f491",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "model_sgd.evaluate(X_test, Y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "300/300 [==============================] - 0s 69us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5066557967662811, 0.610647684733073, 0.4099999996026357, 0.4889739203453064]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "UPnyPQVJOEg2",
        "colab_type": "code",
        "outputId": "2425f59c-0bc6-4b12-8bfb-01e0d98b6c85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "model_adam.evaluate(X_test, Y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "300/300 [==============================] - 0s 67us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5289190216859182, 0.6082527176539103, 0.52, 0.5596633656819662]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "RQ3ttaGiVXIg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Dense models are pretty weak against changing sizes and mooving shapes. That's because the network do not recognize patterns.\n",
        "That is why we will use a ConvNet that is able to learn patterns."
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Rir-JDLPBaOp"
      },
      "cell_type": "markdown",
      "source": [
        "### ConvNet compilation"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "w8wZPXceBaOr",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_model_conv(optimizer, loss, metrics):\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(16, (5, 5), padding='same', activation='relu', input_shape=(IMAGE_SIZE, IMAGE_SIZE, 1)))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(Conv2D(32, (3, 3), padding='same', activation='relu'))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  \n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(1024, activation='relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(3, activation='softmax'))\n",
        "  \n",
        "  model.compile(optimizer=optimizer,\n",
        "               loss=loss,\n",
        "               metrics=metrics)\n",
        "  model.summary()\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FrKx2QdDFBEY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### ConvNet training"
      ]
    },
    {
      "metadata": {
        "id": "h9aJT8jDUemi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We reshape data for ConvNet training.\n",
        "New shape must be : (n_data, image_size, image_size, n_channels)"
      ]
    },
    {
      "metadata": {
        "id": "EcG7HFY7UlXE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], IMAGE_SIZE, IMAGE_SIZE, 1)\n",
        "X_valid = X_valid.reshape(X_valid.shape[0], IMAGE_SIZE, IMAGE_SIZE, 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], IMAGE_SIZE, IMAGE_SIZE, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j0sq4oURVF5U",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we can train our ConvNet model."
      ]
    },
    {
      "metadata": {
        "id": "RvokQ-TSFBjY",
        "colab_type": "code",
        "outputId": "00c9892f-6db2-4803-8f68-ab3d164ef532",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 7245
        }
      },
      "cell_type": "code",
      "source": [
        "optimizer = Adam(0.00001)\n",
        "loss = 'binary_crossentropy'\n",
        "metrics = ['accuracy', get_metrics(0.5)['precision'], get_metrics(0.5)['recall'], get_metrics(0.5)['f1_score']]\n",
        "\n",
        "model_conv = get_model_conv(optimizer, loss, metrics)\n",
        "\n",
        "history_conv = model_conv.fit(X_train, Y_train,\n",
        "          epochs=200,\n",
        "          batch_size=32,\n",
        "          validation_data=(X_valid, Y_valid)\n",
        "         )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_9 (Conv2D)            (None, 72, 72, 16)        416       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 36, 36, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 36, 36, 32)        4640      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 18, 18, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 10368)             0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 1024)              10617856  \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 3)                 3075      \n",
            "=================================================================\n",
            "Total params: 10,625,987\n",
            "Trainable params: 10,625,987\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 300 samples, validate on 60 samples\n",
            "Epoch 1/200\n",
            "300/300 [==============================] - 5s 17ms/step - loss: 0.6381 - acc: 0.6667 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00 - val_loss: 0.6359 - val_acc: 0.6667 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00\n",
            "Epoch 2/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.6257 - acc: 0.6667 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00 - val_loss: 0.6307 - val_acc: 0.6667 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00\n",
            "Epoch 3/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.6141 - acc: 0.6667 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00 - val_loss: 0.6258 - val_acc: 0.6667 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00\n",
            "Epoch 4/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.6174 - acc: 0.6667 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00 - val_loss: 0.6193 - val_acc: 0.6667 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00\n",
            "Epoch 5/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.6126 - acc: 0.6667 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00 - val_loss: 0.6146 - val_acc: 0.6667 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00\n",
            "Epoch 6/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.6007 - acc: 0.6678 - precision: 0.1067 - recall: 0.0033 - f1_score: 0.0065 - val_loss: 0.6098 - val_acc: 0.6667 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00\n",
            "Epoch 7/200\n",
            "300/300 [==============================] - 4s 13ms/step - loss: 0.5955 - acc: 0.6678 - precision: 0.0400 - recall: 0.0033 - f1_score: 0.0062 - val_loss: 0.6127 - val_acc: 0.6667 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00\n",
            "Epoch 8/200\n",
            "300/300 [==============================] - 4s 13ms/step - loss: 0.5855 - acc: 0.6700 - precision: 0.3200 - recall: 0.0100 - f1_score: 0.0194 - val_loss: 0.6040 - val_acc: 0.6667 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00\n",
            "Epoch 9/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.5818 - acc: 0.6744 - precision: 0.6400 - recall: 0.0233 - f1_score: 0.0449 - val_loss: 0.5976 - val_acc: 0.6667 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00\n",
            "Epoch 10/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.5789 - acc: 0.6756 - precision: 0.4667 - recall: 0.0267 - f1_score: 0.0503 - val_loss: 0.5951 - val_acc: 0.6667 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00\n",
            "Epoch 11/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.5708 - acc: 0.6822 - precision: 0.8000 - recall: 0.0500 - f1_score: 0.0938 - val_loss: 0.5900 - val_acc: 0.6722 - val_precision: 0.4667 - val_recall: 0.0167 - val_f1_score: 0.0322\n",
            "Epoch 12/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.5650 - acc: 0.6978 - precision: 0.8720 - recall: 0.0967 - f1_score: 0.1676 - val_loss: 0.5883 - val_acc: 0.6722 - val_precision: 0.4667 - val_recall: 0.0167 - val_f1_score: 0.0322\n",
            "Epoch 13/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.5564 - acc: 0.6956 - precision: 0.9644 - recall: 0.0900 - f1_score: 0.1611 - val_loss: 0.5836 - val_acc: 0.6722 - val_precision: 0.4667 - val_recall: 0.0167 - val_f1_score: 0.0322\n",
            "Epoch 14/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.5461 - acc: 0.7022 - precision: 0.9733 - recall: 0.1100 - f1_score: 0.1917 - val_loss: 0.5758 - val_acc: 0.6778 - val_precision: 1.0000 - val_recall: 0.0333 - val_f1_score: 0.0645\n",
            "Epoch 15/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.5448 - acc: 0.7111 - precision: 0.9141 - recall: 0.1500 - f1_score: 0.2529 - val_loss: 0.5727 - val_acc: 0.6889 - val_precision: 0.8667 - val_recall: 0.0833 - val_f1_score: 0.1511\n",
            "Epoch 16/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.5411 - acc: 0.7244 - precision: 0.9704 - recall: 0.1800 - f1_score: 0.2999 - val_loss: 0.5692 - val_acc: 0.6944 - val_precision: 0.8933 - val_recall: 0.1000 - val_f1_score: 0.1775\n",
            "Epoch 17/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.5304 - acc: 0.7256 - precision: 0.9562 - recall: 0.1867 - f1_score: 0.3079 - val_loss: 0.5622 - val_acc: 0.6944 - val_precision: 0.8933 - val_recall: 0.1000 - val_f1_score: 0.1775\n",
            "Epoch 18/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.5231 - acc: 0.7222 - precision: 0.9435 - recall: 0.1800 - f1_score: 0.2967 - val_loss: 0.5566 - val_acc: 0.6944 - val_precision: 0.8933 - val_recall: 0.1000 - val_f1_score: 0.1775\n",
            "Epoch 19/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.5173 - acc: 0.7411 - precision: 0.9337 - recall: 0.2367 - f1_score: 0.3739 - val_loss: 0.5562 - val_acc: 0.6833 - val_precision: 0.6600 - val_recall: 0.1000 - val_f1_score: 0.1736\n",
            "Epoch 20/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.5087 - acc: 0.7478 - precision: 0.9607 - recall: 0.2567 - f1_score: 0.3988 - val_loss: 0.5482 - val_acc: 0.6889 - val_precision: 0.6438 - val_recall: 0.1333 - val_f1_score: 0.2207\n",
            "Epoch 21/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.5004 - acc: 0.7489 - precision: 0.9535 - recall: 0.2567 - f1_score: 0.4006 - val_loss: 0.5465 - val_acc: 0.6889 - val_precision: 0.6438 - val_recall: 0.1333 - val_f1_score: 0.2207\n",
            "Epoch 22/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.4961 - acc: 0.7656 - precision: 0.9245 - recall: 0.3233 - f1_score: 0.4768 - val_loss: 0.5433 - val_acc: 0.6944 - val_precision: 0.6905 - val_recall: 0.1500 - val_f1_score: 0.2465\n",
            "Epoch 23/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.4933 - acc: 0.7722 - precision: 0.9468 - recall: 0.3367 - f1_score: 0.4921 - val_loss: 0.5378 - val_acc: 0.6944 - val_precision: 0.6905 - val_recall: 0.1500 - val_f1_score: 0.2465\n",
            "Epoch 24/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.4844 - acc: 0.7622 - precision: 0.9033 - recall: 0.3200 - f1_score: 0.4693 - val_loss: 0.5326 - val_acc: 0.6944 - val_precision: 0.6905 - val_recall: 0.1500 - val_f1_score: 0.2465\n",
            "Epoch 25/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.4790 - acc: 0.7733 - precision: 0.9054 - recall: 0.3533 - f1_score: 0.5068 - val_loss: 0.5309 - val_acc: 0.7056 - val_precision: 0.7111 - val_recall: 0.2000 - val_f1_score: 0.3114\n",
            "Epoch 26/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.4721 - acc: 0.7833 - precision: 0.8973 - recall: 0.3900 - f1_score: 0.5400 - val_loss: 0.5243 - val_acc: 0.7222 - val_precision: 0.7852 - val_recall: 0.2333 - val_f1_score: 0.3595\n",
            "Epoch 27/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.4643 - acc: 0.7789 - precision: 0.9194 - recall: 0.3700 - f1_score: 0.5216 - val_loss: 0.5212 - val_acc: 0.7167 - val_precision: 0.7378 - val_recall: 0.2333 - val_f1_score: 0.3545\n",
            "Epoch 28/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.4597 - acc: 0.7922 - precision: 0.9001 - recall: 0.4200 - f1_score: 0.5689 - val_loss: 0.5185 - val_acc: 0.7167 - val_precision: 0.7378 - val_recall: 0.2333 - val_f1_score: 0.3545\n",
            "Epoch 29/200\n",
            "300/300 [==============================] - 4s 13ms/step - loss: 0.4550 - acc: 0.7956 - precision: 0.9101 - recall: 0.4300 - f1_score: 0.5828 - val_loss: 0.5125 - val_acc: 0.7111 - val_precision: 0.6990 - val_recall: 0.2333 - val_f1_score: 0.3498\n",
            "Epoch 30/200\n",
            "300/300 [==============================] - 4s 13ms/step - loss: 0.4478 - acc: 0.8033 - precision: 0.9203 - recall: 0.4467 - f1_score: 0.5990 - val_loss: 0.5098 - val_acc: 0.7222 - val_precision: 0.7267 - val_recall: 0.2667 - val_f1_score: 0.3901\n",
            "Epoch 31/200\n",
            "300/300 [==============================] - 4s 13ms/step - loss: 0.4435 - acc: 0.8011 - precision: 0.9083 - recall: 0.4533 - f1_score: 0.5986 - val_loss: 0.5071 - val_acc: 0.7389 - val_precision: 0.7345 - val_recall: 0.3333 - val_f1_score: 0.4549\n",
            "Epoch 32/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.4471 - acc: 0.8011 - precision: 0.8603 - recall: 0.4700 - f1_score: 0.6015 - val_loss: 0.5032 - val_acc: 0.7444 - val_precision: 0.7389 - val_recall: 0.3500 - val_f1_score: 0.4744\n",
            "Epoch 33/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.4412 - acc: 0.8044 - precision: 0.8692 - recall: 0.4867 - f1_score: 0.6221 - val_loss: 0.5054 - val_acc: 0.7333 - val_precision: 0.7119 - val_recall: 0.3333 - val_f1_score: 0.4493\n",
            "Epoch 34/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.4284 - acc: 0.8156 - precision: 0.9276 - recall: 0.4833 - f1_score: 0.6324 - val_loss: 0.5003 - val_acc: 0.7389 - val_precision: 0.7603 - val_recall: 0.3167 - val_f1_score: 0.4470\n",
            "Epoch 35/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.4300 - acc: 0.8133 - precision: 0.8802 - recall: 0.5100 - f1_score: 0.6443 - val_loss: 0.5009 - val_acc: 0.7389 - val_precision: 0.7041 - val_recall: 0.3667 - val_f1_score: 0.4795\n",
            "Epoch 36/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.4163 - acc: 0.8333 - precision: 0.9076 - recall: 0.5600 - f1_score: 0.6911 - val_loss: 0.4913 - val_acc: 0.7556 - val_precision: 0.7363 - val_recall: 0.4000 - val_f1_score: 0.5168\n",
            "Epoch 37/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.4165 - acc: 0.8311 - precision: 0.8904 - recall: 0.5633 - f1_score: 0.6876 - val_loss: 0.4923 - val_acc: 0.7556 - val_precision: 0.7441 - val_recall: 0.4000 - val_f1_score: 0.5186\n",
            "Epoch 38/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.4068 - acc: 0.8244 - precision: 0.8684 - recall: 0.5600 - f1_score: 0.6795 - val_loss: 0.4891 - val_acc: 0.7556 - val_precision: 0.7189 - val_recall: 0.4167 - val_f1_score: 0.5243\n",
            "Epoch 39/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.4100 - acc: 0.8367 - precision: 0.8662 - recall: 0.6100 - f1_score: 0.7134 - val_loss: 0.4865 - val_acc: 0.7556 - val_precision: 0.7158 - val_recall: 0.4333 - val_f1_score: 0.5396\n",
            "Epoch 40/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.4011 - acc: 0.8411 - precision: 0.8630 - recall: 0.6167 - f1_score: 0.7161 - val_loss: 0.4882 - val_acc: 0.7556 - val_precision: 0.7333 - val_recall: 0.4167 - val_f1_score: 0.5299\n",
            "Epoch 41/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.3983 - acc: 0.8311 - precision: 0.8889 - recall: 0.5667 - f1_score: 0.6897 - val_loss: 0.4865 - val_acc: 0.7500 - val_precision: 0.7111 - val_recall: 0.4167 - val_f1_score: 0.5247\n",
            "Epoch 42/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.3944 - acc: 0.8289 - precision: 0.8706 - recall: 0.5700 - f1_score: 0.6877 - val_loss: 0.4817 - val_acc: 0.7667 - val_precision: 0.7364 - val_recall: 0.4500 - val_f1_score: 0.5556\n",
            "Epoch 43/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.3929 - acc: 0.8467 - precision: 0.8790 - recall: 0.6267 - f1_score: 0.7309 - val_loss: 0.4792 - val_acc: 0.7667 - val_precision: 0.7364 - val_recall: 0.4500 - val_f1_score: 0.5556\n",
            "Epoch 44/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.3830 - acc: 0.8500 - precision: 0.8853 - recall: 0.6233 - f1_score: 0.7256 - val_loss: 0.4808 - val_acc: 0.7611 - val_precision: 0.7232 - val_recall: 0.4500 - val_f1_score: 0.5529\n",
            "Epoch 45/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.3849 - acc: 0.8389 - precision: 0.8525 - recall: 0.6267 - f1_score: 0.7208 - val_loss: 0.4766 - val_acc: 0.7611 - val_precision: 0.7164 - val_recall: 0.4500 - val_f1_score: 0.5509\n",
            "Epoch 46/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.3801 - acc: 0.8522 - precision: 0.8754 - recall: 0.6500 - f1_score: 0.7437 - val_loss: 0.4761 - val_acc: 0.7667 - val_precision: 0.7285 - val_recall: 0.4667 - val_f1_score: 0.5661\n",
            "Epoch 47/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.3745 - acc: 0.8489 - precision: 0.8650 - recall: 0.6467 - f1_score: 0.7393 - val_loss: 0.4761 - val_acc: 0.7611 - val_precision: 0.7091 - val_recall: 0.4667 - val_f1_score: 0.5612\n",
            "Epoch 48/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.3783 - acc: 0.8378 - precision: 0.8630 - recall: 0.6100 - f1_score: 0.7140 - val_loss: 0.4746 - val_acc: 0.7667 - val_precision: 0.7285 - val_recall: 0.4667 - val_f1_score: 0.5661\n",
            "Epoch 49/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.3679 - acc: 0.8478 - precision: 0.8724 - recall: 0.6367 - f1_score: 0.7342 - val_loss: 0.4731 - val_acc: 0.7611 - val_precision: 0.7091 - val_recall: 0.4667 - val_f1_score: 0.5612\n",
            "Epoch 50/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.3689 - acc: 0.8444 - precision: 0.8495 - recall: 0.6433 - f1_score: 0.7301 - val_loss: 0.4722 - val_acc: 0.7556 - val_precision: 0.6876 - val_recall: 0.4833 - val_f1_score: 0.5675\n",
            "Epoch 51/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.3656 - acc: 0.8467 - precision: 0.8544 - recall: 0.6500 - f1_score: 0.7361 - val_loss: 0.4735 - val_acc: 0.7667 - val_precision: 0.7285 - val_recall: 0.4667 - val_f1_score: 0.5661\n",
            "Epoch 52/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.3621 - acc: 0.8522 - precision: 0.8702 - recall: 0.6567 - f1_score: 0.7474 - val_loss: 0.4700 - val_acc: 0.7722 - val_precision: 0.7333 - val_recall: 0.4833 - val_f1_score: 0.5790\n",
            "Epoch 53/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.3538 - acc: 0.8600 - precision: 0.8741 - recall: 0.6767 - f1_score: 0.7611 - val_loss: 0.4682 - val_acc: 0.7556 - val_precision: 0.6876 - val_recall: 0.4833 - val_f1_score: 0.5675\n",
            "Epoch 54/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.3558 - acc: 0.8556 - precision: 0.8683 - recall: 0.6700 - f1_score: 0.7553 - val_loss: 0.4668 - val_acc: 0.7556 - val_precision: 0.6876 - val_recall: 0.4833 - val_f1_score: 0.5675\n",
            "Epoch 55/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.3519 - acc: 0.8611 - precision: 0.8618 - recall: 0.6900 - f1_score: 0.7647 - val_loss: 0.4683 - val_acc: 0.7722 - val_precision: 0.7333 - val_recall: 0.4833 - val_f1_score: 0.5790\n",
            "Epoch 56/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.3477 - acc: 0.8544 - precision: 0.8632 - recall: 0.6700 - f1_score: 0.7528 - val_loss: 0.4648 - val_acc: 0.7667 - val_precision: 0.7074 - val_recall: 0.5000 - val_f1_score: 0.5851\n",
            "Epoch 57/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.3465 - acc: 0.8633 - precision: 0.8650 - recall: 0.7000 - f1_score: 0.7725 - val_loss: 0.4635 - val_acc: 0.7556 - val_precision: 0.6755 - val_recall: 0.5000 - val_f1_score: 0.5740\n",
            "Epoch 58/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.3420 - acc: 0.8678 - precision: 0.8774 - recall: 0.7033 - f1_score: 0.7794 - val_loss: 0.4641 - val_acc: 0.7667 - val_precision: 0.7139 - val_recall: 0.4833 - val_f1_score: 0.5740\n",
            "Epoch 59/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.3423 - acc: 0.8667 - precision: 0.8767 - recall: 0.6967 - f1_score: 0.7751 - val_loss: 0.4636 - val_acc: 0.7556 - val_precision: 0.6876 - val_recall: 0.4833 - val_f1_score: 0.5675\n",
            "Epoch 60/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.3376 - acc: 0.8611 - precision: 0.8673 - recall: 0.6900 - f1_score: 0.7667 - val_loss: 0.4639 - val_acc: 0.7778 - val_precision: 0.7224 - val_recall: 0.5167 - val_f1_score: 0.5983\n",
            "Epoch 61/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.3394 - acc: 0.8633 - precision: 0.8704 - recall: 0.6933 - f1_score: 0.7702 - val_loss: 0.4613 - val_acc: 0.7556 - val_precision: 0.6755 - val_recall: 0.5000 - val_f1_score: 0.5740\n",
            "Epoch 62/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.3386 - acc: 0.8622 - precision: 0.8525 - recall: 0.7033 - f1_score: 0.7686 - val_loss: 0.4606 - val_acc: 0.7556 - val_precision: 0.6755 - val_recall: 0.5000 - val_f1_score: 0.5740\n",
            "Epoch 63/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.3379 - acc: 0.8667 - precision: 0.8681 - recall: 0.7100 - f1_score: 0.7795 - val_loss: 0.4605 - val_acc: 0.7611 - val_precision: 0.6924 - val_recall: 0.5000 - val_f1_score: 0.5803\n",
            "Epoch 64/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.3354 - acc: 0.8600 - precision: 0.8488 - recall: 0.7033 - f1_score: 0.7682 - val_loss: 0.4631 - val_acc: 0.7778 - val_precision: 0.7224 - val_recall: 0.5167 - val_f1_score: 0.5983\n",
            "Epoch 65/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.3282 - acc: 0.8678 - precision: 0.8730 - recall: 0.7067 - f1_score: 0.7804 - val_loss: 0.4589 - val_acc: 0.7500 - val_precision: 0.6620 - val_recall: 0.5000 - val_f1_score: 0.5694\n",
            "Epoch 66/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.3201 - acc: 0.8822 - precision: 0.8768 - recall: 0.7533 - f1_score: 0.8095 - val_loss: 0.4586 - val_acc: 0.7556 - val_precision: 0.6720 - val_recall: 0.5167 - val_f1_score: 0.5841\n",
            "Epoch 67/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.3326 - acc: 0.8667 - precision: 0.8678 - recall: 0.7100 - f1_score: 0.7802 - val_loss: 0.4619 - val_acc: 0.7667 - val_precision: 0.6874 - val_recall: 0.5333 - val_f1_score: 0.6001\n",
            "Epoch 68/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.3180 - acc: 0.8789 - precision: 0.8744 - recall: 0.7433 - f1_score: 0.8022 - val_loss: 0.4569 - val_acc: 0.7500 - val_precision: 0.6620 - val_recall: 0.5000 - val_f1_score: 0.5694\n",
            "Epoch 69/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.3109 - acc: 0.8778 - precision: 0.8833 - recall: 0.7300 - f1_score: 0.7977 - val_loss: 0.4565 - val_acc: 0.7556 - val_precision: 0.6720 - val_recall: 0.5167 - val_f1_score: 0.5841\n",
            "Epoch 70/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.3170 - acc: 0.8778 - precision: 0.8652 - recall: 0.7500 - f1_score: 0.8026 - val_loss: 0.4564 - val_acc: 0.7556 - val_precision: 0.6720 - val_recall: 0.5167 - val_f1_score: 0.5841\n",
            "Epoch 71/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.3128 - acc: 0.8767 - precision: 0.8636 - recall: 0.7500 - f1_score: 0.8019 - val_loss: 0.4563 - val_acc: 0.7500 - val_precision: 0.6620 - val_recall: 0.5000 - val_f1_score: 0.5694\n",
            "Epoch 72/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.3159 - acc: 0.8867 - precision: 0.8833 - recall: 0.7600 - f1_score: 0.8165 - val_loss: 0.4560 - val_acc: 0.7500 - val_precision: 0.6620 - val_recall: 0.5000 - val_f1_score: 0.5694\n",
            "Epoch 73/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.3115 - acc: 0.8822 - precision: 0.8759 - recall: 0.7533 - f1_score: 0.8096 - val_loss: 0.4556 - val_acc: 0.7556 - val_precision: 0.6720 - val_recall: 0.5167 - val_f1_score: 0.5841\n",
            "Epoch 74/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.3075 - acc: 0.8744 - precision: 0.8502 - recall: 0.7567 - f1_score: 0.7998 - val_loss: 0.4552 - val_acc: 0.7556 - val_precision: 0.6720 - val_recall: 0.5167 - val_f1_score: 0.5841\n",
            "Epoch 75/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.3039 - acc: 0.8856 - precision: 0.8718 - recall: 0.7700 - f1_score: 0.8172 - val_loss: 0.4552 - val_acc: 0.7500 - val_precision: 0.6564 - val_recall: 0.5167 - val_f1_score: 0.5780\n",
            "Epoch 76/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.2983 - acc: 0.8900 - precision: 0.8981 - recall: 0.7533 - f1_score: 0.8189 - val_loss: 0.4547 - val_acc: 0.7500 - val_precision: 0.6564 - val_recall: 0.5167 - val_f1_score: 0.5780\n",
            "Epoch 77/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.3020 - acc: 0.8889 - precision: 0.8763 - recall: 0.7767 - f1_score: 0.8231 - val_loss: 0.4540 - val_acc: 0.7556 - val_precision: 0.6720 - val_recall: 0.5167 - val_f1_score: 0.5841\n",
            "Epoch 78/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.3047 - acc: 0.8833 - precision: 0.8765 - recall: 0.7533 - f1_score: 0.8092 - val_loss: 0.4554 - val_acc: 0.7611 - val_precision: 0.6708 - val_recall: 0.5500 - val_f1_score: 0.6042\n",
            "Epoch 79/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.2964 - acc: 0.8922 - precision: 0.8960 - recall: 0.7700 - f1_score: 0.8266 - val_loss: 0.4536 - val_acc: 0.7611 - val_precision: 0.6769 - val_recall: 0.5333 - val_f1_score: 0.5964\n",
            "Epoch 80/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.2980 - acc: 0.8911 - precision: 0.8884 - recall: 0.7700 - f1_score: 0.8244 - val_loss: 0.4531 - val_acc: 0.7611 - val_precision: 0.6769 - val_recall: 0.5333 - val_f1_score: 0.5964\n",
            "Epoch 81/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.3013 - acc: 0.8844 - precision: 0.8764 - recall: 0.7633 - f1_score: 0.8147 - val_loss: 0.4543 - val_acc: 0.7556 - val_precision: 0.6655 - val_recall: 0.5333 - val_f1_score: 0.5921\n",
            "Epoch 82/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.2861 - acc: 0.8989 - precision: 0.8972 - recall: 0.7900 - f1_score: 0.8393 - val_loss: 0.4520 - val_acc: 0.7500 - val_precision: 0.6599 - val_recall: 0.5167 - val_f1_score: 0.5796\n",
            "Epoch 83/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.2934 - acc: 0.8933 - precision: 0.8845 - recall: 0.7833 - f1_score: 0.8305 - val_loss: 0.4531 - val_acc: 0.7611 - val_precision: 0.6708 - val_recall: 0.5500 - val_f1_score: 0.6042\n",
            "Epoch 84/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.2865 - acc: 0.8878 - precision: 0.8737 - recall: 0.7767 - f1_score: 0.8217 - val_loss: 0.4514 - val_acc: 0.7556 - val_precision: 0.6691 - val_recall: 0.5333 - val_f1_score: 0.5935\n",
            "Epoch 85/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.2864 - acc: 0.8956 - precision: 0.8877 - recall: 0.7867 - f1_score: 0.8329 - val_loss: 0.4538 - val_acc: 0.7722 - val_precision: 0.6889 - val_recall: 0.5667 - val_f1_score: 0.6210\n",
            "Epoch 86/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.2791 - acc: 0.8989 - precision: 0.8851 - recall: 0.8000 - f1_score: 0.8399 - val_loss: 0.4511 - val_acc: 0.7444 - val_precision: 0.6443 - val_recall: 0.5167 - val_f1_score: 0.5734\n",
            "Epoch 87/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.2862 - acc: 0.8878 - precision: 0.8686 - recall: 0.7800 - f1_score: 0.8207 - val_loss: 0.4503 - val_acc: 0.7611 - val_precision: 0.6694 - val_recall: 0.5500 - val_f1_score: 0.6037\n",
            "Epoch 88/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.2885 - acc: 0.8911 - precision: 0.8817 - recall: 0.7767 - f1_score: 0.8254 - val_loss: 0.4507 - val_acc: 0.7667 - val_precision: 0.6758 - val_recall: 0.5667 - val_f1_score: 0.6160\n",
            "Epoch 89/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.2746 - acc: 0.9022 - precision: 0.9050 - recall: 0.7933 - f1_score: 0.8445 - val_loss: 0.4488 - val_acc: 0.7500 - val_precision: 0.6535 - val_recall: 0.5333 - val_f1_score: 0.5873\n",
            "Epoch 90/200\n",
            "300/300 [==============================] - 4s 13ms/step - loss: 0.2781 - acc: 0.8956 - precision: 0.8877 - recall: 0.7833 - f1_score: 0.8310 - val_loss: 0.4483 - val_acc: 0.7500 - val_precision: 0.6535 - val_recall: 0.5333 - val_f1_score: 0.5873\n",
            "Epoch 91/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.2780 - acc: 0.9044 - precision: 0.8982 - recall: 0.8067 - f1_score: 0.8495 - val_loss: 0.4481 - val_acc: 0.7500 - val_precision: 0.6535 - val_recall: 0.5333 - val_f1_score: 0.5873\n",
            "Epoch 92/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.2789 - acc: 0.8911 - precision: 0.8857 - recall: 0.7733 - f1_score: 0.8254 - val_loss: 0.4525 - val_acc: 0.7611 - val_precision: 0.6708 - val_recall: 0.5500 - val_f1_score: 0.6042\n",
            "Epoch 93/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.2720 - acc: 0.9067 - precision: 0.9017 - recall: 0.8067 - f1_score: 0.8512 - val_loss: 0.4469 - val_acc: 0.7556 - val_precision: 0.6588 - val_recall: 0.5500 - val_f1_score: 0.5995\n",
            "Epoch 94/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.2726 - acc: 0.9144 - precision: 0.9053 - recall: 0.8300 - f1_score: 0.8655 - val_loss: 0.4496 - val_acc: 0.7778 - val_precision: 0.6948 - val_recall: 0.5833 - val_f1_score: 0.6338\n",
            "Epoch 95/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.2671 - acc: 0.9056 - precision: 0.9032 - recall: 0.8033 - f1_score: 0.8499 - val_loss: 0.4457 - val_acc: 0.7556 - val_precision: 0.6588 - val_recall: 0.5500 - val_f1_score: 0.5995\n",
            "Epoch 96/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.2683 - acc: 0.9022 - precision: 0.8913 - recall: 0.8067 - f1_score: 0.8461 - val_loss: 0.4463 - val_acc: 0.7556 - val_precision: 0.6588 - val_recall: 0.5500 - val_f1_score: 0.5995\n",
            "Epoch 97/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.2677 - acc: 0.9067 - precision: 0.9031 - recall: 0.8067 - f1_score: 0.8516 - val_loss: 0.4442 - val_acc: 0.7611 - val_precision: 0.6638 - val_recall: 0.5667 - val_f1_score: 0.6112\n",
            "Epoch 98/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.2646 - acc: 0.9033 - precision: 0.8948 - recall: 0.8033 - f1_score: 0.8459 - val_loss: 0.4442 - val_acc: 0.7556 - val_precision: 0.6588 - val_recall: 0.5500 - val_f1_score: 0.5995\n",
            "Epoch 99/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.2619 - acc: 0.9122 - precision: 0.9006 - recall: 0.8267 - f1_score: 0.8615 - val_loss: 0.4432 - val_acc: 0.7611 - val_precision: 0.6638 - val_recall: 0.5667 - val_f1_score: 0.6112\n",
            "Epoch 100/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.2604 - acc: 0.9122 - precision: 0.9049 - recall: 0.8267 - f1_score: 0.8634 - val_loss: 0.4449 - val_acc: 0.7556 - val_precision: 0.6588 - val_recall: 0.5500 - val_f1_score: 0.5995\n",
            "Epoch 101/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.2544 - acc: 0.9089 - precision: 0.9072 - recall: 0.8100 - f1_score: 0.8543 - val_loss: 0.4426 - val_acc: 0.7611 - val_precision: 0.6638 - val_recall: 0.5667 - val_f1_score: 0.6112\n",
            "Epoch 102/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.2582 - acc: 0.9122 - precision: 0.9150 - recall: 0.8133 - f1_score: 0.8594 - val_loss: 0.4414 - val_acc: 0.7667 - val_precision: 0.6684 - val_recall: 0.5833 - val_f1_score: 0.6226\n",
            "Epoch 103/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.2552 - acc: 0.9144 - precision: 0.9020 - recall: 0.8333 - f1_score: 0.8660 - val_loss: 0.4437 - val_acc: 0.7778 - val_precision: 0.6887 - val_recall: 0.6000 - val_f1_score: 0.6409\n",
            "Epoch 104/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.2566 - acc: 0.9056 - precision: 0.8990 - recall: 0.8067 - f1_score: 0.8496 - val_loss: 0.4407 - val_acc: 0.7722 - val_precision: 0.6768 - val_recall: 0.6000 - val_f1_score: 0.6360\n",
            "Epoch 105/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.2551 - acc: 0.9200 - precision: 0.9133 - recall: 0.8400 - f1_score: 0.8745 - val_loss: 0.4416 - val_acc: 0.7667 - val_precision: 0.6825 - val_recall: 0.5667 - val_f1_score: 0.6191\n",
            "Epoch 106/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.2535 - acc: 0.9167 - precision: 0.8999 - recall: 0.8433 - f1_score: 0.8705 - val_loss: 0.4425 - val_acc: 0.7611 - val_precision: 0.6524 - val_recall: 0.6000 - val_f1_score: 0.6250\n",
            "Epoch 107/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.2469 - acc: 0.9111 - precision: 0.8943 - recall: 0.8300 - f1_score: 0.8600 - val_loss: 0.4414 - val_acc: 0.7667 - val_precision: 0.6825 - val_recall: 0.5667 - val_f1_score: 0.6191\n",
            "Epoch 108/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.2524 - acc: 0.9167 - precision: 0.9086 - recall: 0.8333 - f1_score: 0.8687 - val_loss: 0.4396 - val_acc: 0.7667 - val_precision: 0.6633 - val_recall: 0.6000 - val_f1_score: 0.6298\n",
            "Epoch 109/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.2430 - acc: 0.9144 - precision: 0.8937 - recall: 0.8433 - f1_score: 0.8674 - val_loss: 0.4388 - val_acc: 0.7833 - val_precision: 0.6889 - val_recall: 0.6333 - val_f1_score: 0.6598\n",
            "Epoch 110/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.2441 - acc: 0.9089 - precision: 0.9006 - recall: 0.8167 - f1_score: 0.8559 - val_loss: 0.4392 - val_acc: 0.7722 - val_precision: 0.6768 - val_recall: 0.6000 - val_f1_score: 0.6360\n",
            "Epoch 111/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.2467 - acc: 0.9178 - precision: 0.9200 - recall: 0.8233 - f1_score: 0.8682 - val_loss: 0.4415 - val_acc: 0.7667 - val_precision: 0.6633 - val_recall: 0.6000 - val_f1_score: 0.6298\n",
            "Epoch 112/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.2504 - acc: 0.9156 - precision: 0.9110 - recall: 0.8267 - f1_score: 0.8658 - val_loss: 0.4413 - val_acc: 0.7722 - val_precision: 0.6768 - val_recall: 0.6000 - val_f1_score: 0.6360\n",
            "Epoch 113/200\n",
            "300/300 [==============================] - 4s 13ms/step - loss: 0.2391 - acc: 0.9200 - precision: 0.9053 - recall: 0.8467 - f1_score: 0.8744 - val_loss: 0.4379 - val_acc: 0.7667 - val_precision: 0.6786 - val_recall: 0.5667 - val_f1_score: 0.6176\n",
            "Epoch 114/200\n",
            "300/300 [==============================] - 4s 13ms/step - loss: 0.2362 - acc: 0.9222 - precision: 0.9203 - recall: 0.8400 - f1_score: 0.8778 - val_loss: 0.4399 - val_acc: 0.7667 - val_precision: 0.6633 - val_recall: 0.6000 - val_f1_score: 0.6298\n",
            "Epoch 115/200\n",
            "300/300 [==============================] - 4s 13ms/step - loss: 0.2391 - acc: 0.9144 - precision: 0.9048 - recall: 0.8300 - f1_score: 0.8652 - val_loss: 0.4398 - val_acc: 0.7667 - val_precision: 0.6825 - val_recall: 0.5667 - val_f1_score: 0.6191\n",
            "Epoch 116/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.2268 - acc: 0.9256 - precision: 0.9211 - recall: 0.8500 - f1_score: 0.8838 - val_loss: 0.4364 - val_acc: 0.7611 - val_precision: 0.6524 - val_recall: 0.6000 - val_f1_score: 0.6250\n",
            "Epoch 117/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.2301 - acc: 0.9289 - precision: 0.9153 - recall: 0.8667 - f1_score: 0.8897 - val_loss: 0.4364 - val_acc: 0.7611 - val_precision: 0.6524 - val_recall: 0.6000 - val_f1_score: 0.6250\n",
            "Epoch 118/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.2384 - acc: 0.9144 - precision: 0.8992 - recall: 0.8333 - f1_score: 0.8642 - val_loss: 0.4359 - val_acc: 0.7667 - val_precision: 0.6633 - val_recall: 0.6000 - val_f1_score: 0.6298\n",
            "Epoch 119/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.2361 - acc: 0.9167 - precision: 0.8971 - recall: 0.8467 - f1_score: 0.8708 - val_loss: 0.4359 - val_acc: 0.7889 - val_precision: 0.7030 - val_recall: 0.6333 - val_f1_score: 0.6663\n",
            "Epoch 120/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.2261 - acc: 0.9356 - precision: 0.9477 - recall: 0.8533 - f1_score: 0.8971 - val_loss: 0.4399 - val_acc: 0.7667 - val_precision: 0.6633 - val_recall: 0.6000 - val_f1_score: 0.6298\n",
            "Epoch 121/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.2288 - acc: 0.9233 - precision: 0.9215 - recall: 0.8433 - f1_score: 0.8800 - val_loss: 0.4350 - val_acc: 0.7778 - val_precision: 0.6846 - val_recall: 0.6167 - val_f1_score: 0.6489\n",
            "Epoch 122/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.2180 - acc: 0.9400 - precision: 0.9322 - recall: 0.8833 - f1_score: 0.9068 - val_loss: 0.4339 - val_acc: 0.7611 - val_precision: 0.6524 - val_recall: 0.6000 - val_f1_score: 0.6250\n",
            "Epoch 123/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.2204 - acc: 0.9311 - precision: 0.9276 - recall: 0.8600 - f1_score: 0.8922 - val_loss: 0.4344 - val_acc: 0.7778 - val_precision: 0.6846 - val_recall: 0.6167 - val_f1_score: 0.6489\n",
            "Epoch 124/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.2165 - acc: 0.9300 - precision: 0.9154 - recall: 0.8700 - f1_score: 0.8918 - val_loss: 0.4332 - val_acc: 0.7667 - val_precision: 0.6633 - val_recall: 0.6000 - val_f1_score: 0.6298\n",
            "Epoch 125/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.2243 - acc: 0.9289 - precision: 0.9197 - recall: 0.8600 - f1_score: 0.8886 - val_loss: 0.4360 - val_acc: 0.7833 - val_precision: 0.6990 - val_recall: 0.6167 - val_f1_score: 0.6553\n",
            "Epoch 126/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.2230 - acc: 0.9322 - precision: 0.9214 - recall: 0.8700 - f1_score: 0.8946 - val_loss: 0.4337 - val_acc: 0.7778 - val_precision: 0.6846 - val_recall: 0.6167 - val_f1_score: 0.6489\n",
            "Epoch 127/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.2171 - acc: 0.9311 - precision: 0.9196 - recall: 0.8700 - f1_score: 0.8939 - val_loss: 0.4339 - val_acc: 0.7611 - val_precision: 0.6524 - val_recall: 0.6000 - val_f1_score: 0.6250\n",
            "Epoch 128/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.2233 - acc: 0.9311 - precision: 0.9283 - recall: 0.8600 - f1_score: 0.8927 - val_loss: 0.4353 - val_acc: 0.7722 - val_precision: 0.6903 - val_recall: 0.5833 - val_f1_score: 0.6320\n",
            "Epoch 129/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.2214 - acc: 0.9356 - precision: 0.9348 - recall: 0.8667 - f1_score: 0.8992 - val_loss: 0.4333 - val_acc: 0.7611 - val_precision: 0.6524 - val_recall: 0.6000 - val_f1_score: 0.6250\n",
            "Epoch 130/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.2197 - acc: 0.9322 - precision: 0.9321 - recall: 0.8600 - f1_score: 0.8941 - val_loss: 0.4305 - val_acc: 0.7667 - val_precision: 0.6603 - val_recall: 0.6167 - val_f1_score: 0.6378\n",
            "Epoch 131/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.2176 - acc: 0.9311 - precision: 0.9265 - recall: 0.8633 - f1_score: 0.8928 - val_loss: 0.4329 - val_acc: 0.7778 - val_precision: 0.6846 - val_recall: 0.6167 - val_f1_score: 0.6489\n",
            "Epoch 132/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.2110 - acc: 0.9311 - precision: 0.9296 - recall: 0.8567 - f1_score: 0.8911 - val_loss: 0.4336 - val_acc: 0.7611 - val_precision: 0.6524 - val_recall: 0.6000 - val_f1_score: 0.6250\n",
            "Epoch 133/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.2176 - acc: 0.9256 - precision: 0.9118 - recall: 0.8600 - f1_score: 0.8848 - val_loss: 0.4308 - val_acc: 0.7778 - val_precision: 0.6846 - val_recall: 0.6167 - val_f1_score: 0.6489\n",
            "Epoch 134/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.2086 - acc: 0.9289 - precision: 0.9313 - recall: 0.8500 - f1_score: 0.8884 - val_loss: 0.4302 - val_acc: 0.7667 - val_precision: 0.6570 - val_recall: 0.6167 - val_f1_score: 0.6360\n",
            "Epoch 135/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.2091 - acc: 0.9378 - precision: 0.9295 - recall: 0.8800 - f1_score: 0.9037 - val_loss: 0.4326 - val_acc: 0.7778 - val_precision: 0.6846 - val_recall: 0.6167 - val_f1_score: 0.6489\n",
            "Epoch 136/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.2125 - acc: 0.9433 - precision: 0.9430 - recall: 0.8833 - f1_score: 0.9116 - val_loss: 0.4340 - val_acc: 0.7722 - val_precision: 0.6768 - val_recall: 0.6000 - val_f1_score: 0.6360\n",
            "Epoch 137/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.2020 - acc: 0.9433 - precision: 0.9361 - recall: 0.8900 - f1_score: 0.9122 - val_loss: 0.4295 - val_acc: 0.7667 - val_precision: 0.6570 - val_recall: 0.6167 - val_f1_score: 0.6360\n",
            "Epoch 138/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.2054 - acc: 0.9311 - precision: 0.9170 - recall: 0.8733 - f1_score: 0.8942 - val_loss: 0.4326 - val_acc: 0.7778 - val_precision: 0.6846 - val_recall: 0.6167 - val_f1_score: 0.6489\n",
            "Epoch 139/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.2051 - acc: 0.9411 - precision: 0.9452 - recall: 0.8733 - f1_score: 0.9069 - val_loss: 0.4322 - val_acc: 0.7722 - val_precision: 0.6679 - val_recall: 0.6167 - val_f1_score: 0.6407\n",
            "Epoch 140/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.2047 - acc: 0.9400 - precision: 0.9429 - recall: 0.8733 - f1_score: 0.9067 - val_loss: 0.4296 - val_acc: 0.7778 - val_precision: 0.6846 - val_recall: 0.6167 - val_f1_score: 0.6489\n",
            "Epoch 141/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.2051 - acc: 0.9400 - precision: 0.9302 - recall: 0.8867 - f1_score: 0.9074 - val_loss: 0.4306 - val_acc: 0.7722 - val_precision: 0.6768 - val_recall: 0.6000 - val_f1_score: 0.6360\n",
            "Epoch 142/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.2004 - acc: 0.9389 - precision: 0.9372 - recall: 0.8767 - f1_score: 0.9056 - val_loss: 0.4312 - val_acc: 0.7667 - val_precision: 0.6570 - val_recall: 0.6167 - val_f1_score: 0.6360\n",
            "Epoch 143/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.2027 - acc: 0.9389 - precision: 0.9323 - recall: 0.8800 - f1_score: 0.9050 - val_loss: 0.4286 - val_acc: 0.7722 - val_precision: 0.6702 - val_recall: 0.6167 - val_f1_score: 0.6422\n",
            "Epoch 144/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.1970 - acc: 0.9444 - precision: 0.9371 - recall: 0.8933 - f1_score: 0.9143 - val_loss: 0.4274 - val_acc: 0.7778 - val_precision: 0.6781 - val_recall: 0.6333 - val_f1_score: 0.6550\n",
            "Epoch 145/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.1930 - acc: 0.9444 - precision: 0.9464 - recall: 0.8833 - f1_score: 0.9134 - val_loss: 0.4286 - val_acc: 0.7722 - val_precision: 0.6702 - val_recall: 0.6167 - val_f1_score: 0.6422\n",
            "Epoch 146/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.2006 - acc: 0.9422 - precision: 0.9400 - recall: 0.8833 - f1_score: 0.9103 - val_loss: 0.4274 - val_acc: 0.7722 - val_precision: 0.6702 - val_recall: 0.6167 - val_f1_score: 0.6422\n",
            "Epoch 147/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.1976 - acc: 0.9400 - precision: 0.9365 - recall: 0.8800 - f1_score: 0.9071 - val_loss: 0.4279 - val_acc: 0.7722 - val_precision: 0.6702 - val_recall: 0.6167 - val_f1_score: 0.6422\n",
            "Epoch 148/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.1992 - acc: 0.9433 - precision: 0.9386 - recall: 0.8867 - f1_score: 0.9116 - val_loss: 0.4273 - val_acc: 0.7722 - val_precision: 0.6702 - val_recall: 0.6167 - val_f1_score: 0.6422\n",
            "Epoch 149/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.1980 - acc: 0.9389 - precision: 0.9330 - recall: 0.8800 - f1_score: 0.9055 - val_loss: 0.4261 - val_acc: 0.7833 - val_precision: 0.6889 - val_recall: 0.6333 - val_f1_score: 0.6598\n",
            "Epoch 150/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.1925 - acc: 0.9422 - precision: 0.9295 - recall: 0.8933 - f1_score: 0.9105 - val_loss: 0.4291 - val_acc: 0.7722 - val_precision: 0.6702 - val_recall: 0.6167 - val_f1_score: 0.6422\n",
            "Epoch 151/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.1928 - acc: 0.9433 - precision: 0.9373 - recall: 0.8900 - f1_score: 0.9125 - val_loss: 0.4299 - val_acc: 0.7778 - val_precision: 0.6811 - val_recall: 0.6167 - val_f1_score: 0.6470\n",
            "Epoch 152/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.1904 - acc: 0.9444 - precision: 0.9343 - recall: 0.8967 - f1_score: 0.9148 - val_loss: 0.4255 - val_acc: 0.7889 - val_precision: 0.6929 - val_recall: 0.6500 - val_f1_score: 0.6705\n",
            "Epoch 153/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.1878 - acc: 0.9444 - precision: 0.9424 - recall: 0.8867 - f1_score: 0.9131 - val_loss: 0.4285 - val_acc: 0.7778 - val_precision: 0.6811 - val_recall: 0.6167 - val_f1_score: 0.6470\n",
            "Epoch 154/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.1875 - acc: 0.9533 - precision: 0.9510 - recall: 0.9067 - f1_score: 0.9282 - val_loss: 0.4241 - val_acc: 0.7778 - val_precision: 0.6781 - val_recall: 0.6333 - val_f1_score: 0.6550\n",
            "Epoch 155/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.1834 - acc: 0.9511 - precision: 0.9475 - recall: 0.9033 - f1_score: 0.9247 - val_loss: 0.4266 - val_acc: 0.7833 - val_precision: 0.6889 - val_recall: 0.6333 - val_f1_score: 0.6598\n",
            "Epoch 156/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.1882 - acc: 0.9500 - precision: 0.9481 - recall: 0.9000 - f1_score: 0.9231 - val_loss: 0.4280 - val_acc: 0.7889 - val_precision: 0.7030 - val_recall: 0.6333 - val_f1_score: 0.6663\n",
            "Epoch 157/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.1840 - acc: 0.9422 - precision: 0.9336 - recall: 0.8900 - f1_score: 0.9109 - val_loss: 0.4244 - val_acc: 0.7722 - val_precision: 0.6702 - val_recall: 0.6167 - val_f1_score: 0.6422\n",
            "Epoch 158/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.1845 - acc: 0.9533 - precision: 0.9507 - recall: 0.9067 - f1_score: 0.9279 - val_loss: 0.4236 - val_acc: 0.7722 - val_precision: 0.6702 - val_recall: 0.6167 - val_f1_score: 0.6422\n",
            "Epoch 159/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.1794 - acc: 0.9567 - precision: 0.9546 - recall: 0.9133 - f1_score: 0.9334 - val_loss: 0.4285 - val_acc: 0.7722 - val_precision: 0.6679 - val_recall: 0.6167 - val_f1_score: 0.6407\n",
            "Epoch 160/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.1778 - acc: 0.9489 - precision: 0.9473 - recall: 0.8967 - f1_score: 0.9209 - val_loss: 0.4232 - val_acc: 0.7889 - val_precision: 0.7030 - val_recall: 0.6333 - val_f1_score: 0.6663\n",
            "Epoch 161/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.1796 - acc: 0.9578 - precision: 0.9490 - recall: 0.9233 - f1_score: 0.9358 - val_loss: 0.4219 - val_acc: 0.7778 - val_precision: 0.6781 - val_recall: 0.6333 - val_f1_score: 0.6550\n",
            "Epoch 162/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.1837 - acc: 0.9544 - precision: 0.9484 - recall: 0.9133 - f1_score: 0.9303 - val_loss: 0.4256 - val_acc: 0.7667 - val_precision: 0.6570 - val_recall: 0.6167 - val_f1_score: 0.6360\n",
            "Epoch 163/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.1796 - acc: 0.9467 - precision: 0.9369 - recall: 0.9000 - f1_score: 0.9178 - val_loss: 0.4214 - val_acc: 0.7833 - val_precision: 0.6889 - val_recall: 0.6333 - val_f1_score: 0.6598\n",
            "Epoch 164/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.1791 - acc: 0.9556 - precision: 0.9511 - recall: 0.9133 - f1_score: 0.9312 - val_loss: 0.4204 - val_acc: 0.7833 - val_precision: 0.6821 - val_recall: 0.6500 - val_f1_score: 0.6656\n",
            "Epoch 165/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.1753 - acc: 0.9567 - precision: 0.9520 - recall: 0.9167 - f1_score: 0.9331 - val_loss: 0.4197 - val_acc: 0.7833 - val_precision: 0.6821 - val_recall: 0.6500 - val_f1_score: 0.6656\n",
            "Epoch 166/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.1756 - acc: 0.9544 - precision: 0.9547 - recall: 0.9067 - f1_score: 0.9297 - val_loss: 0.4212 - val_acc: 0.7833 - val_precision: 0.6800 - val_recall: 0.6500 - val_f1_score: 0.6642\n",
            "Epoch 167/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.1789 - acc: 0.9533 - precision: 0.9515 - recall: 0.9067 - f1_score: 0.9283 - val_loss: 0.4196 - val_acc: 0.7722 - val_precision: 0.6702 - val_recall: 0.6167 - val_f1_score: 0.6422\n",
            "Epoch 168/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.1721 - acc: 0.9611 - precision: 0.9556 - recall: 0.9267 - f1_score: 0.9406 - val_loss: 0.4186 - val_acc: 0.7944 - val_precision: 0.7046 - val_recall: 0.6500 - val_f1_score: 0.6756\n",
            "Epoch 169/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.1697 - acc: 0.9567 - precision: 0.9575 - recall: 0.9100 - f1_score: 0.9328 - val_loss: 0.4195 - val_acc: 0.7833 - val_precision: 0.6821 - val_recall: 0.6500 - val_f1_score: 0.6656\n",
            "Epoch 170/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.1776 - acc: 0.9544 - precision: 0.9510 - recall: 0.9100 - f1_score: 0.9294 - val_loss: 0.4211 - val_acc: 0.7889 - val_precision: 0.6929 - val_recall: 0.6500 - val_f1_score: 0.6705\n",
            "Epoch 171/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.1666 - acc: 0.9556 - precision: 0.9506 - recall: 0.9133 - f1_score: 0.9310 - val_loss: 0.4185 - val_acc: 0.7889 - val_precision: 0.6929 - val_recall: 0.6500 - val_f1_score: 0.6705\n",
            "Epoch 172/200\n",
            "300/300 [==============================] - 4s 13ms/step - loss: 0.1701 - acc: 0.9578 - precision: 0.9579 - recall: 0.9133 - f1_score: 0.9348 - val_loss: 0.4189 - val_acc: 0.7778 - val_precision: 0.6692 - val_recall: 0.6500 - val_f1_score: 0.6593\n",
            "Epoch 173/200\n",
            "300/300 [==============================] - 4s 13ms/step - loss: 0.1682 - acc: 0.9544 - precision: 0.9549 - recall: 0.9067 - f1_score: 0.9299 - val_loss: 0.4193 - val_acc: 0.7889 - val_precision: 0.6929 - val_recall: 0.6500 - val_f1_score: 0.6705\n",
            "Epoch 174/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.1683 - acc: 0.9578 - precision: 0.9568 - recall: 0.9133 - f1_score: 0.9342 - val_loss: 0.4197 - val_acc: 0.7722 - val_precision: 0.6679 - val_recall: 0.6167 - val_f1_score: 0.6407\n",
            "Epoch 175/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.1647 - acc: 0.9489 - precision: 0.9495 - recall: 0.8933 - f1_score: 0.9200 - val_loss: 0.4196 - val_acc: 0.7944 - val_precision: 0.7147 - val_recall: 0.6333 - val_f1_score: 0.6714\n",
            "Epoch 176/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.1729 - acc: 0.9544 - precision: 0.9448 - recall: 0.9167 - f1_score: 0.9305 - val_loss: 0.4170 - val_acc: 0.7833 - val_precision: 0.6800 - val_recall: 0.6500 - val_f1_score: 0.6642\n",
            "Epoch 177/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.1700 - acc: 0.9533 - precision: 0.9450 - recall: 0.9133 - f1_score: 0.9283 - val_loss: 0.4181 - val_acc: 0.8000 - val_precision: 0.7217 - val_recall: 0.6500 - val_f1_score: 0.6839\n",
            "Epoch 178/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.1609 - acc: 0.9633 - precision: 0.9622 - recall: 0.9267 - f1_score: 0.9438 - val_loss: 0.4165 - val_acc: 0.7833 - val_precision: 0.6800 - val_recall: 0.6500 - val_f1_score: 0.6642\n",
            "Epoch 179/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.1596 - acc: 0.9644 - precision: 0.9646 - recall: 0.9267 - f1_score: 0.9448 - val_loss: 0.4160 - val_acc: 0.7944 - val_precision: 0.6987 - val_recall: 0.6667 - val_f1_score: 0.6818\n",
            "Epoch 180/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.1680 - acc: 0.9511 - precision: 0.9447 - recall: 0.9067 - f1_score: 0.9252 - val_loss: 0.4170 - val_acc: 0.7833 - val_precision: 0.6800 - val_recall: 0.6500 - val_f1_score: 0.6642\n",
            "Epoch 181/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.1595 - acc: 0.9633 - precision: 0.9555 - recall: 0.9333 - f1_score: 0.9442 - val_loss: 0.4178 - val_acc: 0.7944 - val_precision: 0.7076 - val_recall: 0.6500 - val_f1_score: 0.6775\n",
            "Epoch 182/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.1623 - acc: 0.9644 - precision: 0.9588 - recall: 0.9333 - f1_score: 0.9458 - val_loss: 0.4156 - val_acc: 0.7889 - val_precision: 0.6872 - val_recall: 0.6667 - val_f1_score: 0.6765\n",
            "Epoch 183/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.1628 - acc: 0.9556 - precision: 0.9584 - recall: 0.9067 - f1_score: 0.9313 - val_loss: 0.4167 - val_acc: 0.7778 - val_precision: 0.6722 - val_recall: 0.6333 - val_f1_score: 0.6513\n",
            "Epoch 184/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.1604 - acc: 0.9600 - precision: 0.9493 - recall: 0.9300 - f1_score: 0.9394 - val_loss: 0.4160 - val_acc: 0.8000 - val_precision: 0.7116 - val_recall: 0.6667 - val_f1_score: 0.6881\n",
            "Epoch 185/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.1580 - acc: 0.9589 - precision: 0.9488 - recall: 0.9267 - f1_score: 0.9373 - val_loss: 0.4180 - val_acc: 0.7944 - val_precision: 0.7046 - val_recall: 0.6500 - val_f1_score: 0.6756\n",
            "Epoch 186/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.1595 - acc: 0.9522 - precision: 0.9445 - recall: 0.9100 - f1_score: 0.9268 - val_loss: 0.4136 - val_acc: 0.7889 - val_precision: 0.6872 - val_recall: 0.6667 - val_f1_score: 0.6765\n",
            "Epoch 187/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.1572 - acc: 0.9700 - precision: 0.9653 - recall: 0.9433 - f1_score: 0.9539 - val_loss: 0.4152 - val_acc: 0.8000 - val_precision: 0.7116 - val_recall: 0.6667 - val_f1_score: 0.6881\n",
            "Epoch 188/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.1581 - acc: 0.9533 - precision: 0.9476 - recall: 0.9100 - f1_score: 0.9281 - val_loss: 0.4158 - val_acc: 0.7889 - val_precision: 0.6929 - val_recall: 0.6500 - val_f1_score: 0.6705\n",
            "Epoch 189/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.1560 - acc: 0.9611 - precision: 0.9521 - recall: 0.9300 - f1_score: 0.9408 - val_loss: 0.4115 - val_acc: 0.8056 - val_precision: 0.7129 - val_recall: 0.7000 - val_f1_score: 0.7063\n",
            "Epoch 190/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.1523 - acc: 0.9667 - precision: 0.9694 - recall: 0.9300 - f1_score: 0.9490 - val_loss: 0.4141 - val_acc: 0.7889 - val_precision: 0.6872 - val_recall: 0.6667 - val_f1_score: 0.6765\n",
            "Epoch 191/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.1516 - acc: 0.9700 - precision: 0.9692 - recall: 0.9400 - f1_score: 0.9542 - val_loss: 0.4186 - val_acc: 0.7944 - val_precision: 0.7076 - val_recall: 0.6500 - val_f1_score: 0.6775\n",
            "Epoch 192/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.1528 - acc: 0.9600 - precision: 0.9528 - recall: 0.9267 - f1_score: 0.9393 - val_loss: 0.4120 - val_acc: 0.7889 - val_precision: 0.6872 - val_recall: 0.6667 - val_f1_score: 0.6765\n",
            "Epoch 193/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.1539 - acc: 0.9611 - precision: 0.9612 - recall: 0.9200 - f1_score: 0.9398 - val_loss: 0.4120 - val_acc: 0.7889 - val_precision: 0.6872 - val_recall: 0.6667 - val_f1_score: 0.6765\n",
            "Epoch 194/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.1468 - acc: 0.9656 - precision: 0.9558 - recall: 0.9400 - f1_score: 0.9478 - val_loss: 0.4136 - val_acc: 0.8111 - val_precision: 0.7240 - val_recall: 0.7000 - val_f1_score: 0.7118\n",
            "Epoch 195/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.1436 - acc: 0.9689 - precision: 0.9691 - recall: 0.9367 - f1_score: 0.9525 - val_loss: 0.4157 - val_acc: 0.7778 - val_precision: 0.6722 - val_recall: 0.6333 - val_f1_score: 0.6513\n",
            "Epoch 196/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.1469 - acc: 0.9756 - precision: 0.9792 - recall: 0.9467 - f1_score: 0.9625 - val_loss: 0.4125 - val_acc: 0.8000 - val_precision: 0.7116 - val_recall: 0.6667 - val_f1_score: 0.6881\n",
            "Epoch 197/200\n",
            "300/300 [==============================] - 4s 13ms/step - loss: 0.1479 - acc: 0.9578 - precision: 0.9585 - recall: 0.9133 - f1_score: 0.9352 - val_loss: 0.4123 - val_acc: 0.7889 - val_precision: 0.6872 - val_recall: 0.6667 - val_f1_score: 0.6765\n",
            "Epoch 198/200\n",
            "300/300 [==============================] - 4s 13ms/step - loss: 0.1481 - acc: 0.9656 - precision: 0.9622 - recall: 0.9333 - f1_score: 0.9473 - val_loss: 0.4121 - val_acc: 0.7944 - val_precision: 0.7001 - val_recall: 0.6667 - val_f1_score: 0.6829\n",
            "Epoch 199/200\n",
            "300/300 [==============================] - 4s 13ms/step - loss: 0.1459 - acc: 0.9689 - precision: 0.9660 - recall: 0.9400 - f1_score: 0.9527 - val_loss: 0.4147 - val_acc: 0.7944 - val_precision: 0.7001 - val_recall: 0.6667 - val_f1_score: 0.6829\n",
            "Epoch 200/200\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.1474 - acc: 0.9700 - precision: 0.9756 - recall: 0.9333 - f1_score: 0.9537 - val_loss: 0.4117 - val_acc: 0.7944 - val_precision: 0.7001 - val_recall: 0.6667 - val_f1_score: 0.6829\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "8QfpDN6JOtCT"
      },
      "cell_type": "markdown",
      "source": [
        "We now plot the training history."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "e0a98fc1-ecbc-4ac2-e93f-ff5710c8ff07",
        "id": "hzcnYNMIOtCU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        }
      },
      "cell_type": "code",
      "source": [
        "plt.plot(history_conv.history['f1_score'])\n",
        "plt.plot(history_conv.history['val_f1_score'])\n",
        "plt.title('model f1 score')\n",
        "plt.ylabel('f1 score')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'valid'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history_conv.history['loss'])\n",
        "plt.plot(history_conv.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'valid'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEVCAYAAADpbDJPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nHNAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fbc56c2e3c8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEVCAYAAADpbDJPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fbc56bd3da0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "pZ1KLyOXV6Mp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### ConvNet test"
      ]
    },
    {
      "metadata": {
        "id": "EnliW6weV7w6",
        "colab_type": "code",
        "outputId": "1f4acf2c-1a2a-4ca5-8320-d67cb2578912",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "model_conv.evaluate(X_test, Y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "300/300 [==============================] - 1s 3ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3276576073964437,\n",
              " 0.8533333269755046,\n",
              " 0.8098224886258443,\n",
              " 0.73,\n",
              " 0.7670909611384074]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    }
  ]
}