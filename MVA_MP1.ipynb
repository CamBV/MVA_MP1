{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MVA-MP1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "XSuFEyo013uH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Given functions"
      ]
    },
    {
      "metadata": {
        "id": "7Kle7SZk4tu5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "\n",
        "# On some implementations of matplotlib, you may need to change this value\n",
        "IMAGE_SIZE = 72\n",
        "\n",
        "def generate_a_drawing(figsize, U, V, noise=0.0):\n",
        "    fig = plt.figure(figsize=(figsize,figsize))\n",
        "    ax = plt.subplot(111)\n",
        "    plt.axis('Off')\n",
        "    ax.set_xlim(0,figsize)\n",
        "    ax.set_ylim(0,figsize)\n",
        "    ax.fill(U, V, \"k\")\n",
        "    fig.canvas.draw()\n",
        "    imdata = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)[::3].astype(np.float32)\n",
        "    imdata = imdata + noise * np.random.random(imdata.size)\n",
        "    plt.close(fig)\n",
        "    return imdata\n",
        "\n",
        "def generate_a_rectangle(noise=0.0, free_location=False):\n",
        "    figsize = 1.0    \n",
        "    U = np.zeros(4)\n",
        "    V = np.zeros(4)\n",
        "    if free_location:\n",
        "        corners = np.random.random(4)\n",
        "        top = max(corners[0], corners[1])\n",
        "        bottom = min(corners[0], corners[1])\n",
        "        left = min(corners[2], corners[3])\n",
        "        right = max(corners[2], corners[3])\n",
        "    else:\n",
        "        side = (0.3 + 0.7 * np.random.random()) * figsize\n",
        "        top = figsize/2 + side/2\n",
        "        bottom = figsize/2 - side/2\n",
        "        left = bottom\n",
        "        right = top\n",
        "    U[0] = U[1] = top\n",
        "    U[2] = U[3] = bottom\n",
        "    V[0] = V[3] = left\n",
        "    V[1] = V[2] = right\n",
        "    return generate_a_drawing(figsize, U, V, noise)\n",
        "\n",
        "\n",
        "def generate_a_disk(noise=0.0, free_location=False):\n",
        "    figsize = 1.0\n",
        "    if free_location:\n",
        "        center = np.random.random(2)\n",
        "    else:\n",
        "        center = (figsize/2, figsize/2)\n",
        "    radius = (0.3 + 0.7 * np.random.random()) * figsize/2\n",
        "    N = 50\n",
        "    U = np.zeros(N)\n",
        "    V = np.zeros(N)\n",
        "    i = 0\n",
        "    for t in np.linspace(0, 2*np.pi, N):\n",
        "        U[i] = center[0] + np.cos(t) * radius\n",
        "        V[i] = center[1] + np.sin(t) * radius\n",
        "        i = i + 1\n",
        "    return generate_a_drawing(figsize, U, V, noise)\n",
        "\n",
        "def generate_a_triangle(noise=0.0, free_location=False):\n",
        "    figsize = 1.0\n",
        "    if free_location:\n",
        "        U = np.random.random(3)\n",
        "        V = np.random.random(3)\n",
        "    else:\n",
        "        size = (0.3 + 0.7 * np.random.random())*figsize/2\n",
        "        middle = figsize/2\n",
        "        U = (middle, middle+size, middle-size)\n",
        "        V = (middle+size, middle-size, middle-size)\n",
        "    imdata = generate_a_drawing(figsize, U, V, noise)\n",
        "    return [imdata, [U[0], V[0], U[1], V[1], U[2], V[2]]]\n",
        "\n",
        "\n",
        "def generate_dataset_classification(nb_samples, noise=0.0, free_location=False):\n",
        "    # Getting im_size:\n",
        "    im_size = generate_a_rectangle().shape[0]\n",
        "    X = np.zeros([nb_samples,im_size])\n",
        "    Y = np.zeros(nb_samples)\n",
        "    print('Creating data:')\n",
        "    for i in range(nb_samples):\n",
        "        if i % 10 == 0:\n",
        "            print(i)\n",
        "        category = np.random.randint(3)\n",
        "        if category == 0:\n",
        "            X[i] = generate_a_rectangle(noise, free_location)\n",
        "        elif category == 1: \n",
        "            X[i] = generate_a_disk(noise, free_location)\n",
        "        else:\n",
        "            [X[i], V] = generate_a_triangle(noise, free_location)\n",
        "        Y[i] = category\n",
        "    X = (X + noise) / (255 + 2 * noise)\n",
        "    return [X, Y]\n",
        "\n",
        "def generate_test_set_classification():\n",
        "    np.random.seed(42)\n",
        "    [X_test, Y_test] = generate_dataset_classification(300, 20, True)\n",
        "    Y_test = np_utils.to_categorical(Y_test, 3) \n",
        "    return [X_test, Y_test]\n",
        "\n",
        "def generate_dataset_regression(nb_samples, noise=0.0):\n",
        "    # Getting im_size:\n",
        "    im_size = generate_a_triangle()[0].shape[0]\n",
        "    X = np.zeros([nb_samples,im_size])\n",
        "    Y = np.zeros([nb_samples, 6])\n",
        "    print('Creating data:')\n",
        "    for i in range(nb_samples):\n",
        "        if i % 10 == 0:\n",
        "            print(i)\n",
        "        [X[i], Y[i]] = generate_a_triangle(noise, True)\n",
        "    X = (X + noise) / (255 + 2 * noise)\n",
        "    return [X, Y]\n",
        "\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "def visualize_prediction(x, y):\n",
        "    fig, ax = plt.subplots(figsize=(5, 5))\n",
        "    I = x.reshape((IMAGE_SIZE,IMAGE_SIZE))\n",
        "    ax.imshow(I, extent=[-0.15,1.15,-0.15,1.15],cmap='gray')\n",
        "    ax.set_xlim([0,1])\n",
        "    ax.set_ylim([0,1])\n",
        "\n",
        "    xy = y.reshape(3,2)\n",
        "    tri = patches.Polygon(xy, closed=True, fill = False, edgecolor = 'r', linewidth = 5, alpha = 0.5)\n",
        "    ax.add_patch(tri)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "def generate_test_set_regression():\n",
        "    np.random.seed(42)\n",
        "    [X_test, Y_test] = generate_dataset_regression(300, 20)\n",
        "    return [X_test, Y_test]\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cA4frNt1_ao5",
        "colab_type": "code",
        "outputId": "523d854c-e1ee-40e3-e747-0283a42f5ed5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "cell_type": "code",
      "source": [
        "im = generate_a_rectangle(10, True)\n",
        "plt.imshow(im.reshape(IMAGE_SIZE,IMAGE_SIZE), cmap='gray')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x11337c278>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "RAo6G6eP_dxu",
        "colab_type": "code",
        "outputId": "819641aa-3196-445e-d0d7-c17294f4fb1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "cell_type": "code",
      "source": [
        "im = generate_a_disk(10)\n",
        "plt.imshow(im.reshape(IMAGE_SIZE,IMAGE_SIZE), cmap='gray')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x1134d2fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "NfthkM27_gJU",
        "colab_type": "code",
        "outputId": "0fab21a1-e44b-4878-f3c1-89c22b447ac2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "cell_type": "code",
      "source": [
        "[im, v] = generate_a_triangle(20, False)\n",
        "plt.imshow(im.reshape(IMAGE_SIZE,IMAGE_SIZE), cmap='gray')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x1135abda0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "f6NY8BKP8T4K",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Simple classification"
      ]
    },
    {
      "metadata": {
        "id": "c0lMgWepQUUi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ]
    },
    {
      "metadata": {
        "id": "OBTwLIj9QVvz",
        "colab_type": "code",
        "outputId": "fb9647ee-5f1b-411c-c0bb-a156c835233a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Conv2D, MaxPooling2D, Flatten\n",
        "from keras.optimizers import SGD, Adam\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "oUxUR8k0HFzk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Metrics\n",
        "\n",
        "Here are some metrics we will use to train our model.\n"
      ]
    },
    {
      "metadata": {
        "id": "yNK67-MAPmA-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "\n",
        "\n",
        "def precision_threshold(threshold=0.5):\n",
        "    def precision(y_true, y_pred):\n",
        "        \"\"\"Precision metric.\n",
        "         Only computes a batch-wise average of precision.\n",
        "         Computes the precision, a metric for multi-label classification of\n",
        "        how many selected items are relevant.\n",
        "        \"\"\"\n",
        "        threshold_value = threshold\n",
        "        y_pred = K.cast(K.greater(K.clip(y_pred, 0, 1), threshold_value), K.floatx())\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        p = true_positives / (predicted_positives + K.epsilon())\n",
        "        return p\n",
        "\n",
        "    return precision\n",
        "\n",
        "\n",
        "def f1_score_threshold(threshold=0.5):\n",
        "    def f1_score(y_true, y_pred, beta=1):\n",
        "        \"\"\"Computes the F score.\n",
        "         The F score is the weighted harmonic mean of precision and recall.\n",
        "        Here it is only computed as a batch-wise average, not globally.\n",
        "         This is useful for multi-label classification, where input samples can be\n",
        "        classified as sets of labels. By only using accuracy (precision) a model\n",
        "        would achieve a perfect score by simply assigning every class to every\n",
        "        input. In order to avoid this, a metric should penalize incorrect class\n",
        "        assignments as well (recall). The F-beta score (ranged from 0.0 to 1.0)\n",
        "        computes this, as a weighted mean of the proportion of correct class\n",
        "        assignments vs. the proportion of incorrect class assignments.\n",
        "         With beta = 1, this is equivalent to a F-measure. With beta < 1, assigning\n",
        "        correct classes becomes more important, and with beta > 1 the metric is\n",
        "        instead weighted towards penalizing incorrect class assignments.\n",
        "        \"\"\"\n",
        "        threshold_value = threshold\n",
        "        if beta < 0:\n",
        "            raise ValueError('The lowest choosable beta is zero (only precision).')\n",
        "        # If there are no true positives, fix the F score at 0 like sklearn.\n",
        "        if K.sum(K.round(K.clip(y_true, 0, 1))) == 0:\n",
        "            return 0\n",
        "        precision = precision_threshold(threshold_value)\n",
        "        recall = recall_threshold(threshold_value)\n",
        "        p = precision(y_true, y_pred)\n",
        "        r = recall(y_true, y_pred)\n",
        "        bb = beta ** 2\n",
        "        fbeta_score = (1 + bb) * (p * r) / (bb * p + r + K.epsilon())\n",
        "        return fbeta_score\n",
        "\n",
        "    return f1_score\n",
        "\n",
        "\n",
        "def recall_threshold(threshold=0.5):\n",
        "    def recall(y_true, y_pred):\n",
        "        \"\"\"Recall metric.\n",
        "         Only computes a batch-wise average of recall.\n",
        "         Computes the recall, a metric for multi-label classification of\n",
        "        how many relevant items are selected.\n",
        "        \"\"\"\n",
        "        threshold_value = threshold\n",
        "        y_pred = K.cast(K.greater(K.clip(y_pred, 0, 1), threshold_value), K.floatx())\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        r = true_positives / (possible_positives + K.epsilon())\n",
        "        return r\n",
        "\n",
        "    return recall\n",
        "\n",
        "\n",
        "def get_metrics(threshold):\n",
        "    return {\n",
        "        'precision': precision_threshold(threshold=threshold),\n",
        "        'recall': recall_threshold(threshold=threshold),\n",
        "        'f1_score': f1_score_threshold(threshold=threshold)\n",
        "    }\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6oIw3TwkP1nd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Model compilation\n",
        "We create a function to create a simple Sequential Dense model with given parameters"
      ]
    },
    {
      "metadata": {
        "id": "rPkB66cW8Tfs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_model(optimizer, loss, metrics):\n",
        "  \"\"\"\n",
        "  Creates then compiles a model and returns it.\n",
        "  The model is very simple : One input layer followed by one Dense layer.\n",
        "  \"\"\"\n",
        "  model = Sequential()\n",
        "  # We use a Dense layer with 3 neurons in order to match the labels's shape.\n",
        "  # Softmax activation to get an output range of [0, 1]\n",
        "  model.add(Dense(3, activation='softmax', input_shape=(IMAGE_SIZE*IMAGE_SIZE,)))\n",
        "  \n",
        "  model.compile(optimizer=optimizer,\n",
        "               loss=loss,\n",
        "               metrics=metrics)\n",
        "  model.summary()\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UuQOKSEUj2a3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Train and validation data\n",
        "We get the data for training and validation. Then we change labels to get an array of 3 element in range of [0, 1]"
      ]
    },
    {
      "metadata": {
        "id": "Xdm6tFtgj2sT",
        "colab_type": "code",
        "outputId": "21095a67-0b98-4a88-a416-65ee17b1cf33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        }
      },
      "cell_type": "code",
      "source": [
        "[X_train, Y_train] = generate_dataset_classification(300, 20)\n",
        "[X_valid, Y_valid] = generate_dataset_classification(60, 20)\n",
        "Y_train = np_utils.to_categorical(Y_train)\n",
        "Y_valid = np_utils.to_categorical(Y_valid)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating data:\n",
            "0\n",
            "10\n",
            "20\n",
            "30\n",
            "40\n",
            "50\n",
            "60\n",
            "70\n",
            "80\n",
            "90\n",
            "100\n",
            "110\n",
            "120\n",
            "130\n",
            "140\n",
            "150\n",
            "160\n",
            "170\n",
            "180\n",
            "190\n",
            "200\n",
            "210\n",
            "220\n",
            "230\n",
            "240\n",
            "250\n",
            "260\n",
            "270\n",
            "280\n",
            "290\n",
            "Creating data:\n",
            "0\n",
            "10\n",
            "20\n",
            "30\n",
            "40\n",
            "50\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "X3gWBEQIP5Pm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Model training"
      ]
    },
    {
      "metadata": {
        "id": "iykQSCDr4avw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Stochastic gradient descent\n",
        "We train our model with SGD.\n",
        "We use an important number of epochs because our learning rate is small (in order to avoid oscillations around a minimum)."
      ]
    },
    {
      "metadata": {
        "id": "ouw8L0VkP94Z",
        "colab_type": "code",
        "outputId": "2ed10027-1577-41fa-9760-870e201e37fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 62665
        }
      },
      "cell_type": "code",
      "source": [
        "optimizer = SGD(lr=0.0001, momentum=0.0, decay=0.0, nesterov=False) # 0.001 learning rate without modifications during gradient descent\n",
        "loss = 'binary_crossentropy'\n",
        "metrics = [get_metrics(0.5)['precision'], get_metrics(0.5)['recall'], get_metrics(0.5)['f1_score']]\n",
        "\n",
        "model_sgd = get_model(optimizer, loss, metrics)\n",
        "\n",
        "history_sgd = model_sgd.fit(X_train, Y_train,\n",
        "          epochs=3000,\n",
        "          batch_size=64,\n",
        "          validation_data=(X_valid, Y_valid)\n",
        "         )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 3)                 15555     \n",
            "=================================================================\n",
            "Total params: 15,555\n",
            "Trainable params: 15,555\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 300 samples, validate on 60 samples\n",
            "Epoch 1/3000\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.7741 - precision: 0.2269 - recall: 0.1167 - f1_score: 0.1501 - val_loss: 0.7743 - val_precision: 0.2593 - val_recall: 0.1167 - val_f1_score: 0.1609\n",
            "Epoch 2/3000\n",
            "300/300 [==============================] - 0s 121us/step - loss: 0.7503 - precision: 0.3023 - recall: 0.0833 - f1_score: 0.1293 - val_loss: 0.7543 - val_precision: 0.2500 - val_recall: 0.0667 - val_f1_score: 0.1053\n",
            "Epoch 3/3000\n",
            "300/300 [==============================] - 0s 122us/step - loss: 0.7371 - precision: 0.1737 - recall: 0.0267 - f1_score: 0.0456 - val_loss: 0.7438 - val_precision: 0.2727 - val_recall: 0.0500 - val_f1_score: 0.0845\n",
            "Epoch 4/3000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.7298 - precision: 0.0660 - recall: 0.0067 - f1_score: 0.0121 - val_loss: 0.7365 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00\n",
            "Epoch 5/3000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.7247 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00 - val_loss: 0.7307 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00\n",
            "Epoch 6/3000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.7208 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00 - val_loss: 0.7270 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00\n",
            "Epoch 7/3000\n",
            "300/300 [==============================] - 0s 113us/step - loss: 0.7174 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00 - val_loss: 0.7229 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00\n",
            "Epoch 8/3000\n",
            "300/300 [==============================] - 0s 106us/step - loss: 0.7144 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00 - val_loss: 0.7192 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00\n",
            "Epoch 9/3000\n",
            "300/300 [==============================] - 0s 113us/step - loss: 0.7114 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00 - val_loss: 0.7158 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00\n",
            "Epoch 10/3000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.7085 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00 - val_loss: 0.7125 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00\n",
            "Epoch 11/3000\n",
            "300/300 [==============================] - 0s 126us/step - loss: 0.7059 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00 - val_loss: 0.7093 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00\n",
            "Epoch 12/3000\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.7034 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00 - val_loss: 0.7066 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00\n",
            "Epoch 13/3000\n",
            "300/300 [==============================] - 0s 108us/step - loss: 0.7009 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00 - val_loss: 0.7036 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00\n",
            "Epoch 14/3000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.6985 - precision: 0.0733 - recall: 0.0033 - f1_score: 0.0064 - val_loss: 0.7009 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00\n",
            "Epoch 15/3000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.6962 - precision: 0.2133 - recall: 0.0033 - f1_score: 0.0066 - val_loss: 0.6981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00\n",
            "Epoch 16/3000\n",
            "300/300 [==============================] - 0s 113us/step - loss: 0.6941 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00 - val_loss: 0.6958 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00\n",
            "Epoch 17/3000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.6916 - precision: 0.2133 - recall: 0.0033 - f1_score: 0.0066 - val_loss: 0.6931 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00\n",
            "Epoch 18/3000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.6894 - precision: 0.2133 - recall: 0.0033 - f1_score: 0.0066 - val_loss: 0.6904 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00\n",
            "Epoch 19/3000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.6871 - precision: 0.2133 - recall: 0.0033 - f1_score: 0.0066 - val_loss: 0.6878 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00\n",
            "Epoch 20/3000\n",
            "300/300 [==============================] - 0s 108us/step - loss: 0.6845 - precision: 0.1467 - recall: 0.0033 - f1_score: 0.0065 - val_loss: 0.6854 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00\n",
            "Epoch 21/3000\n",
            "300/300 [==============================] - 0s 116us/step - loss: 0.6823 - precision: 0.2133 - recall: 0.0033 - f1_score: 0.0066 - val_loss: 0.6829 - val_precision: 1.0000 - val_recall: 0.0333 - val_f1_score: 0.0645\n",
            "Epoch 22/3000\n",
            "300/300 [==============================] - 0s 118us/step - loss: 0.6804 - precision: 0.2133 - recall: 0.0033 - f1_score: 0.0066 - val_loss: 0.6805 - val_precision: 1.0000 - val_recall: 0.0333 - val_f1_score: 0.0645\n",
            "Epoch 23/3000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.6781 - precision: 0.2133 - recall: 0.0033 - f1_score: 0.0066 - val_loss: 0.6780 - val_precision: 1.0000 - val_recall: 0.0333 - val_f1_score: 0.0645\n",
            "Epoch 24/3000\n",
            "300/300 [==============================] - 0s 109us/step - loss: 0.6764 - precision: 0.5733 - recall: 0.0100 - f1_score: 0.0196 - val_loss: 0.6756 - val_precision: 1.0000 - val_recall: 0.0333 - val_f1_score: 0.0645\n",
            "Epoch 25/3000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.6739 - precision: 0.2133 - recall: 0.0033 - f1_score: 0.0066 - val_loss: 0.6731 - val_precision: 1.0000 - val_recall: 0.0333 - val_f1_score: 0.0645\n",
            "Epoch 26/3000\n",
            "300/300 [==============================] - 0s 124us/step - loss: 0.6718 - precision: 0.4267 - recall: 0.0067 - f1_score: 0.0131 - val_loss: 0.6707 - val_precision: 1.0000 - val_recall: 0.0333 - val_f1_score: 0.0645\n",
            "Epoch 27/3000\n",
            "300/300 [==============================] - 0s 114us/step - loss: 0.6696 - precision: 0.4267 - recall: 0.0067 - f1_score: 0.0131 - val_loss: 0.6684 - val_precision: 1.0000 - val_recall: 0.0333 - val_f1_score: 0.0645\n",
            "Epoch 28/3000\n",
            "300/300 [==============================] - 0s 131us/step - loss: 0.6678 - precision: 0.6400 - recall: 0.0100 - f1_score: 0.0197 - val_loss: 0.6666 - val_precision: 1.0000 - val_recall: 0.0333 - val_f1_score: 0.0645\n",
            "Epoch 29/3000\n",
            "300/300 [==============================] - 0s 166us/step - loss: 0.6657 - precision: 0.4267 - recall: 0.0100 - f1_score: 0.0195 - val_loss: 0.6642 - val_precision: 1.0000 - val_recall: 0.0333 - val_f1_score: 0.0645\n",
            "Epoch 30/3000\n",
            "300/300 [==============================] - 0s 127us/step - loss: 0.6633 - precision: 0.3600 - recall: 0.0100 - f1_score: 0.0193 - val_loss: 0.6619 - val_precision: 1.0000 - val_recall: 0.0333 - val_f1_score: 0.0645\n",
            "Epoch 31/3000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.6618 - precision: 0.6400 - recall: 0.0100 - f1_score: 0.0197 - val_loss: 0.6596 - val_precision: 1.0000 - val_recall: 0.0333 - val_f1_score: 0.0645\n",
            "Epoch 32/3000\n",
            "300/300 [==============================] - 0s 133us/step - loss: 0.6595 - precision: 0.5733 - recall: 0.0100 - f1_score: 0.0196 - val_loss: 0.6572 - val_precision: 1.0000 - val_recall: 0.0333 - val_f1_score: 0.0645\n",
            "Epoch 33/3000\n",
            "300/300 [==============================] - 0s 134us/step - loss: 0.6576 - precision: 0.4267 - recall: 0.0100 - f1_score: 0.0195 - val_loss: 0.6551 - val_precision: 1.0000 - val_recall: 0.0333 - val_f1_score: 0.0645\n",
            "Epoch 34/3000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.6556 - precision: 0.5733 - recall: 0.0100 - f1_score: 0.0196 - val_loss: 0.6530 - val_precision: 1.0000 - val_recall: 0.0333 - val_f1_score: 0.0645\n",
            "Epoch 35/3000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.6535 - precision: 0.4267 - recall: 0.0100 - f1_score: 0.0195 - val_loss: 0.6507 - val_precision: 1.0000 - val_recall: 0.0333 - val_f1_score: 0.0645\n",
            "Epoch 36/3000\n",
            "300/300 [==============================] - 0s 114us/step - loss: 0.6515 - precision: 0.4267 - recall: 0.0100 - f1_score: 0.0195 - val_loss: 0.6485 - val_precision: 1.0000 - val_recall: 0.0333 - val_f1_score: 0.0645\n",
            "Epoch 37/3000\n",
            "300/300 [==============================] - 0s 129us/step - loss: 0.6501 - precision: 0.5733 - recall: 0.0100 - f1_score: 0.0196 - val_loss: 0.6469 - val_precision: 1.0000 - val_recall: 0.0333 - val_f1_score: 0.0645\n",
            "Epoch 38/3000\n",
            "300/300 [==============================] - 0s 118us/step - loss: 0.6479 - precision: 0.4267 - recall: 0.0100 - f1_score: 0.0195 - val_loss: 0.6450 - val_precision: 1.0000 - val_recall: 0.0333 - val_f1_score: 0.0645\n",
            "Epoch 39/3000\n",
            "300/300 [==============================] - 0s 120us/step - loss: 0.6459 - precision: 0.5333 - recall: 0.0100 - f1_score: 0.0196 - val_loss: 0.6430 - val_precision: 1.0000 - val_recall: 0.0333 - val_f1_score: 0.0645\n",
            "Epoch 40/3000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.6440 - precision: 0.5733 - recall: 0.0100 - f1_score: 0.0196 - val_loss: 0.6409 - val_precision: 1.0000 - val_recall: 0.0333 - val_f1_score: 0.0645\n",
            "Epoch 41/3000\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.6422 - precision: 0.4267 - recall: 0.0100 - f1_score: 0.0195 - val_loss: 0.6389 - val_precision: 1.0000 - val_recall: 0.0333 - val_f1_score: 0.0645\n",
            "Epoch 42/3000\n",
            "300/300 [==============================] - 0s 117us/step - loss: 0.6407 - precision: 0.5333 - recall: 0.0100 - f1_score: 0.0196 - val_loss: 0.6367 - val_precision: 1.0000 - val_recall: 0.0333 - val_f1_score: 0.0645\n",
            "Epoch 43/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.6384 - precision: 0.4267 - recall: 0.0100 - f1_score: 0.0195 - val_loss: 0.6348 - val_precision: 1.0000 - val_recall: 0.0333 - val_f1_score: 0.0645\n",
            "Epoch 44/3000\n",
            "300/300 [==============================] - 0s 110us/step - loss: 0.6370 - precision: 0.3600 - recall: 0.0100 - f1_score: 0.0194 - val_loss: 0.6328 - val_precision: 1.0000 - val_recall: 0.0333 - val_f1_score: 0.0645\n",
            "Epoch 45/3000\n",
            "300/300 [==============================] - 0s 128us/step - loss: 0.6349 - precision: 0.4267 - recall: 0.0100 - f1_score: 0.0195 - val_loss: 0.6308 - val_precision: 1.0000 - val_recall: 0.0333 - val_f1_score: 0.0645\n",
            "Epoch 46/3000\n",
            "300/300 [==============================] - 0s 121us/step - loss: 0.6334 - precision: 0.6400 - recall: 0.0100 - f1_score: 0.0197 - val_loss: 0.6289 - val_precision: 1.0000 - val_recall: 0.0333 - val_f1_score: 0.0645\n",
            "Epoch 47/3000\n",
            "300/300 [==============================] - 0s 141us/step - loss: 0.6316 - precision: 0.5733 - recall: 0.0100 - f1_score: 0.0196 - val_loss: 0.6270 - val_precision: 1.0000 - val_recall: 0.0333 - val_f1_score: 0.0645\n",
            "Epoch 48/3000\n",
            "300/300 [==============================] - 0s 111us/step - loss: 0.6299 - precision: 0.4267 - recall: 0.0100 - f1_score: 0.0195 - val_loss: 0.6252 - val_precision: 1.0000 - val_recall: 0.0333 - val_f1_score: 0.0645\n",
            "Epoch 49/3000\n",
            "300/300 [==============================] - 0s 139us/step - loss: 0.6281 - precision: 0.3200 - recall: 0.0100 - f1_score: 0.0194 - val_loss: 0.6235 - val_precision: 1.0000 - val_recall: 0.0333 - val_f1_score: 0.0645\n",
            "Epoch 50/3000\n",
            "300/300 [==============================] - 0s 115us/step - loss: 0.6265 - precision: 0.2400 - recall: 0.0133 - f1_score: 0.0252 - val_loss: 0.6215 - val_precision: 1.0000 - val_recall: 0.0333 - val_f1_score: 0.0645\n",
            "Epoch 51/3000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.6247 - precision: 0.7467 - recall: 0.0133 - f1_score: 0.0262 - val_loss: 0.6197 - val_precision: 1.0000 - val_recall: 0.0333 - val_f1_score: 0.0645\n",
            "Epoch 52/3000\n",
            "300/300 [==============================] - 0s 108us/step - loss: 0.6230 - precision: 0.3600 - recall: 0.0133 - f1_score: 0.0253 - val_loss: 0.6181 - val_precision: 1.0000 - val_recall: 0.0500 - val_f1_score: 0.0952\n",
            "Epoch 53/3000\n",
            "300/300 [==============================] - 0s 115us/step - loss: 0.6216 - precision: 0.4622 - recall: 0.0167 - f1_score: 0.0321 - val_loss: 0.6163 - val_precision: 1.0000 - val_recall: 0.0333 - val_f1_score: 0.0645\n",
            "Epoch 54/3000\n",
            "300/300 [==============================] - 0s 101us/step - loss: 0.6198 - precision: 0.7867 - recall: 0.0167 - f1_score: 0.0326 - val_loss: 0.6147 - val_precision: 1.0000 - val_recall: 0.0333 - val_f1_score: 0.0645\n",
            "Epoch 55/3000\n",
            "300/300 [==============================] - 0s 116us/step - loss: 0.6183 - precision: 0.6756 - recall: 0.0167 - f1_score: 0.0323 - val_loss: 0.6129 - val_precision: 1.0000 - val_recall: 0.0500 - val_f1_score: 0.0952\n",
            "Epoch 56/3000\n",
            "300/300 [==============================] - 0s 115us/step - loss: 0.6166 - precision: 0.6800 - recall: 0.0167 - f1_score: 0.0325 - val_loss: 0.6111 - val_precision: 1.0000 - val_recall: 0.0500 - val_f1_score: 0.0952\n",
            "Epoch 57/3000\n",
            "300/300 [==============================] - 0s 103us/step - loss: 0.6152 - precision: 0.4622 - recall: 0.0133 - f1_score: 0.0258 - val_loss: 0.6096 - val_precision: 1.0000 - val_recall: 0.0500 - val_f1_score: 0.0952\n",
            "Epoch 58/3000\n",
            "300/300 [==============================] - 0s 136us/step - loss: 0.6135 - precision: 0.6089 - recall: 0.0200 - f1_score: 0.0386 - val_loss: 0.6081 - val_precision: 1.0000 - val_recall: 0.0500 - val_f1_score: 0.0952\n",
            "Epoch 59/3000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.6118 - precision: 0.6444 - recall: 0.0167 - f1_score: 0.0324 - val_loss: 0.6065 - val_precision: 1.0000 - val_recall: 0.0500 - val_f1_score: 0.0952\n",
            "Epoch 60/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.6108 - precision: 0.4622 - recall: 0.0167 - f1_score: 0.0321 - val_loss: 0.6047 - val_precision: 1.0000 - val_recall: 0.0500 - val_f1_score: 0.0952\n",
            "Epoch 61/3000\n",
            "300/300 [==============================] - 0s 110us/step - loss: 0.6088 - precision: 0.6444 - recall: 0.0200 - f1_score: 0.0386 - val_loss: 0.6032 - val_precision: 1.0000 - val_recall: 0.0500 - val_f1_score: 0.0952\n",
            "Epoch 62/3000\n",
            "300/300 [==============================] - 0s 104us/step - loss: 0.6073 - precision: 0.6222 - recall: 0.0233 - f1_score: 0.0446 - val_loss: 0.6017 - val_precision: 1.0000 - val_recall: 0.0500 - val_f1_score: 0.0952\n",
            "Epoch 63/3000\n",
            "300/300 [==============================] - 0s 104us/step - loss: 0.6058 - precision: 0.8222 - recall: 0.0233 - f1_score: 0.0452 - val_loss: 0.6001 - val_precision: 1.0000 - val_recall: 0.0500 - val_f1_score: 0.0952\n",
            "Epoch 64/3000\n",
            "300/300 [==============================] - 0s 115us/step - loss: 0.6045 - precision: 0.6400 - recall: 0.0233 - f1_score: 0.0446 - val_loss: 0.5987 - val_precision: 1.0000 - val_recall: 0.0500 - val_f1_score: 0.0952\n",
            "Epoch 65/3000\n",
            "300/300 [==============================] - 0s 109us/step - loss: 0.6032 - precision: 0.6067 - recall: 0.0233 - f1_score: 0.0449 - val_loss: 0.5970 - val_precision: 1.0000 - val_recall: 0.0500 - val_f1_score: 0.0952\n",
            "Epoch 66/3000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.6015 - precision: 0.6267 - recall: 0.0233 - f1_score: 0.0448 - val_loss: 0.5953 - val_precision: 0.7500 - val_recall: 0.0500 - val_f1_score: 0.0937\n",
            "Epoch 67/3000\n",
            "300/300 [==============================] - 0s 104us/step - loss: 0.5999 - precision: 0.2895 - recall: 0.0233 - f1_score: 0.0425 - val_loss: 0.5941 - val_precision: 0.7500 - val_recall: 0.0500 - val_f1_score: 0.0937\n",
            "Epoch 68/3000\n",
            "300/300 [==============================] - 0s 119us/step - loss: 0.5988 - precision: 0.7467 - recall: 0.0233 - f1_score: 0.0448 - val_loss: 0.5925 - val_precision: 0.7500 - val_recall: 0.0500 - val_f1_score: 0.0937\n",
            "Epoch 69/3000\n",
            "300/300 [==============================] - 0s 127us/step - loss: 0.5969 - precision: 0.7133 - recall: 0.0233 - f1_score: 0.0450 - val_loss: 0.5909 - val_precision: 0.7500 - val_recall: 0.0500 - val_f1_score: 0.0937\n",
            "Epoch 70/3000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.5956 - precision: 0.5244 - recall: 0.0233 - f1_score: 0.0445 - val_loss: 0.5893 - val_precision: 0.7500 - val_recall: 0.0500 - val_f1_score: 0.0937\n",
            "Epoch 71/3000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.5942 - precision: 0.5867 - recall: 0.0233 - f1_score: 0.0445 - val_loss: 0.5876 - val_precision: 0.7500 - val_recall: 0.0500 - val_f1_score: 0.0937\n",
            "Epoch 72/3000\n",
            "300/300 [==============================] - 0s 122us/step - loss: 0.5930 - precision: 0.5733 - recall: 0.0233 - f1_score: 0.0446 - val_loss: 0.5861 - val_precision: 0.7500 - val_recall: 0.0500 - val_f1_score: 0.0937\n",
            "Epoch 73/3000\n",
            "300/300 [==============================] - 0s 110us/step - loss: 0.5915 - precision: 0.5191 - recall: 0.0233 - f1_score: 0.0438 - val_loss: 0.5847 - val_precision: 0.7500 - val_recall: 0.0500 - val_f1_score: 0.0937\n",
            "Epoch 74/3000\n",
            "300/300 [==============================] - 0s 108us/step - loss: 0.5900 - precision: 0.5564 - recall: 0.0233 - f1_score: 0.0440 - val_loss: 0.5833 - val_precision: 0.7500 - val_recall: 0.0500 - val_f1_score: 0.0937\n",
            "Epoch 75/3000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.5885 - precision: 0.3767 - recall: 0.0233 - f1_score: 0.0437 - val_loss: 0.5818 - val_precision: 0.7500 - val_recall: 0.0500 - val_f1_score: 0.0937\n",
            "Epoch 76/3000\n",
            "300/300 [==============================] - 0s 110us/step - loss: 0.5878 - precision: 0.5422 - recall: 0.0267 - f1_score: 0.0496 - val_loss: 0.5804 - val_precision: 0.7500 - val_recall: 0.0500 - val_f1_score: 0.0937\n",
            "Epoch 77/3000\n",
            "300/300 [==============================] - 0s 145us/step - loss: 0.5857 - precision: 0.4764 - recall: 0.0267 - f1_score: 0.0504 - val_loss: 0.5792 - val_precision: 0.7500 - val_recall: 0.0500 - val_f1_score: 0.0937\n",
            "Epoch 78/3000\n",
            "300/300 [==============================] - 0s 134us/step - loss: 0.5844 - precision: 0.2778 - recall: 0.0267 - f1_score: 0.0482 - val_loss: 0.5780 - val_precision: 0.7500 - val_recall: 0.0500 - val_f1_score: 0.0937\n",
            "Epoch 79/3000\n",
            "300/300 [==============================] - 0s 108us/step - loss: 0.5833 - precision: 0.4200 - recall: 0.0267 - f1_score: 0.0489 - val_loss: 0.5767 - val_precision: 0.7500 - val_recall: 0.0500 - val_f1_score: 0.0937\n",
            "Epoch 80/3000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.5819 - precision: 0.5449 - recall: 0.0267 - f1_score: 0.0500 - val_loss: 0.5753 - val_precision: 0.7500 - val_recall: 0.0500 - val_f1_score: 0.0937\n",
            "Epoch 81/3000\n",
            "300/300 [==============================] - 0s 113us/step - loss: 0.5805 - precision: 0.5067 - recall: 0.0267 - f1_score: 0.0500 - val_loss: 0.5739 - val_precision: 0.7500 - val_recall: 0.0500 - val_f1_score: 0.0937\n",
            "Epoch 82/3000\n",
            "300/300 [==============================] - 0s 116us/step - loss: 0.5792 - precision: 0.5178 - recall: 0.0267 - f1_score: 0.0503 - val_loss: 0.5725 - val_precision: 0.7500 - val_recall: 0.0500 - val_f1_score: 0.0937\n",
            "Epoch 83/3000\n",
            "300/300 [==============================] - 0s 109us/step - loss: 0.5782 - precision: 0.4756 - recall: 0.0300 - f1_score: 0.0562 - val_loss: 0.5713 - val_precision: 0.7500 - val_recall: 0.0500 - val_f1_score: 0.0937\n",
            "Epoch 84/3000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.5765 - precision: 0.4680 - recall: 0.0300 - f1_score: 0.0562 - val_loss: 0.5699 - val_precision: 0.7500 - val_recall: 0.0500 - val_f1_score: 0.0937\n",
            "Epoch 85/3000\n",
            "300/300 [==============================] - 0s 135us/step - loss: 0.5753 - precision: 0.6300 - recall: 0.0333 - f1_score: 0.0623 - val_loss: 0.5688 - val_precision: 0.7500 - val_recall: 0.0500 - val_f1_score: 0.0937\n",
            "Epoch 86/3000\n",
            "300/300 [==============================] - 0s 102us/step - loss: 0.5745 - precision: 0.4480 - recall: 0.0333 - f1_score: 0.0614 - val_loss: 0.5673 - val_precision: 0.7500 - val_recall: 0.0500 - val_f1_score: 0.0937\n",
            "Epoch 87/3000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.5728 - precision: 0.4827 - recall: 0.0333 - f1_score: 0.0618 - val_loss: 0.5659 - val_precision: 0.7500 - val_recall: 0.0500 - val_f1_score: 0.0937\n",
            "Epoch 88/3000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.5714 - precision: 0.5067 - recall: 0.0433 - f1_score: 0.0793 - val_loss: 0.5645 - val_precision: 0.7500 - val_recall: 0.0500 - val_f1_score: 0.0937\n",
            "Epoch 89/3000\n",
            "300/300 [==============================] - 0s 103us/step - loss: 0.5703 - precision: 0.5828 - recall: 0.0533 - f1_score: 0.0969 - val_loss: 0.5633 - val_precision: 0.7500 - val_recall: 0.0500 - val_f1_score: 0.0937\n",
            "Epoch 90/3000\n",
            "300/300 [==============================] - 0s 102us/step - loss: 0.5691 - precision: 0.6253 - recall: 0.0633 - f1_score: 0.1146 - val_loss: 0.5620 - val_precision: 0.7500 - val_recall: 0.0500 - val_f1_score: 0.0937\n",
            "Epoch 91/3000\n",
            "300/300 [==============================] - 0s 126us/step - loss: 0.5678 - precision: 0.5627 - recall: 0.0700 - f1_score: 0.1218 - val_loss: 0.5608 - val_precision: 0.7500 - val_recall: 0.0500 - val_f1_score: 0.0937\n",
            "Epoch 92/3000\n",
            "300/300 [==============================] - 0s 122us/step - loss: 0.5667 - precision: 0.6883 - recall: 0.0733 - f1_score: 0.1311 - val_loss: 0.5595 - val_precision: 0.7500 - val_recall: 0.0500 - val_f1_score: 0.0937\n",
            "Epoch 93/3000\n",
            "300/300 [==============================] - 0s 106us/step - loss: 0.5652 - precision: 0.7200 - recall: 0.0733 - f1_score: 0.1313 - val_loss: 0.5584 - val_precision: 0.7500 - val_recall: 0.0500 - val_f1_score: 0.0937\n",
            "Epoch 94/3000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.5641 - precision: 0.6613 - recall: 0.0800 - f1_score: 0.1420 - val_loss: 0.5574 - val_precision: 0.7500 - val_recall: 0.0500 - val_f1_score: 0.0937\n",
            "Epoch 95/3000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.5629 - precision: 0.6829 - recall: 0.0767 - f1_score: 0.1375 - val_loss: 0.5563 - val_precision: 0.8000 - val_recall: 0.0667 - val_f1_score: 0.1231\n",
            "Epoch 96/3000\n",
            "300/300 [==============================] - 0s 81us/step - loss: 0.5617 - precision: 0.6540 - recall: 0.0767 - f1_score: 0.1349 - val_loss: 0.5550 - val_precision: 0.8000 - val_recall: 0.0667 - val_f1_score: 0.1231\n",
            "Epoch 97/3000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.5609 - precision: 0.7331 - recall: 0.0933 - f1_score: 0.1645 - val_loss: 0.5538 - val_precision: 0.8000 - val_recall: 0.0667 - val_f1_score: 0.1231\n",
            "Epoch 98/3000\n",
            "300/300 [==============================] - 0s 101us/step - loss: 0.5593 - precision: 0.6844 - recall: 0.0933 - f1_score: 0.1615 - val_loss: 0.5528 - val_precision: 0.8000 - val_recall: 0.0667 - val_f1_score: 0.1231\n",
            "Epoch 99/3000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.5582 - precision: 0.7046 - recall: 0.1000 - f1_score: 0.1737 - val_loss: 0.5517 - val_precision: 0.8000 - val_recall: 0.0667 - val_f1_score: 0.1231\n",
            "Epoch 100/3000\n",
            "300/300 [==============================] - 0s 118us/step - loss: 0.5570 - precision: 0.7074 - recall: 0.0967 - f1_score: 0.1697 - val_loss: 0.5503 - val_precision: 0.8000 - val_recall: 0.0667 - val_f1_score: 0.1231\n",
            "Epoch 101/3000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.5558 - precision: 0.7326 - recall: 0.1067 - f1_score: 0.1858 - val_loss: 0.5491 - val_precision: 0.8333 - val_recall: 0.0833 - val_f1_score: 0.1515\n",
            "Epoch 102/3000\n",
            "300/300 [==============================] - 0s 121us/step - loss: 0.5550 - precision: 0.7346 - recall: 0.1000 - f1_score: 0.1748 - val_loss: 0.5480 - val_precision: 0.8571 - val_recall: 0.1000 - val_f1_score: 0.1791\n",
            "Epoch 103/3000\n",
            "300/300 [==============================] - 0s 105us/step - loss: 0.5535 - precision: 0.7261 - recall: 0.1000 - f1_score: 0.1754 - val_loss: 0.5468 - val_precision: 0.7500 - val_recall: 0.1000 - val_f1_score: 0.1765\n",
            "Epoch 104/3000\n",
            "300/300 [==============================] - 0s 103us/step - loss: 0.5525 - precision: 0.7425 - recall: 0.1067 - f1_score: 0.1856 - val_loss: 0.5456 - val_precision: 0.6667 - val_recall: 0.1000 - val_f1_score: 0.1739\n",
            "Epoch 105/3000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.5514 - precision: 0.7637 - recall: 0.1167 - f1_score: 0.2022 - val_loss: 0.5443 - val_precision: 0.7000 - val_recall: 0.1167 - val_f1_score: 0.2000\n",
            "Epoch 106/3000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.5503 - precision: 0.7387 - recall: 0.1467 - f1_score: 0.2418 - val_loss: 0.5431 - val_precision: 0.7000 - val_recall: 0.1167 - val_f1_score: 0.2000\n",
            "Epoch 107/3000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.5493 - precision: 0.8201 - recall: 0.1500 - f1_score: 0.2486 - val_loss: 0.5420 - val_precision: 0.7000 - val_recall: 0.1167 - val_f1_score: 0.2000\n",
            "Epoch 108/3000\n",
            "300/300 [==============================] - 0s 103us/step - loss: 0.5479 - precision: 0.7685 - recall: 0.1567 - f1_score: 0.2587 - val_loss: 0.5410 - val_precision: 0.7000 - val_recall: 0.1167 - val_f1_score: 0.2000\n",
            "Epoch 109/3000\n",
            "300/300 [==============================] - 0s 102us/step - loss: 0.5470 - precision: 0.7941 - recall: 0.1633 - f1_score: 0.2684 - val_loss: 0.5398 - val_precision: 0.7273 - val_recall: 0.1333 - val_f1_score: 0.2254\n",
            "Epoch 110/3000\n",
            "300/300 [==============================] - 0s 101us/step - loss: 0.5458 - precision: 0.7519 - recall: 0.1733 - f1_score: 0.2812 - val_loss: 0.5388 - val_precision: 0.7273 - val_recall: 0.1333 - val_f1_score: 0.2254\n",
            "Epoch 111/3000\n",
            "300/300 [==============================] - 0s 82us/step - loss: 0.5446 - precision: 0.8127 - recall: 0.1733 - f1_score: 0.2828 - val_loss: 0.5376 - val_precision: 0.7273 - val_recall: 0.1333 - val_f1_score: 0.2254\n",
            "Epoch 112/3000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.5437 - precision: 0.7672 - recall: 0.1833 - f1_score: 0.2949 - val_loss: 0.5368 - val_precision: 0.7273 - val_recall: 0.1333 - val_f1_score: 0.2254\n",
            "Epoch 113/3000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.5427 - precision: 0.7933 - recall: 0.1833 - f1_score: 0.2970 - val_loss: 0.5359 - val_precision: 0.7273 - val_recall: 0.1333 - val_f1_score: 0.2254\n",
            "Epoch 114/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.5415 - precision: 0.8352 - recall: 0.1800 - f1_score: 0.2938 - val_loss: 0.5346 - val_precision: 0.7692 - val_recall: 0.1667 - val_f1_score: 0.2740\n",
            "Epoch 115/3000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.5404 - precision: 0.8122 - recall: 0.1900 - f1_score: 0.3075 - val_loss: 0.5337 - val_precision: 0.7692 - val_recall: 0.1667 - val_f1_score: 0.2740\n",
            "Epoch 116/3000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.5392 - precision: 0.8102 - recall: 0.1933 - f1_score: 0.3107 - val_loss: 0.5327 - val_precision: 0.7500 - val_recall: 0.1500 - val_f1_score: 0.2500\n",
            "Epoch 117/3000\n",
            "300/300 [==============================] - 0s 106us/step - loss: 0.5383 - precision: 0.8089 - recall: 0.1967 - f1_score: 0.3105 - val_loss: 0.5317 - val_precision: 0.7692 - val_recall: 0.1667 - val_f1_score: 0.2740\n",
            "Epoch 118/3000\n",
            "300/300 [==============================] - 0s 103us/step - loss: 0.5372 - precision: 0.8181 - recall: 0.1967 - f1_score: 0.3138 - val_loss: 0.5306 - val_precision: 0.7692 - val_recall: 0.1667 - val_f1_score: 0.2740\n",
            "Epoch 119/3000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.5361 - precision: 0.8021 - recall: 0.1967 - f1_score: 0.3132 - val_loss: 0.5294 - val_precision: 0.7692 - val_recall: 0.1667 - val_f1_score: 0.2740\n",
            "Epoch 120/3000\n",
            "300/300 [==============================] - 0s 81us/step - loss: 0.5350 - precision: 0.8023 - recall: 0.2000 - f1_score: 0.3191 - val_loss: 0.5284 - val_precision: 0.7692 - val_recall: 0.1667 - val_f1_score: 0.2740\n",
            "Epoch 121/3000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.5343 - precision: 0.8138 - recall: 0.2000 - f1_score: 0.3184 - val_loss: 0.5274 - val_precision: 0.7857 - val_recall: 0.1833 - val_f1_score: 0.2973\n",
            "Epoch 122/3000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.5331 - precision: 0.8350 - recall: 0.2033 - f1_score: 0.3240 - val_loss: 0.5265 - val_precision: 0.7857 - val_recall: 0.1833 - val_f1_score: 0.2973\n",
            "Epoch 123/3000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.5323 - precision: 0.8293 - recall: 0.2067 - f1_score: 0.3273 - val_loss: 0.5256 - val_precision: 0.7857 - val_recall: 0.1833 - val_f1_score: 0.2973\n",
            "Epoch 124/3000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.5310 - precision: 0.8301 - recall: 0.2100 - f1_score: 0.3322 - val_loss: 0.5246 - val_precision: 0.7857 - val_recall: 0.1833 - val_f1_score: 0.2973\n",
            "Epoch 125/3000\n",
            "300/300 [==============================] - 0s 101us/step - loss: 0.5301 - precision: 0.8325 - recall: 0.2100 - f1_score: 0.3345 - val_loss: 0.5236 - val_precision: 0.7857 - val_recall: 0.1833 - val_f1_score: 0.2973\n",
            "Epoch 126/3000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.5290 - precision: 0.8261 - recall: 0.2167 - f1_score: 0.3411 - val_loss: 0.5226 - val_precision: 0.7857 - val_recall: 0.1833 - val_f1_score: 0.2973\n",
            "Epoch 127/3000\n",
            "300/300 [==============================] - 0s 109us/step - loss: 0.5283 - precision: 0.7962 - recall: 0.2200 - f1_score: 0.3422 - val_loss: 0.5217 - val_precision: 0.7857 - val_recall: 0.1833 - val_f1_score: 0.2973\n",
            "Epoch 128/3000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.5269 - precision: 0.7946 - recall: 0.2200 - f1_score: 0.3430 - val_loss: 0.5207 - val_precision: 0.8000 - val_recall: 0.2000 - val_f1_score: 0.3200\n",
            "Epoch 129/3000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.5260 - precision: 0.7805 - recall: 0.2233 - f1_score: 0.3440 - val_loss: 0.5197 - val_precision: 0.8000 - val_recall: 0.2000 - val_f1_score: 0.3200\n",
            "Epoch 130/3000\n",
            "300/300 [==============================] - 0s 124us/step - loss: 0.5251 - precision: 0.8321 - recall: 0.2200 - f1_score: 0.3444 - val_loss: 0.5189 - val_precision: 0.8000 - val_recall: 0.2000 - val_f1_score: 0.3200\n",
            "Epoch 131/3000\n",
            "300/300 [==============================] - 0s 101us/step - loss: 0.5243 - precision: 0.8019 - recall: 0.2200 - f1_score: 0.3435 - val_loss: 0.5179 - val_precision: 0.8000 - val_recall: 0.2000 - val_f1_score: 0.3200\n",
            "Epoch 132/3000\n",
            "300/300 [==============================] - 0s 82us/step - loss: 0.5231 - precision: 0.8493 - recall: 0.2167 - f1_score: 0.3397 - val_loss: 0.5171 - val_precision: 0.8000 - val_recall: 0.2000 - val_f1_score: 0.3200\n",
            "Epoch 133/3000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.5220 - precision: 0.8394 - recall: 0.2233 - f1_score: 0.3515 - val_loss: 0.5160 - val_precision: 0.8000 - val_recall: 0.2000 - val_f1_score: 0.3200\n",
            "Epoch 134/3000\n",
            "300/300 [==============================] - 0s 107us/step - loss: 0.5211 - precision: 0.8296 - recall: 0.2267 - f1_score: 0.3529 - val_loss: 0.5151 - val_precision: 0.8000 - val_recall: 0.2000 - val_f1_score: 0.3200\n",
            "Epoch 135/3000\n",
            "300/300 [==============================] - 0s 103us/step - loss: 0.5201 - precision: 0.8311 - recall: 0.2300 - f1_score: 0.3600 - val_loss: 0.5143 - val_precision: 0.8000 - val_recall: 0.2000 - val_f1_score: 0.3200\n",
            "Epoch 136/3000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.5191 - precision: 0.8483 - recall: 0.2367 - f1_score: 0.3690 - val_loss: 0.5133 - val_precision: 0.8000 - val_recall: 0.2000 - val_f1_score: 0.3200\n",
            "Epoch 137/3000\n",
            "300/300 [==============================] - 0s 108us/step - loss: 0.5182 - precision: 0.8573 - recall: 0.2433 - f1_score: 0.3768 - val_loss: 0.5123 - val_precision: 0.8000 - val_recall: 0.2000 - val_f1_score: 0.3200\n",
            "Epoch 138/3000\n",
            "300/300 [==============================] - 0s 108us/step - loss: 0.5173 - precision: 0.8302 - recall: 0.2500 - f1_score: 0.3807 - val_loss: 0.5116 - val_precision: 0.8000 - val_recall: 0.2000 - val_f1_score: 0.3200\n",
            "Epoch 139/3000\n",
            "300/300 [==============================] - 0s 173us/step - loss: 0.5166 - precision: 0.8465 - recall: 0.2467 - f1_score: 0.3785 - val_loss: 0.5107 - val_precision: 0.8000 - val_recall: 0.2000 - val_f1_score: 0.3200\n",
            "Epoch 140/3000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.5157 - precision: 0.8517 - recall: 0.2500 - f1_score: 0.3846 - val_loss: 0.5097 - val_precision: 0.8000 - val_recall: 0.2000 - val_f1_score: 0.3200\n",
            "Epoch 141/3000\n",
            "300/300 [==============================] - 0s 177us/step - loss: 0.5146 - precision: 0.8630 - recall: 0.2600 - f1_score: 0.3987 - val_loss: 0.5088 - val_precision: 0.8000 - val_recall: 0.2000 - val_f1_score: 0.3200\n",
            "Epoch 142/3000\n",
            "300/300 [==============================] - 0s 143us/step - loss: 0.5136 - precision: 0.8433 - recall: 0.2500 - f1_score: 0.3854 - val_loss: 0.5078 - val_precision: 0.8125 - val_recall: 0.2167 - val_f1_score: 0.3421\n",
            "Epoch 143/3000\n",
            "300/300 [==============================] - 0s 112us/step - loss: 0.5126 - precision: 0.8409 - recall: 0.2500 - f1_score: 0.3850 - val_loss: 0.5070 - val_precision: 0.8125 - val_recall: 0.2167 - val_f1_score: 0.3421\n",
            "Epoch 144/3000\n",
            "300/300 [==============================] - 0s 144us/step - loss: 0.5120 - precision: 0.8577 - recall: 0.2633 - f1_score: 0.4015 - val_loss: 0.5061 - val_precision: 0.8125 - val_recall: 0.2167 - val_f1_score: 0.3421\n",
            "Epoch 145/3000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.5108 - precision: 0.8487 - recall: 0.2800 - f1_score: 0.4133 - val_loss: 0.5054 - val_precision: 0.8125 - val_recall: 0.2167 - val_f1_score: 0.3421\n",
            "Epoch 146/3000\n",
            "300/300 [==============================] - 0s 135us/step - loss: 0.5103 - precision: 0.8650 - recall: 0.2700 - f1_score: 0.4075 - val_loss: 0.5044 - val_precision: 0.8125 - val_recall: 0.2167 - val_f1_score: 0.3421\n",
            "Epoch 147/3000\n",
            "300/300 [==============================] - 0s 102us/step - loss: 0.5090 - precision: 0.8478 - recall: 0.2833 - f1_score: 0.4238 - val_loss: 0.5036 - val_precision: 0.8125 - val_recall: 0.2167 - val_f1_score: 0.3421\n",
            "Epoch 148/3000\n",
            "300/300 [==============================] - 0s 107us/step - loss: 0.5083 - precision: 0.8650 - recall: 0.2900 - f1_score: 0.4324 - val_loss: 0.5029 - val_precision: 0.8125 - val_recall: 0.2167 - val_f1_score: 0.3421\n",
            "Epoch 149/3000\n",
            "300/300 [==============================] - 0s 105us/step - loss: 0.5079 - precision: 0.8704 - recall: 0.2767 - f1_score: 0.4164 - val_loss: 0.5019 - val_precision: 0.8235 - val_recall: 0.2333 - val_f1_score: 0.3636\n",
            "Epoch 150/3000\n",
            "300/300 [==============================] - 0s 117us/step - loss: 0.5065 - precision: 0.8581 - recall: 0.2933 - f1_score: 0.4360 - val_loss: 0.5013 - val_precision: 0.8333 - val_recall: 0.2500 - val_f1_score: 0.3846\n",
            "Epoch 151/3000\n",
            "300/300 [==============================] - 0s 110us/step - loss: 0.5055 - precision: 0.8796 - recall: 0.2967 - f1_score: 0.4411 - val_loss: 0.5004 - val_precision: 0.8235 - val_recall: 0.2333 - val_f1_score: 0.3636\n",
            "Epoch 152/3000\n",
            "300/300 [==============================] - 0s 107us/step - loss: 0.5046 - precision: 0.8628 - recall: 0.2967 - f1_score: 0.4359 - val_loss: 0.4994 - val_precision: 0.8000 - val_recall: 0.2667 - val_f1_score: 0.4000\n",
            "Epoch 153/3000\n",
            "300/300 [==============================] - 0s 109us/step - loss: 0.5039 - precision: 0.8553 - recall: 0.3000 - f1_score: 0.4420 - val_loss: 0.4987 - val_precision: 0.8571 - val_recall: 0.3000 - val_f1_score: 0.4444\n",
            "Epoch 154/3000\n",
            "300/300 [==============================] - 0s 126us/step - loss: 0.5030 - precision: 0.8727 - recall: 0.2967 - f1_score: 0.4426 - val_loss: 0.4978 - val_precision: 0.8571 - val_recall: 0.3000 - val_f1_score: 0.4444\n",
            "Epoch 155/3000\n",
            "300/300 [==============================] - 0s 107us/step - loss: 0.5021 - precision: 0.8761 - recall: 0.3067 - f1_score: 0.4526 - val_loss: 0.4969 - val_precision: 0.8333 - val_recall: 0.3333 - val_f1_score: 0.4762\n",
            "Epoch 156/3000\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.5014 - precision: 0.8755 - recall: 0.3033 - f1_score: 0.4499 - val_loss: 0.4959 - val_precision: 0.8462 - val_recall: 0.3667 - val_f1_score: 0.5116\n",
            "Epoch 157/3000\n",
            "300/300 [==============================] - 0s 128us/step - loss: 0.5003 - precision: 0.8766 - recall: 0.3167 - f1_score: 0.4644 - val_loss: 0.4950 - val_precision: 0.8462 - val_recall: 0.3667 - val_f1_score: 0.5116\n",
            "Epoch 158/3000\n",
            "300/300 [==============================] - 0s 122us/step - loss: 0.4997 - precision: 0.8495 - recall: 0.3167 - f1_score: 0.4602 - val_loss: 0.4943 - val_precision: 0.8462 - val_recall: 0.3667 - val_f1_score: 0.5116\n",
            "Epoch 159/3000\n",
            "300/300 [==============================] - 0s 112us/step - loss: 0.4986 - precision: 0.8755 - recall: 0.3267 - f1_score: 0.4755 - val_loss: 0.4935 - val_precision: 0.8462 - val_recall: 0.3667 - val_f1_score: 0.5116\n",
            "Epoch 160/3000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.4977 - precision: 0.8646 - recall: 0.3300 - f1_score: 0.4763 - val_loss: 0.4929 - val_precision: 0.8462 - val_recall: 0.3667 - val_f1_score: 0.5116\n",
            "Epoch 161/3000\n",
            "300/300 [==============================] - 0s 126us/step - loss: 0.4971 - precision: 0.8845 - recall: 0.3333 - f1_score: 0.4823 - val_loss: 0.4921 - val_precision: 0.8519 - val_recall: 0.3833 - val_f1_score: 0.5287\n",
            "Epoch 162/3000\n",
            "300/300 [==============================] - 0s 117us/step - loss: 0.4961 - precision: 0.8716 - recall: 0.3233 - f1_score: 0.4688 - val_loss: 0.4911 - val_precision: 0.8621 - val_recall: 0.4167 - val_f1_score: 0.5618\n",
            "Epoch 163/3000\n",
            "300/300 [==============================] - 0s 102us/step - loss: 0.4955 - precision: 0.8635 - recall: 0.3333 - f1_score: 0.4804 - val_loss: 0.4903 - val_precision: 0.8519 - val_recall: 0.3833 - val_f1_score: 0.5287\n",
            "Epoch 164/3000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.4948 - precision: 0.8600 - recall: 0.3400 - f1_score: 0.4863 - val_loss: 0.4897 - val_precision: 0.8462 - val_recall: 0.3667 - val_f1_score: 0.5116\n",
            "Epoch 165/3000\n",
            "300/300 [==============================] - 0s 142us/step - loss: 0.4938 - precision: 0.8834 - recall: 0.3300 - f1_score: 0.4782 - val_loss: 0.4889 - val_precision: 0.8519 - val_recall: 0.3833 - val_f1_score: 0.5287\n",
            "Epoch 166/3000\n",
            "300/300 [==============================] - 0s 101us/step - loss: 0.4930 - precision: 0.8576 - recall: 0.3533 - f1_score: 0.4970 - val_loss: 0.4884 - val_precision: 0.8462 - val_recall: 0.3667 - val_f1_score: 0.5116\n",
            "Epoch 167/3000\n",
            "300/300 [==============================] - 0s 133us/step - loss: 0.4923 - precision: 0.8802 - recall: 0.3333 - f1_score: 0.4821 - val_loss: 0.4874 - val_precision: 0.8519 - val_recall: 0.3833 - val_f1_score: 0.5287\n",
            "Epoch 168/3000\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.4913 - precision: 0.8905 - recall: 0.3333 - f1_score: 0.4831 - val_loss: 0.4865 - val_precision: 0.8571 - val_recall: 0.4000 - val_f1_score: 0.5455\n",
            "Epoch 169/3000\n",
            "300/300 [==============================] - 0s 140us/step - loss: 0.4907 - precision: 0.8869 - recall: 0.3533 - f1_score: 0.5039 - val_loss: 0.4858 - val_precision: 0.8667 - val_recall: 0.4333 - val_f1_score: 0.5778\n",
            "Epoch 170/3000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.4901 - precision: 0.8828 - recall: 0.3467 - f1_score: 0.4931 - val_loss: 0.4848 - val_precision: 0.8788 - val_recall: 0.4833 - val_f1_score: 0.6237\n",
            "Epoch 171/3000\n",
            "300/300 [==============================] - 0s 155us/step - loss: 0.4888 - precision: 0.8851 - recall: 0.3733 - f1_score: 0.5236 - val_loss: 0.4842 - val_precision: 0.8710 - val_recall: 0.4500 - val_f1_score: 0.5934\n",
            "Epoch 172/3000\n",
            "300/300 [==============================] - 0s 120us/step - loss: 0.4879 - precision: 0.8829 - recall: 0.3767 - f1_score: 0.5257 - val_loss: 0.4837 - val_precision: 0.8667 - val_recall: 0.4333 - val_f1_score: 0.5778\n",
            "Epoch 173/3000\n",
            "300/300 [==============================] - 0s 104us/step - loss: 0.4873 - precision: 0.8902 - recall: 0.3733 - f1_score: 0.5256 - val_loss: 0.4829 - val_precision: 0.8667 - val_recall: 0.4333 - val_f1_score: 0.5778\n",
            "Epoch 174/3000\n",
            "300/300 [==============================] - 0s 110us/step - loss: 0.4864 - precision: 0.8974 - recall: 0.3633 - f1_score: 0.5167 - val_loss: 0.4822 - val_precision: 0.8710 - val_recall: 0.4500 - val_f1_score: 0.5934\n",
            "Epoch 175/3000\n",
            "300/300 [==============================] - 0s 105us/step - loss: 0.4855 - precision: 0.9003 - recall: 0.3800 - f1_score: 0.5291 - val_loss: 0.4814 - val_precision: 0.8750 - val_recall: 0.4667 - val_f1_score: 0.6087\n",
            "Epoch 176/3000\n",
            "300/300 [==============================] - 0s 145us/step - loss: 0.4851 - precision: 0.8929 - recall: 0.3700 - f1_score: 0.5215 - val_loss: 0.4807 - val_precision: 0.8824 - val_recall: 0.5000 - val_f1_score: 0.6383\n",
            "Epoch 177/3000\n",
            "300/300 [==============================] - 0s 112us/step - loss: 0.4840 - precision: 0.8916 - recall: 0.3900 - f1_score: 0.5408 - val_loss: 0.4800 - val_precision: 0.8824 - val_recall: 0.5000 - val_f1_score: 0.6383\n",
            "Epoch 178/3000\n",
            "300/300 [==============================] - 0s 119us/step - loss: 0.4832 - precision: 0.8830 - recall: 0.3967 - f1_score: 0.5440 - val_loss: 0.4794 - val_precision: 0.8857 - val_recall: 0.5167 - val_f1_score: 0.6526\n",
            "Epoch 179/3000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.4826 - precision: 0.8914 - recall: 0.3800 - f1_score: 0.5325 - val_loss: 0.4788 - val_precision: 0.8857 - val_recall: 0.5167 - val_f1_score: 0.6526\n",
            "Epoch 180/3000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.4817 - precision: 0.8944 - recall: 0.3933 - f1_score: 0.5443 - val_loss: 0.4783 - val_precision: 0.8824 - val_recall: 0.5000 - val_f1_score: 0.6383\n",
            "Epoch 181/3000\n",
            "300/300 [==============================] - 0s 104us/step - loss: 0.4811 - precision: 0.9024 - recall: 0.3900 - f1_score: 0.5412 - val_loss: 0.4772 - val_precision: 0.8824 - val_recall: 0.5000 - val_f1_score: 0.6383\n",
            "Epoch 182/3000\n",
            "300/300 [==============================] - 0s 108us/step - loss: 0.4806 - precision: 0.8976 - recall: 0.3967 - f1_score: 0.5489 - val_loss: 0.4764 - val_precision: 0.8857 - val_recall: 0.5167 - val_f1_score: 0.6526\n",
            "Epoch 183/3000\n",
            "300/300 [==============================] - 0s 78us/step - loss: 0.4795 - precision: 0.8981 - recall: 0.4100 - f1_score: 0.5616 - val_loss: 0.4760 - val_precision: 0.8857 - val_recall: 0.5167 - val_f1_score: 0.6526\n",
            "Epoch 184/3000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.4786 - precision: 0.9025 - recall: 0.4033 - f1_score: 0.5570 - val_loss: 0.4752 - val_precision: 0.8889 - val_recall: 0.5333 - val_f1_score: 0.6667\n",
            "Epoch 185/3000\n",
            "300/300 [==============================] - 0s 78us/step - loss: 0.4780 - precision: 0.8949 - recall: 0.4200 - f1_score: 0.5708 - val_loss: 0.4745 - val_precision: 0.8857 - val_recall: 0.5167 - val_f1_score: 0.6526\n",
            "Epoch 186/3000\n",
            "300/300 [==============================] - 0s 119us/step - loss: 0.4777 - precision: 0.9103 - recall: 0.4067 - f1_score: 0.5596 - val_loss: 0.4737 - val_precision: 0.8889 - val_recall: 0.5333 - val_f1_score: 0.6667\n",
            "Epoch 187/3000\n",
            "300/300 [==============================] - 0s 78us/step - loss: 0.4764 - precision: 0.9078 - recall: 0.4167 - f1_score: 0.5706 - val_loss: 0.4729 - val_precision: 0.8889 - val_recall: 0.5333 - val_f1_score: 0.6667\n",
            "Epoch 188/3000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.4759 - precision: 0.9109 - recall: 0.4167 - f1_score: 0.5693 - val_loss: 0.4722 - val_precision: 0.8889 - val_recall: 0.5333 - val_f1_score: 0.6667\n",
            "Epoch 189/3000\n",
            "300/300 [==============================] - 0s 111us/step - loss: 0.4751 - precision: 0.9043 - recall: 0.4433 - f1_score: 0.5947 - val_loss: 0.4714 - val_precision: 0.8889 - val_recall: 0.5333 - val_f1_score: 0.6667\n",
            "Epoch 190/3000\n",
            "300/300 [==============================] - 0s 78us/step - loss: 0.4742 - precision: 0.9102 - recall: 0.4333 - f1_score: 0.5863 - val_loss: 0.4705 - val_precision: 0.8889 - val_recall: 0.5333 - val_f1_score: 0.6667\n",
            "Epoch 191/3000\n",
            "300/300 [==============================] - 0s 102us/step - loss: 0.4735 - precision: 0.8909 - recall: 0.4533 - f1_score: 0.6003 - val_loss: 0.4699 - val_precision: 0.8889 - val_recall: 0.5333 - val_f1_score: 0.6667\n",
            "Epoch 192/3000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.4728 - precision: 0.9046 - recall: 0.4400 - f1_score: 0.5908 - val_loss: 0.4692 - val_precision: 0.8889 - val_recall: 0.5333 - val_f1_score: 0.6667\n",
            "Epoch 193/3000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.4724 - precision: 0.8973 - recall: 0.4567 - f1_score: 0.6012 - val_loss: 0.4688 - val_precision: 0.8889 - val_recall: 0.5333 - val_f1_score: 0.6667\n",
            "Epoch 194/3000\n",
            "300/300 [==============================] - 0s 78us/step - loss: 0.4715 - precision: 0.9113 - recall: 0.4400 - f1_score: 0.5917 - val_loss: 0.4679 - val_precision: 0.8857 - val_recall: 0.5167 - val_f1_score: 0.6526\n",
            "Epoch 195/3000\n",
            "300/300 [==============================] - 0s 104us/step - loss: 0.4707 - precision: 0.9050 - recall: 0.4333 - f1_score: 0.5844 - val_loss: 0.4670 - val_precision: 0.8889 - val_recall: 0.5333 - val_f1_score: 0.6667\n",
            "Epoch 196/3000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.4700 - precision: 0.9022 - recall: 0.4500 - f1_score: 0.5992 - val_loss: 0.4665 - val_precision: 0.8919 - val_recall: 0.5500 - val_f1_score: 0.6804\n",
            "Epoch 197/3000\n",
            "300/300 [==============================] - 0s 109us/step - loss: 0.4693 - precision: 0.9011 - recall: 0.4733 - f1_score: 0.6200 - val_loss: 0.4659 - val_precision: 0.8919 - val_recall: 0.5500 - val_f1_score: 0.6804\n",
            "Epoch 198/3000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.4685 - precision: 0.9001 - recall: 0.4700 - f1_score: 0.6153 - val_loss: 0.4654 - val_precision: 0.8889 - val_recall: 0.5333 - val_f1_score: 0.6667\n",
            "Epoch 199/3000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.4677 - precision: 0.9130 - recall: 0.4567 - f1_score: 0.6076 - val_loss: 0.4646 - val_precision: 0.8919 - val_recall: 0.5500 - val_f1_score: 0.6804\n",
            "Epoch 200/3000\n",
            "300/300 [==============================] - 0s 106us/step - loss: 0.4672 - precision: 0.9025 - recall: 0.4633 - f1_score: 0.6114 - val_loss: 0.4639 - val_precision: 0.8947 - val_recall: 0.5667 - val_f1_score: 0.6939\n",
            "Epoch 201/3000\n",
            "300/300 [==============================] - 0s 108us/step - loss: 0.4668 - precision: 0.9058 - recall: 0.4633 - f1_score: 0.6106 - val_loss: 0.4633 - val_precision: 0.8947 - val_recall: 0.5667 - val_f1_score: 0.6939\n",
            "Epoch 202/3000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.4656 - precision: 0.9034 - recall: 0.4700 - f1_score: 0.6182 - val_loss: 0.4628 - val_precision: 0.8947 - val_recall: 0.5667 - val_f1_score: 0.6939\n",
            "Epoch 203/3000\n",
            "300/300 [==============================] - 0s 116us/step - loss: 0.4653 - precision: 0.8988 - recall: 0.4667 - f1_score: 0.6101 - val_loss: 0.4623 - val_precision: 0.8974 - val_recall: 0.5833 - val_f1_score: 0.7071\n",
            "Epoch 204/3000\n",
            "300/300 [==============================] - 0s 146us/step - loss: 0.4643 - precision: 0.9007 - recall: 0.4800 - f1_score: 0.6239 - val_loss: 0.4618 - val_precision: 0.8974 - val_recall: 0.5833 - val_f1_score: 0.7071\n",
            "Epoch 205/3000\n",
            "300/300 [==============================] - 0s 128us/step - loss: 0.4638 - precision: 0.9072 - recall: 0.4800 - f1_score: 0.6270 - val_loss: 0.4612 - val_precision: 0.8974 - val_recall: 0.5833 - val_f1_score: 0.7071\n",
            "Epoch 206/3000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.4632 - precision: 0.9252 - recall: 0.4800 - f1_score: 0.6291 - val_loss: 0.4602 - val_precision: 0.9000 - val_recall: 0.6000 - val_f1_score: 0.7200\n",
            "Epoch 207/3000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.4622 - precision: 0.9058 - recall: 0.4867 - f1_score: 0.6326 - val_loss: 0.4597 - val_precision: 0.8974 - val_recall: 0.5833 - val_f1_score: 0.7071\n",
            "Epoch 208/3000\n",
            "300/300 [==============================] - 0s 103us/step - loss: 0.4615 - precision: 0.9151 - recall: 0.4900 - f1_score: 0.6369 - val_loss: 0.4590 - val_precision: 0.8974 - val_recall: 0.5833 - val_f1_score: 0.7071\n",
            "Epoch 209/3000\n",
            "300/300 [==============================] - 0s 101us/step - loss: 0.4608 - precision: 0.9169 - recall: 0.4867 - f1_score: 0.6328 - val_loss: 0.4584 - val_precision: 0.9000 - val_recall: 0.6000 - val_f1_score: 0.7200\n",
            "Epoch 210/3000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.4603 - precision: 0.9047 - recall: 0.4933 - f1_score: 0.6363 - val_loss: 0.4578 - val_precision: 0.9000 - val_recall: 0.6000 - val_f1_score: 0.7200\n",
            "Epoch 211/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.4595 - precision: 0.9082 - recall: 0.5000 - f1_score: 0.6439 - val_loss: 0.4572 - val_precision: 0.9000 - val_recall: 0.6000 - val_f1_score: 0.7200\n",
            "Epoch 212/3000\n",
            "300/300 [==============================] - 0s 104us/step - loss: 0.4591 - precision: 0.9110 - recall: 0.5000 - f1_score: 0.6440 - val_loss: 0.4566 - val_precision: 0.9000 - val_recall: 0.6000 - val_f1_score: 0.7200\n",
            "Epoch 213/3000\n",
            "300/300 [==============================] - 0s 127us/step - loss: 0.4584 - precision: 0.9138 - recall: 0.5100 - f1_score: 0.6540 - val_loss: 0.4560 - val_precision: 0.9000 - val_recall: 0.6000 - val_f1_score: 0.7200\n",
            "Epoch 214/3000\n",
            "300/300 [==============================] - 0s 102us/step - loss: 0.4574 - precision: 0.9102 - recall: 0.5067 - f1_score: 0.6508 - val_loss: 0.4554 - val_precision: 0.9000 - val_recall: 0.6000 - val_f1_score: 0.7200\n",
            "Epoch 215/3000\n",
            "300/300 [==============================] - 0s 103us/step - loss: 0.4568 - precision: 0.9111 - recall: 0.5100 - f1_score: 0.6534 - val_loss: 0.4548 - val_precision: 0.9000 - val_recall: 0.6000 - val_f1_score: 0.7200\n",
            "Epoch 216/3000\n",
            "300/300 [==============================] - 0s 102us/step - loss: 0.4561 - precision: 0.9163 - recall: 0.5100 - f1_score: 0.6549 - val_loss: 0.4543 - val_precision: 0.9000 - val_recall: 0.6000 - val_f1_score: 0.7200\n",
            "Epoch 217/3000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.4556 - precision: 0.9195 - recall: 0.5233 - f1_score: 0.6662 - val_loss: 0.4536 - val_precision: 0.9000 - val_recall: 0.6000 - val_f1_score: 0.7200\n",
            "Epoch 218/3000\n",
            "300/300 [==============================] - 0s 78us/step - loss: 0.4551 - precision: 0.9139 - recall: 0.5233 - f1_score: 0.6652 - val_loss: 0.4530 - val_precision: 0.9024 - val_recall: 0.6167 - val_f1_score: 0.7327\n",
            "Epoch 219/3000\n",
            "300/300 [==============================] - 0s 104us/step - loss: 0.4543 - precision: 0.9110 - recall: 0.5267 - f1_score: 0.6662 - val_loss: 0.4521 - val_precision: 0.9000 - val_recall: 0.6000 - val_f1_score: 0.7200\n",
            "Epoch 220/3000\n",
            "300/300 [==============================] - 0s 104us/step - loss: 0.4535 - precision: 0.9160 - recall: 0.5300 - f1_score: 0.6702 - val_loss: 0.4513 - val_precision: 0.9024 - val_recall: 0.6167 - val_f1_score: 0.7327\n",
            "Epoch 221/3000\n",
            "300/300 [==============================] - 0s 103us/step - loss: 0.4529 - precision: 0.9155 - recall: 0.5300 - f1_score: 0.6693 - val_loss: 0.4506 - val_precision: 0.9024 - val_recall: 0.6167 - val_f1_score: 0.7327\n",
            "Epoch 222/3000\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.4525 - precision: 0.9155 - recall: 0.5300 - f1_score: 0.6670 - val_loss: 0.4501 - val_precision: 0.9024 - val_recall: 0.6167 - val_f1_score: 0.7327\n",
            "Epoch 223/3000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.4516 - precision: 0.9166 - recall: 0.5400 - f1_score: 0.6779 - val_loss: 0.4495 - val_precision: 0.9024 - val_recall: 0.6167 - val_f1_score: 0.7327\n",
            "Epoch 224/3000\n",
            "300/300 [==============================] - 0s 112us/step - loss: 0.4511 - precision: 0.9191 - recall: 0.5467 - f1_score: 0.6847 - val_loss: 0.4489 - val_precision: 0.9048 - val_recall: 0.6333 - val_f1_score: 0.7451\n",
            "Epoch 225/3000\n",
            "300/300 [==============================] - 0s 108us/step - loss: 0.4507 - precision: 0.9137 - recall: 0.5400 - f1_score: 0.6771 - val_loss: 0.4486 - val_precision: 0.9048 - val_recall: 0.6333 - val_f1_score: 0.7451\n",
            "Epoch 226/3000\n",
            "300/300 [==============================] - 0s 78us/step - loss: 0.4499 - precision: 0.9124 - recall: 0.5400 - f1_score: 0.6769 - val_loss: 0.4481 - val_precision: 0.9048 - val_recall: 0.6333 - val_f1_score: 0.7451\n",
            "Epoch 227/3000\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.4493 - precision: 0.9223 - recall: 0.5533 - f1_score: 0.6912 - val_loss: 0.4474 - val_precision: 0.9048 - val_recall: 0.6333 - val_f1_score: 0.7451\n",
            "Epoch 228/3000\n",
            "300/300 [==============================] - 0s 116us/step - loss: 0.4485 - precision: 0.9164 - recall: 0.5533 - f1_score: 0.6885 - val_loss: 0.4467 - val_precision: 0.9048 - val_recall: 0.6333 - val_f1_score: 0.7451\n",
            "Epoch 229/3000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.4479 - precision: 0.9169 - recall: 0.5567 - f1_score: 0.6919 - val_loss: 0.4461 - val_precision: 0.9048 - val_recall: 0.6333 - val_f1_score: 0.7451\n",
            "Epoch 230/3000\n",
            "300/300 [==============================] - 0s 107us/step - loss: 0.4471 - precision: 0.9179 - recall: 0.5567 - f1_score: 0.6923 - val_loss: 0.4455 - val_precision: 0.9048 - val_recall: 0.6333 - val_f1_score: 0.7451\n",
            "Epoch 231/3000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.4466 - precision: 0.9224 - recall: 0.5600 - f1_score: 0.6955 - val_loss: 0.4448 - val_precision: 0.9048 - val_recall: 0.6333 - val_f1_score: 0.7451\n",
            "Epoch 232/3000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.4464 - precision: 0.9160 - recall: 0.5667 - f1_score: 0.6949 - val_loss: 0.4441 - val_precision: 0.9048 - val_recall: 0.6333 - val_f1_score: 0.7451\n",
            "Epoch 233/3000\n",
            "300/300 [==============================] - 0s 137us/step - loss: 0.4453 - precision: 0.9151 - recall: 0.5600 - f1_score: 0.6938 - val_loss: 0.4436 - val_precision: 0.9048 - val_recall: 0.6333 - val_f1_score: 0.7451\n",
            "Epoch 234/3000\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.4454 - precision: 0.9210 - recall: 0.5667 - f1_score: 0.6986 - val_loss: 0.4431 - val_precision: 0.9048 - val_recall: 0.6333 - val_f1_score: 0.7451\n",
            "Epoch 235/3000\n",
            "300/300 [==============================] - 0s 119us/step - loss: 0.4442 - precision: 0.9199 - recall: 0.5667 - f1_score: 0.7010 - val_loss: 0.4426 - val_precision: 0.9070 - val_recall: 0.6500 - val_f1_score: 0.7573\n",
            "Epoch 236/3000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.4437 - precision: 0.9250 - recall: 0.5700 - f1_score: 0.7048 - val_loss: 0.4422 - val_precision: 0.9070 - val_recall: 0.6500 - val_f1_score: 0.7573\n",
            "Epoch 237/3000\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.4428 - precision: 0.9255 - recall: 0.5767 - f1_score: 0.7105 - val_loss: 0.4415 - val_precision: 0.9070 - val_recall: 0.6500 - val_f1_score: 0.7573\n",
            "Epoch 238/3000\n",
            "300/300 [==============================] - 0s 81us/step - loss: 0.4424 - precision: 0.9212 - recall: 0.5900 - f1_score: 0.7157 - val_loss: 0.4410 - val_precision: 0.9070 - val_recall: 0.6500 - val_f1_score: 0.7573\n",
            "Epoch 239/3000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.4417 - precision: 0.9216 - recall: 0.5867 - f1_score: 0.7163 - val_loss: 0.4404 - val_precision: 0.9070 - val_recall: 0.6500 - val_f1_score: 0.7573\n",
            "Epoch 240/3000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.4412 - precision: 0.9211 - recall: 0.5900 - f1_score: 0.7186 - val_loss: 0.4398 - val_precision: 0.9091 - val_recall: 0.6667 - val_f1_score: 0.7692\n",
            "Epoch 241/3000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.4404 - precision: 0.9283 - recall: 0.5967 - f1_score: 0.7258 - val_loss: 0.4393 - val_precision: 0.9091 - val_recall: 0.6667 - val_f1_score: 0.7692\n",
            "Epoch 242/3000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.4401 - precision: 0.9218 - recall: 0.5900 - f1_score: 0.7180 - val_loss: 0.4389 - val_precision: 0.9111 - val_recall: 0.6833 - val_f1_score: 0.7810\n",
            "Epoch 243/3000\n",
            "300/300 [==============================] - 0s 106us/step - loss: 0.4400 - precision: 0.9213 - recall: 0.5967 - f1_score: 0.7240 - val_loss: 0.4386 - val_precision: 0.9111 - val_recall: 0.6833 - val_f1_score: 0.7810\n",
            "Epoch 244/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.4387 - precision: 0.9294 - recall: 0.6133 - f1_score: 0.7382 - val_loss: 0.4379 - val_precision: 0.9111 - val_recall: 0.6833 - val_f1_score: 0.7810\n",
            "Epoch 245/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.4381 - precision: 0.9286 - recall: 0.6033 - f1_score: 0.7308 - val_loss: 0.4374 - val_precision: 0.9111 - val_recall: 0.6833 - val_f1_score: 0.7810\n",
            "Epoch 246/3000\n",
            "300/300 [==============================] - 0s 105us/step - loss: 0.4376 - precision: 0.9303 - recall: 0.6100 - f1_score: 0.7361 - val_loss: 0.4367 - val_precision: 0.9111 - val_recall: 0.6833 - val_f1_score: 0.7810\n",
            "Epoch 247/3000\n",
            "300/300 [==============================] - 0s 79us/step - loss: 0.4371 - precision: 0.9294 - recall: 0.6100 - f1_score: 0.7364 - val_loss: 0.4362 - val_precision: 0.9111 - val_recall: 0.6833 - val_f1_score: 0.7810\n",
            "Epoch 248/3000\n",
            "300/300 [==============================] - 0s 104us/step - loss: 0.4364 - precision: 0.9287 - recall: 0.6100 - f1_score: 0.7361 - val_loss: 0.4355 - val_precision: 0.9111 - val_recall: 0.6833 - val_f1_score: 0.7810\n",
            "Epoch 249/3000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.4359 - precision: 0.9304 - recall: 0.6167 - f1_score: 0.7403 - val_loss: 0.4350 - val_precision: 0.9111 - val_recall: 0.6833 - val_f1_score: 0.7810\n",
            "Epoch 250/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.4353 - precision: 0.9285 - recall: 0.6167 - f1_score: 0.7406 - val_loss: 0.4344 - val_precision: 0.9111 - val_recall: 0.6833 - val_f1_score: 0.7810\n",
            "Epoch 251/3000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.4348 - precision: 0.9294 - recall: 0.6133 - f1_score: 0.7375 - val_loss: 0.4339 - val_precision: 0.9111 - val_recall: 0.6833 - val_f1_score: 0.7810\n",
            "Epoch 252/3000\n",
            "300/300 [==============================] - 0s 106us/step - loss: 0.4341 - precision: 0.9267 - recall: 0.6133 - f1_score: 0.7366 - val_loss: 0.4333 - val_precision: 0.9111 - val_recall: 0.6833 - val_f1_score: 0.7810\n",
            "Epoch 253/3000\n",
            "300/300 [==============================] - 0s 81us/step - loss: 0.4335 - precision: 0.9251 - recall: 0.6133 - f1_score: 0.7369 - val_loss: 0.4328 - val_precision: 0.9111 - val_recall: 0.6833 - val_f1_score: 0.7810\n",
            "Epoch 254/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.4331 - precision: 0.9287 - recall: 0.6133 - f1_score: 0.7382 - val_loss: 0.4324 - val_precision: 0.9111 - val_recall: 0.6833 - val_f1_score: 0.7810\n",
            "Epoch 255/3000\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.4327 - precision: 0.9271 - recall: 0.6300 - f1_score: 0.7483 - val_loss: 0.4319 - val_precision: 0.9111 - val_recall: 0.6833 - val_f1_score: 0.7810\n",
            "Epoch 256/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.4318 - precision: 0.9296 - recall: 0.6300 - f1_score: 0.7499 - val_loss: 0.4315 - val_precision: 0.9111 - val_recall: 0.6833 - val_f1_score: 0.7810\n",
            "Epoch 257/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.4313 - precision: 0.9294 - recall: 0.6333 - f1_score: 0.7520 - val_loss: 0.4308 - val_precision: 0.9111 - val_recall: 0.6833 - val_f1_score: 0.7810\n",
            "Epoch 258/3000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.4307 - precision: 0.9319 - recall: 0.6333 - f1_score: 0.7537 - val_loss: 0.4303 - val_precision: 0.9111 - val_recall: 0.6833 - val_f1_score: 0.7810\n",
            "Epoch 259/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.4301 - precision: 0.9341 - recall: 0.6433 - f1_score: 0.7607 - val_loss: 0.4298 - val_precision: 0.9111 - val_recall: 0.6833 - val_f1_score: 0.7810\n",
            "Epoch 260/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.4299 - precision: 0.9273 - recall: 0.6267 - f1_score: 0.7470 - val_loss: 0.4292 - val_precision: 0.9111 - val_recall: 0.6833 - val_f1_score: 0.7810\n",
            "Epoch 261/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.4291 - precision: 0.9318 - recall: 0.6433 - f1_score: 0.7606 - val_loss: 0.4287 - val_precision: 0.9111 - val_recall: 0.6833 - val_f1_score: 0.7810\n",
            "Epoch 262/3000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.4287 - precision: 0.9266 - recall: 0.6300 - f1_score: 0.7493 - val_loss: 0.4282 - val_precision: 0.9111 - val_recall: 0.6833 - val_f1_score: 0.7810\n",
            "Epoch 263/3000\n",
            "300/300 [==============================] - 0s 79us/step - loss: 0.4280 - precision: 0.9343 - recall: 0.6333 - f1_score: 0.7529 - val_loss: 0.4277 - val_precision: 0.9111 - val_recall: 0.6833 - val_f1_score: 0.7810\n",
            "Epoch 264/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.4274 - precision: 0.9325 - recall: 0.6367 - f1_score: 0.7551 - val_loss: 0.4275 - val_precision: 0.9111 - val_recall: 0.6833 - val_f1_score: 0.7810\n",
            "Epoch 265/3000\n",
            "300/300 [==============================] - 0s 114us/step - loss: 0.4269 - precision: 0.9303 - recall: 0.6400 - f1_score: 0.7579 - val_loss: 0.4269 - val_precision: 0.9111 - val_recall: 0.6833 - val_f1_score: 0.7810\n",
            "Epoch 266/3000\n",
            "300/300 [==============================] - 0s 79us/step - loss: 0.4266 - precision: 0.9313 - recall: 0.6433 - f1_score: 0.7591 - val_loss: 0.4264 - val_precision: 0.9111 - val_recall: 0.6833 - val_f1_score: 0.7810\n",
            "Epoch 267/3000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.4259 - precision: 0.9339 - recall: 0.6433 - f1_score: 0.7609 - val_loss: 0.4257 - val_precision: 0.9111 - val_recall: 0.6833 - val_f1_score: 0.7810\n",
            "Epoch 268/3000\n",
            "300/300 [==============================] - 0s 78us/step - loss: 0.4253 - precision: 0.9332 - recall: 0.6467 - f1_score: 0.7633 - val_loss: 0.4251 - val_precision: 0.9111 - val_recall: 0.6833 - val_f1_score: 0.7810\n",
            "Epoch 269/3000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.4249 - precision: 0.9338 - recall: 0.6433 - f1_score: 0.7605 - val_loss: 0.4247 - val_precision: 0.9130 - val_recall: 0.7000 - val_f1_score: 0.7925\n",
            "Epoch 270/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.4241 - precision: 0.9337 - recall: 0.6467 - f1_score: 0.7638 - val_loss: 0.4241 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 271/3000\n",
            "300/300 [==============================] - 0s 78us/step - loss: 0.4237 - precision: 0.9331 - recall: 0.6433 - f1_score: 0.7609 - val_loss: 0.4236 - val_precision: 0.9130 - val_recall: 0.7000 - val_f1_score: 0.7925\n",
            "Epoch 272/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.4230 - precision: 0.9333 - recall: 0.6467 - f1_score: 0.7637 - val_loss: 0.4232 - val_precision: 0.9111 - val_recall: 0.6833 - val_f1_score: 0.7810\n",
            "Epoch 273/3000\n",
            "300/300 [==============================] - 0s 122us/step - loss: 0.4228 - precision: 0.9301 - recall: 0.6433 - f1_score: 0.7590 - val_loss: 0.4227 - val_precision: 0.9111 - val_recall: 0.6833 - val_f1_score: 0.7810\n",
            "Epoch 274/3000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.4221 - precision: 0.9319 - recall: 0.6467 - f1_score: 0.7631 - val_loss: 0.4222 - val_precision: 0.9111 - val_recall: 0.6833 - val_f1_score: 0.7810\n",
            "Epoch 275/3000\n",
            "300/300 [==============================] - 0s 157us/step - loss: 0.4215 - precision: 0.9313 - recall: 0.6500 - f1_score: 0.7635 - val_loss: 0.4216 - val_precision: 0.9111 - val_recall: 0.6833 - val_f1_score: 0.7810\n",
            "Epoch 276/3000\n",
            "300/300 [==============================] - 0s 316us/step - loss: 0.4210 - precision: 0.9341 - recall: 0.6467 - f1_score: 0.7639 - val_loss: 0.4212 - val_precision: 0.9130 - val_recall: 0.7000 - val_f1_score: 0.7925\n",
            "Epoch 277/3000\n",
            "300/300 [==============================] - 0s 137us/step - loss: 0.4206 - precision: 0.9343 - recall: 0.6533 - f1_score: 0.7686 - val_loss: 0.4206 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 278/3000\n",
            "300/300 [==============================] - 0s 206us/step - loss: 0.4199 - precision: 0.9336 - recall: 0.6500 - f1_score: 0.7657 - val_loss: 0.4202 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 279/3000\n",
            "300/300 [==============================] - 0s 126us/step - loss: 0.4194 - precision: 0.9328 - recall: 0.6533 - f1_score: 0.7670 - val_loss: 0.4198 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 280/3000\n",
            "300/300 [==============================] - 0s 132us/step - loss: 0.4190 - precision: 0.9405 - recall: 0.6567 - f1_score: 0.7719 - val_loss: 0.4192 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 281/3000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.4183 - precision: 0.9335 - recall: 0.6567 - f1_score: 0.7698 - val_loss: 0.4187 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 282/3000\n",
            "300/300 [==============================] - 0s 141us/step - loss: 0.4180 - precision: 0.9346 - recall: 0.6567 - f1_score: 0.7683 - val_loss: 0.4184 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 283/3000\n",
            "300/300 [==============================] - 0s 81us/step - loss: 0.4175 - precision: 0.9408 - recall: 0.6600 - f1_score: 0.7727 - val_loss: 0.4177 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 284/3000\n",
            "300/300 [==============================] - 0s 81us/step - loss: 0.4170 - precision: 0.9340 - recall: 0.6600 - f1_score: 0.7725 - val_loss: 0.4174 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 285/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.4163 - precision: 0.9381 - recall: 0.6533 - f1_score: 0.7699 - val_loss: 0.4167 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 286/3000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.4160 - precision: 0.9289 - recall: 0.6600 - f1_score: 0.7695 - val_loss: 0.4161 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 287/3000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.4152 - precision: 0.9389 - recall: 0.6567 - f1_score: 0.7702 - val_loss: 0.4157 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 288/3000\n",
            "300/300 [==============================] - 0s 111us/step - loss: 0.4147 - precision: 0.9340 - recall: 0.6567 - f1_score: 0.7707 - val_loss: 0.4152 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 289/3000\n",
            "300/300 [==============================] - 0s 101us/step - loss: 0.4142 - precision: 0.9387 - recall: 0.6567 - f1_score: 0.7720 - val_loss: 0.4149 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 290/3000\n",
            "300/300 [==============================] - 0s 81us/step - loss: 0.4138 - precision: 0.9376 - recall: 0.6633 - f1_score: 0.7767 - val_loss: 0.4145 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 291/3000\n",
            "300/300 [==============================] - 0s 101us/step - loss: 0.4133 - precision: 0.9388 - recall: 0.6667 - f1_score: 0.7795 - val_loss: 0.4141 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 292/3000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.4130 - precision: 0.9389 - recall: 0.6600 - f1_score: 0.7745 - val_loss: 0.4136 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 293/3000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.4123 - precision: 0.9379 - recall: 0.6667 - f1_score: 0.7782 - val_loss: 0.4132 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 294/3000\n",
            "300/300 [==============================] - 0s 106us/step - loss: 0.4117 - precision: 0.9398 - recall: 0.6667 - f1_score: 0.7787 - val_loss: 0.4126 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 295/3000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.4113 - precision: 0.9436 - recall: 0.6700 - f1_score: 0.7830 - val_loss: 0.4122 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 296/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.4107 - precision: 0.9416 - recall: 0.6667 - f1_score: 0.7794 - val_loss: 0.4116 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 297/3000\n",
            "300/300 [==============================] - 0s 79us/step - loss: 0.4103 - precision: 0.9384 - recall: 0.6667 - f1_score: 0.7792 - val_loss: 0.4109 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 298/3000\n",
            "300/300 [==============================] - 0s 112us/step - loss: 0.4097 - precision: 0.9404 - recall: 0.6667 - f1_score: 0.7787 - val_loss: 0.4107 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 299/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.4094 - precision: 0.9361 - recall: 0.6633 - f1_score: 0.7747 - val_loss: 0.4102 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 300/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.4086 - precision: 0.9434 - recall: 0.6700 - f1_score: 0.7832 - val_loss: 0.4097 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 301/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.4084 - precision: 0.9440 - recall: 0.6700 - f1_score: 0.7826 - val_loss: 0.4092 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 302/3000\n",
            "300/300 [==============================] - 0s 105us/step - loss: 0.4080 - precision: 0.9411 - recall: 0.6667 - f1_score: 0.7793 - val_loss: 0.4087 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 303/3000\n",
            "300/300 [==============================] - 0s 82us/step - loss: 0.4075 - precision: 0.9400 - recall: 0.6733 - f1_score: 0.7830 - val_loss: 0.4082 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 304/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.4068 - precision: 0.9407 - recall: 0.6700 - f1_score: 0.7817 - val_loss: 0.4077 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 305/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.4068 - precision: 0.9436 - recall: 0.6700 - f1_score: 0.7832 - val_loss: 0.4074 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 306/3000\n",
            "300/300 [==============================] - 0s 112us/step - loss: 0.4061 - precision: 0.9423 - recall: 0.6767 - f1_score: 0.7861 - val_loss: 0.4067 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 307/3000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.4056 - precision: 0.9347 - recall: 0.6700 - f1_score: 0.7804 - val_loss: 0.4064 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 308/3000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.4052 - precision: 0.9380 - recall: 0.6700 - f1_score: 0.7803 - val_loss: 0.4062 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 309/3000\n",
            "300/300 [==============================] - 0s 104us/step - loss: 0.4044 - precision: 0.9447 - recall: 0.6800 - f1_score: 0.7902 - val_loss: 0.4057 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 310/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.4041 - precision: 0.9438 - recall: 0.6733 - f1_score: 0.7853 - val_loss: 0.4052 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 311/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.4036 - precision: 0.9446 - recall: 0.6767 - f1_score: 0.7880 - val_loss: 0.4048 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 312/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.4032 - precision: 0.9433 - recall: 0.6700 - f1_score: 0.7832 - val_loss: 0.4042 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 313/3000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.4028 - precision: 0.9406 - recall: 0.6800 - f1_score: 0.7885 - val_loss: 0.4039 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 314/3000\n",
            "300/300 [==============================] - 0s 105us/step - loss: 0.4023 - precision: 0.9442 - recall: 0.6800 - f1_score: 0.7904 - val_loss: 0.4036 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 315/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.4016 - precision: 0.9426 - recall: 0.6800 - f1_score: 0.7886 - val_loss: 0.4031 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 316/3000\n",
            "300/300 [==============================] - 0s 103us/step - loss: 0.4013 - precision: 0.9469 - recall: 0.6867 - f1_score: 0.7940 - val_loss: 0.4026 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 317/3000\n",
            "300/300 [==============================] - 0s 157us/step - loss: 0.4010 - precision: 0.9424 - recall: 0.6833 - f1_score: 0.7914 - val_loss: 0.4022 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 318/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.4005 - precision: 0.9440 - recall: 0.6833 - f1_score: 0.7920 - val_loss: 0.4017 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 319/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.3999 - precision: 0.9448 - recall: 0.6867 - f1_score: 0.7928 - val_loss: 0.4013 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 320/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.3994 - precision: 0.9457 - recall: 0.6900 - f1_score: 0.7970 - val_loss: 0.4009 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 321/3000\n",
            "300/300 [==============================] - 0s 103us/step - loss: 0.3990 - precision: 0.9479 - recall: 0.6800 - f1_score: 0.7889 - val_loss: 0.4006 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 322/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.3985 - precision: 0.9460 - recall: 0.6933 - f1_score: 0.7995 - val_loss: 0.4001 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 323/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.3985 - precision: 0.9439 - recall: 0.6867 - f1_score: 0.7946 - val_loss: 0.3996 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 324/3000\n",
            "300/300 [==============================] - 0s 82us/step - loss: 0.3977 - precision: 0.9462 - recall: 0.7033 - f1_score: 0.8051 - val_loss: 0.3989 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 325/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.3972 - precision: 0.9444 - recall: 0.6933 - f1_score: 0.7984 - val_loss: 0.3985 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 326/3000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.3967 - precision: 0.9473 - recall: 0.6967 - f1_score: 0.8021 - val_loss: 0.3982 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 327/3000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.3963 - precision: 0.9446 - recall: 0.6900 - f1_score: 0.7973 - val_loss: 0.3978 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 328/3000\n",
            "300/300 [==============================] - 0s 79us/step - loss: 0.3959 - precision: 0.9450 - recall: 0.6933 - f1_score: 0.7990 - val_loss: 0.3973 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 329/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.3954 - precision: 0.9465 - recall: 0.6933 - f1_score: 0.7991 - val_loss: 0.3970 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 330/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.3953 - precision: 0.9454 - recall: 0.7000 - f1_score: 0.8029 - val_loss: 0.3965 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 331/3000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.3946 - precision: 0.9460 - recall: 0.6933 - f1_score: 0.7981 - val_loss: 0.3961 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 332/3000\n",
            "300/300 [==============================] - 0s 82us/step - loss: 0.3943 - precision: 0.9456 - recall: 0.7000 - f1_score: 0.8023 - val_loss: 0.3958 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 333/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.3936 - precision: 0.9467 - recall: 0.7067 - f1_score: 0.8089 - val_loss: 0.3952 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 334/3000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.3935 - precision: 0.9465 - recall: 0.7000 - f1_score: 0.8045 - val_loss: 0.3949 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 335/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3930 - precision: 0.9467 - recall: 0.7033 - f1_score: 0.8054 - val_loss: 0.3945 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 336/3000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.3926 - precision: 0.9466 - recall: 0.7033 - f1_score: 0.8062 - val_loss: 0.3940 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 337/3000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.3919 - precision: 0.9482 - recall: 0.7033 - f1_score: 0.8048 - val_loss: 0.3936 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 338/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.3913 - precision: 0.9462 - recall: 0.7067 - f1_score: 0.8070 - val_loss: 0.3932 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 339/3000\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.3912 - precision: 0.9478 - recall: 0.7067 - f1_score: 0.8092 - val_loss: 0.3927 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 340/3000\n",
            "300/300 [==============================] - 0s 79us/step - loss: 0.3908 - precision: 0.9454 - recall: 0.7067 - f1_score: 0.8085 - val_loss: 0.3923 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 341/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.3902 - precision: 0.9468 - recall: 0.7067 - f1_score: 0.8081 - val_loss: 0.3920 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 342/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.3898 - precision: 0.9461 - recall: 0.7067 - f1_score: 0.8071 - val_loss: 0.3916 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 343/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.3894 - precision: 0.9479 - recall: 0.7100 - f1_score: 0.8096 - val_loss: 0.3912 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 344/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.3889 - precision: 0.9465 - recall: 0.7100 - f1_score: 0.8110 - val_loss: 0.3908 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 345/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.3886 - precision: 0.9462 - recall: 0.7067 - f1_score: 0.8078 - val_loss: 0.3903 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 346/3000\n",
            "300/300 [==============================] - 0s 112us/step - loss: 0.3882 - precision: 0.9449 - recall: 0.7067 - f1_score: 0.8079 - val_loss: 0.3899 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 347/3000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.3876 - precision: 0.9457 - recall: 0.7067 - f1_score: 0.8080 - val_loss: 0.3896 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 348/3000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.3872 - precision: 0.9470 - recall: 0.7167 - f1_score: 0.8151 - val_loss: 0.3892 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 349/3000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.3868 - precision: 0.9475 - recall: 0.7167 - f1_score: 0.8156 - val_loss: 0.3888 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 350/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.3863 - precision: 0.9450 - recall: 0.7100 - f1_score: 0.8098 - val_loss: 0.3886 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 351/3000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.3860 - precision: 0.9465 - recall: 0.7167 - f1_score: 0.8153 - val_loss: 0.3881 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 352/3000\n",
            "300/300 [==============================] - 0s 78us/step - loss: 0.3856 - precision: 0.9509 - recall: 0.7200 - f1_score: 0.8169 - val_loss: 0.3877 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 353/3000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.3852 - precision: 0.9474 - recall: 0.7167 - f1_score: 0.8152 - val_loss: 0.3872 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 354/3000\n",
            "300/300 [==============================] - 0s 78us/step - loss: 0.3848 - precision: 0.9471 - recall: 0.7133 - f1_score: 0.8135 - val_loss: 0.3870 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 355/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.3843 - precision: 0.9473 - recall: 0.7167 - f1_score: 0.8157 - val_loss: 0.3865 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 356/3000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.3840 - precision: 0.9473 - recall: 0.7200 - f1_score: 0.8175 - val_loss: 0.3861 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 357/3000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.3837 - precision: 0.9466 - recall: 0.7133 - f1_score: 0.8134 - val_loss: 0.3857 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 358/3000\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.3833 - precision: 0.9490 - recall: 0.7167 - f1_score: 0.8147 - val_loss: 0.3852 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 359/3000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.3827 - precision: 0.9480 - recall: 0.7167 - f1_score: 0.8157 - val_loss: 0.3848 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 360/3000\n",
            "300/300 [==============================] - 0s 82us/step - loss: 0.3822 - precision: 0.9480 - recall: 0.7133 - f1_score: 0.8138 - val_loss: 0.3844 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 361/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.3819 - precision: 0.9478 - recall: 0.7200 - f1_score: 0.8176 - val_loss: 0.3841 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 362/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.3816 - precision: 0.9474 - recall: 0.7167 - f1_score: 0.8160 - val_loss: 0.3837 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 363/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.3812 - precision: 0.9468 - recall: 0.7233 - f1_score: 0.8173 - val_loss: 0.3833 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 364/3000\n",
            "300/300 [==============================] - 0s 81us/step - loss: 0.3808 - precision: 0.9474 - recall: 0.7167 - f1_score: 0.8156 - val_loss: 0.3830 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 365/3000\n",
            "300/300 [==============================] - 0s 107us/step - loss: 0.3803 - precision: 0.9461 - recall: 0.7200 - f1_score: 0.8171 - val_loss: 0.3826 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 366/3000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.3800 - precision: 0.9471 - recall: 0.7167 - f1_score: 0.8156 - val_loss: 0.3822 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 367/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.3795 - precision: 0.9468 - recall: 0.7167 - f1_score: 0.8156 - val_loss: 0.3818 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 368/3000\n",
            "300/300 [==============================] - 0s 102us/step - loss: 0.3793 - precision: 0.9466 - recall: 0.7167 - f1_score: 0.8147 - val_loss: 0.3815 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 369/3000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.3787 - precision: 0.9466 - recall: 0.7200 - f1_score: 0.8176 - val_loss: 0.3813 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 370/3000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.3788 - precision: 0.9478 - recall: 0.7233 - f1_score: 0.8201 - val_loss: 0.3808 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 371/3000\n",
            "300/300 [==============================] - 0s 123us/step - loss: 0.3779 - precision: 0.9471 - recall: 0.7233 - f1_score: 0.8197 - val_loss: 0.3804 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 372/3000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.3776 - precision: 0.9475 - recall: 0.7267 - f1_score: 0.8213 - val_loss: 0.3801 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 373/3000\n",
            "300/300 [==============================] - 0s 79us/step - loss: 0.3772 - precision: 0.9475 - recall: 0.7233 - f1_score: 0.8201 - val_loss: 0.3797 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 374/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.3767 - precision: 0.9478 - recall: 0.7233 - f1_score: 0.8202 - val_loss: 0.3793 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 375/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.3765 - precision: 0.9472 - recall: 0.7267 - f1_score: 0.8213 - val_loss: 0.3788 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 376/3000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.3760 - precision: 0.9480 - recall: 0.7233 - f1_score: 0.8200 - val_loss: 0.3785 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 377/3000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.3756 - precision: 0.9471 - recall: 0.7233 - f1_score: 0.8201 - val_loss: 0.3781 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 378/3000\n",
            "300/300 [==============================] - 0s 79us/step - loss: 0.3752 - precision: 0.9471 - recall: 0.7233 - f1_score: 0.8197 - val_loss: 0.3777 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 379/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.3748 - precision: 0.9502 - recall: 0.7233 - f1_score: 0.8190 - val_loss: 0.3774 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 380/3000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.3745 - precision: 0.9467 - recall: 0.7233 - f1_score: 0.8198 - val_loss: 0.3770 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 381/3000\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.3742 - precision: 0.9471 - recall: 0.7233 - f1_score: 0.8193 - val_loss: 0.3766 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 382/3000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.3737 - precision: 0.9479 - recall: 0.7233 - f1_score: 0.8196 - val_loss: 0.3762 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 383/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.3735 - precision: 0.9483 - recall: 0.7233 - f1_score: 0.8206 - val_loss: 0.3759 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 384/3000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.3731 - precision: 0.9477 - recall: 0.7233 - f1_score: 0.8199 - val_loss: 0.3756 - val_precision: 0.9167 - val_recall: 0.7333 - val_f1_score: 0.8148\n",
            "Epoch 385/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.3730 - precision: 0.9473 - recall: 0.7200 - f1_score: 0.8177 - val_loss: 0.3753 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 386/3000\n",
            "300/300 [==============================] - 0s 79us/step - loss: 0.3723 - precision: 0.9423 - recall: 0.7200 - f1_score: 0.8157 - val_loss: 0.3750 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 387/3000\n",
            "300/300 [==============================] - 0s 79us/step - loss: 0.3718 - precision: 0.9486 - recall: 0.7267 - f1_score: 0.8219 - val_loss: 0.3746 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 388/3000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.3716 - precision: 0.9482 - recall: 0.7267 - f1_score: 0.8217 - val_loss: 0.3744 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 389/3000\n",
            "300/300 [==============================] - 0s 80us/step - loss: 0.3711 - precision: 0.9471 - recall: 0.7267 - f1_score: 0.8218 - val_loss: 0.3739 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 390/3000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.3707 - precision: 0.9489 - recall: 0.7233 - f1_score: 0.8205 - val_loss: 0.3737 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 391/3000\n",
            "300/300 [==============================] - 0s 79us/step - loss: 0.3705 - precision: 0.9462 - recall: 0.7233 - f1_score: 0.8186 - val_loss: 0.3734 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 392/3000\n",
            "300/300 [==============================] - 0s 79us/step - loss: 0.3700 - precision: 0.9476 - recall: 0.7267 - f1_score: 0.8223 - val_loss: 0.3730 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 393/3000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.3697 - precision: 0.9481 - recall: 0.7267 - f1_score: 0.8227 - val_loss: 0.3726 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 394/3000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.3694 - precision: 0.9475 - recall: 0.7267 - f1_score: 0.8221 - val_loss: 0.3722 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 395/3000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.3688 - precision: 0.9494 - recall: 0.7233 - f1_score: 0.8203 - val_loss: 0.3719 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 396/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.3686 - precision: 0.9480 - recall: 0.7267 - f1_score: 0.8224 - val_loss: 0.3715 - val_precision: 0.9167 - val_recall: 0.7333 - val_f1_score: 0.8148\n",
            "Epoch 397/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.3682 - precision: 0.9474 - recall: 0.7300 - f1_score: 0.8235 - val_loss: 0.3711 - val_precision: 0.9167 - val_recall: 0.7333 - val_f1_score: 0.8148\n",
            "Epoch 398/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.3679 - precision: 0.9471 - recall: 0.7267 - f1_score: 0.8221 - val_loss: 0.3706 - val_precision: 0.9167 - val_recall: 0.7333 - val_f1_score: 0.8148\n",
            "Epoch 399/3000\n",
            "300/300 [==============================] - 0s 110us/step - loss: 0.3677 - precision: 0.9478 - recall: 0.7233 - f1_score: 0.8191 - val_loss: 0.3703 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 400/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.3671 - precision: 0.9474 - recall: 0.7267 - f1_score: 0.8217 - val_loss: 0.3701 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 401/3000\n",
            "300/300 [==============================] - 0s 80us/step - loss: 0.3667 - precision: 0.9478 - recall: 0.7267 - f1_score: 0.8224 - val_loss: 0.3696 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 402/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.3665 - precision: 0.9485 - recall: 0.7267 - f1_score: 0.8224 - val_loss: 0.3692 - val_precision: 0.9149 - val_recall: 0.7167 - val_f1_score: 0.8037\n",
            "Epoch 403/3000\n",
            "300/300 [==============================] - 0s 78us/step - loss: 0.3662 - precision: 0.9481 - recall: 0.7267 - f1_score: 0.8216 - val_loss: 0.3688 - val_precision: 0.9167 - val_recall: 0.7333 - val_f1_score: 0.8148\n",
            "Epoch 404/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.3656 - precision: 0.9468 - recall: 0.7267 - f1_score: 0.8214 - val_loss: 0.3685 - val_precision: 0.9167 - val_recall: 0.7333 - val_f1_score: 0.8148\n",
            "Epoch 405/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.3654 - precision: 0.9490 - recall: 0.7300 - f1_score: 0.8236 - val_loss: 0.3681 - val_precision: 0.9167 - val_recall: 0.7333 - val_f1_score: 0.8148\n",
            "Epoch 406/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.3651 - precision: 0.9483 - recall: 0.7267 - f1_score: 0.8213 - val_loss: 0.3678 - val_precision: 0.9167 - val_recall: 0.7333 - val_f1_score: 0.8148\n",
            "Epoch 407/3000\n",
            "300/300 [==============================] - 0s 115us/step - loss: 0.3646 - precision: 0.9504 - recall: 0.7300 - f1_score: 0.8244 - val_loss: 0.3675 - val_precision: 0.9167 - val_recall: 0.7333 - val_f1_score: 0.8148\n",
            "Epoch 408/3000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.3642 - precision: 0.9470 - recall: 0.7267 - f1_score: 0.8220 - val_loss: 0.3671 - val_precision: 0.9167 - val_recall: 0.7333 - val_f1_score: 0.8148\n",
            "Epoch 409/3000\n",
            "300/300 [==============================] - 0s 134us/step - loss: 0.3639 - precision: 0.9479 - recall: 0.7300 - f1_score: 0.8215 - val_loss: 0.3667 - val_precision: 0.9167 - val_recall: 0.7333 - val_f1_score: 0.8148\n",
            "Epoch 410/3000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.3637 - precision: 0.9463 - recall: 0.7300 - f1_score: 0.8233 - val_loss: 0.3664 - val_precision: 0.9167 - val_recall: 0.7333 - val_f1_score: 0.8148\n",
            "Epoch 411/3000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.3640 - precision: 0.9533 - recall: 0.7300 - f1_score: 0.8259 - val_loss: 0.3662 - val_precision: 0.9167 - val_recall: 0.7333 - val_f1_score: 0.8148\n",
            "Epoch 412/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3629 - precision: 0.9473 - recall: 0.7300 - f1_score: 0.8241 - val_loss: 0.3659 - val_precision: 0.9167 - val_recall: 0.7333 - val_f1_score: 0.8148\n",
            "Epoch 413/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3625 - precision: 0.9477 - recall: 0.7300 - f1_score: 0.8238 - val_loss: 0.3656 - val_precision: 0.9167 - val_recall: 0.7333 - val_f1_score: 0.8148\n",
            "Epoch 414/3000\n",
            "300/300 [==============================] - 0s 81us/step - loss: 0.3621 - precision: 0.9477 - recall: 0.7300 - f1_score: 0.8238 - val_loss: 0.3652 - val_precision: 0.9167 - val_recall: 0.7333 - val_f1_score: 0.8148\n",
            "Epoch 415/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.3617 - precision: 0.9479 - recall: 0.7333 - f1_score: 0.8265 - val_loss: 0.3650 - val_precision: 0.9167 - val_recall: 0.7333 - val_f1_score: 0.8148\n",
            "Epoch 416/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.3615 - precision: 0.9590 - recall: 0.7300 - f1_score: 0.8271 - val_loss: 0.3646 - val_precision: 0.9167 - val_recall: 0.7333 - val_f1_score: 0.8148\n",
            "Epoch 417/3000\n",
            "300/300 [==============================] - 0s 79us/step - loss: 0.3612 - precision: 0.9483 - recall: 0.7300 - f1_score: 0.8247 - val_loss: 0.3643 - val_precision: 0.9167 - val_recall: 0.7333 - val_f1_score: 0.8148\n",
            "Epoch 418/3000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.3610 - precision: 0.9608 - recall: 0.7300 - f1_score: 0.8288 - val_loss: 0.3639 - val_precision: 0.9167 - val_recall: 0.7333 - val_f1_score: 0.8148\n",
            "Epoch 419/3000\n",
            "300/300 [==============================] - 0s 81us/step - loss: 0.3603 - precision: 0.9483 - recall: 0.7333 - f1_score: 0.8267 - val_loss: 0.3636 - val_precision: 0.9167 - val_recall: 0.7333 - val_f1_score: 0.8148\n",
            "Epoch 420/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.3603 - precision: 0.9563 - recall: 0.7333 - f1_score: 0.8299 - val_loss: 0.3632 - val_precision: 0.9167 - val_recall: 0.7333 - val_f1_score: 0.8148\n",
            "Epoch 421/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.3598 - precision: 0.9480 - recall: 0.7367 - f1_score: 0.8280 - val_loss: 0.3628 - val_precision: 0.9167 - val_recall: 0.7333 - val_f1_score: 0.8148\n",
            "Epoch 422/3000\n",
            "300/300 [==============================] - 0s 102us/step - loss: 0.3593 - precision: 0.9486 - recall: 0.7367 - f1_score: 0.8285 - val_loss: 0.3625 - val_precision: 0.9167 - val_recall: 0.7333 - val_f1_score: 0.8148\n",
            "Epoch 423/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.3591 - precision: 0.9531 - recall: 0.7333 - f1_score: 0.8278 - val_loss: 0.3622 - val_precision: 0.9167 - val_recall: 0.7333 - val_f1_score: 0.8148\n",
            "Epoch 424/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.3590 - precision: 0.9520 - recall: 0.7300 - f1_score: 0.8260 - val_loss: 0.3620 - val_precision: 0.9167 - val_recall: 0.7333 - val_f1_score: 0.8148\n",
            "Epoch 425/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.3586 - precision: 0.9544 - recall: 0.7300 - f1_score: 0.8260 - val_loss: 0.3616 - val_precision: 0.9167 - val_recall: 0.7333 - val_f1_score: 0.8148\n",
            "Epoch 426/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.3580 - precision: 0.9522 - recall: 0.7367 - f1_score: 0.8304 - val_loss: 0.3613 - val_precision: 0.9167 - val_recall: 0.7333 - val_f1_score: 0.8148\n",
            "Epoch 427/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.3578 - precision: 0.9575 - recall: 0.7333 - f1_score: 0.8289 - val_loss: 0.3610 - val_precision: 0.9167 - val_recall: 0.7333 - val_f1_score: 0.8148\n",
            "Epoch 428/3000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.3575 - precision: 0.9406 - recall: 0.7333 - f1_score: 0.8228 - val_loss: 0.3607 - val_precision: 0.9362 - val_recall: 0.7333 - val_f1_score: 0.8224\n",
            "Epoch 429/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.3570 - precision: 0.9572 - recall: 0.7333 - f1_score: 0.8299 - val_loss: 0.3604 - val_precision: 0.9362 - val_recall: 0.7333 - val_f1_score: 0.8224\n",
            "Epoch 430/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3570 - precision: 0.9591 - recall: 0.7300 - f1_score: 0.8281 - val_loss: 0.3601 - val_precision: 0.9362 - val_recall: 0.7333 - val_f1_score: 0.8224\n",
            "Epoch 431/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.3564 - precision: 0.9643 - recall: 0.7300 - f1_score: 0.8305 - val_loss: 0.3597 - val_precision: 0.9362 - val_recall: 0.7333 - val_f1_score: 0.8224\n",
            "Epoch 432/3000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.3563 - precision: 0.9562 - recall: 0.7333 - f1_score: 0.8286 - val_loss: 0.3594 - val_precision: 0.9362 - val_recall: 0.7333 - val_f1_score: 0.8224\n",
            "Epoch 433/3000\n",
            "300/300 [==============================] - 0s 80us/step - loss: 0.3557 - precision: 0.9651 - recall: 0.7333 - f1_score: 0.8326 - val_loss: 0.3591 - val_precision: 0.9362 - val_recall: 0.7333 - val_f1_score: 0.8224\n",
            "Epoch 434/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.3556 - precision: 0.9609 - recall: 0.7367 - f1_score: 0.8339 - val_loss: 0.3588 - val_precision: 0.9362 - val_recall: 0.7333 - val_f1_score: 0.8224\n",
            "Epoch 435/3000\n",
            "300/300 [==============================] - 0s 104us/step - loss: 0.3554 - precision: 0.9643 - recall: 0.7333 - f1_score: 0.8319 - val_loss: 0.3585 - val_precision: 0.9362 - val_recall: 0.7333 - val_f1_score: 0.8224\n",
            "Epoch 436/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.3547 - precision: 0.9644 - recall: 0.7367 - f1_score: 0.8340 - val_loss: 0.3582 - val_precision: 0.9362 - val_recall: 0.7333 - val_f1_score: 0.8224\n",
            "Epoch 437/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.3546 - precision: 0.9651 - recall: 0.7367 - f1_score: 0.8332 - val_loss: 0.3578 - val_precision: 0.9362 - val_recall: 0.7333 - val_f1_score: 0.8224\n",
            "Epoch 438/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.3542 - precision: 0.9643 - recall: 0.7333 - f1_score: 0.8328 - val_loss: 0.3574 - val_precision: 0.9362 - val_recall: 0.7333 - val_f1_score: 0.8224\n",
            "Epoch 439/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.3540 - precision: 0.9654 - recall: 0.7367 - f1_score: 0.8346 - val_loss: 0.3571 - val_precision: 0.9167 - val_recall: 0.7333 - val_f1_score: 0.8148\n",
            "Epoch 440/3000\n",
            "300/300 [==============================] - 0s 104us/step - loss: 0.3535 - precision: 0.9483 - recall: 0.7367 - f1_score: 0.8291 - val_loss: 0.3568 - val_precision: 0.9362 - val_recall: 0.7333 - val_f1_score: 0.8224\n",
            "Epoch 441/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.3532 - precision: 0.9526 - recall: 0.7367 - f1_score: 0.8301 - val_loss: 0.3564 - val_precision: 0.9362 - val_recall: 0.7333 - val_f1_score: 0.8224\n",
            "Epoch 442/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.3529 - precision: 0.9651 - recall: 0.7367 - f1_score: 0.8344 - val_loss: 0.3562 - val_precision: 0.9362 - val_recall: 0.7333 - val_f1_score: 0.8224\n",
            "Epoch 443/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3525 - precision: 0.9652 - recall: 0.7367 - f1_score: 0.8355 - val_loss: 0.3559 - val_precision: 0.9362 - val_recall: 0.7333 - val_f1_score: 0.8224\n",
            "Epoch 444/3000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.3521 - precision: 0.9675 - recall: 0.7400 - f1_score: 0.8365 - val_loss: 0.3555 - val_precision: 0.9362 - val_recall: 0.7333 - val_f1_score: 0.8224\n",
            "Epoch 445/3000\n",
            "300/300 [==============================] - 0s 78us/step - loss: 0.3518 - precision: 0.9652 - recall: 0.7367 - f1_score: 0.8346 - val_loss: 0.3552 - val_precision: 0.9362 - val_recall: 0.7333 - val_f1_score: 0.8224\n",
            "Epoch 446/3000\n",
            "300/300 [==============================] - 0s 79us/step - loss: 0.3514 - precision: 0.9655 - recall: 0.7400 - f1_score: 0.8359 - val_loss: 0.3549 - val_precision: 0.9362 - val_recall: 0.7333 - val_f1_score: 0.8224\n",
            "Epoch 447/3000\n",
            "300/300 [==============================] - 0s 113us/step - loss: 0.3511 - precision: 0.9666 - recall: 0.7400 - f1_score: 0.8377 - val_loss: 0.3546 - val_precision: 0.9362 - val_recall: 0.7333 - val_f1_score: 0.8224\n",
            "Epoch 448/3000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.3507 - precision: 0.9663 - recall: 0.7400 - f1_score: 0.8369 - val_loss: 0.3544 - val_precision: 0.9362 - val_recall: 0.7333 - val_f1_score: 0.8224\n",
            "Epoch 449/3000\n",
            "300/300 [==============================] - 0s 102us/step - loss: 0.3505 - precision: 0.9655 - recall: 0.7400 - f1_score: 0.8374 - val_loss: 0.3540 - val_precision: 0.9362 - val_recall: 0.7333 - val_f1_score: 0.8224\n",
            "Epoch 450/3000\n",
            "300/300 [==============================] - 0s 82us/step - loss: 0.3504 - precision: 0.9644 - recall: 0.7400 - f1_score: 0.8368 - val_loss: 0.3537 - val_precision: 0.9375 - val_recall: 0.7500 - val_f1_score: 0.8333\n",
            "Epoch 451/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.3501 - precision: 0.9637 - recall: 0.7367 - f1_score: 0.8345 - val_loss: 0.3533 - val_precision: 0.9362 - val_recall: 0.7333 - val_f1_score: 0.8224\n",
            "Epoch 452/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.3496 - precision: 0.9646 - recall: 0.7367 - f1_score: 0.8351 - val_loss: 0.3531 - val_precision: 0.9362 - val_recall: 0.7333 - val_f1_score: 0.8224\n",
            "Epoch 453/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3492 - precision: 0.9649 - recall: 0.7400 - f1_score: 0.8374 - val_loss: 0.3528 - val_precision: 0.9362 - val_recall: 0.7333 - val_f1_score: 0.8224\n",
            "Epoch 454/3000\n",
            "300/300 [==============================] - 0s 80us/step - loss: 0.3495 - precision: 0.9628 - recall: 0.7400 - f1_score: 0.8350 - val_loss: 0.3525 - val_precision: 0.9362 - val_recall: 0.7333 - val_f1_score: 0.8224\n",
            "Epoch 455/3000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.3487 - precision: 0.9649 - recall: 0.7400 - f1_score: 0.8371 - val_loss: 0.3521 - val_precision: 0.9362 - val_recall: 0.7333 - val_f1_score: 0.8224\n",
            "Epoch 456/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.3485 - precision: 0.9662 - recall: 0.7433 - f1_score: 0.8399 - val_loss: 0.3518 - val_precision: 0.9362 - val_recall: 0.7333 - val_f1_score: 0.8224\n",
            "Epoch 457/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.3480 - precision: 0.9644 - recall: 0.7400 - f1_score: 0.8368 - val_loss: 0.3515 - val_precision: 0.9375 - val_recall: 0.7500 - val_f1_score: 0.8333\n",
            "Epoch 458/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3478 - precision: 0.9658 - recall: 0.7400 - f1_score: 0.8362 - val_loss: 0.3512 - val_precision: 0.9375 - val_recall: 0.7500 - val_f1_score: 0.8333\n",
            "Epoch 459/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3475 - precision: 0.9640 - recall: 0.7367 - f1_score: 0.8347 - val_loss: 0.3509 - val_precision: 0.9375 - val_recall: 0.7500 - val_f1_score: 0.8333\n",
            "Epoch 460/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3470 - precision: 0.9668 - recall: 0.7400 - f1_score: 0.8376 - val_loss: 0.3506 - val_precision: 0.9375 - val_recall: 0.7500 - val_f1_score: 0.8333\n",
            "Epoch 461/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.3469 - precision: 0.9652 - recall: 0.7433 - f1_score: 0.8391 - val_loss: 0.3503 - val_precision: 0.9375 - val_recall: 0.7500 - val_f1_score: 0.8333\n",
            "Epoch 462/3000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.3465 - precision: 0.9652 - recall: 0.7367 - f1_score: 0.8352 - val_loss: 0.3500 - val_precision: 0.9375 - val_recall: 0.7500 - val_f1_score: 0.8333\n",
            "Epoch 463/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.3462 - precision: 0.9651 - recall: 0.7400 - f1_score: 0.8374 - val_loss: 0.3497 - val_precision: 0.9375 - val_recall: 0.7500 - val_f1_score: 0.8333\n",
            "Epoch 464/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3460 - precision: 0.9668 - recall: 0.7500 - f1_score: 0.8442 - val_loss: 0.3494 - val_precision: 0.9375 - val_recall: 0.7500 - val_f1_score: 0.8333\n",
            "Epoch 465/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.3457 - precision: 0.9616 - recall: 0.7467 - f1_score: 0.8403 - val_loss: 0.3490 - val_precision: 0.9375 - val_recall: 0.7500 - val_f1_score: 0.8333\n",
            "Epoch 466/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.3456 - precision: 0.9608 - recall: 0.7433 - f1_score: 0.8371 - val_loss: 0.3488 - val_precision: 0.9362 - val_recall: 0.7333 - val_f1_score: 0.8224\n",
            "Epoch 467/3000\n",
            "300/300 [==============================] - 0s 106us/step - loss: 0.3451 - precision: 0.9658 - recall: 0.7400 - f1_score: 0.8367 - val_loss: 0.3485 - val_precision: 0.9362 - val_recall: 0.7333 - val_f1_score: 0.8224\n",
            "Epoch 468/3000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.3446 - precision: 0.9699 - recall: 0.7400 - f1_score: 0.8389 - val_loss: 0.3481 - val_precision: 0.9375 - val_recall: 0.7500 - val_f1_score: 0.8333\n",
            "Epoch 469/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.3443 - precision: 0.9660 - recall: 0.7400 - f1_score: 0.8374 - val_loss: 0.3477 - val_precision: 0.9375 - val_recall: 0.7500 - val_f1_score: 0.8333\n",
            "Epoch 470/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3440 - precision: 0.9654 - recall: 0.7400 - f1_score: 0.8361 - val_loss: 0.3475 - val_precision: 0.9375 - val_recall: 0.7500 - val_f1_score: 0.8333\n",
            "Epoch 471/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.3438 - precision: 0.9647 - recall: 0.7433 - f1_score: 0.8377 - val_loss: 0.3472 - val_precision: 0.9375 - val_recall: 0.7500 - val_f1_score: 0.8333\n",
            "Epoch 472/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.3435 - precision: 0.9655 - recall: 0.7400 - f1_score: 0.8372 - val_loss: 0.3468 - val_precision: 0.9375 - val_recall: 0.7500 - val_f1_score: 0.8333\n",
            "Epoch 473/3000\n",
            "300/300 [==============================] - 0s 106us/step - loss: 0.3432 - precision: 0.9650 - recall: 0.7500 - f1_score: 0.8436 - val_loss: 0.3465 - val_precision: 0.9375 - val_recall: 0.7500 - val_f1_score: 0.8333\n",
            "Epoch 474/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.3429 - precision: 0.9662 - recall: 0.7600 - f1_score: 0.8507 - val_loss: 0.3463 - val_precision: 0.9375 - val_recall: 0.7500 - val_f1_score: 0.8333\n",
            "Epoch 475/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.3425 - precision: 0.9660 - recall: 0.7433 - f1_score: 0.8396 - val_loss: 0.3461 - val_precision: 0.9375 - val_recall: 0.7500 - val_f1_score: 0.8333\n",
            "Epoch 476/3000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.3423 - precision: 0.9697 - recall: 0.7600 - f1_score: 0.8515 - val_loss: 0.3458 - val_precision: 0.9375 - val_recall: 0.7500 - val_f1_score: 0.8333\n",
            "Epoch 477/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.3419 - precision: 0.9657 - recall: 0.7433 - f1_score: 0.8397 - val_loss: 0.3455 - val_precision: 0.9375 - val_recall: 0.7500 - val_f1_score: 0.8333\n",
            "Epoch 478/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.3415 - precision: 0.9700 - recall: 0.7533 - f1_score: 0.8479 - val_loss: 0.3452 - val_precision: 0.9375 - val_recall: 0.7500 - val_f1_score: 0.8333\n",
            "Epoch 479/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.3413 - precision: 0.9626 - recall: 0.7567 - f1_score: 0.8471 - val_loss: 0.3448 - val_precision: 0.9375 - val_recall: 0.7500 - val_f1_score: 0.8333\n",
            "Epoch 480/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.3412 - precision: 0.9708 - recall: 0.7433 - f1_score: 0.8412 - val_loss: 0.3446 - val_precision: 0.9375 - val_recall: 0.7500 - val_f1_score: 0.8333\n",
            "Epoch 481/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.3408 - precision: 0.9740 - recall: 0.7433 - f1_score: 0.8423 - val_loss: 0.3443 - val_precision: 0.9375 - val_recall: 0.7500 - val_f1_score: 0.8333\n",
            "Epoch 482/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.3406 - precision: 0.9576 - recall: 0.7500 - f1_score: 0.8407 - val_loss: 0.3440 - val_precision: 0.9375 - val_recall: 0.7500 - val_f1_score: 0.8333\n",
            "Epoch 483/3000\n",
            "300/300 [==============================] - 0s 109us/step - loss: 0.3402 - precision: 0.9693 - recall: 0.7467 - f1_score: 0.8433 - val_loss: 0.3436 - val_precision: 0.9375 - val_recall: 0.7500 - val_f1_score: 0.8333\n",
            "Epoch 484/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.3398 - precision: 0.9673 - recall: 0.7667 - f1_score: 0.8541 - val_loss: 0.3434 - val_precision: 0.9375 - val_recall: 0.7500 - val_f1_score: 0.8333\n",
            "Epoch 485/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.3398 - precision: 0.9610 - recall: 0.7600 - f1_score: 0.8482 - val_loss: 0.3431 - val_precision: 0.9375 - val_recall: 0.7500 - val_f1_score: 0.8333\n",
            "Epoch 486/3000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.3393 - precision: 0.9691 - recall: 0.7533 - f1_score: 0.8471 - val_loss: 0.3427 - val_precision: 0.9375 - val_recall: 0.7500 - val_f1_score: 0.8333\n",
            "Epoch 487/3000\n",
            "300/300 [==============================] - 0s 136us/step - loss: 0.3392 - precision: 0.9668 - recall: 0.7600 - f1_score: 0.8500 - val_loss: 0.3425 - val_precision: 0.9375 - val_recall: 0.7500 - val_f1_score: 0.8333\n",
            "Epoch 488/3000\n",
            "300/300 [==============================] - 0s 112us/step - loss: 0.3386 - precision: 0.9694 - recall: 0.7467 - f1_score: 0.8426 - val_loss: 0.3422 - val_precision: 0.9375 - val_recall: 0.7500 - val_f1_score: 0.8333\n",
            "Epoch 489/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.3387 - precision: 0.9644 - recall: 0.7633 - f1_score: 0.8509 - val_loss: 0.3419 - val_precision: 0.9375 - val_recall: 0.7500 - val_f1_score: 0.8333\n",
            "Epoch 490/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.3381 - precision: 0.9693 - recall: 0.7600 - f1_score: 0.8515 - val_loss: 0.3416 - val_precision: 0.9375 - val_recall: 0.7500 - val_f1_score: 0.8333\n",
            "Epoch 491/3000\n",
            "300/300 [==============================] - 0s 79us/step - loss: 0.3379 - precision: 0.9743 - recall: 0.7533 - f1_score: 0.8487 - val_loss: 0.3412 - val_precision: 0.9375 - val_recall: 0.7500 - val_f1_score: 0.8333\n",
            "Epoch 492/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.3377 - precision: 0.9699 - recall: 0.7500 - f1_score: 0.8459 - val_loss: 0.3411 - val_precision: 0.9375 - val_recall: 0.7500 - val_f1_score: 0.8333\n",
            "Epoch 493/3000\n",
            "300/300 [==============================] - 0s 105us/step - loss: 0.3374 - precision: 0.9750 - recall: 0.7633 - f1_score: 0.8538 - val_loss: 0.3406 - val_precision: 0.9375 - val_recall: 0.7500 - val_f1_score: 0.8333\n",
            "Epoch 494/3000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.3369 - precision: 0.9632 - recall: 0.7833 - f1_score: 0.8640 - val_loss: 0.3403 - val_precision: 0.9375 - val_recall: 0.7500 - val_f1_score: 0.8333\n",
            "Epoch 495/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.3367 - precision: 0.9701 - recall: 0.7600 - f1_score: 0.8509 - val_loss: 0.3400 - val_precision: 0.9375 - val_recall: 0.7500 - val_f1_score: 0.8333\n",
            "Epoch 496/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.3364 - precision: 0.9696 - recall: 0.7733 - f1_score: 0.8591 - val_loss: 0.3398 - val_precision: 0.9375 - val_recall: 0.7500 - val_f1_score: 0.8333\n",
            "Epoch 497/3000\n",
            "300/300 [==============================] - 0s 78us/step - loss: 0.3361 - precision: 0.9711 - recall: 0.7733 - f1_score: 0.8598 - val_loss: 0.3396 - val_precision: 0.9375 - val_recall: 0.7500 - val_f1_score: 0.8333\n",
            "Epoch 498/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.3357 - precision: 0.9742 - recall: 0.7700 - f1_score: 0.8599 - val_loss: 0.3392 - val_precision: 0.9375 - val_recall: 0.7500 - val_f1_score: 0.8333\n",
            "Epoch 499/3000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.3356 - precision: 0.9703 - recall: 0.7567 - f1_score: 0.8500 - val_loss: 0.3391 - val_precision: 0.9375 - val_recall: 0.7500 - val_f1_score: 0.8333\n",
            "Epoch 500/3000\n",
            "300/300 [==============================] - 0s 121us/step - loss: 0.3353 - precision: 0.9748 - recall: 0.7767 - f1_score: 0.8638 - val_loss: 0.3388 - val_precision: 0.9375 - val_recall: 0.7500 - val_f1_score: 0.8333\n",
            "Epoch 501/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.3352 - precision: 0.9744 - recall: 0.7733 - f1_score: 0.8615 - val_loss: 0.3386 - val_precision: 0.9375 - val_recall: 0.7500 - val_f1_score: 0.8333\n",
            "Epoch 502/3000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.3350 - precision: 0.9705 - recall: 0.7667 - f1_score: 0.8561 - val_loss: 0.3383 - val_precision: 0.9375 - val_recall: 0.7500 - val_f1_score: 0.8333\n",
            "Epoch 503/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.3345 - precision: 0.9746 - recall: 0.7567 - f1_score: 0.8509 - val_loss: 0.3381 - val_precision: 0.9375 - val_recall: 0.7500 - val_f1_score: 0.8333\n",
            "Epoch 504/3000\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.3343 - precision: 0.9741 - recall: 0.7633 - f1_score: 0.8554 - val_loss: 0.3377 - val_precision: 0.9375 - val_recall: 0.7500 - val_f1_score: 0.8333\n",
            "Epoch 505/3000\n",
            "300/300 [==============================] - 0s 106us/step - loss: 0.3340 - precision: 0.9757 - recall: 0.7633 - f1_score: 0.8554 - val_loss: 0.3375 - val_precision: 0.9375 - val_recall: 0.7500 - val_f1_score: 0.8333\n",
            "Epoch 506/3000\n",
            "300/300 [==============================] - 0s 78us/step - loss: 0.3336 - precision: 0.9747 - recall: 0.7633 - f1_score: 0.8560 - val_loss: 0.3372 - val_precision: 0.9375 - val_recall: 0.7500 - val_f1_score: 0.8333\n",
            "Epoch 507/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.3335 - precision: 0.9750 - recall: 0.7767 - f1_score: 0.8639 - val_loss: 0.3369 - val_precision: 0.9375 - val_recall: 0.7500 - val_f1_score: 0.8333\n",
            "Epoch 508/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.3330 - precision: 0.9743 - recall: 0.7667 - f1_score: 0.8578 - val_loss: 0.3366 - val_precision: 0.9375 - val_recall: 0.7500 - val_f1_score: 0.8333\n",
            "Epoch 509/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.3327 - precision: 0.9748 - recall: 0.7700 - f1_score: 0.8603 - val_loss: 0.3364 - val_precision: 0.9375 - val_recall: 0.7500 - val_f1_score: 0.8333\n",
            "Epoch 510/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.3324 - precision: 0.9795 - recall: 0.7767 - f1_score: 0.8658 - val_loss: 0.3361 - val_precision: 0.9375 - val_recall: 0.7500 - val_f1_score: 0.8333\n",
            "Epoch 511/3000\n",
            "300/300 [==============================] - 0s 102us/step - loss: 0.3322 - precision: 0.9742 - recall: 0.7733 - f1_score: 0.8615 - val_loss: 0.3359 - val_precision: 0.9375 - val_recall: 0.7500 - val_f1_score: 0.8333\n",
            "Epoch 512/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.3319 - precision: 0.9743 - recall: 0.7800 - f1_score: 0.8659 - val_loss: 0.3355 - val_precision: 0.9375 - val_recall: 0.7500 - val_f1_score: 0.8333\n",
            "Epoch 513/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.3318 - precision: 0.9701 - recall: 0.7767 - f1_score: 0.8619 - val_loss: 0.3353 - val_precision: 0.9375 - val_recall: 0.7500 - val_f1_score: 0.8333\n",
            "Epoch 514/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3314 - precision: 0.9746 - recall: 0.7700 - f1_score: 0.8599 - val_loss: 0.3350 - val_precision: 0.9375 - val_recall: 0.7500 - val_f1_score: 0.8333\n",
            "Epoch 515/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.3312 - precision: 0.9639 - recall: 0.7800 - f1_score: 0.8616 - val_loss: 0.3348 - val_precision: 0.9375 - val_recall: 0.7500 - val_f1_score: 0.8333\n",
            "Epoch 516/3000\n",
            "300/300 [==============================] - 0s 114us/step - loss: 0.3308 - precision: 0.9750 - recall: 0.7767 - f1_score: 0.8634 - val_loss: 0.3346 - val_precision: 0.9375 - val_recall: 0.7500 - val_f1_score: 0.8333\n",
            "Epoch 517/3000\n",
            "300/300 [==============================] - 0s 124us/step - loss: 0.3305 - precision: 0.9757 - recall: 0.7767 - f1_score: 0.8639 - val_loss: 0.3344 - val_precision: 0.9375 - val_recall: 0.7500 - val_f1_score: 0.8333\n",
            "Epoch 518/3000\n",
            "300/300 [==============================] - 0s 108us/step - loss: 0.3304 - precision: 0.9739 - recall: 0.7800 - f1_score: 0.8651 - val_loss: 0.3341 - val_precision: 0.9375 - val_recall: 0.7500 - val_f1_score: 0.8333\n",
            "Epoch 519/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.3301 - precision: 0.9705 - recall: 0.7800 - f1_score: 0.8636 - val_loss: 0.3338 - val_precision: 0.9375 - val_recall: 0.7500 - val_f1_score: 0.8333\n",
            "Epoch 520/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3298 - precision: 0.9715 - recall: 0.7833 - f1_score: 0.8665 - val_loss: 0.3334 - val_precision: 0.9375 - val_recall: 0.7500 - val_f1_score: 0.8333\n",
            "Epoch 521/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.3295 - precision: 0.9730 - recall: 0.7833 - f1_score: 0.8673 - val_loss: 0.3331 - val_precision: 0.9375 - val_recall: 0.7500 - val_f1_score: 0.8333\n",
            "Epoch 522/3000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.3292 - precision: 0.9751 - recall: 0.7833 - f1_score: 0.8676 - val_loss: 0.3328 - val_precision: 0.9375 - val_recall: 0.7500 - val_f1_score: 0.8333\n",
            "Epoch 523/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.3290 - precision: 0.9753 - recall: 0.7800 - f1_score: 0.8664 - val_loss: 0.3325 - val_precision: 0.9375 - val_recall: 0.7500 - val_f1_score: 0.8333\n",
            "Epoch 524/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.3286 - precision: 0.9743 - recall: 0.7800 - f1_score: 0.8655 - val_loss: 0.3322 - val_precision: 0.9375 - val_recall: 0.7500 - val_f1_score: 0.8333\n",
            "Epoch 525/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.3285 - precision: 0.9752 - recall: 0.7833 - f1_score: 0.8687 - val_loss: 0.3319 - val_precision: 0.9375 - val_recall: 0.7500 - val_f1_score: 0.8333\n",
            "Epoch 526/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.3282 - precision: 0.9742 - recall: 0.7833 - f1_score: 0.8671 - val_loss: 0.3317 - val_precision: 0.9375 - val_recall: 0.7500 - val_f1_score: 0.8333\n",
            "Epoch 527/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.3279 - precision: 0.9756 - recall: 0.7767 - f1_score: 0.8628 - val_loss: 0.3314 - val_precision: 0.9375 - val_recall: 0.7500 - val_f1_score: 0.8333\n",
            "Epoch 528/3000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.3277 - precision: 0.9745 - recall: 0.7833 - f1_score: 0.8668 - val_loss: 0.3311 - val_precision: 0.9375 - val_recall: 0.7500 - val_f1_score: 0.8333\n",
            "Epoch 529/3000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.3274 - precision: 0.9752 - recall: 0.7867 - f1_score: 0.8705 - val_loss: 0.3308 - val_precision: 0.9375 - val_recall: 0.7500 - val_f1_score: 0.8333\n",
            "Epoch 530/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3272 - precision: 0.9753 - recall: 0.7900 - f1_score: 0.8723 - val_loss: 0.3306 - val_precision: 0.9375 - val_recall: 0.7500 - val_f1_score: 0.8333\n",
            "Epoch 531/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.3270 - precision: 0.9753 - recall: 0.7833 - f1_score: 0.8688 - val_loss: 0.3303 - val_precision: 0.9375 - val_recall: 0.7500 - val_f1_score: 0.8333\n",
            "Epoch 532/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3265 - precision: 0.9753 - recall: 0.7867 - f1_score: 0.8705 - val_loss: 0.3300 - val_precision: 0.9375 - val_recall: 0.7500 - val_f1_score: 0.8333\n",
            "Epoch 533/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3263 - precision: 0.9752 - recall: 0.7900 - f1_score: 0.8728 - val_loss: 0.3297 - val_precision: 0.9375 - val_recall: 0.7500 - val_f1_score: 0.8333\n",
            "Epoch 534/3000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.3261 - precision: 0.9753 - recall: 0.7867 - f1_score: 0.8706 - val_loss: 0.3295 - val_precision: 0.9375 - val_recall: 0.7500 - val_f1_score: 0.8333\n",
            "Epoch 535/3000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.3257 - precision: 0.9753 - recall: 0.7867 - f1_score: 0.8706 - val_loss: 0.3292 - val_precision: 0.9388 - val_recall: 0.7667 - val_f1_score: 0.8440\n",
            "Epoch 536/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.3255 - precision: 0.9750 - recall: 0.7800 - f1_score: 0.8663 - val_loss: 0.3290 - val_precision: 0.9388 - val_recall: 0.7667 - val_f1_score: 0.8440\n",
            "Epoch 537/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3253 - precision: 0.9742 - recall: 0.7867 - f1_score: 0.8682 - val_loss: 0.3286 - val_precision: 0.9388 - val_recall: 0.7667 - val_f1_score: 0.8440\n",
            "Epoch 538/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3249 - precision: 0.9755 - recall: 0.7800 - f1_score: 0.8660 - val_loss: 0.3284 - val_precision: 0.9388 - val_recall: 0.7667 - val_f1_score: 0.8440\n",
            "Epoch 539/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3250 - precision: 0.9751 - recall: 0.7800 - f1_score: 0.8666 - val_loss: 0.3281 - val_precision: 0.9388 - val_recall: 0.7667 - val_f1_score: 0.8440\n",
            "Epoch 540/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.3245 - precision: 0.9753 - recall: 0.7867 - f1_score: 0.8704 - val_loss: 0.3278 - val_precision: 0.9375 - val_recall: 0.7500 - val_f1_score: 0.8333\n",
            "Epoch 541/3000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.3245 - precision: 0.9754 - recall: 0.7833 - f1_score: 0.8686 - val_loss: 0.3277 - val_precision: 0.9375 - val_recall: 0.7500 - val_f1_score: 0.8333\n",
            "Epoch 542/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.3240 - precision: 0.9712 - recall: 0.7933 - f1_score: 0.8733 - val_loss: 0.3274 - val_precision: 0.9375 - val_recall: 0.7500 - val_f1_score: 0.8333\n",
            "Epoch 543/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3238 - precision: 0.9759 - recall: 0.7900 - f1_score: 0.8729 - val_loss: 0.3271 - val_precision: 0.9388 - val_recall: 0.7667 - val_f1_score: 0.8440\n",
            "Epoch 544/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.3237 - precision: 0.9746 - recall: 0.7767 - f1_score: 0.8637 - val_loss: 0.3270 - val_precision: 0.9400 - val_recall: 0.7833 - val_f1_score: 0.8545\n",
            "Epoch 545/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.3231 - precision: 0.9755 - recall: 0.7900 - f1_score: 0.8728 - val_loss: 0.3267 - val_precision: 0.9375 - val_recall: 0.7500 - val_f1_score: 0.8333\n",
            "Epoch 546/3000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.3229 - precision: 0.9754 - recall: 0.7867 - f1_score: 0.8705 - val_loss: 0.3265 - val_precision: 0.9375 - val_recall: 0.7500 - val_f1_score: 0.8333\n",
            "Epoch 547/3000\n",
            "300/300 [==============================] - 0s 130us/step - loss: 0.3230 - precision: 0.9657 - recall: 0.7900 - f1_score: 0.8671 - val_loss: 0.3262 - val_precision: 0.9388 - val_recall: 0.7667 - val_f1_score: 0.8440\n",
            "Epoch 548/3000\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.3225 - precision: 0.9755 - recall: 0.7867 - f1_score: 0.8704 - val_loss: 0.3259 - val_precision: 0.9388 - val_recall: 0.7667 - val_f1_score: 0.8440\n",
            "Epoch 549/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3221 - precision: 0.9758 - recall: 0.7867 - f1_score: 0.8705 - val_loss: 0.3257 - val_precision: 0.9388 - val_recall: 0.7667 - val_f1_score: 0.8440\n",
            "Epoch 550/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.3219 - precision: 0.9763 - recall: 0.7933 - f1_score: 0.8747 - val_loss: 0.3254 - val_precision: 0.9388 - val_recall: 0.7667 - val_f1_score: 0.8440\n",
            "Epoch 551/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.3216 - precision: 0.9763 - recall: 0.7900 - f1_score: 0.8715 - val_loss: 0.3251 - val_precision: 0.9388 - val_recall: 0.7667 - val_f1_score: 0.8440\n",
            "Epoch 552/3000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.3214 - precision: 0.9753 - recall: 0.7867 - f1_score: 0.8699 - val_loss: 0.3249 - val_precision: 0.9388 - val_recall: 0.7667 - val_f1_score: 0.8440\n",
            "Epoch 553/3000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.3213 - precision: 0.9750 - recall: 0.7867 - f1_score: 0.8694 - val_loss: 0.3246 - val_precision: 0.9400 - val_recall: 0.7833 - val_f1_score: 0.8545\n",
            "Epoch 554/3000\n",
            "300/300 [==============================] - 0s 80us/step - loss: 0.3209 - precision: 0.9764 - recall: 0.7900 - f1_score: 0.8725 - val_loss: 0.3244 - val_precision: 0.9400 - val_recall: 0.7833 - val_f1_score: 0.8545\n",
            "Epoch 555/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3210 - precision: 0.9755 - recall: 0.7933 - f1_score: 0.8746 - val_loss: 0.3241 - val_precision: 0.9412 - val_recall: 0.8000 - val_f1_score: 0.8649\n",
            "Epoch 556/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3204 - precision: 0.9753 - recall: 0.7933 - f1_score: 0.8746 - val_loss: 0.3239 - val_precision: 0.9412 - val_recall: 0.8000 - val_f1_score: 0.8649\n",
            "Epoch 557/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3203 - precision: 0.9751 - recall: 0.7900 - f1_score: 0.8718 - val_loss: 0.3238 - val_precision: 0.9400 - val_recall: 0.7833 - val_f1_score: 0.8545\n",
            "Epoch 558/3000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.3199 - precision: 0.9722 - recall: 0.7933 - f1_score: 0.8730 - val_loss: 0.3235 - val_precision: 0.9400 - val_recall: 0.7833 - val_f1_score: 0.8545\n",
            "Epoch 559/3000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.3196 - precision: 0.9757 - recall: 0.7933 - f1_score: 0.8749 - val_loss: 0.3232 - val_precision: 0.9412 - val_recall: 0.8000 - val_f1_score: 0.8649\n",
            "Epoch 560/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.3196 - precision: 0.9742 - recall: 0.7933 - f1_score: 0.8732 - val_loss: 0.3231 - val_precision: 0.9412 - val_recall: 0.8000 - val_f1_score: 0.8649\n",
            "Epoch 561/3000\n",
            "300/300 [==============================] - 0s 78us/step - loss: 0.3191 - precision: 0.9839 - recall: 0.7933 - f1_score: 0.8776 - val_loss: 0.3227 - val_precision: 0.9400 - val_recall: 0.7833 - val_f1_score: 0.8545\n",
            "Epoch 562/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3190 - precision: 0.9753 - recall: 0.7967 - f1_score: 0.8764 - val_loss: 0.3225 - val_precision: 0.9400 - val_recall: 0.7833 - val_f1_score: 0.8545\n",
            "Epoch 563/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3189 - precision: 0.9755 - recall: 0.7900 - f1_score: 0.8725 - val_loss: 0.3222 - val_precision: 0.9400 - val_recall: 0.7833 - val_f1_score: 0.8545\n",
            "Epoch 564/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.3184 - precision: 0.9755 - recall: 0.7933 - f1_score: 0.8746 - val_loss: 0.3221 - val_precision: 0.9412 - val_recall: 0.8000 - val_f1_score: 0.8649\n",
            "Epoch 565/3000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.3182 - precision: 0.9770 - recall: 0.7933 - f1_score: 0.8744 - val_loss: 0.3218 - val_precision: 0.9412 - val_recall: 0.8000 - val_f1_score: 0.8649\n",
            "Epoch 566/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.3184 - precision: 0.9712 - recall: 0.8000 - f1_score: 0.8771 - val_loss: 0.3216 - val_precision: 0.9412 - val_recall: 0.8000 - val_f1_score: 0.8649\n",
            "Epoch 567/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3177 - precision: 0.9720 - recall: 0.7967 - f1_score: 0.8751 - val_loss: 0.3214 - val_precision: 0.9412 - val_recall: 0.8000 - val_f1_score: 0.8649\n",
            "Epoch 568/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3176 - precision: 0.9877 - recall: 0.7967 - f1_score: 0.8812 - val_loss: 0.3211 - val_precision: 0.9412 - val_recall: 0.8000 - val_f1_score: 0.8649\n",
            "Epoch 569/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3175 - precision: 0.9749 - recall: 0.8033 - f1_score: 0.8798 - val_loss: 0.3209 - val_precision: 0.9412 - val_recall: 0.8000 - val_f1_score: 0.8649\n",
            "Epoch 570/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.3169 - precision: 0.9795 - recall: 0.7967 - f1_score: 0.8781 - val_loss: 0.3207 - val_precision: 0.9412 - val_recall: 0.8000 - val_f1_score: 0.8649\n",
            "Epoch 571/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3169 - precision: 0.9791 - recall: 0.8000 - f1_score: 0.8795 - val_loss: 0.3203 - val_precision: 0.9412 - val_recall: 0.8000 - val_f1_score: 0.8649\n",
            "Epoch 572/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3164 - precision: 0.9759 - recall: 0.8033 - f1_score: 0.8806 - val_loss: 0.3201 - val_precision: 0.9412 - val_recall: 0.8000 - val_f1_score: 0.8649\n",
            "Epoch 573/3000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.3166 - precision: 0.9839 - recall: 0.7967 - f1_score: 0.8802 - val_loss: 0.3199 - val_precision: 0.9400 - val_recall: 0.7833 - val_f1_score: 0.8545\n",
            "Epoch 574/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.3160 - precision: 0.9720 - recall: 0.8000 - f1_score: 0.8770 - val_loss: 0.3196 - val_precision: 0.9400 - val_recall: 0.7833 - val_f1_score: 0.8545\n",
            "Epoch 575/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.3157 - precision: 0.9724 - recall: 0.8033 - f1_score: 0.8792 - val_loss: 0.3193 - val_precision: 0.9412 - val_recall: 0.8000 - val_f1_score: 0.8649\n",
            "Epoch 576/3000\n",
            "300/300 [==============================] - 0s 81us/step - loss: 0.3155 - precision: 0.9758 - recall: 0.8033 - f1_score: 0.8806 - val_loss: 0.3190 - val_precision: 0.9412 - val_recall: 0.8000 - val_f1_score: 0.8649\n",
            "Epoch 577/3000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.3152 - precision: 0.9763 - recall: 0.8033 - f1_score: 0.8811 - val_loss: 0.3188 - val_precision: 0.9412 - val_recall: 0.8000 - val_f1_score: 0.8649\n",
            "Epoch 578/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.3155 - precision: 0.9756 - recall: 0.8000 - f1_score: 0.8790 - val_loss: 0.3186 - val_precision: 0.9412 - val_recall: 0.8000 - val_f1_score: 0.8649\n",
            "Epoch 579/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.3147 - precision: 0.9759 - recall: 0.8033 - f1_score: 0.8810 - val_loss: 0.3184 - val_precision: 0.9412 - val_recall: 0.8000 - val_f1_score: 0.8649\n",
            "Epoch 580/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3145 - precision: 0.9760 - recall: 0.8000 - f1_score: 0.8788 - val_loss: 0.3181 - val_precision: 0.9412 - val_recall: 0.8000 - val_f1_score: 0.8649\n",
            "Epoch 581/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3143 - precision: 0.9756 - recall: 0.8000 - f1_score: 0.8786 - val_loss: 0.3180 - val_precision: 0.9412 - val_recall: 0.8000 - val_f1_score: 0.8649\n",
            "Epoch 582/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3141 - precision: 0.9797 - recall: 0.8000 - f1_score: 0.8804 - val_loss: 0.3178 - val_precision: 0.9400 - val_recall: 0.7833 - val_f1_score: 0.8545\n",
            "Epoch 583/3000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.3139 - precision: 0.9705 - recall: 0.8067 - f1_score: 0.8801 - val_loss: 0.3176 - val_precision: 0.9412 - val_recall: 0.8000 - val_f1_score: 0.8649\n",
            "Epoch 584/3000\n",
            "300/300 [==============================] - 0s 81us/step - loss: 0.3140 - precision: 0.9797 - recall: 0.8067 - f1_score: 0.8839 - val_loss: 0.3174 - val_precision: 0.9400 - val_recall: 0.7833 - val_f1_score: 0.8545\n",
            "Epoch 585/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3134 - precision: 0.9709 - recall: 0.8067 - f1_score: 0.8806 - val_loss: 0.3172 - val_precision: 0.9412 - val_recall: 0.8000 - val_f1_score: 0.8649\n",
            "Epoch 586/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.3134 - precision: 0.9873 - recall: 0.8100 - f1_score: 0.8894 - val_loss: 0.3170 - val_precision: 0.9412 - val_recall: 0.8000 - val_f1_score: 0.8649\n",
            "Epoch 587/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3129 - precision: 0.9776 - recall: 0.8133 - f1_score: 0.8868 - val_loss: 0.3167 - val_precision: 0.9412 - val_recall: 0.8000 - val_f1_score: 0.8649\n",
            "Epoch 588/3000\n",
            "300/300 [==============================] - 0s 78us/step - loss: 0.3125 - precision: 0.9797 - recall: 0.8067 - f1_score: 0.8845 - val_loss: 0.3165 - val_precision: 0.9412 - val_recall: 0.8000 - val_f1_score: 0.8649\n",
            "Epoch 589/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3126 - precision: 0.9763 - recall: 0.8067 - f1_score: 0.8830 - val_loss: 0.3163 - val_precision: 0.9412 - val_recall: 0.8000 - val_f1_score: 0.8649\n",
            "Epoch 590/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3123 - precision: 0.9837 - recall: 0.8033 - f1_score: 0.8840 - val_loss: 0.3161 - val_precision: 0.9412 - val_recall: 0.8000 - val_f1_score: 0.8649\n",
            "Epoch 591/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3119 - precision: 0.9792 - recall: 0.8067 - f1_score: 0.8841 - val_loss: 0.3158 - val_precision: 0.9412 - val_recall: 0.8000 - val_f1_score: 0.8649\n",
            "Epoch 592/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3118 - precision: 0.9795 - recall: 0.8100 - f1_score: 0.8866 - val_loss: 0.3156 - val_precision: 0.9412 - val_recall: 0.8000 - val_f1_score: 0.8649\n",
            "Epoch 593/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.3114 - precision: 0.9880 - recall: 0.8100 - f1_score: 0.8893 - val_loss: 0.3153 - val_precision: 0.9412 - val_recall: 0.8000 - val_f1_score: 0.8649\n",
            "Epoch 594/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.3113 - precision: 0.9751 - recall: 0.8133 - f1_score: 0.8862 - val_loss: 0.3151 - val_precision: 0.9412 - val_recall: 0.8000 - val_f1_score: 0.8649\n",
            "Epoch 595/3000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.3111 - precision: 0.9833 - recall: 0.8033 - f1_score: 0.8839 - val_loss: 0.3150 - val_precision: 0.9412 - val_recall: 0.8000 - val_f1_score: 0.8649\n",
            "Epoch 596/3000\n",
            "300/300 [==============================] - 0s 81us/step - loss: 0.3108 - precision: 0.9760 - recall: 0.8167 - f1_score: 0.8889 - val_loss: 0.3146 - val_precision: 0.9412 - val_recall: 0.8000 - val_f1_score: 0.8649\n",
            "Epoch 597/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.3106 - precision: 0.9880 - recall: 0.8167 - f1_score: 0.8936 - val_loss: 0.3143 - val_precision: 0.9412 - val_recall: 0.8000 - val_f1_score: 0.8649\n",
            "Epoch 598/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.3104 - precision: 0.9755 - recall: 0.8100 - f1_score: 0.8847 - val_loss: 0.3141 - val_precision: 0.9412 - val_recall: 0.8000 - val_f1_score: 0.8649\n",
            "Epoch 599/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3101 - precision: 0.9877 - recall: 0.8067 - f1_score: 0.8876 - val_loss: 0.3139 - val_precision: 0.9412 - val_recall: 0.8000 - val_f1_score: 0.8649\n",
            "Epoch 600/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3101 - precision: 0.9832 - recall: 0.8067 - f1_score: 0.8849 - val_loss: 0.3136 - val_precision: 0.9412 - val_recall: 0.8000 - val_f1_score: 0.8649\n",
            "Epoch 601/3000\n",
            "300/300 [==============================] - 0s 78us/step - loss: 0.3097 - precision: 0.9717 - recall: 0.8067 - f1_score: 0.8815 - val_loss: 0.3134 - val_precision: 0.9412 - val_recall: 0.8000 - val_f1_score: 0.8649\n",
            "Epoch 602/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3094 - precision: 0.9802 - recall: 0.8100 - f1_score: 0.8868 - val_loss: 0.3132 - val_precision: 0.9412 - val_recall: 0.8000 - val_f1_score: 0.8649\n",
            "Epoch 603/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3093 - precision: 0.9797 - recall: 0.8067 - f1_score: 0.8838 - val_loss: 0.3130 - val_precision: 0.9412 - val_recall: 0.8000 - val_f1_score: 0.8649\n",
            "Epoch 604/3000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.3089 - precision: 0.9918 - recall: 0.8067 - f1_score: 0.8895 - val_loss: 0.3128 - val_precision: 0.9412 - val_recall: 0.8000 - val_f1_score: 0.8649\n",
            "Epoch 605/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.3087 - precision: 0.9876 - recall: 0.8100 - f1_score: 0.8893 - val_loss: 0.3126 - val_precision: 0.9412 - val_recall: 0.8000 - val_f1_score: 0.8649\n",
            "Epoch 606/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.3088 - precision: 0.9755 - recall: 0.8133 - f1_score: 0.8864 - val_loss: 0.3123 - val_precision: 0.9412 - val_recall: 0.8000 - val_f1_score: 0.8649\n",
            "Epoch 607/3000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.3085 - precision: 0.9880 - recall: 0.8167 - f1_score: 0.8917 - val_loss: 0.3122 - val_precision: 0.9423 - val_recall: 0.8167 - val_f1_score: 0.8750\n",
            "Epoch 608/3000\n",
            "300/300 [==============================] - 0s 115us/step - loss: 0.3082 - precision: 0.9793 - recall: 0.8200 - f1_score: 0.8918 - val_loss: 0.3119 - val_precision: 0.9412 - val_recall: 0.8000 - val_f1_score: 0.8649\n",
            "Epoch 609/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.3079 - precision: 0.9756 - recall: 0.8133 - f1_score: 0.8869 - val_loss: 0.3117 - val_precision: 0.9412 - val_recall: 0.8000 - val_f1_score: 0.8649\n",
            "Epoch 610/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3078 - precision: 0.9840 - recall: 0.8200 - f1_score: 0.8938 - val_loss: 0.3115 - val_precision: 0.9412 - val_recall: 0.8000 - val_f1_score: 0.8649\n",
            "Epoch 611/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.3076 - precision: 0.9917 - recall: 0.8133 - f1_score: 0.8931 - val_loss: 0.3112 - val_precision: 0.9412 - val_recall: 0.8000 - val_f1_score: 0.8649\n",
            "Epoch 612/3000\n",
            "300/300 [==============================] - 0s 109us/step - loss: 0.3072 - precision: 0.9838 - recall: 0.8133 - f1_score: 0.8896 - val_loss: 0.3110 - val_precision: 0.9412 - val_recall: 0.8000 - val_f1_score: 0.8649\n",
            "Epoch 613/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3070 - precision: 0.9877 - recall: 0.8200 - f1_score: 0.8959 - val_loss: 0.3107 - val_precision: 0.9412 - val_recall: 0.8000 - val_f1_score: 0.8649\n",
            "Epoch 614/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.3068 - precision: 0.9800 - recall: 0.8200 - f1_score: 0.8928 - val_loss: 0.3106 - val_precision: 0.9412 - val_recall: 0.8000 - val_f1_score: 0.8649\n",
            "Epoch 615/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.3066 - precision: 0.9876 - recall: 0.8233 - f1_score: 0.8968 - val_loss: 0.3103 - val_precision: 0.9423 - val_recall: 0.8167 - val_f1_score: 0.8750\n",
            "Epoch 616/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3064 - precision: 0.9793 - recall: 0.8100 - f1_score: 0.8863 - val_loss: 0.3101 - val_precision: 0.9412 - val_recall: 0.8000 - val_f1_score: 0.8649\n",
            "Epoch 617/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3061 - precision: 0.9795 - recall: 0.8200 - f1_score: 0.8922 - val_loss: 0.3099 - val_precision: 0.9412 - val_recall: 0.8000 - val_f1_score: 0.8649\n",
            "Epoch 618/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.3061 - precision: 0.9831 - recall: 0.8167 - f1_score: 0.8914 - val_loss: 0.3098 - val_precision: 0.9423 - val_recall: 0.8167 - val_f1_score: 0.8750\n",
            "Epoch 619/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.3056 - precision: 0.9801 - recall: 0.8233 - f1_score: 0.8944 - val_loss: 0.3096 - val_precision: 0.9423 - val_recall: 0.8167 - val_f1_score: 0.8750\n",
            "Epoch 620/3000\n",
            "300/300 [==============================] - 0s 105us/step - loss: 0.3055 - precision: 0.9921 - recall: 0.8200 - f1_score: 0.8975 - val_loss: 0.3093 - val_precision: 0.9423 - val_recall: 0.8167 - val_f1_score: 0.8750\n",
            "Epoch 621/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3052 - precision: 0.9832 - recall: 0.8300 - f1_score: 0.8988 - val_loss: 0.3091 - val_precision: 0.9423 - val_recall: 0.8167 - val_f1_score: 0.8750\n",
            "Epoch 622/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3049 - precision: 0.9888 - recall: 0.8267 - f1_score: 0.8990 - val_loss: 0.3088 - val_precision: 0.9423 - val_recall: 0.8167 - val_f1_score: 0.8750\n",
            "Epoch 623/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3048 - precision: 0.9762 - recall: 0.8233 - f1_score: 0.8931 - val_loss: 0.3086 - val_precision: 0.9434 - val_recall: 0.8333 - val_f1_score: 0.8850\n",
            "Epoch 624/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3046 - precision: 0.9808 - recall: 0.8333 - f1_score: 0.9003 - val_loss: 0.3083 - val_precision: 0.9423 - val_recall: 0.8167 - val_f1_score: 0.8750\n",
            "Epoch 625/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.3042 - precision: 0.9843 - recall: 0.8267 - f1_score: 0.8978 - val_loss: 0.3082 - val_precision: 0.9423 - val_recall: 0.8167 - val_f1_score: 0.8750\n",
            "Epoch 626/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.3040 - precision: 0.9881 - recall: 0.8267 - f1_score: 0.8999 - val_loss: 0.3079 - val_precision: 0.9434 - val_recall: 0.8333 - val_f1_score: 0.8850\n",
            "Epoch 627/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3039 - precision: 0.9838 - recall: 0.8300 - f1_score: 0.8994 - val_loss: 0.3077 - val_precision: 0.9423 - val_recall: 0.8167 - val_f1_score: 0.8750\n",
            "Epoch 628/3000\n",
            "300/300 [==============================] - 0s 82us/step - loss: 0.3036 - precision: 0.9883 - recall: 0.8300 - f1_score: 0.9018 - val_loss: 0.3074 - val_precision: 0.9434 - val_recall: 0.8333 - val_f1_score: 0.8850\n",
            "Epoch 629/3000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.3036 - precision: 0.9802 - recall: 0.8300 - f1_score: 0.8985 - val_loss: 0.3072 - val_precision: 0.9423 - val_recall: 0.8167 - val_f1_score: 0.8750\n",
            "Epoch 630/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.3033 - precision: 0.9839 - recall: 0.8267 - f1_score: 0.8978 - val_loss: 0.3070 - val_precision: 0.9423 - val_recall: 0.8167 - val_f1_score: 0.8750\n",
            "Epoch 631/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3032 - precision: 0.9835 - recall: 0.8267 - f1_score: 0.8964 - val_loss: 0.3067 - val_precision: 0.9423 - val_recall: 0.8167 - val_f1_score: 0.8750\n",
            "Epoch 632/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3029 - precision: 0.9843 - recall: 0.8233 - f1_score: 0.8957 - val_loss: 0.3065 - val_precision: 0.9423 - val_recall: 0.8167 - val_f1_score: 0.8750\n",
            "Epoch 633/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3025 - precision: 0.9842 - recall: 0.8267 - f1_score: 0.8985 - val_loss: 0.3063 - val_precision: 0.9423 - val_recall: 0.8167 - val_f1_score: 0.8750\n",
            "Epoch 634/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3024 - precision: 0.9881 - recall: 0.8267 - f1_score: 0.8998 - val_loss: 0.3060 - val_precision: 0.9423 - val_recall: 0.8167 - val_f1_score: 0.8750\n",
            "Epoch 635/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.3021 - precision: 0.9846 - recall: 0.8267 - f1_score: 0.8976 - val_loss: 0.3059 - val_precision: 0.9423 - val_recall: 0.8167 - val_f1_score: 0.8750\n",
            "Epoch 636/3000\n",
            "300/300 [==============================] - 0s 104us/step - loss: 0.3019 - precision: 0.9880 - recall: 0.8300 - f1_score: 0.9018 - val_loss: 0.3057 - val_precision: 0.9423 - val_recall: 0.8167 - val_f1_score: 0.8750\n",
            "Epoch 637/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.3017 - precision: 0.9919 - recall: 0.8300 - f1_score: 0.9037 - val_loss: 0.3056 - val_precision: 0.9423 - val_recall: 0.8167 - val_f1_score: 0.8750\n",
            "Epoch 638/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3015 - precision: 0.9922 - recall: 0.8300 - f1_score: 0.9024 - val_loss: 0.3054 - val_precision: 0.9434 - val_recall: 0.8333 - val_f1_score: 0.8850\n",
            "Epoch 639/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3014 - precision: 0.9921 - recall: 0.8300 - f1_score: 0.9037 - val_loss: 0.3051 - val_precision: 0.9434 - val_recall: 0.8333 - val_f1_score: 0.8850\n",
            "Epoch 640/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3015 - precision: 0.9923 - recall: 0.8200 - f1_score: 0.8964 - val_loss: 0.3050 - val_precision: 0.9434 - val_recall: 0.8333 - val_f1_score: 0.8850\n",
            "Epoch 641/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3008 - precision: 0.9845 - recall: 0.8367 - f1_score: 0.9043 - val_loss: 0.3047 - val_precision: 0.9434 - val_recall: 0.8333 - val_f1_score: 0.8850\n",
            "Epoch 642/3000\n",
            "300/300 [==============================] - 0s 106us/step - loss: 0.3006 - precision: 0.9920 - recall: 0.8333 - f1_score: 0.9049 - val_loss: 0.3045 - val_precision: 0.9434 - val_recall: 0.8333 - val_f1_score: 0.8850\n",
            "Epoch 643/3000\n",
            "300/300 [==============================] - 0s 107us/step - loss: 0.3005 - precision: 0.9875 - recall: 0.8333 - f1_score: 0.9027 - val_loss: 0.3044 - val_precision: 0.9434 - val_recall: 0.8333 - val_f1_score: 0.8850\n",
            "Epoch 644/3000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.3005 - precision: 0.9804 - recall: 0.8367 - f1_score: 0.9014 - val_loss: 0.3042 - val_precision: 0.9434 - val_recall: 0.8333 - val_f1_score: 0.8850\n",
            "Epoch 645/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.3000 - precision: 0.9881 - recall: 0.8400 - f1_score: 0.9080 - val_loss: 0.3039 - val_precision: 0.9434 - val_recall: 0.8333 - val_f1_score: 0.8850\n",
            "Epoch 646/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2999 - precision: 0.9842 - recall: 0.8367 - f1_score: 0.9034 - val_loss: 0.3037 - val_precision: 0.9434 - val_recall: 0.8333 - val_f1_score: 0.8850\n",
            "Epoch 647/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2997 - precision: 0.9886 - recall: 0.8333 - f1_score: 0.9036 - val_loss: 0.3035 - val_precision: 0.9434 - val_recall: 0.8333 - val_f1_score: 0.8850\n",
            "Epoch 648/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2995 - precision: 0.9923 - recall: 0.8333 - f1_score: 0.9055 - val_loss: 0.3033 - val_precision: 0.9434 - val_recall: 0.8333 - val_f1_score: 0.8850\n",
            "Epoch 649/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2993 - precision: 0.9850 - recall: 0.8367 - f1_score: 0.9036 - val_loss: 0.3031 - val_precision: 0.9434 - val_recall: 0.8333 - val_f1_score: 0.8850\n",
            "Epoch 650/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2992 - precision: 0.9922 - recall: 0.8367 - f1_score: 0.9077 - val_loss: 0.3030 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 651/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2988 - precision: 0.9846 - recall: 0.8400 - f1_score: 0.9064 - val_loss: 0.3028 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 652/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2986 - precision: 0.9921 - recall: 0.8367 - f1_score: 0.9072 - val_loss: 0.3026 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 653/3000\n",
            "300/300 [==============================] - 0s 78us/step - loss: 0.2984 - precision: 0.9839 - recall: 0.8400 - f1_score: 0.9052 - val_loss: 0.3023 - val_precision: 0.9434 - val_recall: 0.8333 - val_f1_score: 0.8850\n",
            "Epoch 654/3000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.2982 - precision: 0.9885 - recall: 0.8400 - f1_score: 0.9073 - val_loss: 0.3020 - val_precision: 0.9434 - val_recall: 0.8333 - val_f1_score: 0.8850\n",
            "Epoch 655/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2981 - precision: 0.9836 - recall: 0.8400 - f1_score: 0.9053 - val_loss: 0.3018 - val_precision: 0.9434 - val_recall: 0.8333 - val_f1_score: 0.8850\n",
            "Epoch 656/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2977 - precision: 0.9804 - recall: 0.8433 - f1_score: 0.9063 - val_loss: 0.3016 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 657/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.2974 - precision: 0.9921 - recall: 0.8333 - f1_score: 0.9052 - val_loss: 0.3014 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 658/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.2973 - precision: 0.9843 - recall: 0.8400 - f1_score: 0.9064 - val_loss: 0.3012 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 659/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2972 - precision: 0.9883 - recall: 0.8400 - f1_score: 0.9078 - val_loss: 0.3009 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 660/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2969 - precision: 0.9922 - recall: 0.8400 - f1_score: 0.9096 - val_loss: 0.3007 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 661/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2972 - precision: 0.9920 - recall: 0.8267 - f1_score: 0.9014 - val_loss: 0.3005 - val_precision: 0.9434 - val_recall: 0.8333 - val_f1_score: 0.8850\n",
            "Epoch 662/3000\n",
            "300/300 [==============================] - 0s 79us/step - loss: 0.2966 - precision: 0.9886 - recall: 0.8400 - f1_score: 0.9074 - val_loss: 0.3003 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 663/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.2963 - precision: 0.9922 - recall: 0.8333 - f1_score: 0.9056 - val_loss: 0.3001 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 664/3000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.2962 - precision: 0.9918 - recall: 0.8400 - f1_score: 0.9085 - val_loss: 0.2999 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 665/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2958 - precision: 0.9921 - recall: 0.8367 - f1_score: 0.9072 - val_loss: 0.2997 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 666/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2956 - precision: 0.9924 - recall: 0.8367 - f1_score: 0.9073 - val_loss: 0.2995 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 667/3000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.2955 - precision: 0.9920 - recall: 0.8400 - f1_score: 0.9091 - val_loss: 0.2994 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 668/3000\n",
            "300/300 [==============================] - 0s 104us/step - loss: 0.2953 - precision: 0.9923 - recall: 0.8400 - f1_score: 0.9080 - val_loss: 0.2992 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 669/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2952 - precision: 0.9920 - recall: 0.8433 - f1_score: 0.9114 - val_loss: 0.2989 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 670/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2951 - precision: 0.9924 - recall: 0.8300 - f1_score: 0.9033 - val_loss: 0.2988 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 671/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2946 - precision: 0.9923 - recall: 0.8433 - f1_score: 0.9115 - val_loss: 0.2986 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 672/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2945 - precision: 0.9888 - recall: 0.8433 - f1_score: 0.9092 - val_loss: 0.2984 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 673/3000\n",
            "300/300 [==============================] - 0s 111us/step - loss: 0.2943 - precision: 0.9919 - recall: 0.8367 - f1_score: 0.9070 - val_loss: 0.2981 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 674/3000\n",
            "300/300 [==============================] - 0s 106us/step - loss: 0.2946 - precision: 0.9914 - recall: 0.8400 - f1_score: 0.9080 - val_loss: 0.2980 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 675/3000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.2940 - precision: 0.9886 - recall: 0.8433 - f1_score: 0.9100 - val_loss: 0.2978 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 676/3000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.2937 - precision: 0.9849 - recall: 0.8433 - f1_score: 0.9082 - val_loss: 0.2977 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 677/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.2935 - precision: 0.9922 - recall: 0.8433 - f1_score: 0.9116 - val_loss: 0.2975 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 678/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2932 - precision: 0.9917 - recall: 0.8433 - f1_score: 0.9108 - val_loss: 0.2972 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 679/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2932 - precision: 0.9769 - recall: 0.8433 - f1_score: 0.9043 - val_loss: 0.2970 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 680/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2930 - precision: 0.9924 - recall: 0.8433 - f1_score: 0.9111 - val_loss: 0.2968 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 681/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2928 - precision: 0.9924 - recall: 0.8367 - f1_score: 0.9076 - val_loss: 0.2967 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 682/3000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.2925 - precision: 0.9808 - recall: 0.8433 - f1_score: 0.9055 - val_loss: 0.2965 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 683/3000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.2923 - precision: 0.9808 - recall: 0.8433 - f1_score: 0.9066 - val_loss: 0.2963 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 684/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2921 - precision: 0.9922 - recall: 0.8433 - f1_score: 0.9117 - val_loss: 0.2961 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 685/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2920 - precision: 0.9926 - recall: 0.8433 - f1_score: 0.9113 - val_loss: 0.2960 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 686/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.2918 - precision: 0.9922 - recall: 0.8467 - f1_score: 0.9136 - val_loss: 0.2958 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 687/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2916 - precision: 0.9845 - recall: 0.8400 - f1_score: 0.9064 - val_loss: 0.2956 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 688/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.2914 - precision: 0.9883 - recall: 0.8467 - f1_score: 0.9116 - val_loss: 0.2953 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 689/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.2912 - precision: 0.9919 - recall: 0.8433 - f1_score: 0.9112 - val_loss: 0.2951 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 690/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2911 - precision: 0.9921 - recall: 0.8467 - f1_score: 0.9133 - val_loss: 0.2949 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 691/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2912 - precision: 0.9916 - recall: 0.8400 - f1_score: 0.9078 - val_loss: 0.2947 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 692/3000\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.2906 - precision: 0.9808 - recall: 0.8467 - f1_score: 0.9085 - val_loss: 0.2946 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 693/3000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.2904 - precision: 0.9806 - recall: 0.8467 - f1_score: 0.9082 - val_loss: 0.2944 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 694/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.2902 - precision: 0.9886 - recall: 0.8467 - f1_score: 0.9118 - val_loss: 0.2942 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 695/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.2899 - precision: 0.9843 - recall: 0.8433 - f1_score: 0.9077 - val_loss: 0.2940 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 696/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2898 - precision: 0.9919 - recall: 0.8467 - f1_score: 0.9133 - val_loss: 0.2937 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 697/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.2897 - precision: 0.9924 - recall: 0.8467 - f1_score: 0.9135 - val_loss: 0.2935 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 698/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2894 - precision: 0.9922 - recall: 0.8467 - f1_score: 0.9131 - val_loss: 0.2932 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 699/3000\n",
            "300/300 [==============================] - 0s 128us/step - loss: 0.2895 - precision: 0.9914 - recall: 0.8400 - f1_score: 0.9074 - val_loss: 0.2930 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 700/3000\n",
            "300/300 [==============================] - 0s 126us/step - loss: 0.2890 - precision: 0.9840 - recall: 0.8467 - f1_score: 0.9096 - val_loss: 0.2928 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 701/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.2887 - precision: 0.9919 - recall: 0.8433 - f1_score: 0.9112 - val_loss: 0.2926 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 702/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2887 - precision: 0.9922 - recall: 0.8433 - f1_score: 0.9107 - val_loss: 0.2925 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 703/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.2886 - precision: 0.9920 - recall: 0.8467 - f1_score: 0.9123 - val_loss: 0.2923 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 704/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2884 - precision: 0.9915 - recall: 0.8433 - f1_score: 0.9108 - val_loss: 0.2921 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 705/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.2882 - precision: 0.9919 - recall: 0.8433 - f1_score: 0.9113 - val_loss: 0.2920 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 706/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2880 - precision: 0.9922 - recall: 0.8433 - f1_score: 0.9111 - val_loss: 0.2919 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 707/3000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.2877 - precision: 0.9920 - recall: 0.8467 - f1_score: 0.9129 - val_loss: 0.2917 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 708/3000\n",
            "300/300 [==============================] - 0s 82us/step - loss: 0.2875 - precision: 0.9921 - recall: 0.8467 - f1_score: 0.9133 - val_loss: 0.2915 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 709/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.2874 - precision: 0.9927 - recall: 0.8467 - f1_score: 0.9130 - val_loss: 0.2913 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 710/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2872 - precision: 0.9835 - recall: 0.8467 - f1_score: 0.9089 - val_loss: 0.2910 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 711/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2869 - precision: 0.9921 - recall: 0.8467 - f1_score: 0.9133 - val_loss: 0.2908 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 712/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2867 - precision: 0.9923 - recall: 0.8433 - f1_score: 0.9114 - val_loss: 0.2906 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 713/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.2868 - precision: 0.9921 - recall: 0.8433 - f1_score: 0.9112 - val_loss: 0.2904 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 714/3000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.2864 - precision: 0.9921 - recall: 0.8467 - f1_score: 0.9130 - val_loss: 0.2903 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 715/3000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.2862 - precision: 0.9924 - recall: 0.8467 - f1_score: 0.9130 - val_loss: 0.2901 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 716/3000\n",
            "300/300 [==============================] - 0s 78us/step - loss: 0.2861 - precision: 0.9846 - recall: 0.8467 - f1_score: 0.9102 - val_loss: 0.2900 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 717/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.2861 - precision: 0.9885 - recall: 0.8467 - f1_score: 0.9112 - val_loss: 0.2898 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 718/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2857 - precision: 0.9924 - recall: 0.8467 - f1_score: 0.9135 - val_loss: 0.2897 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 719/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2854 - precision: 0.9918 - recall: 0.8467 - f1_score: 0.9131 - val_loss: 0.2895 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 720/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.2852 - precision: 0.9919 - recall: 0.8467 - f1_score: 0.9134 - val_loss: 0.2894 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 721/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.2852 - precision: 0.9848 - recall: 0.8467 - f1_score: 0.9100 - val_loss: 0.2891 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 722/3000\n",
            "300/300 [==============================] - 0s 124us/step - loss: 0.2849 - precision: 0.9922 - recall: 0.8467 - f1_score: 0.9131 - val_loss: 0.2889 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 723/3000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.2848 - precision: 0.9923 - recall: 0.8467 - f1_score: 0.9134 - val_loss: 0.2887 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 724/3000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.2847 - precision: 0.9922 - recall: 0.8467 - f1_score: 0.9126 - val_loss: 0.2884 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 725/3000\n",
            "300/300 [==============================] - 0s 80us/step - loss: 0.2844 - precision: 0.9882 - recall: 0.8467 - f1_score: 0.9116 - val_loss: 0.2882 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 726/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2841 - precision: 0.9918 - recall: 0.8467 - f1_score: 0.9129 - val_loss: 0.2880 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 727/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2840 - precision: 0.9922 - recall: 0.8467 - f1_score: 0.9131 - val_loss: 0.2879 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 728/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2839 - precision: 0.9922 - recall: 0.8467 - f1_score: 0.9132 - val_loss: 0.2877 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 729/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2836 - precision: 0.9921 - recall: 0.8467 - f1_score: 0.9126 - val_loss: 0.2876 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 730/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.2834 - precision: 0.9924 - recall: 0.8467 - f1_score: 0.9133 - val_loss: 0.2874 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 731/3000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.2833 - precision: 0.9919 - recall: 0.8467 - f1_score: 0.9132 - val_loss: 0.2872 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 732/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.2832 - precision: 0.9813 - recall: 0.8467 - f1_score: 0.9086 - val_loss: 0.2870 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 733/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2831 - precision: 0.9921 - recall: 0.8467 - f1_score: 0.9134 - val_loss: 0.2869 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 734/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2829 - precision: 0.9921 - recall: 0.8467 - f1_score: 0.9135 - val_loss: 0.2868 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 735/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2825 - precision: 0.9890 - recall: 0.8467 - f1_score: 0.9109 - val_loss: 0.2866 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 736/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2823 - precision: 0.9920 - recall: 0.8467 - f1_score: 0.9129 - val_loss: 0.2864 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 737/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2822 - precision: 0.9877 - recall: 0.8467 - f1_score: 0.9107 - val_loss: 0.2862 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 738/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2819 - precision: 0.9924 - recall: 0.8467 - f1_score: 0.9129 - val_loss: 0.2859 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 739/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2819 - precision: 0.9885 - recall: 0.8467 - f1_score: 0.9117 - val_loss: 0.2857 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 740/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.2816 - precision: 0.9921 - recall: 0.8467 - f1_score: 0.9134 - val_loss: 0.2855 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 741/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2814 - precision: 0.9922 - recall: 0.8467 - f1_score: 0.9129 - val_loss: 0.2854 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 742/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2813 - precision: 0.9922 - recall: 0.8500 - f1_score: 0.9152 - val_loss: 0.2852 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 743/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2812 - precision: 0.9922 - recall: 0.8500 - f1_score: 0.9155 - val_loss: 0.2851 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 744/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2810 - precision: 0.9887 - recall: 0.8467 - f1_score: 0.9110 - val_loss: 0.2849 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 745/3000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.2809 - precision: 0.9925 - recall: 0.8467 - f1_score: 0.9133 - val_loss: 0.2848 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 746/3000\n",
            "300/300 [==============================] - 0s 78us/step - loss: 0.2808 - precision: 0.9884 - recall: 0.8467 - f1_score: 0.9118 - val_loss: 0.2846 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 747/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.2804 - precision: 0.9885 - recall: 0.8467 - f1_score: 0.9119 - val_loss: 0.2844 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 748/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2803 - precision: 0.9924 - recall: 0.8467 - f1_score: 0.9130 - val_loss: 0.2843 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 749/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2801 - precision: 0.9882 - recall: 0.8467 - f1_score: 0.9113 - val_loss: 0.2840 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 750/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.2798 - precision: 0.9924 - recall: 0.8467 - f1_score: 0.9136 - val_loss: 0.2837 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 751/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2799 - precision: 0.9923 - recall: 0.8467 - f1_score: 0.9133 - val_loss: 0.2835 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 752/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2795 - precision: 0.9925 - recall: 0.8467 - f1_score: 0.9133 - val_loss: 0.2833 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 753/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2793 - precision: 0.9920 - recall: 0.8467 - f1_score: 0.9133 - val_loss: 0.2832 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 754/3000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.2792 - precision: 0.9925 - recall: 0.8467 - f1_score: 0.9133 - val_loss: 0.2831 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 755/3000\n",
            "300/300 [==============================] - 0s 124us/step - loss: 0.2791 - precision: 0.9916 - recall: 0.8467 - f1_score: 0.9128 - val_loss: 0.2829 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 756/3000\n",
            "300/300 [==============================] - 0s 101us/step - loss: 0.2788 - precision: 0.9924 - recall: 0.8467 - f1_score: 0.9135 - val_loss: 0.2828 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 757/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2788 - precision: 0.9919 - recall: 0.8467 - f1_score: 0.9131 - val_loss: 0.2826 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 758/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2786 - precision: 0.9922 - recall: 0.8467 - f1_score: 0.9135 - val_loss: 0.2825 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 759/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2785 - precision: 0.9924 - recall: 0.8467 - f1_score: 0.9136 - val_loss: 0.2823 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 760/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2781 - precision: 0.9884 - recall: 0.8467 - f1_score: 0.9114 - val_loss: 0.2820 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 761/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2779 - precision: 0.9922 - recall: 0.8467 - f1_score: 0.9135 - val_loss: 0.2818 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 762/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2779 - precision: 0.9920 - recall: 0.8467 - f1_score: 0.9133 - val_loss: 0.2817 - val_precision: 0.9615 - val_recall: 0.8333 - val_f1_score: 0.8929\n",
            "Epoch 763/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.2777 - precision: 0.9881 - recall: 0.8467 - f1_score: 0.9116 - val_loss: 0.2815 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 764/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2778 - precision: 0.9873 - recall: 0.8467 - f1_score: 0.9108 - val_loss: 0.2813 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 765/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2772 - precision: 0.9922 - recall: 0.8467 - f1_score: 0.9131 - val_loss: 0.2811 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 766/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.2772 - precision: 0.9924 - recall: 0.8500 - f1_score: 0.9154 - val_loss: 0.2810 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 767/3000\n",
            "300/300 [==============================] - 0s 101us/step - loss: 0.2771 - precision: 0.9925 - recall: 0.8467 - f1_score: 0.9130 - val_loss: 0.2809 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 768/3000\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.2767 - precision: 0.9922 - recall: 0.8467 - f1_score: 0.9134 - val_loss: 0.2807 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 769/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.2765 - precision: 0.9921 - recall: 0.8467 - f1_score: 0.9125 - val_loss: 0.2805 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 770/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2765 - precision: 0.9920 - recall: 0.8500 - f1_score: 0.9153 - val_loss: 0.2803 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 771/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2763 - precision: 0.9926 - recall: 0.8500 - f1_score: 0.9149 - val_loss: 0.2801 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 772/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.2761 - precision: 0.9922 - recall: 0.8467 - f1_score: 0.9131 - val_loss: 0.2800 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 773/3000\n",
            "300/300 [==============================] - 0s 107us/step - loss: 0.2759 - precision: 0.9921 - recall: 0.8467 - f1_score: 0.9135 - val_loss: 0.2798 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 774/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2757 - precision: 0.9924 - recall: 0.8500 - f1_score: 0.9152 - val_loss: 0.2796 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 775/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2755 - precision: 0.9925 - recall: 0.8500 - f1_score: 0.9150 - val_loss: 0.2794 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 776/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2755 - precision: 0.9922 - recall: 0.8467 - f1_score: 0.9134 - val_loss: 0.2792 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 777/3000\n",
            "300/300 [==============================] - 0s 115us/step - loss: 0.2752 - precision: 0.9927 - recall: 0.8500 - f1_score: 0.9152 - val_loss: 0.2791 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 778/3000\n",
            "300/300 [==============================] - 0s 81us/step - loss: 0.2751 - precision: 0.9919 - recall: 0.8467 - f1_score: 0.9134 - val_loss: 0.2789 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 779/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.2751 - precision: 0.9919 - recall: 0.8500 - f1_score: 0.9150 - val_loss: 0.2788 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 780/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2749 - precision: 0.9916 - recall: 0.8467 - f1_score: 0.9130 - val_loss: 0.2786 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 781/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2746 - precision: 0.9922 - recall: 0.8467 - f1_score: 0.9136 - val_loss: 0.2784 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 782/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2744 - precision: 0.9916 - recall: 0.8500 - f1_score: 0.9148 - val_loss: 0.2783 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 783/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2742 - precision: 0.9924 - recall: 0.8500 - f1_score: 0.9149 - val_loss: 0.2781 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 784/3000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.2741 - precision: 0.9914 - recall: 0.8467 - f1_score: 0.9118 - val_loss: 0.2779 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 785/3000\n",
            "300/300 [==============================] - 0s 112us/step - loss: 0.2740 - precision: 0.9916 - recall: 0.8467 - f1_score: 0.9126 - val_loss: 0.2777 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 786/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.2740 - precision: 0.9915 - recall: 0.8500 - f1_score: 0.9141 - val_loss: 0.2775 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 787/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2737 - precision: 0.9919 - recall: 0.8500 - f1_score: 0.9148 - val_loss: 0.2773 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 788/3000\n",
            "300/300 [==============================] - 0s 109us/step - loss: 0.2735 - precision: 0.9922 - recall: 0.8500 - f1_score: 0.9153 - val_loss: 0.2772 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 789/3000\n",
            "300/300 [==============================] - 0s 78us/step - loss: 0.2733 - precision: 0.9924 - recall: 0.8467 - f1_score: 0.9130 - val_loss: 0.2770 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 790/3000\n",
            "300/300 [==============================] - 0s 81us/step - loss: 0.2730 - precision: 0.9924 - recall: 0.8500 - f1_score: 0.9156 - val_loss: 0.2769 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 791/3000\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.2729 - precision: 0.9922 - recall: 0.8500 - f1_score: 0.9155 - val_loss: 0.2767 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 792/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2727 - precision: 0.9925 - recall: 0.8500 - f1_score: 0.9155 - val_loss: 0.2765 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 793/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.2727 - precision: 0.9923 - recall: 0.8500 - f1_score: 0.9153 - val_loss: 0.2763 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 794/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2724 - precision: 0.9923 - recall: 0.8500 - f1_score: 0.9155 - val_loss: 0.2762 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 795/3000\n",
            "300/300 [==============================] - 0s 80us/step - loss: 0.2725 - precision: 0.9925 - recall: 0.8467 - f1_score: 0.9134 - val_loss: 0.2760 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 796/3000\n",
            "300/300 [==============================] - 0s 102us/step - loss: 0.2721 - precision: 0.9924 - recall: 0.8500 - f1_score: 0.9151 - val_loss: 0.2759 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 797/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.2720 - precision: 0.9917 - recall: 0.8500 - f1_score: 0.9146 - val_loss: 0.2757 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 798/3000\n",
            "300/300 [==============================] - 0s 81us/step - loss: 0.2718 - precision: 0.9921 - recall: 0.8500 - f1_score: 0.9152 - val_loss: 0.2756 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 799/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.2716 - precision: 0.9923 - recall: 0.8500 - f1_score: 0.9152 - val_loss: 0.2754 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 800/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.2718 - precision: 0.9922 - recall: 0.8467 - f1_score: 0.9135 - val_loss: 0.2753 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 801/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.2713 - precision: 0.9924 - recall: 0.8500 - f1_score: 0.9155 - val_loss: 0.2751 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 802/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.2711 - precision: 0.9924 - recall: 0.8500 - f1_score: 0.9150 - val_loss: 0.2749 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 803/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.2710 - precision: 0.9921 - recall: 0.8500 - f1_score: 0.9151 - val_loss: 0.2747 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 804/3000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.2710 - precision: 0.9919 - recall: 0.8500 - f1_score: 0.9148 - val_loss: 0.2746 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 805/3000\n",
            "300/300 [==============================] - 0s 113us/step - loss: 0.2707 - precision: 0.9923 - recall: 0.8500 - f1_score: 0.9154 - val_loss: 0.2746 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 806/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2705 - precision: 0.9918 - recall: 0.8500 - f1_score: 0.9149 - val_loss: 0.2744 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 807/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.2703 - precision: 0.9956 - recall: 0.8500 - f1_score: 0.9163 - val_loss: 0.2742 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 808/3000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.2701 - precision: 0.9925 - recall: 0.8500 - f1_score: 0.9148 - val_loss: 0.2740 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 809/3000\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.2701 - precision: 0.9920 - recall: 0.8467 - f1_score: 0.9128 - val_loss: 0.2738 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 810/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.2700 - precision: 0.9915 - recall: 0.8500 - f1_score: 0.9146 - val_loss: 0.2736 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 811/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.2698 - precision: 0.9917 - recall: 0.8533 - f1_score: 0.9167 - val_loss: 0.2735 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 812/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2695 - precision: 0.9923 - recall: 0.8500 - f1_score: 0.9156 - val_loss: 0.2733 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 813/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.2693 - precision: 0.9924 - recall: 0.8500 - f1_score: 0.9154 - val_loss: 0.2732 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 814/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.2693 - precision: 0.9922 - recall: 0.8500 - f1_score: 0.9153 - val_loss: 0.2730 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 815/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2690 - precision: 0.9922 - recall: 0.8500 - f1_score: 0.9138 - val_loss: 0.2729 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 816/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2688 - precision: 0.9963 - recall: 0.8500 - f1_score: 0.9169 - val_loss: 0.2727 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 817/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2688 - precision: 0.9915 - recall: 0.8467 - f1_score: 0.9129 - val_loss: 0.2725 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 818/3000\n",
            "300/300 [==============================] - 0s 106us/step - loss: 0.2688 - precision: 0.9923 - recall: 0.8500 - f1_score: 0.9147 - val_loss: 0.2724 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 819/3000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.2684 - precision: 0.9920 - recall: 0.8500 - f1_score: 0.9151 - val_loss: 0.2722 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 820/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.2681 - precision: 0.9919 - recall: 0.8500 - f1_score: 0.9147 - val_loss: 0.2720 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 821/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.2681 - precision: 0.9917 - recall: 0.8500 - f1_score: 0.9149 - val_loss: 0.2718 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 822/3000\n",
            "300/300 [==============================] - 0s 79us/step - loss: 0.2680 - precision: 0.9917 - recall: 0.8500 - f1_score: 0.9144 - val_loss: 0.2716 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 823/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.2678 - precision: 0.9922 - recall: 0.8500 - f1_score: 0.9155 - val_loss: 0.2714 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 824/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.2676 - precision: 0.9924 - recall: 0.8500 - f1_score: 0.9147 - val_loss: 0.2713 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 825/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.2676 - precision: 0.9924 - recall: 0.8500 - f1_score: 0.9149 - val_loss: 0.2712 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 826/3000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.2673 - precision: 0.9920 - recall: 0.8500 - f1_score: 0.9151 - val_loss: 0.2710 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 827/3000\n",
            "300/300 [==============================] - 0s 115us/step - loss: 0.2671 - precision: 0.9919 - recall: 0.8500 - f1_score: 0.9150 - val_loss: 0.2708 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 828/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.2670 - precision: 0.9925 - recall: 0.8500 - f1_score: 0.9153 - val_loss: 0.2706 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 829/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.2669 - precision: 0.9923 - recall: 0.8500 - f1_score: 0.9151 - val_loss: 0.2705 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 830/3000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.2667 - precision: 0.9923 - recall: 0.8500 - f1_score: 0.9153 - val_loss: 0.2704 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 831/3000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.2666 - precision: 0.9924 - recall: 0.8500 - f1_score: 0.9152 - val_loss: 0.2702 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 832/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.2665 - precision: 0.9922 - recall: 0.8500 - f1_score: 0.9151 - val_loss: 0.2700 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 833/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2665 - precision: 0.9919 - recall: 0.8533 - f1_score: 0.9169 - val_loss: 0.2699 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 834/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2661 - precision: 0.9923 - recall: 0.8500 - f1_score: 0.9154 - val_loss: 0.2698 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 835/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.2658 - precision: 0.9920 - recall: 0.8500 - f1_score: 0.9151 - val_loss: 0.2696 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 836/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.2659 - precision: 0.9924 - recall: 0.8500 - f1_score: 0.9152 - val_loss: 0.2695 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 837/3000\n",
            "300/300 [==============================] - 0s 80us/step - loss: 0.2656 - precision: 0.9918 - recall: 0.8533 - f1_score: 0.9162 - val_loss: 0.2694 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 838/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2654 - precision: 0.9961 - recall: 0.8500 - f1_score: 0.9170 - val_loss: 0.2692 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 839/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2652 - precision: 0.9922 - recall: 0.8500 - f1_score: 0.9156 - val_loss: 0.2690 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 840/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2651 - precision: 0.9919 - recall: 0.8500 - f1_score: 0.9149 - val_loss: 0.2688 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 841/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.2650 - precision: 0.9925 - recall: 0.8500 - f1_score: 0.9151 - val_loss: 0.2689 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 842/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.2648 - precision: 0.9922 - recall: 0.8500 - f1_score: 0.9149 - val_loss: 0.2687 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 843/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2647 - precision: 0.9922 - recall: 0.8500 - f1_score: 0.9155 - val_loss: 0.2686 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 844/3000\n",
            "300/300 [==============================] - 0s 103us/step - loss: 0.2646 - precision: 0.9921 - recall: 0.8500 - f1_score: 0.9151 - val_loss: 0.2684 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 845/3000\n",
            "300/300 [==============================] - 0s 78us/step - loss: 0.2644 - precision: 0.9920 - recall: 0.8500 - f1_score: 0.9153 - val_loss: 0.2681 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 846/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2643 - precision: 0.9922 - recall: 0.8500 - f1_score: 0.9154 - val_loss: 0.2680 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 847/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2641 - precision: 0.9919 - recall: 0.8500 - f1_score: 0.9151 - val_loss: 0.2679 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 848/3000\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.2641 - precision: 0.9919 - recall: 0.8500 - f1_score: 0.9150 - val_loss: 0.2677 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 849/3000\n",
            "300/300 [==============================] - 0s 111us/step - loss: 0.2638 - precision: 0.9922 - recall: 0.8500 - f1_score: 0.9156 - val_loss: 0.2677 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 850/3000\n",
            "300/300 [==============================] - 0s 80us/step - loss: 0.2637 - precision: 0.9922 - recall: 0.8500 - f1_score: 0.9155 - val_loss: 0.2674 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 851/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2634 - precision: 0.9961 - recall: 0.8500 - f1_score: 0.9170 - val_loss: 0.2671 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 852/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.2634 - precision: 0.9919 - recall: 0.8500 - f1_score: 0.9149 - val_loss: 0.2670 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 853/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.2631 - precision: 0.9921 - recall: 0.8500 - f1_score: 0.9152 - val_loss: 0.2668 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 854/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.2631 - precision: 0.9924 - recall: 0.8533 - f1_score: 0.9166 - val_loss: 0.2667 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 855/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2628 - precision: 0.9920 - recall: 0.8500 - f1_score: 0.9153 - val_loss: 0.2665 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 856/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2627 - precision: 0.9916 - recall: 0.8500 - f1_score: 0.9143 - val_loss: 0.2664 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 857/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2626 - precision: 0.9921 - recall: 0.8533 - f1_score: 0.9171 - val_loss: 0.2663 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 858/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.2624 - precision: 0.9930 - recall: 0.8500 - f1_score: 0.9152 - val_loss: 0.2662 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 859/3000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.2622 - precision: 0.9922 - recall: 0.8500 - f1_score: 0.9154 - val_loss: 0.2659 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 860/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2622 - precision: 0.9915 - recall: 0.8500 - f1_score: 0.9142 - val_loss: 0.2658 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 861/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2623 - precision: 0.9914 - recall: 0.8500 - f1_score: 0.9131 - val_loss: 0.2656 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 862/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2618 - precision: 0.9921 - recall: 0.8500 - f1_score: 0.9151 - val_loss: 0.2655 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 863/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.2616 - precision: 0.9922 - recall: 0.8500 - f1_score: 0.9155 - val_loss: 0.2654 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 864/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2615 - precision: 0.9960 - recall: 0.8500 - f1_score: 0.9169 - val_loss: 0.2652 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 865/3000\n",
            "300/300 [==============================] - 0s 101us/step - loss: 0.2613 - precision: 0.9960 - recall: 0.8533 - f1_score: 0.9190 - val_loss: 0.2651 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 866/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.2613 - precision: 0.9958 - recall: 0.8533 - f1_score: 0.9186 - val_loss: 0.2651 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 867/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2612 - precision: 0.9922 - recall: 0.8500 - f1_score: 0.9151 - val_loss: 0.2650 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 868/3000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.2609 - precision: 1.0000 - recall: 0.8500 - f1_score: 0.9188 - val_loss: 0.2648 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 869/3000\n",
            "300/300 [==============================] - 0s 119us/step - loss: 0.2609 - precision: 1.0000 - recall: 0.8500 - f1_score: 0.9182 - val_loss: 0.2646 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 870/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2607 - precision: 1.0000 - recall: 0.8500 - f1_score: 0.9183 - val_loss: 0.2645 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 871/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2606 - precision: 1.0000 - recall: 0.8500 - f1_score: 0.9186 - val_loss: 0.2643 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 872/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2603 - precision: 0.9960 - recall: 0.8533 - f1_score: 0.9191 - val_loss: 0.2642 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 873/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2602 - precision: 0.9924 - recall: 0.8500 - f1_score: 0.9149 - val_loss: 0.2640 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 874/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2601 - precision: 0.9922 - recall: 0.8500 - f1_score: 0.9156 - val_loss: 0.2638 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 875/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.2598 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9205 - val_loss: 0.2636 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 876/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.2598 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9203 - val_loss: 0.2635 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 877/3000\n",
            "300/300 [==============================] - 0s 107us/step - loss: 0.2596 - precision: 0.9964 - recall: 0.8500 - f1_score: 0.9166 - val_loss: 0.2632 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 878/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2595 - precision: 0.9924 - recall: 0.8533 - f1_score: 0.9173 - val_loss: 0.2631 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 879/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2593 - precision: 0.9922 - recall: 0.8533 - f1_score: 0.9174 - val_loss: 0.2630 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 880/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2592 - precision: 0.9959 - recall: 0.8533 - f1_score: 0.9184 - val_loss: 0.2628 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 881/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2590 - precision: 0.9923 - recall: 0.8500 - f1_score: 0.9155 - val_loss: 0.2627 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 882/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.2589 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9206 - val_loss: 0.2625 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 883/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.2587 - precision: 0.9926 - recall: 0.8500 - f1_score: 0.9144 - val_loss: 0.2623 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 884/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2585 - precision: 0.9930 - recall: 0.8533 - f1_score: 0.9168 - val_loss: 0.2622 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 885/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2584 - precision: 0.9958 - recall: 0.8533 - f1_score: 0.9185 - val_loss: 0.2621 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 886/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.2583 - precision: 0.9921 - recall: 0.8533 - f1_score: 0.9171 - val_loss: 0.2619 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 887/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.2582 - precision: 0.9921 - recall: 0.8533 - f1_score: 0.9174 - val_loss: 0.2617 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 888/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.2582 - precision: 0.9957 - recall: 0.8533 - f1_score: 0.9183 - val_loss: 0.2616 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 889/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.2580 - precision: 0.9918 - recall: 0.8533 - f1_score: 0.9171 - val_loss: 0.2616 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 890/3000\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.2577 - precision: 0.9924 - recall: 0.8533 - f1_score: 0.9171 - val_loss: 0.2614 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 891/3000\n",
            "300/300 [==============================] - 0s 109us/step - loss: 0.2576 - precision: 0.9924 - recall: 0.8533 - f1_score: 0.9169 - val_loss: 0.2613 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 892/3000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.2577 - precision: 0.9922 - recall: 0.8500 - f1_score: 0.9153 - val_loss: 0.2611 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 893/3000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.2574 - precision: 0.9923 - recall: 0.8500 - f1_score: 0.9148 - val_loss: 0.2610 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 894/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.2573 - precision: 1.0000 - recall: 0.8500 - f1_score: 0.9180 - val_loss: 0.2608 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 895/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2570 - precision: 0.9959 - recall: 0.8533 - f1_score: 0.9188 - val_loss: 0.2607 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 896/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2570 - precision: 0.9923 - recall: 0.8500 - f1_score: 0.9155 - val_loss: 0.2606 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 897/3000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.2568 - precision: 0.9921 - recall: 0.8533 - f1_score: 0.9175 - val_loss: 0.2604 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 898/3000\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.2566 - precision: 0.9917 - recall: 0.8533 - f1_score: 0.9162 - val_loss: 0.2603 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 899/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.2566 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9202 - val_loss: 0.2602 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 900/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.2564 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9205 - val_loss: 0.2601 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 901/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.2563 - precision: 0.9925 - recall: 0.8533 - f1_score: 0.9158 - val_loss: 0.2599 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 902/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2560 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9204 - val_loss: 0.2598 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 903/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.2559 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9205 - val_loss: 0.2596 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 904/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2557 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9205 - val_loss: 0.2595 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 905/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.2557 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9205 - val_loss: 0.2593 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 906/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2556 - precision: 0.9919 - recall: 0.8500 - f1_score: 0.9153 - val_loss: 0.2591 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 907/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2553 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9206 - val_loss: 0.2589 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 908/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.2552 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9202 - val_loss: 0.2587 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 909/3000\n",
            "300/300 [==============================] - 0s 110us/step - loss: 0.2551 - precision: 0.9921 - recall: 0.8533 - f1_score: 0.9172 - val_loss: 0.2585 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 910/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.2551 - precision: 0.9927 - recall: 0.8533 - f1_score: 0.9161 - val_loss: 0.2584 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 911/3000\n",
            "300/300 [==============================] - 0s 82us/step - loss: 0.2550 - precision: 0.9962 - recall: 0.8533 - f1_score: 0.9168 - val_loss: 0.2583 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 912/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.2547 - precision: 0.9922 - recall: 0.8533 - f1_score: 0.9175 - val_loss: 0.2583 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 913/3000\n",
            "300/300 [==============================] - 0s 108us/step - loss: 0.2545 - precision: 0.9924 - recall: 0.8533 - f1_score: 0.9170 - val_loss: 0.2582 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 914/3000\n",
            "300/300 [==============================] - 0s 125us/step - loss: 0.2545 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9208 - val_loss: 0.2580 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 915/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2543 - precision: 0.9958 - recall: 0.8533 - f1_score: 0.9186 - val_loss: 0.2578 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 916/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.2541 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9206 - val_loss: 0.2576 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 917/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.2540 - precision: 0.9961 - recall: 0.8533 - f1_score: 0.9190 - val_loss: 0.2574 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 918/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.2540 - precision: 0.9922 - recall: 0.8533 - f1_score: 0.9169 - val_loss: 0.2574 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 919/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2538 - precision: 0.9921 - recall: 0.8533 - f1_score: 0.9172 - val_loss: 0.2573 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 920/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.2537 - precision: 0.9962 - recall: 0.8533 - f1_score: 0.9187 - val_loss: 0.2571 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 921/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.2535 - precision: 0.9924 - recall: 0.8533 - f1_score: 0.9175 - val_loss: 0.2570 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 922/3000\n",
            "300/300 [==============================] - 0s 111us/step - loss: 0.2533 - precision: 0.9921 - recall: 0.8533 - f1_score: 0.9173 - val_loss: 0.2569 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 923/3000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.2534 - precision: 0.9924 - recall: 0.8533 - f1_score: 0.9174 - val_loss: 0.2569 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 924/3000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.2531 - precision: 0.9929 - recall: 0.8533 - f1_score: 0.9170 - val_loss: 0.2567 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 925/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2529 - precision: 0.9924 - recall: 0.8533 - f1_score: 0.9173 - val_loss: 0.2565 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 926/3000\n",
            "300/300 [==============================] - 0s 79us/step - loss: 0.2530 - precision: 0.9922 - recall: 0.8533 - f1_score: 0.9163 - val_loss: 0.2564 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 927/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2527 - precision: 0.9922 - recall: 0.8533 - f1_score: 0.9173 - val_loss: 0.2563 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 928/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.2524 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9205 - val_loss: 0.2561 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 929/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2524 - precision: 0.9925 - recall: 0.8533 - f1_score: 0.9172 - val_loss: 0.2559 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 930/3000\n",
            "300/300 [==============================] - 0s 79us/step - loss: 0.2525 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9204 - val_loss: 0.2557 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 931/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2520 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9208 - val_loss: 0.2556 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 932/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.2520 - precision: 0.9953 - recall: 0.8533 - f1_score: 0.9174 - val_loss: 0.2555 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 933/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.2518 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9198 - val_loss: 0.2554 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 934/3000\n",
            "300/300 [==============================] - 0s 143us/step - loss: 0.2519 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9205 - val_loss: 0.2554 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 935/3000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.2516 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9204 - val_loss: 0.2552 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 936/3000\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.2516 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9200 - val_loss: 0.2551 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 937/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2515 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9198 - val_loss: 0.2550 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 938/3000\n",
            "300/300 [==============================] - 0s 79us/step - loss: 0.2511 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9208 - val_loss: 0.2548 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 939/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.2511 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9205 - val_loss: 0.2546 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 940/3000\n",
            "300/300 [==============================] - 0s 79us/step - loss: 0.2508 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9207 - val_loss: 0.2545 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 941/3000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.2509 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9201 - val_loss: 0.2544 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 942/3000\n",
            "300/300 [==============================] - 0s 80us/step - loss: 0.2506 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9208 - val_loss: 0.2543 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 943/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2505 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9205 - val_loss: 0.2543 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 944/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.2504 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9208 - val_loss: 0.2541 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 945/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2502 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9202 - val_loss: 0.2539 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 946/3000\n",
            "300/300 [==============================] - 0s 81us/step - loss: 0.2500 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9203 - val_loss: 0.2537 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 947/3000\n",
            "300/300 [==============================] - 0s 79us/step - loss: 0.2500 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9206 - val_loss: 0.2536 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 948/3000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.2498 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9203 - val_loss: 0.2534 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 949/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.2496 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9201 - val_loss: 0.2533 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 950/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.2497 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9207 - val_loss: 0.2533 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 951/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2498 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9201 - val_loss: 0.2532 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 952/3000\n",
            "300/300 [==============================] - 0s 78us/step - loss: 0.2495 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9206 - val_loss: 0.2529 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 953/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2492 - precision: 0.9963 - recall: 0.8533 - f1_score: 0.9191 - val_loss: 0.2528 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 954/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2490 - precision: 0.9959 - recall: 0.8533 - f1_score: 0.9188 - val_loss: 0.2527 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 955/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2489 - precision: 0.9961 - recall: 0.8533 - f1_score: 0.9192 - val_loss: 0.2526 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 956/3000\n",
            "300/300 [==============================] - 0s 141us/step - loss: 0.2488 - precision: 0.9959 - recall: 0.8533 - f1_score: 0.9185 - val_loss: 0.2524 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 957/3000\n",
            "300/300 [==============================] - 0s 122us/step - loss: 0.2486 - precision: 0.9962 - recall: 0.8533 - f1_score: 0.9190 - val_loss: 0.2523 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 958/3000\n",
            "300/300 [==============================] - 0s 81us/step - loss: 0.2485 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9207 - val_loss: 0.2522 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 959/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.2484 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9202 - val_loss: 0.2521 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 960/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.2483 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9205 - val_loss: 0.2519 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 961/3000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.2482 - precision: 0.9957 - recall: 0.8533 - f1_score: 0.9176 - val_loss: 0.2519 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 962/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2480 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9206 - val_loss: 0.2517 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 963/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2478 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9204 - val_loss: 0.2515 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 964/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2477 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9207 - val_loss: 0.2514 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 965/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2477 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9204 - val_loss: 0.2513 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 966/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2479 - precision: 0.9959 - recall: 0.8533 - f1_score: 0.9189 - val_loss: 0.2510 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 967/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2475 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9208 - val_loss: 0.2509 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 968/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2474 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9203 - val_loss: 0.2509 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 969/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.2471 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9204 - val_loss: 0.2507 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 970/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.2469 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9206 - val_loss: 0.2506 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 971/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2471 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9197 - val_loss: 0.2504 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 972/3000\n",
            "300/300 [==============================] - 0s 79us/step - loss: 0.2467 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9204 - val_loss: 0.2502 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 973/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.2467 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9201 - val_loss: 0.2500 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 974/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2466 - precision: 0.9961 - recall: 0.8533 - f1_score: 0.9181 - val_loss: 0.2500 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 975/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2465 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9197 - val_loss: 0.2499 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 976/3000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.2462 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9204 - val_loss: 0.2497 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 977/3000\n",
            "300/300 [==============================] - 0s 110us/step - loss: 0.2460 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9205 - val_loss: 0.2496 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 978/3000\n",
            "300/300 [==============================] - 0s 82us/step - loss: 0.2461 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9201 - val_loss: 0.2495 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 979/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.2459 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9206 - val_loss: 0.2495 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 980/3000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.2457 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9203 - val_loss: 0.2493 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 981/3000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.2456 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9202 - val_loss: 0.2491 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 982/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.2455 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9206 - val_loss: 0.2490 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 983/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.2452 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9203 - val_loss: 0.2489 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 984/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2452 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9200 - val_loss: 0.2488 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 985/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2451 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9203 - val_loss: 0.2486 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 986/3000\n",
            "300/300 [==============================] - 0s 80us/step - loss: 0.2450 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9207 - val_loss: 0.2487 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 987/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.2448 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9205 - val_loss: 0.2485 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 988/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2447 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9208 - val_loss: 0.2483 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 989/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2446 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9205 - val_loss: 0.2481 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 990/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2446 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9197 - val_loss: 0.2480 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 991/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2443 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9208 - val_loss: 0.2479 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 992/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.2442 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9206 - val_loss: 0.2477 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 993/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.2441 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9201 - val_loss: 0.2475 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 994/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.2439 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9202 - val_loss: 0.2474 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 995/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.2438 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9200 - val_loss: 0.2472 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 996/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2437 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9206 - val_loss: 0.2471 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 997/3000\n",
            "300/300 [==============================] - 0s 106us/step - loss: 0.2437 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9207 - val_loss: 0.2470 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 998/3000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.2435 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9201 - val_loss: 0.2470 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 999/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2433 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9201 - val_loss: 0.2469 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1000/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.2431 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9206 - val_loss: 0.2467 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1001/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2430 - precision: 0.9960 - recall: 0.8533 - f1_score: 0.9190 - val_loss: 0.2466 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1002/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2431 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9203 - val_loss: 0.2465 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1003/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.2428 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9206 - val_loss: 0.2464 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1004/3000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.2429 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9207 - val_loss: 0.2464 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1005/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.2428 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9204 - val_loss: 0.2463 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1006/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.2426 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9200 - val_loss: 0.2461 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1007/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2423 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9208 - val_loss: 0.2460 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1008/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2423 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9207 - val_loss: 0.2460 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1009/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2421 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9203 - val_loss: 0.2460 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1010/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2420 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9207 - val_loss: 0.2458 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1011/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.2419 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9200 - val_loss: 0.2456 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1012/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2417 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9205 - val_loss: 0.2454 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1013/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2418 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9205 - val_loss: 0.2452 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1014/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2414 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9206 - val_loss: 0.2451 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1015/3000\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.2413 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9206 - val_loss: 0.2449 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1016/3000\n",
            "300/300 [==============================] - 0s 101us/step - loss: 0.2415 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9199 - val_loss: 0.2447 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1017/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2411 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9202 - val_loss: 0.2446 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1018/3000\n",
            "300/300 [==============================] - 0s 81us/step - loss: 0.2410 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9205 - val_loss: 0.2446 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1019/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2409 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9205 - val_loss: 0.2444 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1020/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2409 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9207 - val_loss: 0.2442 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1021/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2408 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9197 - val_loss: 0.2441 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1022/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2405 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9204 - val_loss: 0.2439 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1023/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2404 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9207 - val_loss: 0.2438 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1024/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2403 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9205 - val_loss: 0.2437 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1025/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2405 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9201 - val_loss: 0.2437 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1026/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.2400 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9205 - val_loss: 0.2436 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1027/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.2399 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9206 - val_loss: 0.2435 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1028/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.2398 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9203 - val_loss: 0.2435 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1029/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.2399 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9204 - val_loss: 0.2435 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1030/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2398 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9206 - val_loss: 0.2433 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1031/3000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.2395 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9207 - val_loss: 0.2433 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1032/3000\n",
            "300/300 [==============================] - 0s 138us/step - loss: 0.2393 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9200 - val_loss: 0.2431 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1033/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.2395 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9203 - val_loss: 0.2429 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1034/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.2391 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9202 - val_loss: 0.2427 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1035/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2390 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9201 - val_loss: 0.2426 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1036/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2390 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9207 - val_loss: 0.2425 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1037/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2388 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9198 - val_loss: 0.2422 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1038/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2386 - precision: 1.0000 - recall: 0.8567 - f1_score: 0.9225 - val_loss: 0.2422 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1039/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2385 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9199 - val_loss: 0.2420 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1040/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.2383 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9208 - val_loss: 0.2419 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1041/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.2383 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9205 - val_loss: 0.2417 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1042/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.2382 - precision: 1.0000 - recall: 0.8567 - f1_score: 0.9223 - val_loss: 0.2417 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1043/3000\n",
            "300/300 [==============================] - 0s 81us/step - loss: 0.2380 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9202 - val_loss: 0.2415 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1044/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2379 - precision: 1.0000 - recall: 0.8567 - f1_score: 0.9227 - val_loss: 0.2414 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1045/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2378 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9200 - val_loss: 0.2413 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1046/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2377 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9207 - val_loss: 0.2412 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1047/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2377 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9199 - val_loss: 0.2411 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1048/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.2375 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9199 - val_loss: 0.2411 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1049/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.2375 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9203 - val_loss: 0.2410 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1050/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.2373 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9206 - val_loss: 0.2409 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1051/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.2371 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9206 - val_loss: 0.2407 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1052/3000\n",
            "300/300 [==============================] - 0s 161us/step - loss: 0.2372 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9203 - val_loss: 0.2406 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1053/3000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.2370 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9205 - val_loss: 0.2404 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1054/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2367 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9202 - val_loss: 0.2404 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1055/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2367 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9205 - val_loss: 0.2403 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1056/3000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.2365 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9198 - val_loss: 0.2402 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1057/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2366 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9195 - val_loss: 0.2401 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1058/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2364 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9203 - val_loss: 0.2400 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1059/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2363 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9206 - val_loss: 0.2397 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1060/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2361 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9203 - val_loss: 0.2396 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1061/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2361 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9206 - val_loss: 0.2394 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1062/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2360 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9205 - val_loss: 0.2393 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1063/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.2358 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9203 - val_loss: 0.2392 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1064/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.2356 - precision: 1.0000 - recall: 0.8567 - f1_score: 0.9225 - val_loss: 0.2391 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1065/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2355 - precision: 1.0000 - recall: 0.8567 - f1_score: 0.9224 - val_loss: 0.2390 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1066/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2354 - precision: 1.0000 - recall: 0.8567 - f1_score: 0.9221 - val_loss: 0.2390 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1067/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2353 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9197 - val_loss: 0.2389 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1068/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2352 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9204 - val_loss: 0.2387 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1069/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.2353 - precision: 1.0000 - recall: 0.8567 - f1_score: 0.9217 - val_loss: 0.2387 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1070/3000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.2350 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9206 - val_loss: 0.2385 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1071/3000\n",
            "300/300 [==============================] - 0s 102us/step - loss: 0.2349 - precision: 1.0000 - recall: 0.8567 - f1_score: 0.9226 - val_loss: 0.2385 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1072/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.2348 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9207 - val_loss: 0.2383 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1073/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.2348 - precision: 1.0000 - recall: 0.8567 - f1_score: 0.9220 - val_loss: 0.2382 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1074/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2345 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9205 - val_loss: 0.2379 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1075/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2345 - precision: 1.0000 - recall: 0.8567 - f1_score: 0.9225 - val_loss: 0.2380 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1076/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2342 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9202 - val_loss: 0.2378 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1077/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2343 - precision: 1.0000 - recall: 0.8567 - f1_score: 0.9227 - val_loss: 0.2379 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1078/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2340 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9203 - val_loss: 0.2378 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1079/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2340 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9207 - val_loss: 0.2376 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1080/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2339 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9201 - val_loss: 0.2375 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1081/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2337 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9206 - val_loss: 0.2374 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1082/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.2336 - precision: 1.0000 - recall: 0.8567 - f1_score: 0.9223 - val_loss: 0.2373 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1083/3000\n",
            "300/300 [==============================] - 0s 81us/step - loss: 0.2335 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9205 - val_loss: 0.2371 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1084/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2336 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9204 - val_loss: 0.2371 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1085/3000\n",
            "300/300 [==============================] - 0s 81us/step - loss: 0.2333 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9204 - val_loss: 0.2369 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1086/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2331 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9201 - val_loss: 0.2367 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1087/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2332 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9200 - val_loss: 0.2366 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1088/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.2330 - precision: 1.0000 - recall: 0.8567 - f1_score: 0.9225 - val_loss: 0.2366 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1089/3000\n",
            "300/300 [==============================] - 0s 102us/step - loss: 0.2329 - precision: 1.0000 - recall: 0.8567 - f1_score: 0.9222 - val_loss: 0.2365 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1090/3000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.2327 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9206 - val_loss: 0.2363 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1091/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2326 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9186 - val_loss: 0.2361 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1092/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.2325 - precision: 1.0000 - recall: 0.8567 - f1_score: 0.9225 - val_loss: 0.2360 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1093/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2324 - precision: 1.0000 - recall: 0.8567 - f1_score: 0.9225 - val_loss: 0.2359 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1094/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2323 - precision: 1.0000 - recall: 0.8567 - f1_score: 0.9226 - val_loss: 0.2358 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1095/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2323 - precision: 1.0000 - recall: 0.8567 - f1_score: 0.9217 - val_loss: 0.2357 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1096/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2323 - precision: 1.0000 - recall: 0.8567 - f1_score: 0.9226 - val_loss: 0.2354 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1097/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2319 - precision: 1.0000 - recall: 0.8567 - f1_score: 0.9225 - val_loss: 0.2353 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1098/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2325 - precision: 1.0000 - recall: 0.8567 - f1_score: 0.9222 - val_loss: 0.2350 - val_precision: 0.9808 - val_recall: 0.8500 - val_f1_score: 0.9107\n",
            "Epoch 1099/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2318 - precision: 1.0000 - recall: 0.8567 - f1_score: 0.9219 - val_loss: 0.2350 - val_precision: 0.9808 - val_recall: 0.8500 - val_f1_score: 0.9107\n",
            "Epoch 1100/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2317 - precision: 1.0000 - recall: 0.8567 - f1_score: 0.9213 - val_loss: 0.2348 - val_precision: 0.9808 - val_recall: 0.8500 - val_f1_score: 0.9107\n",
            "Epoch 1101/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2316 - precision: 1.0000 - recall: 0.8567 - f1_score: 0.9226 - val_loss: 0.2347 - val_precision: 0.9808 - val_recall: 0.8500 - val_f1_score: 0.9107\n",
            "Epoch 1102/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2315 - precision: 1.0000 - recall: 0.8667 - f1_score: 0.9283 - val_loss: 0.2347 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1103/3000\n",
            "300/300 [==============================] - 0s 104us/step - loss: 0.2312 - precision: 1.0000 - recall: 0.8567 - f1_score: 0.9228 - val_loss: 0.2346 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1104/3000\n",
            "300/300 [==============================] - 0s 113us/step - loss: 0.2311 - precision: 1.0000 - recall: 0.8567 - f1_score: 0.9227 - val_loss: 0.2346 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1105/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.2311 - precision: 1.0000 - recall: 0.8567 - f1_score: 0.9222 - val_loss: 0.2345 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1106/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2313 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9196 - val_loss: 0.2344 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1107/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2310 - precision: 1.0000 - recall: 0.8567 - f1_score: 0.9227 - val_loss: 0.2341 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1108/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.2308 - precision: 1.0000 - recall: 0.8567 - f1_score: 0.9217 - val_loss: 0.2342 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1109/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.2306 - precision: 1.0000 - recall: 0.8567 - f1_score: 0.9224 - val_loss: 0.2341 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1110/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.2307 - precision: 1.0000 - recall: 0.8567 - f1_score: 0.9224 - val_loss: 0.2339 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1111/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.2305 - precision: 1.0000 - recall: 0.8567 - f1_score: 0.9223 - val_loss: 0.2339 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1112/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.2305 - precision: 1.0000 - recall: 0.8567 - f1_score: 0.9226 - val_loss: 0.2336 - val_precision: 0.9808 - val_recall: 0.8500 - val_f1_score: 0.9107\n",
            "Epoch 1113/3000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.2303 - precision: 1.0000 - recall: 0.8567 - f1_score: 0.9219 - val_loss: 0.2335 - val_precision: 0.9808 - val_recall: 0.8500 - val_f1_score: 0.9107\n",
            "Epoch 1114/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2301 - precision: 1.0000 - recall: 0.8567 - f1_score: 0.9224 - val_loss: 0.2334 - val_precision: 0.9808 - val_recall: 0.8500 - val_f1_score: 0.9107\n",
            "Epoch 1115/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2300 - precision: 1.0000 - recall: 0.8567 - f1_score: 0.9220 - val_loss: 0.2333 - val_precision: 0.9808 - val_recall: 0.8500 - val_f1_score: 0.9107\n",
            "Epoch 1116/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.2304 - precision: 1.0000 - recall: 0.8567 - f1_score: 0.9228 - val_loss: 0.2333 - val_precision: 0.9808 - val_recall: 0.8500 - val_f1_score: 0.9107\n",
            "Epoch 1117/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2299 - precision: 1.0000 - recall: 0.8600 - f1_score: 0.9243 - val_loss: 0.2331 - val_precision: 0.9808 - val_recall: 0.8500 - val_f1_score: 0.9107\n",
            "Epoch 1118/3000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.2298 - precision: 1.0000 - recall: 0.8633 - f1_score: 0.9258 - val_loss: 0.2331 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1119/3000\n",
            "300/300 [==============================] - 0s 112us/step - loss: 0.2298 - precision: 1.0000 - recall: 0.8600 - f1_score: 0.9241 - val_loss: 0.2332 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1120/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2295 - precision: 1.0000 - recall: 0.8567 - f1_score: 0.9219 - val_loss: 0.2330 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1121/3000\n",
            "300/300 [==============================] - 0s 81us/step - loss: 0.2295 - precision: 1.0000 - recall: 0.8567 - f1_score: 0.9223 - val_loss: 0.2329 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1122/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.2293 - precision: 1.0000 - recall: 0.8567 - f1_score: 0.9226 - val_loss: 0.2328 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1123/3000\n",
            "300/300 [==============================] - 0s 79us/step - loss: 0.2293 - precision: 1.0000 - recall: 0.8533 - f1_score: 0.9205 - val_loss: 0.2326 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1124/3000\n",
            "300/300 [==============================] - 0s 79us/step - loss: 0.2291 - precision: 1.0000 - recall: 0.8567 - f1_score: 0.9225 - val_loss: 0.2325 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1125/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.2289 - precision: 1.0000 - recall: 0.8600 - f1_score: 0.9243 - val_loss: 0.2324 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1126/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2289 - precision: 1.0000 - recall: 0.8567 - f1_score: 0.9223 - val_loss: 0.2324 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1127/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.2288 - precision: 1.0000 - recall: 0.8567 - f1_score: 0.9221 - val_loss: 0.2322 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1128/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2287 - precision: 1.0000 - recall: 0.8667 - f1_score: 0.9285 - val_loss: 0.2322 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1129/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2286 - precision: 1.0000 - recall: 0.8567 - f1_score: 0.9221 - val_loss: 0.2320 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1130/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.2284 - precision: 1.0000 - recall: 0.8567 - f1_score: 0.9222 - val_loss: 0.2319 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1131/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.2284 - precision: 1.0000 - recall: 0.8567 - f1_score: 0.9225 - val_loss: 0.2317 - val_precision: 0.9811 - val_recall: 0.8667 - val_f1_score: 0.9204\n",
            "Epoch 1132/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.2283 - precision: 1.0000 - recall: 0.8567 - f1_score: 0.9214 - val_loss: 0.2315 - val_precision: 0.9815 - val_recall: 0.8833 - val_f1_score: 0.9298\n",
            "Epoch 1133/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2281 - precision: 1.0000 - recall: 0.8633 - f1_score: 0.9262 - val_loss: 0.2315 - val_precision: 0.9808 - val_recall: 0.8500 - val_f1_score: 0.9107\n",
            "Epoch 1134/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2281 - precision: 1.0000 - recall: 0.8600 - f1_score: 0.9244 - val_loss: 0.2314 - val_precision: 0.9815 - val_recall: 0.8833 - val_f1_score: 0.9298\n",
            "Epoch 1135/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2279 - precision: 1.0000 - recall: 0.8633 - f1_score: 0.9258 - val_loss: 0.2312 - val_precision: 0.9811 - val_recall: 0.8667 - val_f1_score: 0.9204\n",
            "Epoch 1136/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2278 - precision: 1.0000 - recall: 0.8633 - f1_score: 0.9263 - val_loss: 0.2312 - val_precision: 0.9808 - val_recall: 0.8500 - val_f1_score: 0.9107\n",
            "Epoch 1137/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2279 - precision: 1.0000 - recall: 0.8600 - f1_score: 0.9236 - val_loss: 0.2311 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1138/3000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.2277 - precision: 1.0000 - recall: 0.8633 - f1_score: 0.9260 - val_loss: 0.2310 - val_precision: 0.9808 - val_recall: 0.8500 - val_f1_score: 0.9107\n",
            "Epoch 1139/3000\n",
            "300/300 [==============================] - 0s 102us/step - loss: 0.2274 - precision: 1.0000 - recall: 0.8567 - f1_score: 0.9222 - val_loss: 0.2309 - val_precision: 0.9808 - val_recall: 0.8500 - val_f1_score: 0.9107\n",
            "Epoch 1140/3000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.2274 - precision: 1.0000 - recall: 0.8600 - f1_score: 0.9243 - val_loss: 0.2308 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1141/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.2273 - precision: 1.0000 - recall: 0.8600 - f1_score: 0.9245 - val_loss: 0.2307 - val_precision: 0.9808 - val_recall: 0.8500 - val_f1_score: 0.9107\n",
            "Epoch 1142/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2272 - precision: 1.0000 - recall: 0.8600 - f1_score: 0.9241 - val_loss: 0.2305 - val_precision: 0.9811 - val_recall: 0.8667 - val_f1_score: 0.9204\n",
            "Epoch 1143/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.2271 - precision: 1.0000 - recall: 0.8600 - f1_score: 0.9239 - val_loss: 0.2304 - val_precision: 0.9815 - val_recall: 0.8833 - val_f1_score: 0.9298\n",
            "Epoch 1144/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2270 - precision: 1.0000 - recall: 0.8633 - f1_score: 0.9266 - val_loss: 0.2303 - val_precision: 0.9815 - val_recall: 0.8833 - val_f1_score: 0.9298\n",
            "Epoch 1145/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2268 - precision: 1.0000 - recall: 0.8633 - f1_score: 0.9258 - val_loss: 0.2302 - val_precision: 0.9815 - val_recall: 0.8833 - val_f1_score: 0.9298\n",
            "Epoch 1146/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.2270 - precision: 1.0000 - recall: 0.8567 - f1_score: 0.9219 - val_loss: 0.2303 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1147/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.2266 - precision: 1.0000 - recall: 0.8667 - f1_score: 0.9284 - val_loss: 0.2302 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1148/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2266 - precision: 1.0000 - recall: 0.8600 - f1_score: 0.9245 - val_loss: 0.2302 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1149/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.2265 - precision: 1.0000 - recall: 0.8600 - f1_score: 0.9241 - val_loss: 0.2300 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1150/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2263 - precision: 1.0000 - recall: 0.8567 - f1_score: 0.9225 - val_loss: 0.2299 - val_precision: 0.9808 - val_recall: 0.8500 - val_f1_score: 0.9107\n",
            "Epoch 1151/3000\n",
            "300/300 [==============================] - 0s 78us/step - loss: 0.2262 - precision: 1.0000 - recall: 0.8567 - f1_score: 0.9224 - val_loss: 0.2297 - val_precision: 0.9808 - val_recall: 0.8500 - val_f1_score: 0.9107\n",
            "Epoch 1152/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2262 - precision: 1.0000 - recall: 0.8667 - f1_score: 0.9282 - val_loss: 0.2297 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1153/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.2260 - precision: 1.0000 - recall: 0.8600 - f1_score: 0.9244 - val_loss: 0.2296 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1154/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2259 - precision: 1.0000 - recall: 0.8600 - f1_score: 0.9242 - val_loss: 0.2294 - val_precision: 0.9811 - val_recall: 0.8667 - val_f1_score: 0.9204\n",
            "Epoch 1155/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.2259 - precision: 1.0000 - recall: 0.8600 - f1_score: 0.9241 - val_loss: 0.2294 - val_precision: 0.9808 - val_recall: 0.8500 - val_f1_score: 0.9107\n",
            "Epoch 1156/3000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.2257 - precision: 1.0000 - recall: 0.8600 - f1_score: 0.9245 - val_loss: 0.2293 - val_precision: 0.9808 - val_recall: 0.8500 - val_f1_score: 0.9107\n",
            "Epoch 1157/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2256 - precision: 1.0000 - recall: 0.8600 - f1_score: 0.9245 - val_loss: 0.2291 - val_precision: 0.9815 - val_recall: 0.8833 - val_f1_score: 0.9298\n",
            "Epoch 1158/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2257 - precision: 1.0000 - recall: 0.8667 - f1_score: 0.9284 - val_loss: 0.2291 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1159/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.2254 - precision: 1.0000 - recall: 0.8667 - f1_score: 0.9277 - val_loss: 0.2291 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1160/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2253 - precision: 1.0000 - recall: 0.8600 - f1_score: 0.9246 - val_loss: 0.2289 - val_precision: 0.9811 - val_recall: 0.8667 - val_f1_score: 0.9204\n",
            "Epoch 1161/3000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.2252 - precision: 1.0000 - recall: 0.8600 - f1_score: 0.9244 - val_loss: 0.2288 - val_precision: 0.9811 - val_recall: 0.8667 - val_f1_score: 0.9204\n",
            "Epoch 1162/3000\n",
            "300/300 [==============================] - 0s 106us/step - loss: 0.2252 - precision: 1.0000 - recall: 0.8667 - f1_score: 0.9285 - val_loss: 0.2288 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1163/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2252 - precision: 1.0000 - recall: 0.8600 - f1_score: 0.9246 - val_loss: 0.2286 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1164/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2251 - precision: 1.0000 - recall: 0.8567 - f1_score: 0.9228 - val_loss: 0.2286 - val_precision: 0.9804 - val_recall: 0.8333 - val_f1_score: 0.9009\n",
            "Epoch 1165/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.2252 - precision: 1.0000 - recall: 0.8600 - f1_score: 0.9241 - val_loss: 0.2283 - val_precision: 0.9815 - val_recall: 0.8833 - val_f1_score: 0.9298\n",
            "Epoch 1166/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2248 - precision: 1.0000 - recall: 0.8633 - f1_score: 0.9262 - val_loss: 0.2282 - val_precision: 0.9815 - val_recall: 0.8833 - val_f1_score: 0.9298\n",
            "Epoch 1167/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.2246 - precision: 1.0000 - recall: 0.8667 - f1_score: 0.9284 - val_loss: 0.2281 - val_precision: 0.9815 - val_recall: 0.8833 - val_f1_score: 0.9298\n",
            "Epoch 1168/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.2249 - precision: 1.0000 - recall: 0.8667 - f1_score: 0.9280 - val_loss: 0.2280 - val_precision: 0.9815 - val_recall: 0.8833 - val_f1_score: 0.9298\n",
            "Epoch 1169/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.2244 - precision: 1.0000 - recall: 0.8567 - f1_score: 0.9225 - val_loss: 0.2280 - val_precision: 0.9815 - val_recall: 0.8833 - val_f1_score: 0.9298\n",
            "Epoch 1170/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2243 - precision: 1.0000 - recall: 0.8633 - f1_score: 0.9262 - val_loss: 0.2277 - val_precision: 0.9815 - val_recall: 0.8833 - val_f1_score: 0.9298\n",
            "Epoch 1171/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2242 - precision: 1.0000 - recall: 0.8700 - f1_score: 0.9294 - val_loss: 0.2276 - val_precision: 0.9815 - val_recall: 0.8833 - val_f1_score: 0.9298\n",
            "Epoch 1172/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.2241 - precision: 1.0000 - recall: 0.8733 - f1_score: 0.9319 - val_loss: 0.2276 - val_precision: 0.9815 - val_recall: 0.8833 - val_f1_score: 0.9298\n",
            "Epoch 1173/3000\n",
            "300/300 [==============================] - 0s 116us/step - loss: 0.2239 - precision: 1.0000 - recall: 0.8667 - f1_score: 0.9283 - val_loss: 0.2274 - val_precision: 0.9815 - val_recall: 0.8833 - val_f1_score: 0.9298\n",
            "Epoch 1174/3000\n",
            "300/300 [==============================] - 0s 82us/step - loss: 0.2238 - precision: 1.0000 - recall: 0.8700 - f1_score: 0.9304 - val_loss: 0.2273 - val_precision: 0.9815 - val_recall: 0.8833 - val_f1_score: 0.9298\n",
            "Epoch 1175/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.2238 - precision: 1.0000 - recall: 0.8700 - f1_score: 0.9301 - val_loss: 0.2272 - val_precision: 0.9815 - val_recall: 0.8833 - val_f1_score: 0.9298\n",
            "Epoch 1176/3000\n",
            "300/300 [==============================] - 0s 108us/step - loss: 0.2236 - precision: 1.0000 - recall: 0.8700 - f1_score: 0.9302 - val_loss: 0.2271 - val_precision: 0.9815 - val_recall: 0.8833 - val_f1_score: 0.9298\n",
            "Epoch 1177/3000\n",
            "300/300 [==============================] - 0s 112us/step - loss: 0.2236 - precision: 1.0000 - recall: 0.8700 - f1_score: 0.9297 - val_loss: 0.2271 - val_precision: 0.9815 - val_recall: 0.8833 - val_f1_score: 0.9298\n",
            "Epoch 1178/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.2235 - precision: 1.0000 - recall: 0.8667 - f1_score: 0.9282 - val_loss: 0.2269 - val_precision: 0.9815 - val_recall: 0.8833 - val_f1_score: 0.9298\n",
            "Epoch 1179/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.2235 - precision: 1.0000 - recall: 0.8667 - f1_score: 0.9284 - val_loss: 0.2268 - val_precision: 0.9815 - val_recall: 0.8833 - val_f1_score: 0.9298\n",
            "Epoch 1180/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2233 - precision: 1.0000 - recall: 0.8667 - f1_score: 0.9283 - val_loss: 0.2267 - val_precision: 0.9815 - val_recall: 0.8833 - val_f1_score: 0.9298\n",
            "Epoch 1181/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2232 - precision: 1.0000 - recall: 0.8700 - f1_score: 0.9300 - val_loss: 0.2266 - val_precision: 0.9815 - val_recall: 0.8833 - val_f1_score: 0.9298\n",
            "Epoch 1182/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2232 - precision: 1.0000 - recall: 0.8633 - f1_score: 0.9261 - val_loss: 0.2264 - val_precision: 0.9815 - val_recall: 0.8833 - val_f1_score: 0.9298\n",
            "Epoch 1183/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.2230 - precision: 1.0000 - recall: 0.8700 - f1_score: 0.9302 - val_loss: 0.2262 - val_precision: 0.9815 - val_recall: 0.8833 - val_f1_score: 0.9298\n",
            "Epoch 1184/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.2229 - precision: 1.0000 - recall: 0.8700 - f1_score: 0.9301 - val_loss: 0.2262 - val_precision: 0.9815 - val_recall: 0.8833 - val_f1_score: 0.9298\n",
            "Epoch 1185/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2228 - precision: 1.0000 - recall: 0.8700 - f1_score: 0.9302 - val_loss: 0.2262 - val_precision: 0.9815 - val_recall: 0.8833 - val_f1_score: 0.9298\n",
            "Epoch 1186/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2227 - precision: 1.0000 - recall: 0.8667 - f1_score: 0.9284 - val_loss: 0.2263 - val_precision: 0.9815 - val_recall: 0.8833 - val_f1_score: 0.9298\n",
            "Epoch 1187/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.2227 - precision: 1.0000 - recall: 0.8667 - f1_score: 0.9278 - val_loss: 0.2262 - val_precision: 0.9811 - val_recall: 0.8667 - val_f1_score: 0.9204\n",
            "Epoch 1188/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.2225 - precision: 1.0000 - recall: 0.8633 - f1_score: 0.9265 - val_loss: 0.2261 - val_precision: 0.9815 - val_recall: 0.8833 - val_f1_score: 0.9298\n",
            "Epoch 1189/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.2225 - precision: 1.0000 - recall: 0.8600 - f1_score: 0.9238 - val_loss: 0.2259 - val_precision: 0.9815 - val_recall: 0.8833 - val_f1_score: 0.9298\n",
            "Epoch 1190/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2224 - precision: 1.0000 - recall: 0.8700 - f1_score: 0.9299 - val_loss: 0.2258 - val_precision: 0.9815 - val_recall: 0.8833 - val_f1_score: 0.9298\n",
            "Epoch 1191/3000\n",
            "300/300 [==============================] - 0s 79us/step - loss: 0.2223 - precision: 1.0000 - recall: 0.8633 - f1_score: 0.9264 - val_loss: 0.2256 - val_precision: 0.9815 - val_recall: 0.8833 - val_f1_score: 0.9298\n",
            "Epoch 1192/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2223 - precision: 1.0000 - recall: 0.8700 - f1_score: 0.9304 - val_loss: 0.2256 - val_precision: 0.9815 - val_recall: 0.8833 - val_f1_score: 0.9298\n",
            "Epoch 1193/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.2220 - precision: 1.0000 - recall: 0.8667 - f1_score: 0.9276 - val_loss: 0.2255 - val_precision: 0.9815 - val_recall: 0.8833 - val_f1_score: 0.9298\n",
            "Epoch 1194/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.2220 - precision: 1.0000 - recall: 0.8700 - f1_score: 0.9305 - val_loss: 0.2255 - val_precision: 0.9815 - val_recall: 0.8833 - val_f1_score: 0.9298\n",
            "Epoch 1195/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.2218 - precision: 1.0000 - recall: 0.8700 - f1_score: 0.9298 - val_loss: 0.2255 - val_precision: 0.9815 - val_recall: 0.8833 - val_f1_score: 0.9298\n",
            "Epoch 1196/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2217 - precision: 1.0000 - recall: 0.8667 - f1_score: 0.9276 - val_loss: 0.2252 - val_precision: 0.9815 - val_recall: 0.8833 - val_f1_score: 0.9298\n",
            "Epoch 1197/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2216 - precision: 1.0000 - recall: 0.8700 - f1_score: 0.9293 - val_loss: 0.2251 - val_precision: 0.9815 - val_recall: 0.8833 - val_f1_score: 0.9298\n",
            "Epoch 1198/3000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.2216 - precision: 1.0000 - recall: 0.8733 - f1_score: 0.9322 - val_loss: 0.2251 - val_precision: 0.9815 - val_recall: 0.8833 - val_f1_score: 0.9298\n",
            "Epoch 1199/3000\n",
            "300/300 [==============================] - 0s 110us/step - loss: 0.2216 - precision: 1.0000 - recall: 0.8700 - f1_score: 0.9299 - val_loss: 0.2251 - val_precision: 0.9815 - val_recall: 0.8833 - val_f1_score: 0.9298\n",
            "Epoch 1200/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.2214 - precision: 1.0000 - recall: 0.8700 - f1_score: 0.9302 - val_loss: 0.2251 - val_precision: 0.9811 - val_recall: 0.8667 - val_f1_score: 0.9204\n",
            "Epoch 1201/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2213 - precision: 1.0000 - recall: 0.8633 - f1_score: 0.9264 - val_loss: 0.2248 - val_precision: 0.9815 - val_recall: 0.8833 - val_f1_score: 0.9298\n",
            "Epoch 1202/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2211 - precision: 1.0000 - recall: 0.8733 - f1_score: 0.9319 - val_loss: 0.2247 - val_precision: 0.9815 - val_recall: 0.8833 - val_f1_score: 0.9298\n",
            "Epoch 1203/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2210 - precision: 1.0000 - recall: 0.8633 - f1_score: 0.9263 - val_loss: 0.2244 - val_precision: 0.9815 - val_recall: 0.8833 - val_f1_score: 0.9298\n",
            "Epoch 1204/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2209 - precision: 1.0000 - recall: 0.8700 - f1_score: 0.9300 - val_loss: 0.2244 - val_precision: 0.9815 - val_recall: 0.8833 - val_f1_score: 0.9298\n",
            "Epoch 1205/3000\n",
            "300/300 [==============================] - 0s 81us/step - loss: 0.2209 - precision: 1.0000 - recall: 0.8700 - f1_score: 0.9302 - val_loss: 0.2242 - val_precision: 0.9815 - val_recall: 0.8833 - val_f1_score: 0.9298\n",
            "Epoch 1206/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2207 - precision: 1.0000 - recall: 0.8733 - f1_score: 0.9322 - val_loss: 0.2240 - val_precision: 0.9815 - val_recall: 0.8833 - val_f1_score: 0.9298\n",
            "Epoch 1207/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2206 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9340 - val_loss: 0.2240 - val_precision: 0.9815 - val_recall: 0.8833 - val_f1_score: 0.9298\n",
            "Epoch 1208/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2205 - precision: 1.0000 - recall: 0.8733 - f1_score: 0.9322 - val_loss: 0.2239 - val_precision: 0.9815 - val_recall: 0.8833 - val_f1_score: 0.9298\n",
            "Epoch 1209/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2204 - precision: 1.0000 - recall: 0.8700 - f1_score: 0.9301 - val_loss: 0.2238 - val_precision: 0.9815 - val_recall: 0.8833 - val_f1_score: 0.9298\n",
            "Epoch 1210/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.2206 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9342 - val_loss: 0.2239 - val_precision: 0.9815 - val_recall: 0.8833 - val_f1_score: 0.9298\n",
            "Epoch 1211/3000\n",
            "300/300 [==============================] - 0s 116us/step - loss: 0.2203 - precision: 1.0000 - recall: 0.8700 - f1_score: 0.9298 - val_loss: 0.2236 - val_precision: 0.9815 - val_recall: 0.8833 - val_f1_score: 0.9298\n",
            "Epoch 1212/3000\n",
            "300/300 [==============================] - 0s 104us/step - loss: 0.2202 - precision: 1.0000 - recall: 0.8667 - f1_score: 0.9284 - val_loss: 0.2235 - val_precision: 0.9815 - val_recall: 0.8833 - val_f1_score: 0.9298\n",
            "Epoch 1213/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.2201 - precision: 1.0000 - recall: 0.8733 - f1_score: 0.9316 - val_loss: 0.2233 - val_precision: 0.9815 - val_recall: 0.8833 - val_f1_score: 0.9298\n",
            "Epoch 1214/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.2199 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9339 - val_loss: 0.2234 - val_precision: 0.9815 - val_recall: 0.8833 - val_f1_score: 0.9298\n",
            "Epoch 1215/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2198 - precision: 1.0000 - recall: 0.8700 - f1_score: 0.9297 - val_loss: 0.2232 - val_precision: 0.9815 - val_recall: 0.8833 - val_f1_score: 0.9298\n",
            "Epoch 1216/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2197 - precision: 1.0000 - recall: 0.8733 - f1_score: 0.9319 - val_loss: 0.2232 - val_precision: 0.9815 - val_recall: 0.8833 - val_f1_score: 0.9298\n",
            "Epoch 1217/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.2197 - precision: 1.0000 - recall: 0.8733 - f1_score: 0.9321 - val_loss: 0.2231 - val_precision: 0.9815 - val_recall: 0.8833 - val_f1_score: 0.9298\n",
            "Epoch 1218/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2196 - precision: 1.0000 - recall: 0.8700 - f1_score: 0.9288 - val_loss: 0.2229 - val_precision: 1.0000 - val_recall: 0.8833 - val_f1_score: 0.9381\n",
            "Epoch 1219/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2195 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9332 - val_loss: 0.2228 - val_precision: 1.0000 - val_recall: 0.8833 - val_f1_score: 0.9381\n",
            "Epoch 1220/3000\n",
            "300/300 [==============================] - 0s 79us/step - loss: 0.2196 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9333 - val_loss: 0.2228 - val_precision: 1.0000 - val_recall: 0.8833 - val_f1_score: 0.9381\n",
            "Epoch 1221/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.2193 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9334 - val_loss: 0.2226 - val_precision: 1.0000 - val_recall: 0.8833 - val_f1_score: 0.9381\n",
            "Epoch 1222/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.2195 - precision: 1.0000 - recall: 0.8733 - f1_score: 0.9322 - val_loss: 0.2226 - val_precision: 1.0000 - val_recall: 0.8833 - val_f1_score: 0.9381\n",
            "Epoch 1223/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2191 - precision: 1.0000 - recall: 0.8733 - f1_score: 0.9322 - val_loss: 0.2225 - val_precision: 1.0000 - val_recall: 0.8833 - val_f1_score: 0.9381\n",
            "Epoch 1224/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2190 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9341 - val_loss: 0.2224 - val_precision: 0.9815 - val_recall: 0.8833 - val_f1_score: 0.9298\n",
            "Epoch 1225/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2190 - precision: 1.0000 - recall: 0.8733 - f1_score: 0.9320 - val_loss: 0.2224 - val_precision: 1.0000 - val_recall: 0.8833 - val_f1_score: 0.9381\n",
            "Epoch 1226/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.2187 - precision: 1.0000 - recall: 0.8733 - f1_score: 0.9320 - val_loss: 0.2222 - val_precision: 0.9815 - val_recall: 0.8833 - val_f1_score: 0.9298\n",
            "Epoch 1227/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2187 - precision: 1.0000 - recall: 0.8733 - f1_score: 0.9321 - val_loss: 0.2221 - val_precision: 0.9815 - val_recall: 0.8833 - val_f1_score: 0.9298\n",
            "Epoch 1228/3000\n",
            "300/300 [==============================] - 0s 78us/step - loss: 0.2186 - precision: 1.0000 - recall: 0.8733 - f1_score: 0.9321 - val_loss: 0.2220 - val_precision: 0.9815 - val_recall: 0.8833 - val_f1_score: 0.9298\n",
            "Epoch 1229/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2186 - precision: 1.0000 - recall: 0.8733 - f1_score: 0.9322 - val_loss: 0.2220 - val_precision: 0.9815 - val_recall: 0.8833 - val_f1_score: 0.9298\n",
            "Epoch 1230/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2186 - precision: 1.0000 - recall: 0.8700 - f1_score: 0.9303 - val_loss: 0.2218 - val_precision: 0.9815 - val_recall: 0.8833 - val_f1_score: 0.9298\n",
            "Epoch 1231/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.2184 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9342 - val_loss: 0.2216 - val_precision: 0.9815 - val_recall: 0.8833 - val_f1_score: 0.9298\n",
            "Epoch 1232/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2184 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9336 - val_loss: 0.2216 - val_precision: 0.9815 - val_recall: 0.8833 - val_f1_score: 0.9298\n",
            "Epoch 1233/3000\n",
            "300/300 [==============================] - 0s 80us/step - loss: 0.2183 - precision: 1.0000 - recall: 0.8733 - f1_score: 0.9322 - val_loss: 0.2215 - val_precision: 0.9815 - val_recall: 0.8833 - val_f1_score: 0.9298\n",
            "Epoch 1234/3000\n",
            "300/300 [==============================] - 0s 158us/step - loss: 0.2182 - precision: 1.0000 - recall: 0.8733 - f1_score: 0.9306 - val_loss: 0.2214 - val_precision: 1.0000 - val_recall: 0.8833 - val_f1_score: 0.9381\n",
            "Epoch 1235/3000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.2180 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9342 - val_loss: 0.2214 - val_precision: 1.0000 - val_recall: 0.8833 - val_f1_score: 0.9381\n",
            "Epoch 1236/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2178 - precision: 1.0000 - recall: 0.8733 - f1_score: 0.9306 - val_loss: 0.2213 - val_precision: 1.0000 - val_recall: 0.8833 - val_f1_score: 0.9381\n",
            "Epoch 1237/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2177 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9341 - val_loss: 0.2212 - val_precision: 1.0000 - val_recall: 0.8833 - val_f1_score: 0.9381\n",
            "Epoch 1238/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2177 - precision: 1.0000 - recall: 0.8733 - f1_score: 0.9315 - val_loss: 0.2211 - val_precision: 1.0000 - val_recall: 0.8833 - val_f1_score: 0.9381\n",
            "Epoch 1239/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.2178 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9333 - val_loss: 0.2210 - val_precision: 1.0000 - val_recall: 0.8833 - val_f1_score: 0.9381\n",
            "Epoch 1240/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2175 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9329 - val_loss: 0.2209 - val_precision: 1.0000 - val_recall: 0.8833 - val_f1_score: 0.9381\n",
            "Epoch 1241/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2174 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9334 - val_loss: 0.2208 - val_precision: 1.0000 - val_recall: 0.8833 - val_f1_score: 0.9381\n",
            "Epoch 1242/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2174 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9331 - val_loss: 0.2207 - val_precision: 1.0000 - val_recall: 0.8833 - val_f1_score: 0.9381\n",
            "Epoch 1243/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2173 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9340 - val_loss: 0.2206 - val_precision: 1.0000 - val_recall: 0.8833 - val_f1_score: 0.9381\n",
            "Epoch 1244/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2173 - precision: 1.0000 - recall: 0.8733 - f1_score: 0.9320 - val_loss: 0.2204 - val_precision: 1.0000 - val_recall: 0.8833 - val_f1_score: 0.9381\n",
            "Epoch 1245/3000\n",
            "300/300 [==============================] - 0s 81us/step - loss: 0.2172 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9340 - val_loss: 0.2202 - val_precision: 1.0000 - val_recall: 0.8833 - val_f1_score: 0.9381\n",
            "Epoch 1246/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.2171 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9341 - val_loss: 0.2201 - val_precision: 1.0000 - val_recall: 0.8833 - val_f1_score: 0.9381\n",
            "Epoch 1247/3000\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.2168 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9342 - val_loss: 0.2201 - val_precision: 1.0000 - val_recall: 0.8833 - val_f1_score: 0.9381\n",
            "Epoch 1248/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2169 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9341 - val_loss: 0.2201 - val_precision: 1.0000 - val_recall: 0.8833 - val_f1_score: 0.9381\n",
            "Epoch 1249/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2166 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9341 - val_loss: 0.2199 - val_precision: 1.0000 - val_recall: 0.8833 - val_f1_score: 0.9381\n",
            "Epoch 1250/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2168 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9340 - val_loss: 0.2198 - val_precision: 1.0000 - val_recall: 0.8833 - val_f1_score: 0.9381\n",
            "Epoch 1251/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2165 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9340 - val_loss: 0.2198 - val_precision: 0.9815 - val_recall: 0.8833 - val_f1_score: 0.9298\n",
            "Epoch 1252/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2165 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9339 - val_loss: 0.2196 - val_precision: 0.9815 - val_recall: 0.8833 - val_f1_score: 0.9298\n",
            "Epoch 1253/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2165 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9337 - val_loss: 0.2195 - val_precision: 0.9815 - val_recall: 0.8833 - val_f1_score: 0.9298\n",
            "Epoch 1254/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2163 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9333 - val_loss: 0.2193 - val_precision: 0.9815 - val_recall: 0.8833 - val_f1_score: 0.9298\n",
            "Epoch 1255/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2162 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9341 - val_loss: 0.2193 - val_precision: 0.9815 - val_recall: 0.8833 - val_f1_score: 0.9298\n",
            "Epoch 1256/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2160 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9337 - val_loss: 0.2193 - val_precision: 0.9815 - val_recall: 0.8833 - val_f1_score: 0.9298\n",
            "Epoch 1257/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2160 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9342 - val_loss: 0.2191 - val_precision: 0.9815 - val_recall: 0.8833 - val_f1_score: 0.9298\n",
            "Epoch 1258/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2158 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9340 - val_loss: 0.2191 - val_precision: 0.9815 - val_recall: 0.8833 - val_f1_score: 0.9298\n",
            "Epoch 1259/3000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.2157 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9340 - val_loss: 0.2189 - val_precision: 0.9815 - val_recall: 0.8833 - val_f1_score: 0.9298\n",
            "Epoch 1260/3000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.2156 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9331 - val_loss: 0.2188 - val_precision: 0.9815 - val_recall: 0.8833 - val_f1_score: 0.9298\n",
            "Epoch 1261/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2155 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9339 - val_loss: 0.2187 - val_precision: 0.9815 - val_recall: 0.8833 - val_f1_score: 0.9298\n",
            "Epoch 1262/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2155 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9340 - val_loss: 0.2187 - val_precision: 0.9815 - val_recall: 0.8833 - val_f1_score: 0.9298\n",
            "Epoch 1263/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2153 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9337 - val_loss: 0.2186 - val_precision: 0.9815 - val_recall: 0.8833 - val_f1_score: 0.9298\n",
            "Epoch 1264/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2154 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9339 - val_loss: 0.2186 - val_precision: 0.9815 - val_recall: 0.8833 - val_f1_score: 0.9298\n",
            "Epoch 1265/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2153 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9341 - val_loss: 0.2187 - val_precision: 0.9815 - val_recall: 0.8833 - val_f1_score: 0.9298\n",
            "Epoch 1266/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2151 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9330 - val_loss: 0.2185 - val_precision: 0.9815 - val_recall: 0.8833 - val_f1_score: 0.9298\n",
            "Epoch 1267/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.2150 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9339 - val_loss: 0.2183 - val_precision: 0.9815 - val_recall: 0.8833 - val_f1_score: 0.9298\n",
            "Epoch 1268/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2151 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9334 - val_loss: 0.2182 - val_precision: 1.0000 - val_recall: 0.8833 - val_f1_score: 0.9381\n",
            "Epoch 1269/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.2150 - precision: 1.0000 - recall: 0.8733 - f1_score: 0.9321 - val_loss: 0.2181 - val_precision: 1.0000 - val_recall: 0.8833 - val_f1_score: 0.9381\n",
            "Epoch 1270/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2147 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9337 - val_loss: 0.2179 - val_precision: 1.0000 - val_recall: 0.8833 - val_f1_score: 0.9381\n",
            "Epoch 1271/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.2147 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9338 - val_loss: 0.2178 - val_precision: 0.9815 - val_recall: 0.8833 - val_f1_score: 0.9298\n",
            "Epoch 1272/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2148 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9338 - val_loss: 0.2177 - val_precision: 1.0000 - val_recall: 0.8833 - val_f1_score: 0.9381\n",
            "Epoch 1273/3000\n",
            "300/300 [==============================] - 0s 79us/step - loss: 0.2145 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9339 - val_loss: 0.2177 - val_precision: 1.0000 - val_recall: 0.8833 - val_f1_score: 0.9381\n",
            "Epoch 1274/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.2144 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9338 - val_loss: 0.2176 - val_precision: 1.0000 - val_recall: 0.8833 - val_f1_score: 0.9381\n",
            "Epoch 1275/3000\n",
            "300/300 [==============================] - 0s 79us/step - loss: 0.2143 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9338 - val_loss: 0.2175 - val_precision: 1.0000 - val_recall: 0.8833 - val_f1_score: 0.9381\n",
            "Epoch 1276/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2141 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9341 - val_loss: 0.2174 - val_precision: 1.0000 - val_recall: 0.8833 - val_f1_score: 0.9381\n",
            "Epoch 1277/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.2141 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9336 - val_loss: 0.2172 - val_precision: 1.0000 - val_recall: 0.8833 - val_f1_score: 0.9381\n",
            "Epoch 1278/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2141 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9340 - val_loss: 0.2171 - val_precision: 1.0000 - val_recall: 0.8833 - val_f1_score: 0.9381\n",
            "Epoch 1279/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2140 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9341 - val_loss: 0.2172 - val_precision: 1.0000 - val_recall: 0.8833 - val_f1_score: 0.9381\n",
            "Epoch 1280/3000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.2138 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9336 - val_loss: 0.2171 - val_precision: 1.0000 - val_recall: 0.8833 - val_f1_score: 0.9381\n",
            "Epoch 1281/3000\n",
            "300/300 [==============================] - 0s 126us/step - loss: 0.2138 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9339 - val_loss: 0.2170 - val_precision: 1.0000 - val_recall: 0.8833 - val_f1_score: 0.9381\n",
            "Epoch 1282/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2137 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9338 - val_loss: 0.2168 - val_precision: 1.0000 - val_recall: 0.8833 - val_f1_score: 0.9381\n",
            "Epoch 1283/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.2136 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9341 - val_loss: 0.2167 - val_precision: 1.0000 - val_recall: 0.8833 - val_f1_score: 0.9381\n",
            "Epoch 1284/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2136 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9327 - val_loss: 0.2166 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1285/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2135 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9340 - val_loss: 0.2163 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1286/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2133 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9336 - val_loss: 0.2163 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1287/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.2132 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9342 - val_loss: 0.2163 - val_precision: 1.0000 - val_recall: 0.8833 - val_f1_score: 0.9381\n",
            "Epoch 1288/3000\n",
            "300/300 [==============================] - 0s 80us/step - loss: 0.2131 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9341 - val_loss: 0.2163 - val_precision: 1.0000 - val_recall: 0.8833 - val_f1_score: 0.9381\n",
            "Epoch 1289/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.2130 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9341 - val_loss: 0.2162 - val_precision: 1.0000 - val_recall: 0.8833 - val_f1_score: 0.9381\n",
            "Epoch 1290/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.2130 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9341 - val_loss: 0.2159 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1291/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.2129 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9338 - val_loss: 0.2158 - val_precision: 0.9818 - val_recall: 0.9000 - val_f1_score: 0.9391\n",
            "Epoch 1292/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.2128 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9340 - val_loss: 0.2156 - val_precision: 0.9818 - val_recall: 0.9000 - val_f1_score: 0.9391\n",
            "Epoch 1293/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.2127 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9337 - val_loss: 0.2156 - val_precision: 0.9818 - val_recall: 0.9000 - val_f1_score: 0.9391\n",
            "Epoch 1294/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2126 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9330 - val_loss: 0.2156 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1295/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.2125 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9340 - val_loss: 0.2155 - val_precision: 0.9818 - val_recall: 0.9000 - val_f1_score: 0.9391\n",
            "Epoch 1296/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2125 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9341 - val_loss: 0.2154 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1297/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2125 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9336 - val_loss: 0.2153 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1298/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.2123 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9337 - val_loss: 0.2152 - val_precision: 0.9818 - val_recall: 0.9000 - val_f1_score: 0.9391\n",
            "Epoch 1299/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2123 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9336 - val_loss: 0.2151 - val_precision: 0.9818 - val_recall: 0.9000 - val_f1_score: 0.9391\n",
            "Epoch 1300/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2121 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9337 - val_loss: 0.2151 - val_precision: 0.9818 - val_recall: 0.9000 - val_f1_score: 0.9391\n",
            "Epoch 1301/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2120 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9342 - val_loss: 0.2151 - val_precision: 0.9818 - val_recall: 0.9000 - val_f1_score: 0.9391\n",
            "Epoch 1302/3000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.2119 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9339 - val_loss: 0.2150 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1303/3000\n",
            "300/300 [==============================] - 0s 107us/step - loss: 0.2118 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9335 - val_loss: 0.2148 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1304/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2117 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9339 - val_loss: 0.2148 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1305/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2116 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9342 - val_loss: 0.2147 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1306/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2116 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9341 - val_loss: 0.2146 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1307/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2116 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9332 - val_loss: 0.2146 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1308/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2114 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9342 - val_loss: 0.2145 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1309/3000\n",
            "300/300 [==============================] - 0s 78us/step - loss: 0.2114 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9337 - val_loss: 0.2145 - val_precision: 1.0000 - val_recall: 0.8833 - val_f1_score: 0.9381\n",
            "Epoch 1310/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.2111 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9339 - val_loss: 0.2144 - val_precision: 1.0000 - val_recall: 0.8833 - val_f1_score: 0.9381\n",
            "Epoch 1311/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2111 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9340 - val_loss: 0.2143 - val_precision: 0.9815 - val_recall: 0.8833 - val_f1_score: 0.9298\n",
            "Epoch 1312/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.2111 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9340 - val_loss: 0.2141 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1313/3000\n",
            "300/300 [==============================] - 0s 79us/step - loss: 0.2110 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9340 - val_loss: 0.2140 - val_precision: 0.9818 - val_recall: 0.9000 - val_f1_score: 0.9391\n",
            "Epoch 1314/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2108 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9341 - val_loss: 0.2139 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1315/3000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.2110 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9332 - val_loss: 0.2139 - val_precision: 0.9818 - val_recall: 0.9000 - val_f1_score: 0.9391\n",
            "Epoch 1316/3000\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.2107 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9341 - val_loss: 0.2139 - val_precision: 1.0000 - val_recall: 0.8833 - val_f1_score: 0.9381\n",
            "Epoch 1317/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2105 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9342 - val_loss: 0.2137 - val_precision: 0.9818 - val_recall: 0.9000 - val_f1_score: 0.9391\n",
            "Epoch 1318/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.2106 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9341 - val_loss: 0.2136 - val_precision: 0.9818 - val_recall: 0.9000 - val_f1_score: 0.9391\n",
            "Epoch 1319/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.2105 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9340 - val_loss: 0.2135 - val_precision: 0.9818 - val_recall: 0.9000 - val_f1_score: 0.9391\n",
            "Epoch 1320/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.2105 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9335 - val_loss: 0.2135 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1321/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.2103 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9339 - val_loss: 0.2133 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1322/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2101 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9341 - val_loss: 0.2132 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1323/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.2102 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9339 - val_loss: 0.2130 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1324/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2100 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9342 - val_loss: 0.2129 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1325/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2098 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9335 - val_loss: 0.2129 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1326/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2098 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9342 - val_loss: 0.2128 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1327/3000\n",
            "300/300 [==============================] - 0s 117us/step - loss: 0.2099 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9360 - val_loss: 0.2127 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1328/3000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.2096 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9342 - val_loss: 0.2126 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1329/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.2095 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9339 - val_loss: 0.2126 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1330/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2094 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9339 - val_loss: 0.2126 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1331/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.2093 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9338 - val_loss: 0.2124 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1332/3000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.2093 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9336 - val_loss: 0.2123 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1333/3000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.2093 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9342 - val_loss: 0.2122 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1334/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.2092 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9337 - val_loss: 0.2122 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1335/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.2091 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9336 - val_loss: 0.2122 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1336/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2091 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9340 - val_loss: 0.2119 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1337/3000\n",
            "300/300 [==============================] - 0s 78us/step - loss: 0.2089 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9340 - val_loss: 0.2119 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1338/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.2088 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9334 - val_loss: 0.2119 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1339/3000\n",
            "300/300 [==============================] - 0s 81us/step - loss: 0.2089 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9342 - val_loss: 0.2120 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1340/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.2086 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9336 - val_loss: 0.2118 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1341/3000\n",
            "300/300 [==============================] - 0s 80us/step - loss: 0.2086 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9337 - val_loss: 0.2117 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1342/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2085 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9337 - val_loss: 0.2117 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1343/3000\n",
            "300/300 [==============================] - 0s 82us/step - loss: 0.2084 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9331 - val_loss: 0.2114 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1344/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2084 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9341 - val_loss: 0.2113 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1345/3000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.2081 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9340 - val_loss: 0.2112 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1346/3000\n",
            "300/300 [==============================] - 0s 139us/step - loss: 0.2081 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9334 - val_loss: 0.2112 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1347/3000\n",
            "300/300 [==============================] - 0s 104us/step - loss: 0.2080 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9340 - val_loss: 0.2110 - val_precision: 0.9818 - val_recall: 0.9000 - val_f1_score: 0.9391\n",
            "Epoch 1348/3000\n",
            "300/300 [==============================] - 0s 78us/step - loss: 0.2079 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9337 - val_loss: 0.2110 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1349/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.2078 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9339 - val_loss: 0.2109 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1350/3000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.2079 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9341 - val_loss: 0.2108 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1351/3000\n",
            "300/300 [==============================] - 0s 81us/step - loss: 0.2076 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9337 - val_loss: 0.2108 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1352/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.2077 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9336 - val_loss: 0.2108 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1353/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2076 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9340 - val_loss: 0.2108 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1354/3000\n",
            "300/300 [==============================] - 0s 79us/step - loss: 0.2074 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9333 - val_loss: 0.2106 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1355/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2074 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9342 - val_loss: 0.2106 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1356/3000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.2073 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9338 - val_loss: 0.2104 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1357/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.2073 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9339 - val_loss: 0.2102 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1358/3000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.2072 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9341 - val_loss: 0.2102 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1359/3000\n",
            "300/300 [==============================] - 0s 159us/step - loss: 0.2070 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9335 - val_loss: 0.2102 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1360/3000\n",
            "300/300 [==============================] - 0s 78us/step - loss: 0.2069 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9338 - val_loss: 0.2101 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1361/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.2069 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9339 - val_loss: 0.2100 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1362/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2070 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9341 - val_loss: 0.2100 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1363/3000\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.2067 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9339 - val_loss: 0.2098 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1364/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.2067 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9334 - val_loss: 0.2097 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1365/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.2069 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9338 - val_loss: 0.2098 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1366/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.2065 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9340 - val_loss: 0.2095 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1367/3000\n",
            "300/300 [==============================] - 0s 82us/step - loss: 0.2064 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9340 - val_loss: 0.2094 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1368/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.2064 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9338 - val_loss: 0.2091 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1369/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.2063 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9359 - val_loss: 0.2090 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1370/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2062 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9360 - val_loss: 0.2090 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1371/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2061 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9360 - val_loss: 0.2091 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1372/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2061 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9333 - val_loss: 0.2089 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1373/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.2059 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9357 - val_loss: 0.2089 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1374/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2058 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9338 - val_loss: 0.2089 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1375/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2058 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9340 - val_loss: 0.2087 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1376/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2057 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9359 - val_loss: 0.2087 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1377/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.2058 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9358 - val_loss: 0.2086 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1378/3000\n",
            "300/300 [==============================] - 0s 80us/step - loss: 0.2055 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9331 - val_loss: 0.2085 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1379/3000\n",
            "300/300 [==============================] - 0s 107us/step - loss: 0.2054 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9340 - val_loss: 0.2084 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1380/3000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.2054 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9359 - val_loss: 0.2085 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1381/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.2053 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9357 - val_loss: 0.2086 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1382/3000\n",
            "300/300 [==============================] - 0s 78us/step - loss: 0.2051 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9331 - val_loss: 0.2084 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1383/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2053 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9341 - val_loss: 0.2082 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1384/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.2050 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9342 - val_loss: 0.2082 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1385/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.2049 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9337 - val_loss: 0.2081 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1386/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2048 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9360 - val_loss: 0.2082 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1387/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2048 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9334 - val_loss: 0.2080 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1388/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2046 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9339 - val_loss: 0.2079 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1389/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2047 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9335 - val_loss: 0.2078 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1390/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2046 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9340 - val_loss: 0.2077 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1391/3000\n",
            "300/300 [==============================] - 0s 78us/step - loss: 0.2045 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9338 - val_loss: 0.2076 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1392/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2043 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9335 - val_loss: 0.2076 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1393/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2043 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9360 - val_loss: 0.2077 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1394/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2044 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9340 - val_loss: 0.2076 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1395/3000\n",
            "300/300 [==============================] - 0s 78us/step - loss: 0.2042 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9340 - val_loss: 0.2074 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1396/3000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.2040 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9334 - val_loss: 0.2073 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1397/3000\n",
            "300/300 [==============================] - 0s 103us/step - loss: 0.2040 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9357 - val_loss: 0.2073 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1398/3000\n",
            "300/300 [==============================] - 0s 105us/step - loss: 0.2039 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9357 - val_loss: 0.2072 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1399/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.2039 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9342 - val_loss: 0.2071 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1400/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.2037 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9342 - val_loss: 0.2070 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1401/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.2036 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9342 - val_loss: 0.2070 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1402/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2035 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9337 - val_loss: 0.2068 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1403/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.2035 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9358 - val_loss: 0.2066 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1404/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.2033 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9357 - val_loss: 0.2066 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1405/3000\n",
            "300/300 [==============================] - 0s 80us/step - loss: 0.2033 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9361 - val_loss: 0.2066 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1406/3000\n",
            "300/300 [==============================] - 0s 80us/step - loss: 0.2032 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9335 - val_loss: 0.2066 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1407/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2031 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9336 - val_loss: 0.2064 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1408/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2032 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9339 - val_loss: 0.2063 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1409/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.2030 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9359 - val_loss: 0.2063 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1410/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.2029 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9358 - val_loss: 0.2063 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1411/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2028 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9341 - val_loss: 0.2061 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1412/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2029 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9341 - val_loss: 0.2059 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1413/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.2027 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9342 - val_loss: 0.2057 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1414/3000\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.2026 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9352 - val_loss: 0.2058 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1415/3000\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.2026 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9351 - val_loss: 0.2057 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1416/3000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.2024 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9357 - val_loss: 0.2057 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1417/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2024 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9358 - val_loss: 0.2056 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1418/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2023 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9360 - val_loss: 0.2055 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1419/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2021 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9358 - val_loss: 0.2054 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1420/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2021 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9358 - val_loss: 0.2052 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1421/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.2021 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9354 - val_loss: 0.2051 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1422/3000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.2023 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9350 - val_loss: 0.2051 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1423/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2018 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9361 - val_loss: 0.2051 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1424/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2018 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9360 - val_loss: 0.2050 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1425/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2018 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9359 - val_loss: 0.2050 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1426/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.2017 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9357 - val_loss: 0.2049 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1427/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.2017 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9354 - val_loss: 0.2049 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1428/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2015 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9339 - val_loss: 0.2048 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1429/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2014 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9355 - val_loss: 0.2047 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1430/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.2013 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9342 - val_loss: 0.2045 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1431/3000\n",
            "300/300 [==============================] - 0s 82us/step - loss: 0.2012 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9358 - val_loss: 0.2045 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1432/3000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.2012 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9360 - val_loss: 0.2045 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1433/3000\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.2012 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9360 - val_loss: 0.2045 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1434/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2011 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9359 - val_loss: 0.2045 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1435/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2010 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9350 - val_loss: 0.2044 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1436/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.2008 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9358 - val_loss: 0.2042 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1437/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2010 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9357 - val_loss: 0.2040 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1438/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.2008 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9378 - val_loss: 0.2041 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1439/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2007 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9360 - val_loss: 0.2040 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1440/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2006 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9356 - val_loss: 0.2038 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1441/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.2005 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9351 - val_loss: 0.2037 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1442/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2004 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9352 - val_loss: 0.2035 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1443/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.2004 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9359 - val_loss: 0.2036 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1444/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2004 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9357 - val_loss: 0.2033 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1445/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.2001 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9379 - val_loss: 0.2033 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1446/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.2001 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9371 - val_loss: 0.2033 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1447/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.2002 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9360 - val_loss: 0.2034 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1448/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.1999 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9357 - val_loss: 0.2032 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1449/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.1999 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9360 - val_loss: 0.2030 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1450/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.1999 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9357 - val_loss: 0.2030 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1451/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.1997 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9356 - val_loss: 0.2028 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1452/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.1996 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9355 - val_loss: 0.2027 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1453/3000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.1997 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9353 - val_loss: 0.2024 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1454/3000\n",
            "300/300 [==============================] - 0s 110us/step - loss: 0.1996 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9376 - val_loss: 0.2024 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1455/3000\n",
            "300/300 [==============================] - 0s 81us/step - loss: 0.1995 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9373 - val_loss: 0.2023 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1456/3000\n",
            "300/300 [==============================] - 0s 79us/step - loss: 0.1994 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9355 - val_loss: 0.2022 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1457/3000\n",
            "300/300 [==============================] - 0s 79us/step - loss: 0.1992 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9378 - val_loss: 0.2022 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1458/3000\n",
            "300/300 [==============================] - 0s 122us/step - loss: 0.1992 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9380 - val_loss: 0.2023 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1459/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.1992 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9360 - val_loss: 0.2024 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1460/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.1991 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9354 - val_loss: 0.2024 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1461/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.1990 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9358 - val_loss: 0.2023 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1462/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1989 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9357 - val_loss: 0.2022 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1463/3000\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.1990 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9355 - val_loss: 0.2021 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1464/3000\n",
            "300/300 [==============================] - 0s 124us/step - loss: 0.1989 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9359 - val_loss: 0.2020 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1465/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.1988 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9355 - val_loss: 0.2020 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1466/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.1987 - precision: 1.0000 - recall: 0.8767 - f1_score: 0.9339 - val_loss: 0.2018 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1467/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.1986 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9357 - val_loss: 0.2015 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1468/3000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.1984 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9360 - val_loss: 0.2015 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1469/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.1983 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9356 - val_loss: 0.2014 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1470/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.1984 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9371 - val_loss: 0.2013 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1471/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.1982 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9375 - val_loss: 0.2012 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1472/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.1981 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9377 - val_loss: 0.2010 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1473/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.1980 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9377 - val_loss: 0.2010 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1474/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.1979 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9376 - val_loss: 0.2009 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1475/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.1979 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9380 - val_loss: 0.2008 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1476/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.1978 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9379 - val_loss: 0.2008 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1477/3000\n",
            "300/300 [==============================] - 0s 80us/step - loss: 0.1977 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9377 - val_loss: 0.2007 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1478/3000\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.1978 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9378 - val_loss: 0.2008 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1479/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.1977 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9359 - val_loss: 0.2006 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1480/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1976 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9373 - val_loss: 0.2006 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1481/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.1975 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9358 - val_loss: 0.2006 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1482/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.1974 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9359 - val_loss: 0.2005 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1483/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1973 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9360 - val_loss: 0.2003 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1484/3000\n",
            "300/300 [==============================] - 0s 118us/step - loss: 0.1973 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9356 - val_loss: 0.2002 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1485/3000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.1973 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9354 - val_loss: 0.2002 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1486/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.1972 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9342 - val_loss: 0.2001 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1487/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.1971 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9373 - val_loss: 0.2000 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1488/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.1969 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9360 - val_loss: 0.1999 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1489/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.1968 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9378 - val_loss: 0.1999 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1490/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.1969 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9377 - val_loss: 0.1998 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1491/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1967 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9375 - val_loss: 0.1998 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1492/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1966 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9373 - val_loss: 0.1997 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1493/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.1966 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9357 - val_loss: 0.1996 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1494/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1966 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9379 - val_loss: 0.1995 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1495/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.1964 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9378 - val_loss: 0.1995 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1496/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.1964 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9373 - val_loss: 0.1993 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1497/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.1963 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9377 - val_loss: 0.1992 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1498/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.1962 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9377 - val_loss: 0.1991 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1499/3000\n",
            "300/300 [==============================] - 0s 110us/step - loss: 0.1963 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9379 - val_loss: 0.1993 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1500/3000\n",
            "300/300 [==============================] - 0s 117us/step - loss: 0.1960 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9359 - val_loss: 0.1992 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1501/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.1961 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9377 - val_loss: 0.1992 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1502/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.1960 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9361 - val_loss: 0.1991 - val_precision: 1.0000 - val_recall: 0.9000 - val_f1_score: 0.9474\n",
            "Epoch 1503/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.1959 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9357 - val_loss: 0.1989 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1504/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1958 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9377 - val_loss: 0.1990 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1505/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.1957 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9375 - val_loss: 0.1989 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1506/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.1956 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9378 - val_loss: 0.1987 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1507/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.1955 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9375 - val_loss: 0.1986 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1508/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.1955 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9378 - val_loss: 0.1985 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1509/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.1954 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9365 - val_loss: 0.1985 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1510/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.1953 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9377 - val_loss: 0.1983 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1511/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.1952 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9376 - val_loss: 0.1982 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1512/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.1952 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9380 - val_loss: 0.1981 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1513/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.1953 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9376 - val_loss: 0.1980 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1514/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1952 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9376 - val_loss: 0.1977 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1515/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1950 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9377 - val_loss: 0.1977 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1516/3000\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.1949 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9375 - val_loss: 0.1977 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1517/3000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.1948 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9377 - val_loss: 0.1976 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1518/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.1948 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9378 - val_loss: 0.1976 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1519/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.1948 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9373 - val_loss: 0.1975 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1520/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.1946 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9375 - val_loss: 0.1974 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1521/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.1945 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9376 - val_loss: 0.1974 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1522/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1946 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9376 - val_loss: 0.1974 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1523/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1945 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9378 - val_loss: 0.1974 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1524/3000\n",
            "300/300 [==============================] - 0s 79us/step - loss: 0.1944 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9379 - val_loss: 0.1973 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1525/3000\n",
            "300/300 [==============================] - 0s 80us/step - loss: 0.1943 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9374 - val_loss: 0.1973 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1526/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.1942 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9378 - val_loss: 0.1972 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1527/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.1942 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9379 - val_loss: 0.1971 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1528/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.1940 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9373 - val_loss: 0.1971 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1529/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.1941 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9375 - val_loss: 0.1972 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1530/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.1939 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9376 - val_loss: 0.1971 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1531/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.1938 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9377 - val_loss: 0.1969 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1532/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.1938 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9378 - val_loss: 0.1967 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1533/3000\n",
            "300/300 [==============================] - 0s 80us/step - loss: 0.1937 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9375 - val_loss: 0.1965 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1534/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1939 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9373 - val_loss: 0.1965 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1535/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.1936 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9376 - val_loss: 0.1963 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1536/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.1935 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9376 - val_loss: 0.1963 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1537/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.1933 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9376 - val_loss: 0.1963 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1538/3000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.1933 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9376 - val_loss: 0.1962 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1539/3000\n",
            "300/300 [==============================] - 0s 110us/step - loss: 0.1932 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9376 - val_loss: 0.1962 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1540/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.1933 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9379 - val_loss: 0.1961 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1541/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.1931 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9373 - val_loss: 0.1960 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1542/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1930 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9377 - val_loss: 0.1961 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1543/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1930 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9372 - val_loss: 0.1960 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1544/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.1930 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9373 - val_loss: 0.1961 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1545/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.1929 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9379 - val_loss: 0.1959 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1546/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.1927 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9378 - val_loss: 0.1959 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1547/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1929 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9374 - val_loss: 0.1961 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1548/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.1927 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9371 - val_loss: 0.1959 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1549/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1927 - precision: 1.0000 - recall: 0.8800 - f1_score: 0.9359 - val_loss: 0.1956 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1550/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1926 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9378 - val_loss: 0.1956 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1551/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.1924 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9379 - val_loss: 0.1956 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1552/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1923 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9379 - val_loss: 0.1955 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1553/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.1924 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9374 - val_loss: 0.1955 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1554/3000\n",
            "300/300 [==============================] - 0s 80us/step - loss: 0.1923 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9378 - val_loss: 0.1955 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1555/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.1921 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9374 - val_loss: 0.1955 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1556/3000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.1924 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9380 - val_loss: 0.1951 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1557/3000\n",
            "300/300 [==============================] - 0s 102us/step - loss: 0.1920 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9373 - val_loss: 0.1951 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1558/3000\n",
            "300/300 [==============================] - 0s 79us/step - loss: 0.1920 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9377 - val_loss: 0.1949 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1559/3000\n",
            "300/300 [==============================] - 0s 78us/step - loss: 0.1919 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9374 - val_loss: 0.1950 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1560/3000\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.1919 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9377 - val_loss: 0.1949 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1561/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.1919 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9377 - val_loss: 0.1949 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1562/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.1917 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9378 - val_loss: 0.1949 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1563/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1916 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9377 - val_loss: 0.1948 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1564/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.1915 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9377 - val_loss: 0.1946 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1565/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1915 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9379 - val_loss: 0.1945 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1566/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1916 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9379 - val_loss: 0.1945 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1567/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.1914 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9379 - val_loss: 0.1946 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1568/3000\n",
            "300/300 [==============================] - 0s 102us/step - loss: 0.1913 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9369 - val_loss: 0.1947 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1569/3000\n",
            "300/300 [==============================] - 0s 106us/step - loss: 0.1912 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9377 - val_loss: 0.1944 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1570/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1911 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9379 - val_loss: 0.1943 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1571/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1913 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9375 - val_loss: 0.1942 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1572/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.1910 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9380 - val_loss: 0.1940 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1573/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.1909 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9379 - val_loss: 0.1940 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1574/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.1908 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9380 - val_loss: 0.1938 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1575/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.1909 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9377 - val_loss: 0.1935 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1576/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.1907 - precision: 1.0000 - recall: 0.8933 - f1_score: 0.9435 - val_loss: 0.1936 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1577/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1906 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9376 - val_loss: 0.1935 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1578/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.1905 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9377 - val_loss: 0.1936 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1579/3000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.1904 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9372 - val_loss: 0.1936 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1580/3000\n",
            "300/300 [==============================] - 0s 105us/step - loss: 0.1904 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9377 - val_loss: 0.1934 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1581/3000\n",
            "300/300 [==============================] - 0s 79us/step - loss: 0.1904 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9375 - val_loss: 0.1933 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1582/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.1904 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9375 - val_loss: 0.1932 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1583/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.1902 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9376 - val_loss: 0.1931 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1584/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.1901 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9379 - val_loss: 0.1930 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1585/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.1902 - precision: 1.0000 - recall: 0.8900 - f1_score: 0.9416 - val_loss: 0.1929 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1586/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.1900 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9375 - val_loss: 0.1928 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1587/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.1900 - precision: 1.0000 - recall: 0.8900 - f1_score: 0.9414 - val_loss: 0.1929 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1588/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.1898 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9377 - val_loss: 0.1928 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1589/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1899 - precision: 1.0000 - recall: 0.8900 - f1_score: 0.9415 - val_loss: 0.1927 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1590/3000\n",
            "300/300 [==============================] - 0s 130us/step - loss: 0.1897 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9374 - val_loss: 0.1927 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1591/3000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.1897 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9376 - val_loss: 0.1925 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1592/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.1897 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9375 - val_loss: 0.1925 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1593/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.1895 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9378 - val_loss: 0.1925 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1594/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.1895 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9377 - val_loss: 0.1924 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1595/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.1894 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9379 - val_loss: 0.1923 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1596/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.1894 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9378 - val_loss: 0.1922 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1597/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1893 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9377 - val_loss: 0.1921 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1598/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.1892 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9373 - val_loss: 0.1921 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1599/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.1892 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9378 - val_loss: 0.1921 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1600/3000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.1892 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9379 - val_loss: 0.1920 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1601/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.1890 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9378 - val_loss: 0.1919 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1602/3000\n",
            "300/300 [==============================] - 0s 114us/step - loss: 0.1890 - precision: 1.0000 - recall: 0.8867 - f1_score: 0.9397 - val_loss: 0.1918 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1603/3000\n",
            "300/300 [==============================] - 0s 109us/step - loss: 0.1889 - precision: 1.0000 - recall: 0.8933 - f1_score: 0.9433 - val_loss: 0.1919 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1604/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.1888 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9375 - val_loss: 0.1919 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1605/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1888 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9380 - val_loss: 0.1920 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1606/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1887 - precision: 1.0000 - recall: 0.8867 - f1_score: 0.9394 - val_loss: 0.1919 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1607/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.1886 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9377 - val_loss: 0.1918 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1608/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1886 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9377 - val_loss: 0.1917 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1609/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1884 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9380 - val_loss: 0.1916 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1610/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.1884 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9379 - val_loss: 0.1915 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1611/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.1884 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9377 - val_loss: 0.1913 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1612/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.1883 - precision: 1.0000 - recall: 0.8867 - f1_score: 0.9396 - val_loss: 0.1913 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1613/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.1883 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9372 - val_loss: 0.1914 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1614/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.1883 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9380 - val_loss: 0.1911 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1615/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.1882 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9374 - val_loss: 0.1912 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1616/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.1881 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9377 - val_loss: 0.1911 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1617/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.1879 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9379 - val_loss: 0.1910 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1618/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1880 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9378 - val_loss: 0.1908 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1619/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.1879 - precision: 1.0000 - recall: 0.8933 - f1_score: 0.9433 - val_loss: 0.1908 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1620/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.1878 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9376 - val_loss: 0.1907 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1621/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.1877 - precision: 1.0000 - recall: 0.8833 - f1_score: 0.9379 - val_loss: 0.1905 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1622/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.1878 - precision: 1.0000 - recall: 0.8900 - f1_score: 0.9414 - val_loss: 0.1904 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1623/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.1876 - precision: 1.0000 - recall: 0.8867 - f1_score: 0.9395 - val_loss: 0.1903 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1624/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.1875 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9446 - val_loss: 0.1903 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1625/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.1874 - precision: 1.0000 - recall: 0.8867 - f1_score: 0.9397 - val_loss: 0.1902 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1626/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.1873 - precision: 1.0000 - recall: 0.8900 - f1_score: 0.9417 - val_loss: 0.1902 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1627/3000\n",
            "300/300 [==============================] - 0s 120us/step - loss: 0.1872 - precision: 1.0000 - recall: 0.8867 - f1_score: 0.9393 - val_loss: 0.1901 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1628/3000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.1872 - precision: 1.0000 - recall: 0.8867 - f1_score: 0.9392 - val_loss: 0.1901 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1629/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.1873 - precision: 1.0000 - recall: 0.8933 - f1_score: 0.9436 - val_loss: 0.1900 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1630/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.1871 - precision: 1.0000 - recall: 0.8900 - f1_score: 0.9415 - val_loss: 0.1898 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1631/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1871 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9450 - val_loss: 0.1898 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1632/3000\n",
            "300/300 [==============================] - 0s 78us/step - loss: 0.1871 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9452 - val_loss: 0.1897 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1633/3000\n",
            "300/300 [==============================] - 0s 79us/step - loss: 0.1869 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9454 - val_loss: 0.1897 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1634/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.1870 - precision: 1.0000 - recall: 0.8900 - f1_score: 0.9415 - val_loss: 0.1895 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1635/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1867 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9455 - val_loss: 0.1896 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1636/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1867 - precision: 1.0000 - recall: 0.8933 - f1_score: 0.9436 - val_loss: 0.1896 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1637/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.1866 - precision: 1.0000 - recall: 0.8933 - f1_score: 0.9428 - val_loss: 0.1894 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1638/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.1866 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9449 - val_loss: 0.1896 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1639/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.1868 - precision: 1.0000 - recall: 0.8867 - f1_score: 0.9392 - val_loss: 0.1894 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1640/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.1865 - precision: 1.0000 - recall: 0.8900 - f1_score: 0.9412 - val_loss: 0.1893 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1641/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1863 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9454 - val_loss: 0.1894 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1642/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.1864 - precision: 1.0000 - recall: 0.8933 - f1_score: 0.9432 - val_loss: 0.1893 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1643/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1862 - precision: 1.0000 - recall: 0.8933 - f1_score: 0.9429 - val_loss: 0.1892 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1644/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1862 - precision: 1.0000 - recall: 0.8900 - f1_score: 0.9416 - val_loss: 0.1891 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1645/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1862 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9454 - val_loss: 0.1891 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1646/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.1862 - precision: 1.0000 - recall: 0.8867 - f1_score: 0.9396 - val_loss: 0.1889 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1647/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.1860 - precision: 1.0000 - recall: 0.8900 - f1_score: 0.9416 - val_loss: 0.1887 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1648/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.1859 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9453 - val_loss: 0.1887 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1649/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.1859 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9451 - val_loss: 0.1888 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1650/3000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.1858 - precision: 1.0000 - recall: 0.8867 - f1_score: 0.9396 - val_loss: 0.1885 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1651/3000\n",
            "300/300 [==============================] - 0s 106us/step - loss: 0.1858 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9449 - val_loss: 0.1885 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1652/3000\n",
            "300/300 [==============================] - 0s 79us/step - loss: 0.1859 - precision: 1.0000 - recall: 0.8900 - f1_score: 0.9415 - val_loss: 0.1884 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1653/3000\n",
            "300/300 [==============================] - 0s 118us/step - loss: 0.1856 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9450 - val_loss: 0.1884 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1654/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.1857 - precision: 1.0000 - recall: 0.8933 - f1_score: 0.9431 - val_loss: 0.1884 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1655/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.1856 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9442 - val_loss: 0.1883 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1656/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1855 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9453 - val_loss: 0.1882 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1657/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.1853 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9452 - val_loss: 0.1881 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1658/3000\n",
            "300/300 [==============================] - 0s 78us/step - loss: 0.1852 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9451 - val_loss: 0.1881 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1659/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.1853 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9453 - val_loss: 0.1880 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1660/3000\n",
            "300/300 [==============================] - 0s 78us/step - loss: 0.1852 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9452 - val_loss: 0.1879 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1661/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1851 - precision: 1.0000 - recall: 0.8933 - f1_score: 0.9429 - val_loss: 0.1879 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1662/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1852 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9448 - val_loss: 0.1879 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1663/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.1850 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9454 - val_loss: 0.1879 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1664/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.1849 - precision: 1.0000 - recall: 0.8933 - f1_score: 0.9434 - val_loss: 0.1879 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1665/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.1848 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9453 - val_loss: 0.1878 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1666/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.1849 - precision: 1.0000 - recall: 0.8900 - f1_score: 0.9416 - val_loss: 0.1878 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1667/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.1847 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9452 - val_loss: 0.1878 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1668/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.1848 - precision: 1.0000 - recall: 0.8900 - f1_score: 0.9418 - val_loss: 0.1878 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1669/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.1846 - precision: 1.0000 - recall: 0.8933 - f1_score: 0.9432 - val_loss: 0.1877 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1670/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1846 - precision: 1.0000 - recall: 0.8867 - f1_score: 0.9389 - val_loss: 0.1875 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1671/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1847 - precision: 1.0000 - recall: 0.8900 - f1_score: 0.9415 - val_loss: 0.1871 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1672/3000\n",
            "300/300 [==============================] - 0s 114us/step - loss: 0.1844 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9452 - val_loss: 0.1871 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1673/3000\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.1843 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9447 - val_loss: 0.1871 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1674/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1843 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9448 - val_loss: 0.1871 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1675/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1842 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9448 - val_loss: 0.1871 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1676/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1842 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9454 - val_loss: 0.1870 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1677/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.1840 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9453 - val_loss: 0.1869 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1678/3000\n",
            "300/300 [==============================] - 0s 79us/step - loss: 0.1842 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9451 - val_loss: 0.1871 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1679/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.1840 - precision: 1.0000 - recall: 0.8933 - f1_score: 0.9428 - val_loss: 0.1869 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1680/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1840 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9453 - val_loss: 0.1869 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1681/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.1838 - precision: 1.0000 - recall: 0.8933 - f1_score: 0.9431 - val_loss: 0.1868 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1682/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1838 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9452 - val_loss: 0.1868 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1683/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.1837 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9454 - val_loss: 0.1866 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1684/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.1838 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9452 - val_loss: 0.1864 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1685/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.1835 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9454 - val_loss: 0.1863 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1686/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.1838 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9453 - val_loss: 0.1864 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1687/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1835 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9450 - val_loss: 0.1863 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1688/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.1835 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9447 - val_loss: 0.1863 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1689/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1833 - precision: 1.0000 - recall: 0.8933 - f1_score: 0.9434 - val_loss: 0.1862 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1690/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.1833 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9453 - val_loss: 0.1861 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1691/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.1832 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9448 - val_loss: 0.1860 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1692/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.1832 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9454 - val_loss: 0.1859 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1693/3000\n",
            "300/300 [==============================] - 0s 110us/step - loss: 0.1831 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9455 - val_loss: 0.1860 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1694/3000\n",
            "300/300 [==============================] - 0s 103us/step - loss: 0.1831 - precision: 1.0000 - recall: 0.9000 - f1_score: 0.9470 - val_loss: 0.1859 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1695/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.1830 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9449 - val_loss: 0.1860 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1696/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.1829 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9454 - val_loss: 0.1860 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1697/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.1828 - precision: 1.0000 - recall: 0.9000 - f1_score: 0.9473 - val_loss: 0.1859 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1698/3000\n",
            "300/300 [==============================] - 0s 80us/step - loss: 0.1828 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9453 - val_loss: 0.1857 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1699/3000\n",
            "300/300 [==============================] - 0s 78us/step - loss: 0.1827 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9454 - val_loss: 0.1857 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1700/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.1827 - precision: 1.0000 - recall: 0.9000 - f1_score: 0.9473 - val_loss: 0.1857 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1701/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.1826 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9450 - val_loss: 0.1856 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1702/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1826 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9455 - val_loss: 0.1855 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1703/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.1825 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9453 - val_loss: 0.1856 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1704/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.1824 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9490 - val_loss: 0.1855 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1705/3000\n",
            "300/300 [==============================] - 0s 105us/step - loss: 0.1823 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9452 - val_loss: 0.1853 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1706/3000\n",
            "300/300 [==============================] - 0s 105us/step - loss: 0.1823 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9454 - val_loss: 0.1851 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1707/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.1822 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9453 - val_loss: 0.1851 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1708/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.1822 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9452 - val_loss: 0.1851 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1709/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.1821 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9455 - val_loss: 0.1850 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1710/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.1821 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9449 - val_loss: 0.1850 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1711/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.1820 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9453 - val_loss: 0.1850 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1712/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.1819 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9454 - val_loss: 0.1849 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1713/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.1819 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9439 - val_loss: 0.1849 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1714/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.1818 - precision: 1.0000 - recall: 0.9000 - f1_score: 0.9471 - val_loss: 0.1849 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1715/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.1817 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9488 - val_loss: 0.1848 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1716/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.1817 - precision: 1.0000 - recall: 0.9000 - f1_score: 0.9471 - val_loss: 0.1848 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1717/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.1816 - precision: 1.0000 - recall: 0.9000 - f1_score: 0.9466 - val_loss: 0.1846 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1718/3000\n",
            "300/300 [==============================] - 0s 105us/step - loss: 0.1816 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9449 - val_loss: 0.1845 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1719/3000\n",
            "300/300 [==============================] - 0s 79us/step - loss: 0.1816 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9452 - val_loss: 0.1845 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1720/3000\n",
            "300/300 [==============================] - 0s 80us/step - loss: 0.1815 - precision: 1.0000 - recall: 0.9000 - f1_score: 0.9472 - val_loss: 0.1844 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1721/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.1814 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9448 - val_loss: 0.1844 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1722/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.1814 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9452 - val_loss: 0.1846 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1723/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1813 - precision: 1.0000 - recall: 0.9000 - f1_score: 0.9469 - val_loss: 0.1846 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1724/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1812 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9490 - val_loss: 0.1845 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1725/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1813 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9449 - val_loss: 0.1845 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1726/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.1811 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9452 - val_loss: 0.1842 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1727/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1812 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9491 - val_loss: 0.1844 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1728/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.1810 - precision: 1.0000 - recall: 0.9000 - f1_score: 0.9473 - val_loss: 0.1842 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1729/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.1811 - precision: 1.0000 - recall: 0.9000 - f1_score: 0.9468 - val_loss: 0.1839 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1730/3000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.1808 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9452 - val_loss: 0.1839 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1731/3000\n",
            "300/300 [==============================] - 0s 80us/step - loss: 0.1808 - precision: 1.0000 - recall: 0.9000 - f1_score: 0.9471 - val_loss: 0.1840 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1732/3000\n",
            "300/300 [==============================] - 0s 78us/step - loss: 0.1808 - precision: 1.0000 - recall: 0.9000 - f1_score: 0.9471 - val_loss: 0.1838 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1733/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.1807 - precision: 1.0000 - recall: 0.9000 - f1_score: 0.9473 - val_loss: 0.1837 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1734/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.1806 - precision: 1.0000 - recall: 0.9000 - f1_score: 0.9471 - val_loss: 0.1836 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1735/3000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.1806 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9491 - val_loss: 0.1834 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1736/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.1804 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9454 - val_loss: 0.1833 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1737/3000\n",
            "300/300 [==============================] - 0s 80us/step - loss: 0.1804 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9489 - val_loss: 0.1832 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1738/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.1804 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9454 - val_loss: 0.1832 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1739/3000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.1804 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9454 - val_loss: 0.1831 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1740/3000\n",
            "300/300 [==============================] - 0s 115us/step - loss: 0.1802 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9455 - val_loss: 0.1831 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1741/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.1802 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9450 - val_loss: 0.1831 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1742/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.1802 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9486 - val_loss: 0.1831 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1743/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1800 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9490 - val_loss: 0.1829 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1744/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.1802 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9490 - val_loss: 0.1827 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1745/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.1801 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9454 - val_loss: 0.1829 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1746/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.1798 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9490 - val_loss: 0.1829 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1747/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.1798 - precision: 1.0000 - recall: 0.9000 - f1_score: 0.9472 - val_loss: 0.1827 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1748/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.1797 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9492 - val_loss: 0.1827 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1749/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.1796 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9486 - val_loss: 0.1826 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1750/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.1797 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9486 - val_loss: 0.1823 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1751/3000\n",
            "300/300 [==============================] - 0s 126us/step - loss: 0.1796 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9450 - val_loss: 0.1824 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1752/3000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.1795 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9452 - val_loss: 0.1824 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1753/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.1795 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9491 - val_loss: 0.1822 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1754/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.1793 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9490 - val_loss: 0.1821 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1755/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.1793 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9451 - val_loss: 0.1821 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1756/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.1792 - precision: 1.0000 - recall: 0.9000 - f1_score: 0.9472 - val_loss: 0.1820 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1757/3000\n",
            "300/300 [==============================] - 0s 81us/step - loss: 0.1792 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9455 - val_loss: 0.1819 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1758/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1792 - precision: 1.0000 - recall: 0.9000 - f1_score: 0.9472 - val_loss: 0.1818 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1759/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.1792 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9449 - val_loss: 0.1818 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1760/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1791 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9453 - val_loss: 0.1817 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1761/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.1790 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9455 - val_loss: 0.1817 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1762/3000\n",
            "300/300 [==============================] - 0s 78us/step - loss: 0.1790 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9448 - val_loss: 0.1815 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1763/3000\n",
            "300/300 [==============================] - 0s 127us/step - loss: 0.1789 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9455 - val_loss: 0.1816 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1764/3000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.1789 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9454 - val_loss: 0.1816 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1765/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.1788 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9491 - val_loss: 0.1816 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1766/3000\n",
            "300/300 [==============================] - 0s 82us/step - loss: 0.1787 - precision: 1.0000 - recall: 0.8967 - f1_score: 0.9452 - val_loss: 0.1817 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1767/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1786 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9486 - val_loss: 0.1817 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1768/3000\n",
            "300/300 [==============================] - 0s 81us/step - loss: 0.1786 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9491 - val_loss: 0.1815 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1769/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.1784 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9492 - val_loss: 0.1814 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1770/3000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.1785 - precision: 1.0000 - recall: 0.9000 - f1_score: 0.9473 - val_loss: 0.1815 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1771/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.1785 - precision: 1.0000 - recall: 0.9000 - f1_score: 0.9472 - val_loss: 0.1815 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1772/3000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.1784 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9489 - val_loss: 0.1814 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1773/3000\n",
            "300/300 [==============================] - 0s 110us/step - loss: 0.1782 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9488 - val_loss: 0.1813 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1774/3000\n",
            "300/300 [==============================] - 0s 124us/step - loss: 0.1783 - precision: 1.0000 - recall: 0.9000 - f1_score: 0.9468 - val_loss: 0.1812 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1775/3000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.1781 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9491 - val_loss: 0.1812 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1776/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.1781 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9490 - val_loss: 0.1811 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1777/3000\n",
            "300/300 [==============================] - 0s 79us/step - loss: 0.1782 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9488 - val_loss: 0.1810 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1778/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1781 - precision: 1.0000 - recall: 0.9000 - f1_score: 0.9472 - val_loss: 0.1810 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1779/3000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.1779 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9485 - val_loss: 0.1809 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1780/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.1778 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9491 - val_loss: 0.1808 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1781/3000\n",
            "300/300 [==============================] - 0s 80us/step - loss: 0.1778 - precision: 1.0000 - recall: 0.9000 - f1_score: 0.9472 - val_loss: 0.1808 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1782/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.1779 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9490 - val_loss: 0.1808 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1783/3000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.1777 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9490 - val_loss: 0.1808 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1784/3000\n",
            "300/300 [==============================] - 0s 115us/step - loss: 0.1777 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9485 - val_loss: 0.1807 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1785/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.1777 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9492 - val_loss: 0.1806 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1786/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.1776 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9490 - val_loss: 0.1803 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1787/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.1775 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9488 - val_loss: 0.1803 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1788/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.1774 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9486 - val_loss: 0.1802 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1789/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.1773 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9487 - val_loss: 0.1801 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1790/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.1773 - precision: 1.0000 - recall: 0.9000 - f1_score: 0.9469 - val_loss: 0.1800 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1791/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.1773 - precision: 1.0000 - recall: 0.9000 - f1_score: 0.9472 - val_loss: 0.1800 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1792/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.1772 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9476 - val_loss: 0.1800 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1793/3000\n",
            "300/300 [==============================] - 0s 105us/step - loss: 0.1774 - precision: 1.0000 - recall: 0.9000 - f1_score: 0.9469 - val_loss: 0.1801 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1794/3000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.1770 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9487 - val_loss: 0.1801 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1795/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.1770 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9488 - val_loss: 0.1799 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1796/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.1769 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9490 - val_loss: 0.1799 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1797/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1771 - precision: 1.0000 - recall: 0.9000 - f1_score: 0.9463 - val_loss: 0.1801 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1798/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.1768 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9489 - val_loss: 0.1800 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1799/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.1769 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9507 - val_loss: 0.1798 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1800/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.1767 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9491 - val_loss: 0.1798 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1801/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.1766 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9489 - val_loss: 0.1797 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1802/3000\n",
            "300/300 [==============================] - 0s 80us/step - loss: 0.1768 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9488 - val_loss: 0.1797 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1803/3000\n",
            "300/300 [==============================] - 0s 105us/step - loss: 0.1766 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9489 - val_loss: 0.1798 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1804/3000\n",
            "300/300 [==============================] - 0s 101us/step - loss: 0.1765 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9492 - val_loss: 0.1796 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1805/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1765 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9507 - val_loss: 0.1795 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1806/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.1765 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9506 - val_loss: 0.1793 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1807/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.1764 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9492 - val_loss: 0.1793 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1808/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.1763 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9491 - val_loss: 0.1793 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1809/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1762 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9491 - val_loss: 0.1793 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1810/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1762 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9480 - val_loss: 0.1792 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1811/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1760 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9490 - val_loss: 0.1792 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1812/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1763 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9484 - val_loss: 0.1791 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1813/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.1760 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9492 - val_loss: 0.1792 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1814/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.1759 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9491 - val_loss: 0.1790 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1815/3000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.1758 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9488 - val_loss: 0.1789 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1816/3000\n",
            "300/300 [==============================] - 0s 106us/step - loss: 0.1760 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9491 - val_loss: 0.1789 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1817/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.1757 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9489 - val_loss: 0.1787 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1818/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1757 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9489 - val_loss: 0.1787 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1819/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.1756 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9487 - val_loss: 0.1786 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1820/3000\n",
            "300/300 [==============================] - 0s 80us/step - loss: 0.1756 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9489 - val_loss: 0.1786 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1821/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.1755 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9488 - val_loss: 0.1786 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1822/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.1754 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9487 - val_loss: 0.1786 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1823/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.1754 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9501 - val_loss: 0.1785 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1824/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.1754 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9508 - val_loss: 0.1782 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1825/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.1753 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9507 - val_loss: 0.1783 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1826/3000\n",
            "300/300 [==============================] - 0s 101us/step - loss: 0.1753 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9488 - val_loss: 0.1783 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1827/3000\n",
            "300/300 [==============================] - 0s 119us/step - loss: 0.1751 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9488 - val_loss: 0.1781 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1828/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.1752 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9505 - val_loss: 0.1779 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1829/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.1751 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9491 - val_loss: 0.1778 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1830/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.1751 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9480 - val_loss: 0.1777 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1831/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.1750 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9492 - val_loss: 0.1775 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1832/3000\n",
            "300/300 [==============================] - 0s 81us/step - loss: 0.1749 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9506 - val_loss: 0.1775 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1833/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1750 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9507 - val_loss: 0.1775 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1834/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.1749 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9489 - val_loss: 0.1775 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1835/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.1747 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9509 - val_loss: 0.1775 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1836/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1748 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9487 - val_loss: 0.1775 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1837/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.1747 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9507 - val_loss: 0.1774 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1838/3000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.1746 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9490 - val_loss: 0.1773 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1839/3000\n",
            "300/300 [==============================] - 0s 107us/step - loss: 0.1744 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9510 - val_loss: 0.1773 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1840/3000\n",
            "300/300 [==============================] - 0s 78us/step - loss: 0.1744 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9490 - val_loss: 0.1772 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1841/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.1745 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9505 - val_loss: 0.1773 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1842/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1743 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9509 - val_loss: 0.1773 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1843/3000\n",
            "300/300 [==============================] - 0s 80us/step - loss: 0.1743 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9506 - val_loss: 0.1772 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1844/3000\n",
            "300/300 [==============================] - 0s 82us/step - loss: 0.1744 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9492 - val_loss: 0.1773 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1845/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.1741 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9486 - val_loss: 0.1772 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1846/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.1742 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9506 - val_loss: 0.1771 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1847/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.1740 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9488 - val_loss: 0.1770 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1848/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.1741 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9507 - val_loss: 0.1769 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1849/3000\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.1740 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9507 - val_loss: 0.1768 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1850/3000\n",
            "300/300 [==============================] - 0s 131us/step - loss: 0.1740 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9487 - val_loss: 0.1769 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1851/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1739 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9489 - val_loss: 0.1767 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1852/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.1738 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9486 - val_loss: 0.1766 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1853/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1737 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9508 - val_loss: 0.1765 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1854/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.1737 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9509 - val_loss: 0.1765 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1855/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.1737 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9509 - val_loss: 0.1764 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1856/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.1738 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9492 - val_loss: 0.1765 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1857/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1736 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9507 - val_loss: 0.1764 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1858/3000\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.1734 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9509 - val_loss: 0.1764 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1859/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.1735 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9492 - val_loss: 0.1763 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1860/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.1733 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9491 - val_loss: 0.1763 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1861/3000\n",
            "300/300 [==============================] - 0s 80us/step - loss: 0.1733 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9508 - val_loss: 0.1762 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1862/3000\n",
            "300/300 [==============================] - 0s 110us/step - loss: 0.1732 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9510 - val_loss: 0.1761 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1863/3000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.1731 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9490 - val_loss: 0.1760 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1864/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.1731 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9507 - val_loss: 0.1759 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1865/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.1731 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9499 - val_loss: 0.1760 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1866/3000\n",
            "300/300 [==============================] - 0s 78us/step - loss: 0.1730 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9487 - val_loss: 0.1759 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1867/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.1730 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9508 - val_loss: 0.1759 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1868/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.1731 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9526 - val_loss: 0.1759 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1869/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.1729 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9507 - val_loss: 0.1760 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1870/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.1728 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9510 - val_loss: 0.1758 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1871/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.1727 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9490 - val_loss: 0.1758 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1872/3000\n",
            "300/300 [==============================] - 0s 109us/step - loss: 0.1726 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9510 - val_loss: 0.1757 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1873/3000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.1726 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9508 - val_loss: 0.1757 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1874/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.1725 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9510 - val_loss: 0.1755 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1875/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1727 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9521 - val_loss: 0.1754 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1876/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1725 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9509 - val_loss: 0.1753 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1877/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.1724 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9491 - val_loss: 0.1753 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1878/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.1724 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9505 - val_loss: 0.1751 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1879/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.1723 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9504 - val_loss: 0.1753 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1880/3000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.1722 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9527 - val_loss: 0.1752 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1881/3000\n",
            "300/300 [==============================] - 0s 116us/step - loss: 0.1723 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9510 - val_loss: 0.1750 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1882/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.1722 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9509 - val_loss: 0.1750 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1883/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.1721 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9524 - val_loss: 0.1748 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1884/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.1720 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9508 - val_loss: 0.1749 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1885/3000\n",
            "300/300 [==============================] - 0s 82us/step - loss: 0.1722 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9510 - val_loss: 0.1749 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1886/3000\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.1721 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9509 - val_loss: 0.1749 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1887/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.1719 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9509 - val_loss: 0.1747 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1888/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.1719 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9526 - val_loss: 0.1745 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1889/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.1718 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9509 - val_loss: 0.1745 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1890/3000\n",
            "300/300 [==============================] - 0s 141us/step - loss: 0.1718 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9507 - val_loss: 0.1745 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1891/3000\n",
            "300/300 [==============================] - 0s 80us/step - loss: 0.1718 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9505 - val_loss: 0.1746 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1892/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.1716 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9508 - val_loss: 0.1743 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1893/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.1716 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9509 - val_loss: 0.1743 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1894/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.1714 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9509 - val_loss: 0.1742 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1895/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.1714 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9505 - val_loss: 0.1742 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1896/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.1714 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9510 - val_loss: 0.1743 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1897/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.1714 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9528 - val_loss: 0.1742 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1898/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.1713 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9528 - val_loss: 0.1740 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1899/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.1712 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9502 - val_loss: 0.1741 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1900/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1711 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9510 - val_loss: 0.1740 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1901/3000\n",
            "300/300 [==============================] - 0s 82us/step - loss: 0.1711 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9524 - val_loss: 0.1740 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1902/3000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.1711 - precision: 1.0000 - recall: 0.9033 - f1_score: 0.9491 - val_loss: 0.1738 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1903/3000\n",
            "300/300 [==============================] - 0s 106us/step - loss: 0.1710 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9506 - val_loss: 0.1736 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1904/3000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.1710 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9509 - val_loss: 0.1735 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1905/3000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.1711 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9505 - val_loss: 0.1736 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1906/3000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.1710 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9507 - val_loss: 0.1736 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1907/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.1708 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9508 - val_loss: 0.1736 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1908/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.1709 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9510 - val_loss: 0.1734 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1909/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.1707 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9509 - val_loss: 0.1733 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1910/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1707 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9505 - val_loss: 0.1735 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1911/3000\n",
            "300/300 [==============================] - 0s 79us/step - loss: 0.1706 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9527 - val_loss: 0.1734 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1912/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.1706 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9523 - val_loss: 0.1734 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1913/3000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.1705 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9505 - val_loss: 0.1732 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1914/3000\n",
            "300/300 [==============================] - 0s 112us/step - loss: 0.1706 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9508 - val_loss: 0.1732 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1915/3000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.1704 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9507 - val_loss: 0.1733 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1916/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.1703 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9525 - val_loss: 0.1734 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1917/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1703 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9527 - val_loss: 0.1734 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1918/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.1703 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9527 - val_loss: 0.1734 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1919/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.1703 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9504 - val_loss: 0.1733 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1920/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.1702 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9523 - val_loss: 0.1733 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1921/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1702 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9510 - val_loss: 0.1732 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1922/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.1701 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9526 - val_loss: 0.1732 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1923/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1700 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9508 - val_loss: 0.1732 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1924/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.1699 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9508 - val_loss: 0.1730 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1925/3000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.1698 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9528 - val_loss: 0.1729 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1926/3000\n",
            "300/300 [==============================] - 0s 119us/step - loss: 0.1699 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9522 - val_loss: 0.1729 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1927/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.1698 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9527 - val_loss: 0.1727 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1928/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.1697 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9528 - val_loss: 0.1725 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1929/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.1697 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9519 - val_loss: 0.1723 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1930/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.1696 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9510 - val_loss: 0.1723 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1931/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1696 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9521 - val_loss: 0.1724 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1932/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.1696 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9526 - val_loss: 0.1724 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1933/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1695 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9521 - val_loss: 0.1725 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1934/3000\n",
            "300/300 [==============================] - 0s 80us/step - loss: 0.1694 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9526 - val_loss: 0.1724 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1935/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.1694 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9528 - val_loss: 0.1723 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1936/3000\n",
            "300/300 [==============================] - 0s 113us/step - loss: 0.1693 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9525 - val_loss: 0.1721 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1937/3000\n",
            "300/300 [==============================] - 0s 113us/step - loss: 0.1693 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9503 - val_loss: 0.1722 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1938/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1692 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9520 - val_loss: 0.1721 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1939/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.1691 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9525 - val_loss: 0.1720 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1940/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.1691 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9528 - val_loss: 0.1719 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1941/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1691 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9522 - val_loss: 0.1717 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1942/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.1689 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9523 - val_loss: 0.1718 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1943/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.1690 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9522 - val_loss: 0.1718 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1944/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.1688 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9525 - val_loss: 0.1718 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1945/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.1688 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9528 - val_loss: 0.1719 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1946/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.1688 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9524 - val_loss: 0.1719 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1947/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1687 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9527 - val_loss: 0.1719 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1948/3000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.1687 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9527 - val_loss: 0.1717 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1949/3000\n",
            "300/300 [==============================] - 0s 110us/step - loss: 0.1686 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9524 - val_loss: 0.1717 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1950/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.1686 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9518 - val_loss: 0.1715 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1951/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1685 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9525 - val_loss: 0.1714 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1952/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.1686 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9522 - val_loss: 0.1713 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1953/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.1684 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9523 - val_loss: 0.1713 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1954/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1685 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9525 - val_loss: 0.1711 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1955/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.1683 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9521 - val_loss: 0.1711 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1956/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.1683 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9525 - val_loss: 0.1711 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1957/3000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.1683 - precision: 1.0000 - recall: 0.9067 - f1_score: 0.9508 - val_loss: 0.1712 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1958/3000\n",
            "300/300 [==============================] - 0s 108us/step - loss: 0.1683 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9522 - val_loss: 0.1711 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1959/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.1681 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9527 - val_loss: 0.1710 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1960/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.1681 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9527 - val_loss: 0.1709 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1961/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.1682 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9526 - val_loss: 0.1709 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1962/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.1679 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9520 - val_loss: 0.1708 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1963/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.1680 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9524 - val_loss: 0.1706 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1964/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.1679 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9526 - val_loss: 0.1707 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1965/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.1678 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9527 - val_loss: 0.1707 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1966/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.1677 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9525 - val_loss: 0.1706 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1967/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.1677 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9526 - val_loss: 0.1706 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1968/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.1676 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9525 - val_loss: 0.1706 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1969/3000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.1677 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9523 - val_loss: 0.1705 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1970/3000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.1675 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9526 - val_loss: 0.1705 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1971/3000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.1676 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9516 - val_loss: 0.1706 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1972/3000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.1675 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9524 - val_loss: 0.1705 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1973/3000\n",
            "300/300 [==============================] - 0s 78us/step - loss: 0.1675 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9524 - val_loss: 0.1703 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1974/3000\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.1674 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9527 - val_loss: 0.1704 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1975/3000\n",
            "300/300 [==============================] - 0s 78us/step - loss: 0.1673 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9521 - val_loss: 0.1704 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1976/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.1672 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9527 - val_loss: 0.1703 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1977/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.1672 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9524 - val_loss: 0.1704 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1978/3000\n",
            "300/300 [==============================] - 0s 117us/step - loss: 0.1673 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9528 - val_loss: 0.1705 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1979/3000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.1671 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9547 - val_loss: 0.1704 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1980/3000\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.1671 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9546 - val_loss: 0.1702 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1981/3000\n",
            "300/300 [==============================] - 0s 80us/step - loss: 0.1670 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9526 - val_loss: 0.1701 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1982/3000\n",
            "300/300 [==============================] - 0s 81us/step - loss: 0.1669 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9528 - val_loss: 0.1700 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1983/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.1670 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9546 - val_loss: 0.1699 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1984/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1669 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9525 - val_loss: 0.1700 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1985/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1668 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9527 - val_loss: 0.1699 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1986/3000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.1667 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9527 - val_loss: 0.1698 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1987/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.1667 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9543 - val_loss: 0.1699 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1988/3000\n",
            "300/300 [==============================] - 0s 81us/step - loss: 0.1667 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9527 - val_loss: 0.1698 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1989/3000\n",
            "300/300 [==============================] - 0s 118us/step - loss: 0.1666 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9527 - val_loss: 0.1698 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1990/3000\n",
            "300/300 [==============================] - 0s 114us/step - loss: 0.1667 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9545 - val_loss: 0.1698 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1991/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.1665 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9545 - val_loss: 0.1696 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1992/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1664 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9525 - val_loss: 0.1694 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1993/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.1664 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9525 - val_loss: 0.1695 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1994/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1664 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9526 - val_loss: 0.1693 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1995/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.1664 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9543 - val_loss: 0.1693 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1996/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.1662 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9526 - val_loss: 0.1693 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1997/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.1662 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9527 - val_loss: 0.1691 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1998/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.1662 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9546 - val_loss: 0.1691 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 1999/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.1660 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9523 - val_loss: 0.1691 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2000/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.1661 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9546 - val_loss: 0.1689 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2001/3000\n",
            "300/300 [==============================] - 0s 244us/step - loss: 0.1661 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9528 - val_loss: 0.1689 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2002/3000\n",
            "300/300 [==============================] - 0s 147us/step - loss: 0.1660 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9525 - val_loss: 0.1688 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2003/3000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.1659 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9546 - val_loss: 0.1689 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2004/3000\n",
            "300/300 [==============================] - 0s 111us/step - loss: 0.1659 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9546 - val_loss: 0.1688 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2005/3000\n",
            "300/300 [==============================] - 0s 108us/step - loss: 0.1659 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9528 - val_loss: 0.1687 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2006/3000\n",
            "300/300 [==============================] - 0s 104us/step - loss: 0.1657 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9544 - val_loss: 0.1688 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2007/3000\n",
            "300/300 [==============================] - 0s 105us/step - loss: 0.1657 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9542 - val_loss: 0.1686 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2008/3000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.1657 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9524 - val_loss: 0.1684 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2009/3000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.1656 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9546 - val_loss: 0.1685 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2010/3000\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.1656 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9544 - val_loss: 0.1684 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2011/3000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.1655 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9525 - val_loss: 0.1682 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2012/3000\n",
            "300/300 [==============================] - 0s 101us/step - loss: 0.1656 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9563 - val_loss: 0.1684 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2013/3000\n",
            "300/300 [==============================] - 0s 103us/step - loss: 0.1654 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9540 - val_loss: 0.1682 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2014/3000\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.1657 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9528 - val_loss: 0.1679 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2015/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.1653 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9542 - val_loss: 0.1679 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2016/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.1652 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9545 - val_loss: 0.1679 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2017/3000\n",
            "300/300 [==============================] - 0s 81us/step - loss: 0.1653 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9541 - val_loss: 0.1679 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2018/3000\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.1652 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9541 - val_loss: 0.1678 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2019/3000\n",
            "300/300 [==============================] - 0s 102us/step - loss: 0.1651 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9546 - val_loss: 0.1679 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2020/3000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.1651 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9544 - val_loss: 0.1680 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2021/3000\n",
            "300/300 [==============================] - 0s 103us/step - loss: 0.1651 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9545 - val_loss: 0.1681 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2022/3000\n",
            "300/300 [==============================] - 0s 112us/step - loss: 0.1650 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9544 - val_loss: 0.1681 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2023/3000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.1649 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9544 - val_loss: 0.1679 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2024/3000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.1649 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9527 - val_loss: 0.1678 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2025/3000\n",
            "300/300 [==============================] - 0s 170us/step - loss: 0.1648 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9546 - val_loss: 0.1678 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2026/3000\n",
            "300/300 [==============================] - 0s 161us/step - loss: 0.1648 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9528 - val_loss: 0.1678 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2027/3000\n",
            "300/300 [==============================] - 0s 131us/step - loss: 0.1647 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9545 - val_loss: 0.1677 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2028/3000\n",
            "300/300 [==============================] - 0s 120us/step - loss: 0.1646 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9546 - val_loss: 0.1677 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2029/3000\n",
            "300/300 [==============================] - 0s 115us/step - loss: 0.1647 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9544 - val_loss: 0.1675 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2030/3000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.1646 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9546 - val_loss: 0.1675 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2031/3000\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.1645 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9540 - val_loss: 0.1675 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2032/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.1645 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9546 - val_loss: 0.1675 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2033/3000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.1644 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9563 - val_loss: 0.1674 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2034/3000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.1645 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9547 - val_loss: 0.1673 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2035/3000\n",
            "300/300 [==============================] - 0s 107us/step - loss: 0.1643 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9542 - val_loss: 0.1675 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2036/3000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.1644 - precision: 1.0000 - recall: 0.9100 - f1_score: 0.9525 - val_loss: 0.1674 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2037/3000\n",
            "300/300 [==============================] - 0s 105us/step - loss: 0.1643 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9547 - val_loss: 0.1672 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2038/3000\n",
            "300/300 [==============================] - 0s 123us/step - loss: 0.1642 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9545 - val_loss: 0.1671 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2039/3000\n",
            "300/300 [==============================] - 0s 154us/step - loss: 0.1641 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9543 - val_loss: 0.1671 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2040/3000\n",
            "300/300 [==============================] - 0s 105us/step - loss: 0.1642 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9543 - val_loss: 0.1671 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2041/3000\n",
            "300/300 [==============================] - 0s 116us/step - loss: 0.1641 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9544 - val_loss: 0.1669 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2042/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.1640 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9564 - val_loss: 0.1668 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2043/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.1639 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9562 - val_loss: 0.1667 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2044/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1639 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9546 - val_loss: 0.1665 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2045/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1638 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9545 - val_loss: 0.1666 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2046/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1639 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9540 - val_loss: 0.1666 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2047/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.1637 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9545 - val_loss: 0.1667 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2048/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.1637 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9544 - val_loss: 0.1665 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2049/3000\n",
            "300/300 [==============================] - 0s 103us/step - loss: 0.1636 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9543 - val_loss: 0.1665 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2050/3000\n",
            "300/300 [==============================] - 0s 122us/step - loss: 0.1636 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9546 - val_loss: 0.1666 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2051/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1636 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9565 - val_loss: 0.1664 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2052/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1635 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9565 - val_loss: 0.1665 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2053/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1635 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9562 - val_loss: 0.1664 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2054/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1635 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9557 - val_loss: 0.1662 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2055/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.1633 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9564 - val_loss: 0.1661 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2056/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1634 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9546 - val_loss: 0.1660 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2057/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.1632 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9545 - val_loss: 0.1660 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2058/3000\n",
            "300/300 [==============================] - 0s 79us/step - loss: 0.1632 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9545 - val_loss: 0.1660 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2059/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.1631 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9564 - val_loss: 0.1660 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2060/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1632 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9545 - val_loss: 0.1661 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2061/3000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.1630 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9564 - val_loss: 0.1660 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2062/3000\n",
            "300/300 [==============================] - 0s 126us/step - loss: 0.1630 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9564 - val_loss: 0.1659 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2063/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1630 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9563 - val_loss: 0.1657 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2064/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.1630 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9564 - val_loss: 0.1656 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2065/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.1629 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9556 - val_loss: 0.1656 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2066/3000\n",
            "300/300 [==============================] - 0s 82us/step - loss: 0.1629 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9582 - val_loss: 0.1657 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2067/3000\n",
            "300/300 [==============================] - 0s 80us/step - loss: 0.1628 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9563 - val_loss: 0.1657 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2068/3000\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.1628 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9561 - val_loss: 0.1658 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2069/3000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.1627 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9546 - val_loss: 0.1655 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2070/3000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.1628 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9560 - val_loss: 0.1655 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2071/3000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.1628 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9564 - val_loss: 0.1657 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2072/3000\n",
            "300/300 [==============================] - 0s 105us/step - loss: 0.1627 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9564 - val_loss: 0.1656 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2073/3000\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.1626 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9564 - val_loss: 0.1657 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2074/3000\n",
            "300/300 [==============================] - 0s 119us/step - loss: 0.1624 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9564 - val_loss: 0.1655 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2075/3000\n",
            "300/300 [==============================] - 0s 111us/step - loss: 0.1626 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9544 - val_loss: 0.1653 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2076/3000\n",
            "300/300 [==============================] - 0s 134us/step - loss: 0.1624 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9562 - val_loss: 0.1652 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2077/3000\n",
            "300/300 [==============================] - 0s 148us/step - loss: 0.1624 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9564 - val_loss: 0.1652 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2078/3000\n",
            "300/300 [==============================] - 0s 117us/step - loss: 0.1623 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9563 - val_loss: 0.1652 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2079/3000\n",
            "300/300 [==============================] - 0s 101us/step - loss: 0.1624 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9561 - val_loss: 0.1650 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2080/3000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.1622 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9583 - val_loss: 0.1649 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2081/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1622 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9581 - val_loss: 0.1651 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2082/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1621 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9563 - val_loss: 0.1650 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2083/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.1621 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9563 - val_loss: 0.1651 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2084/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.1623 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9544 - val_loss: 0.1654 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2085/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1620 - precision: 1.0000 - recall: 0.9133 - f1_score: 0.9546 - val_loss: 0.1653 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2086/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.1619 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9564 - val_loss: 0.1652 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2087/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1619 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9561 - val_loss: 0.1650 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2088/3000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.1618 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9564 - val_loss: 0.1649 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2089/3000\n",
            "300/300 [==============================] - 0s 166us/step - loss: 0.1619 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9563 - val_loss: 0.1650 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2090/3000\n",
            "300/300 [==============================] - 0s 129us/step - loss: 0.1618 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9557 - val_loss: 0.1648 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2091/3000\n",
            "300/300 [==============================] - 0s 126us/step - loss: 0.1616 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9559 - val_loss: 0.1647 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2092/3000\n",
            "300/300 [==============================] - 0s 115us/step - loss: 0.1616 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9564 - val_loss: 0.1645 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2093/3000\n",
            "300/300 [==============================] - 0s 122us/step - loss: 0.1616 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9580 - val_loss: 0.1644 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2094/3000\n",
            "300/300 [==============================] - 0s 112us/step - loss: 0.1615 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9565 - val_loss: 0.1643 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2095/3000\n",
            "300/300 [==============================] - 0s 109us/step - loss: 0.1615 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9574 - val_loss: 0.1642 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2096/3000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.1614 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9583 - val_loss: 0.1641 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2097/3000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.1616 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9557 - val_loss: 0.1640 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2098/3000\n",
            "300/300 [==============================] - 0s 82us/step - loss: 0.1613 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9578 - val_loss: 0.1640 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2099/3000\n",
            "300/300 [==============================] - 0s 128us/step - loss: 0.1614 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9561 - val_loss: 0.1639 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2100/3000\n",
            "300/300 [==============================] - 0s 144us/step - loss: 0.1614 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9563 - val_loss: 0.1639 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2101/3000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.1613 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9582 - val_loss: 0.1639 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2102/3000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.1611 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9564 - val_loss: 0.1639 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2103/3000\n",
            "300/300 [==============================] - 0s 78us/step - loss: 0.1611 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9581 - val_loss: 0.1638 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2104/3000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.1611 - precision: 1.0000 - recall: 0.9233 - f1_score: 0.9596 - val_loss: 0.1638 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2105/3000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.1611 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9582 - val_loss: 0.1638 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2106/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.1611 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9564 - val_loss: 0.1635 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2107/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.1609 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9582 - val_loss: 0.1636 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2108/3000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.1609 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9582 - val_loss: 0.1635 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2109/3000\n",
            "300/300 [==============================] - 0s 141us/step - loss: 0.1608 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9561 - val_loss: 0.1636 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2110/3000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.1611 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9580 - val_loss: 0.1637 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2111/3000\n",
            "300/300 [==============================] - 0s 78us/step - loss: 0.1608 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9561 - val_loss: 0.1636 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2112/3000\n",
            "300/300 [==============================] - 0s 78us/step - loss: 0.1607 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9559 - val_loss: 0.1635 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2113/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1607 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9582 - val_loss: 0.1635 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2114/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1607 - precision: 1.0000 - recall: 0.9233 - f1_score: 0.9601 - val_loss: 0.1636 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2115/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.1605 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9580 - val_loss: 0.1636 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2116/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1606 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9583 - val_loss: 0.1636 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2117/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.1606 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9564 - val_loss: 0.1635 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2118/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.1605 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9560 - val_loss: 0.1632 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2119/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.1603 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9581 - val_loss: 0.1631 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2120/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.1603 - precision: 1.0000 - recall: 0.9233 - f1_score: 0.9601 - val_loss: 0.1630 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2121/3000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.1603 - precision: 1.0000 - recall: 0.9233 - f1_score: 0.9599 - val_loss: 0.1631 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2122/3000\n",
            "300/300 [==============================] - 0s 113us/step - loss: 0.1602 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9580 - val_loss: 0.1629 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2123/3000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.1602 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9582 - val_loss: 0.1628 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2124/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.1603 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9560 - val_loss: 0.1627 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2125/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.1602 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.1627 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2126/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.1601 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.1627 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2127/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.1600 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9581 - val_loss: 0.1627 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2128/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.1600 - precision: 1.0000 - recall: 0.9233 - f1_score: 0.9598 - val_loss: 0.1625 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2129/3000\n",
            "300/300 [==============================] - 0s 78us/step - loss: 0.1599 - precision: 1.0000 - recall: 0.9233 - f1_score: 0.9600 - val_loss: 0.1626 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2130/3000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.1599 - precision: 1.0000 - recall: 0.9233 - f1_score: 0.9598 - val_loss: 0.1627 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2131/3000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.1598 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9581 - val_loss: 0.1625 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2132/3000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.1600 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9578 - val_loss: 0.1626 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2133/3000\n",
            "300/300 [==============================] - 0s 160us/step - loss: 0.1599 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9582 - val_loss: 0.1625 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2134/3000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.1597 - precision: 1.0000 - recall: 0.9233 - f1_score: 0.9594 - val_loss: 0.1626 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2135/3000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.1597 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9582 - val_loss: 0.1624 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2136/3000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.1596 - precision: 1.0000 - recall: 0.9233 - f1_score: 0.9596 - val_loss: 0.1625 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2137/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.1596 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9582 - val_loss: 0.1624 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2138/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1595 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9564 - val_loss: 0.1623 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2139/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.1595 - precision: 1.0000 - recall: 0.9233 - f1_score: 0.9599 - val_loss: 0.1623 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2140/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.1594 - precision: 1.0000 - recall: 0.9233 - f1_score: 0.9601 - val_loss: 0.1622 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2141/3000\n",
            "300/300 [==============================] - 0s 80us/step - loss: 0.1594 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9581 - val_loss: 0.1622 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2142/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1593 - precision: 1.0000 - recall: 0.9233 - f1_score: 0.9599 - val_loss: 0.1621 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2143/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.1594 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9580 - val_loss: 0.1621 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2144/3000\n",
            "300/300 [==============================] - 0s 124us/step - loss: 0.1593 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9574 - val_loss: 0.1620 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2145/3000\n",
            "300/300 [==============================] - 0s 112us/step - loss: 0.1592 - precision: 1.0000 - recall: 0.9233 - f1_score: 0.9600 - val_loss: 0.1620 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2146/3000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.1593 - precision: 1.0000 - recall: 0.9233 - f1_score: 0.9596 - val_loss: 0.1619 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2147/3000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.1591 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9581 - val_loss: 0.1619 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2148/3000\n",
            "300/300 [==============================] - 0s 80us/step - loss: 0.1591 - precision: 1.0000 - recall: 0.9233 - f1_score: 0.9596 - val_loss: 0.1619 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2149/3000\n",
            "300/300 [==============================] - 0s 79us/step - loss: 0.1591 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9581 - val_loss: 0.1619 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2150/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.1589 - precision: 1.0000 - recall: 0.9233 - f1_score: 0.9599 - val_loss: 0.1619 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2151/3000\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.1589 - precision: 1.0000 - recall: 0.9233 - f1_score: 0.9599 - val_loss: 0.1619 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2152/3000\n",
            "300/300 [==============================] - 0s 79us/step - loss: 0.1589 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9580 - val_loss: 0.1617 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2153/3000\n",
            "300/300 [==============================] - 0s 139us/step - loss: 0.1588 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.1617 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2154/3000\n",
            "300/300 [==============================] - 0s 139us/step - loss: 0.1588 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9578 - val_loss: 0.1617 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2155/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.1588 - precision: 1.0000 - recall: 0.9233 - f1_score: 0.9599 - val_loss: 0.1616 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2156/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1587 - precision: 1.0000 - recall: 0.9233 - f1_score: 0.9600 - val_loss: 0.1616 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2157/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1586 - precision: 1.0000 - recall: 0.9233 - f1_score: 0.9597 - val_loss: 0.1615 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2158/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.1585 - precision: 1.0000 - recall: 0.9233 - f1_score: 0.9596 - val_loss: 0.1614 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2159/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.1587 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9616 - val_loss: 0.1612 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2160/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1586 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.1611 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2161/3000\n",
            "300/300 [==============================] - 0s 79us/step - loss: 0.1585 - precision: 1.0000 - recall: 0.9233 - f1_score: 0.9600 - val_loss: 0.1610 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2162/3000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.1587 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9653 - val_loss: 0.1613 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2163/3000\n",
            "300/300 [==============================] - 0s 78us/step - loss: 0.1585 - precision: 1.0000 - recall: 0.9233 - f1_score: 0.9598 - val_loss: 0.1613 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2164/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1585 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9619 - val_loss: 0.1613 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2165/3000\n",
            "300/300 [==============================] - 0s 106us/step - loss: 0.1584 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.1613 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2166/3000\n",
            "300/300 [==============================] - 0s 133us/step - loss: 0.1582 - precision: 1.0000 - recall: 0.9233 - f1_score: 0.9600 - val_loss: 0.1611 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2167/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.1582 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9617 - val_loss: 0.1611 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2168/3000\n",
            "300/300 [==============================] - 0s 81us/step - loss: 0.1582 - precision: 1.0000 - recall: 0.9300 - f1_score: 0.9628 - val_loss: 0.1611 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2169/3000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.1581 - precision: 1.0000 - recall: 0.9233 - f1_score: 0.9599 - val_loss: 0.1611 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2170/3000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.1580 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9583 - val_loss: 0.1611 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2171/3000\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.1581 - precision: 1.0000 - recall: 0.9300 - f1_score: 0.9634 - val_loss: 0.1612 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2172/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.1581 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9582 - val_loss: 0.1611 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2173/3000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.1579 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9579 - val_loss: 0.1610 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2174/3000\n",
            "300/300 [==============================] - 0s 107us/step - loss: 0.1579 - precision: 1.0000 - recall: 0.9233 - f1_score: 0.9601 - val_loss: 0.1607 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2175/3000\n",
            "300/300 [==============================] - 0s 117us/step - loss: 0.1578 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9617 - val_loss: 0.1606 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2176/3000\n",
            "300/300 [==============================] - 0s 81us/step - loss: 0.1578 - precision: 1.0000 - recall: 0.9300 - f1_score: 0.9637 - val_loss: 0.1606 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2177/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.1577 - precision: 1.0000 - recall: 0.9300 - f1_score: 0.9634 - val_loss: 0.1606 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2178/3000\n",
            "300/300 [==============================] - 0s 81us/step - loss: 0.1577 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9576 - val_loss: 0.1604 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2179/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.1577 - precision: 1.0000 - recall: 0.9300 - f1_score: 0.9631 - val_loss: 0.1605 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2180/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.1576 - precision: 1.0000 - recall: 0.9300 - f1_score: 0.9635 - val_loss: 0.1605 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2181/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.1576 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9617 - val_loss: 0.1604 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2182/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.1576 - precision: 1.0000 - recall: 0.9233 - f1_score: 0.9600 - val_loss: 0.1602 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2183/3000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.1575 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9616 - val_loss: 0.1603 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2184/3000\n",
            "300/300 [==============================] - 0s 104us/step - loss: 0.1575 - precision: 1.0000 - recall: 0.9300 - f1_score: 0.9632 - val_loss: 0.1602 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2185/3000\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.1576 - precision: 1.0000 - recall: 0.9300 - f1_score: 0.9637 - val_loss: 0.1604 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2186/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.1574 - precision: 1.0000 - recall: 0.9233 - f1_score: 0.9587 - val_loss: 0.1603 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2187/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.1574 - precision: 1.0000 - recall: 0.9300 - f1_score: 0.9636 - val_loss: 0.1604 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2188/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1573 - precision: 1.0000 - recall: 0.9233 - f1_score: 0.9599 - val_loss: 0.1602 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2189/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.1573 - precision: 1.0000 - recall: 0.9233 - f1_score: 0.9599 - val_loss: 0.1600 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2190/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1572 - precision: 1.0000 - recall: 0.9300 - f1_score: 0.9634 - val_loss: 0.1599 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2191/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1571 - precision: 1.0000 - recall: 0.9300 - f1_score: 0.9633 - val_loss: 0.1600 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2192/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.1573 - precision: 1.0000 - recall: 0.9300 - f1_score: 0.9636 - val_loss: 0.1601 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2193/3000\n",
            "300/300 [==============================] - 0s 126us/step - loss: 0.1571 - precision: 1.0000 - recall: 0.9233 - f1_score: 0.9600 - val_loss: 0.1601 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2194/3000\n",
            "300/300 [==============================] - 0s 119us/step - loss: 0.1570 - precision: 1.0000 - recall: 0.9233 - f1_score: 0.9595 - val_loss: 0.1601 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2195/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.1569 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9616 - val_loss: 0.1601 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2196/3000\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.1570 - precision: 1.0000 - recall: 0.9300 - f1_score: 0.9636 - val_loss: 0.1602 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2197/3000\n",
            "300/300 [==============================] - 0s 81us/step - loss: 0.1569 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.1602 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2198/3000\n",
            "300/300 [==============================] - 0s 81us/step - loss: 0.1569 - precision: 1.0000 - recall: 0.9233 - f1_score: 0.9599 - val_loss: 0.1602 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2199/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.1568 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9580 - val_loss: 0.1600 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2200/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.1568 - precision: 1.0000 - recall: 0.9300 - f1_score: 0.9637 - val_loss: 0.1601 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2201/3000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.1567 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9581 - val_loss: 0.1600 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2202/3000\n",
            "300/300 [==============================] - 0s 115us/step - loss: 0.1567 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9617 - val_loss: 0.1599 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2203/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.1567 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.1599 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2204/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.1566 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9616 - val_loss: 0.1599 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2205/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.1566 - precision: 1.0000 - recall: 0.9167 - f1_score: 0.9563 - val_loss: 0.1596 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2206/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1564 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9617 - val_loss: 0.1594 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2207/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1565 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.1593 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2208/3000\n",
            "300/300 [==============================] - 0s 110us/step - loss: 0.1564 - precision: 1.0000 - recall: 0.9300 - f1_score: 0.9636 - val_loss: 0.1592 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2209/3000\n",
            "300/300 [==============================] - 0s 111us/step - loss: 0.1566 - precision: 1.0000 - recall: 0.9200 - f1_score: 0.9581 - val_loss: 0.1592 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2210/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.1564 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.1591 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2211/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.1564 - precision: 1.0000 - recall: 0.9300 - f1_score: 0.9637 - val_loss: 0.1591 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2212/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1565 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9619 - val_loss: 0.1590 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2213/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.1562 - precision: 1.0000 - recall: 0.9300 - f1_score: 0.9637 - val_loss: 0.1590 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2214/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.1562 - precision: 1.0000 - recall: 0.9300 - f1_score: 0.9636 - val_loss: 0.1589 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2215/3000\n",
            "300/300 [==============================] - 0s 105us/step - loss: 0.1562 - precision: 1.0000 - recall: 0.9300 - f1_score: 0.9635 - val_loss: 0.1588 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2216/3000\n",
            "300/300 [==============================] - 0s 103us/step - loss: 0.1560 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9651 - val_loss: 0.1588 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2217/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.1560 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9653 - val_loss: 0.1588 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2218/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.1560 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9654 - val_loss: 0.1586 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2219/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.1559 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9653 - val_loss: 0.1585 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2220/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.1560 - precision: 1.0000 - recall: 0.9300 - f1_score: 0.9636 - val_loss: 0.1585 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2221/3000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.1559 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9653 - val_loss: 0.1585 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2222/3000\n",
            "300/300 [==============================] - 0s 112us/step - loss: 0.1558 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9652 - val_loss: 0.1584 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2223/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.1558 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9652 - val_loss: 0.1586 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2224/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.1558 - precision: 1.0000 - recall: 0.9300 - f1_score: 0.9637 - val_loss: 0.1587 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2225/3000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.1556 - precision: 1.0000 - recall: 0.9300 - f1_score: 0.9635 - val_loss: 0.1586 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2226/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.1557 - precision: 1.0000 - recall: 0.9300 - f1_score: 0.9633 - val_loss: 0.1587 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2227/3000\n",
            "300/300 [==============================] - 0s 81us/step - loss: 0.1556 - precision: 1.0000 - recall: 0.9300 - f1_score: 0.9637 - val_loss: 0.1586 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2228/3000\n",
            "300/300 [==============================] - 0s 167us/step - loss: 0.1556 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9619 - val_loss: 0.1584 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2229/3000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.1555 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9649 - val_loss: 0.1585 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2230/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.1555 - precision: 1.0000 - recall: 0.9300 - f1_score: 0.9637 - val_loss: 0.1585 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2231/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.1555 - precision: 1.0000 - recall: 0.9233 - f1_score: 0.9594 - val_loss: 0.1582 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2232/3000\n",
            "300/300 [==============================] - 0s 79us/step - loss: 0.1554 - precision: 1.0000 - recall: 0.9300 - f1_score: 0.9635 - val_loss: 0.1583 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2233/3000\n",
            "300/300 [==============================] - 0s 117us/step - loss: 0.1553 - precision: 1.0000 - recall: 0.9300 - f1_score: 0.9634 - val_loss: 0.1582 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2234/3000\n",
            "300/300 [==============================] - 0s 115us/step - loss: 0.1553 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9652 - val_loss: 0.1582 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2235/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.1554 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9649 - val_loss: 0.1583 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2236/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.1552 - precision: 1.0000 - recall: 0.9300 - f1_score: 0.9635 - val_loss: 0.1583 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2237/3000\n",
            "300/300 [==============================] - 0s 81us/step - loss: 0.1552 - precision: 1.0000 - recall: 0.9300 - f1_score: 0.9633 - val_loss: 0.1580 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2238/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1551 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9652 - val_loss: 0.1579 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2239/3000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.1552 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9654 - val_loss: 0.1580 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2240/3000\n",
            "300/300 [==============================] - 0s 135us/step - loss: 0.1550 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9653 - val_loss: 0.1580 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2241/3000\n",
            "300/300 [==============================] - 0s 116us/step - loss: 0.1550 - precision: 1.0000 - recall: 0.9300 - f1_score: 0.9636 - val_loss: 0.1580 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2242/3000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.1549 - precision: 1.0000 - recall: 0.9300 - f1_score: 0.9636 - val_loss: 0.1580 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2243/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.1550 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9618 - val_loss: 0.1579 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2244/3000\n",
            "300/300 [==============================] - 0s 79us/step - loss: 0.1549 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9654 - val_loss: 0.1579 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2245/3000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.1549 - precision: 1.0000 - recall: 0.9300 - f1_score: 0.9637 - val_loss: 0.1580 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2246/3000\n",
            "300/300 [==============================] - 0s 105us/step - loss: 0.1548 - precision: 1.0000 - recall: 0.9300 - f1_score: 0.9632 - val_loss: 0.1578 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2247/3000\n",
            "300/300 [==============================] - 0s 118us/step - loss: 0.1549 - precision: 1.0000 - recall: 0.9300 - f1_score: 0.9636 - val_loss: 0.1578 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2248/3000\n",
            "300/300 [==============================] - 0s 79us/step - loss: 0.1548 - precision: 1.0000 - recall: 0.9300 - f1_score: 0.9635 - val_loss: 0.1577 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2249/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.1547 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9653 - val_loss: 0.1576 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2250/3000\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.1546 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9651 - val_loss: 0.1575 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2251/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1547 - precision: 1.0000 - recall: 0.9300 - f1_score: 0.9633 - val_loss: 0.1575 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2252/3000\n",
            "300/300 [==============================] - 0s 118us/step - loss: 0.1545 - precision: 1.0000 - recall: 0.9300 - f1_score: 0.9636 - val_loss: 0.1573 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2253/3000\n",
            "300/300 [==============================] - 0s 106us/step - loss: 0.1545 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9653 - val_loss: 0.1572 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2254/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.1545 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9650 - val_loss: 0.1573 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2255/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1544 - precision: 1.0000 - recall: 0.9300 - f1_score: 0.9633 - val_loss: 0.1572 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2256/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.1544 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9655 - val_loss: 0.1572 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2257/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1543 - precision: 1.0000 - recall: 0.9300 - f1_score: 0.9637 - val_loss: 0.1573 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2258/3000\n",
            "300/300 [==============================] - 0s 102us/step - loss: 0.1542 - precision: 1.0000 - recall: 0.9300 - f1_score: 0.9635 - val_loss: 0.1572 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2259/3000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.1543 - precision: 1.0000 - recall: 0.9300 - f1_score: 0.9636 - val_loss: 0.1572 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2260/3000\n",
            "300/300 [==============================] - 0s 78us/step - loss: 0.1542 - precision: 1.0000 - recall: 0.9300 - f1_score: 0.9635 - val_loss: 0.1573 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2261/3000\n",
            "300/300 [==============================] - 0s 82us/step - loss: 0.1542 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9619 - val_loss: 0.1571 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2262/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.1541 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9654 - val_loss: 0.1572 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2263/3000\n",
            "300/300 [==============================] - 0s 82us/step - loss: 0.1541 - precision: 1.0000 - recall: 0.9267 - f1_score: 0.9617 - val_loss: 0.1570 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2264/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.1541 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9650 - val_loss: 0.1568 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2265/3000\n",
            "300/300 [==============================] - 0s 150us/step - loss: 0.1540 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9654 - val_loss: 0.1567 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2266/3000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.1540 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9652 - val_loss: 0.1567 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2267/3000\n",
            "300/300 [==============================] - 0s 80us/step - loss: 0.1539 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9652 - val_loss: 0.1567 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2268/3000\n",
            "300/300 [==============================] - 0s 79us/step - loss: 0.1538 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9654 - val_loss: 0.1566 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2269/3000\n",
            "300/300 [==============================] - 0s 81us/step - loss: 0.1538 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9650 - val_loss: 0.1565 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2270/3000\n",
            "300/300 [==============================] - 0s 134us/step - loss: 0.1537 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9652 - val_loss: 0.1564 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2271/3000\n",
            "300/300 [==============================] - 0s 110us/step - loss: 0.1539 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9654 - val_loss: 0.1562 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2272/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.1537 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9654 - val_loss: 0.1563 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2273/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.1537 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9649 - val_loss: 0.1562 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2274/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.1536 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9654 - val_loss: 0.1561 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2275/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.1536 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9654 - val_loss: 0.1561 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2276/3000\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.1535 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9650 - val_loss: 0.1563 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2277/3000\n",
            "300/300 [==============================] - 0s 119us/step - loss: 0.1536 - precision: 1.0000 - recall: 0.9367 - f1_score: 0.9669 - val_loss: 0.1564 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2278/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.1534 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9652 - val_loss: 0.1564 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2279/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.1535 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9652 - val_loss: 0.1564 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2280/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.1533 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9654 - val_loss: 0.1563 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2281/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.1535 - precision: 1.0000 - recall: 0.9300 - f1_score: 0.9633 - val_loss: 0.1561 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2282/3000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.1533 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9650 - val_loss: 0.1561 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2283/3000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.1532 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9653 - val_loss: 0.1561 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2284/3000\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.1532 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9651 - val_loss: 0.1560 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2285/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.1532 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9653 - val_loss: 0.1559 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2286/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.1531 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9654 - val_loss: 0.1560 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2287/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.1530 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9654 - val_loss: 0.1559 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2288/3000\n",
            "300/300 [==============================] - 0s 104us/step - loss: 0.1531 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9654 - val_loss: 0.1559 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2289/3000\n",
            "300/300 [==============================] - 0s 118us/step - loss: 0.1529 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9655 - val_loss: 0.1558 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2290/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.1529 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9655 - val_loss: 0.1557 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2291/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.1529 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9654 - val_loss: 0.1556 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2292/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.1528 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9653 - val_loss: 0.1556 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2293/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.1528 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9654 - val_loss: 0.1556 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2294/3000\n",
            "300/300 [==============================] - 0s 81us/step - loss: 0.1527 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9652 - val_loss: 0.1556 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2295/3000\n",
            "300/300 [==============================] - 0s 261us/step - loss: 0.1527 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9654 - val_loss: 0.1555 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2296/3000\n",
            "300/300 [==============================] - 0s 114us/step - loss: 0.1528 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9653 - val_loss: 0.1556 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2297/3000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.1527 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9655 - val_loss: 0.1557 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2298/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.1526 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9653 - val_loss: 0.1556 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2299/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1526 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9654 - val_loss: 0.1554 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2300/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.1525 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9655 - val_loss: 0.1554 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2301/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.1524 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9655 - val_loss: 0.1553 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2302/3000\n",
            "300/300 [==============================] - 0s 115us/step - loss: 0.1524 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9653 - val_loss: 0.1553 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2303/3000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.1524 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9653 - val_loss: 0.1552 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2304/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.1524 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9652 - val_loss: 0.1551 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2305/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1525 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9653 - val_loss: 0.1550 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2306/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.1523 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9655 - val_loss: 0.1550 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2307/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.1523 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9652 - val_loss: 0.1549 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2308/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.1523 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9652 - val_loss: 0.1549 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2309/3000\n",
            "300/300 [==============================] - 0s 116us/step - loss: 0.1521 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9653 - val_loss: 0.1549 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2310/3000\n",
            "300/300 [==============================] - 0s 131us/step - loss: 0.1521 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9652 - val_loss: 0.1548 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2311/3000\n",
            "300/300 [==============================] - 0s 81us/step - loss: 0.1521 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9653 - val_loss: 0.1547 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2312/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.1521 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9654 - val_loss: 0.1545 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2313/3000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.1520 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9687 - val_loss: 0.1546 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2314/3000\n",
            "300/300 [==============================] - 0s 101us/step - loss: 0.1521 - precision: 1.0000 - recall: 0.9367 - f1_score: 0.9671 - val_loss: 0.1547 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2315/3000\n",
            "300/300 [==============================] - 0s 116us/step - loss: 0.1519 - precision: 1.0000 - recall: 0.9367 - f1_score: 0.9672 - val_loss: 0.1548 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2316/3000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.1519 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9654 - val_loss: 0.1548 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2317/3000\n",
            "300/300 [==============================] - 0s 81us/step - loss: 0.1518 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9655 - val_loss: 0.1547 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2318/3000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.1518 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9654 - val_loss: 0.1547 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2319/3000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.1517 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9652 - val_loss: 0.1546 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2320/3000\n",
            "300/300 [==============================] - 0s 129us/step - loss: 0.1519 - precision: 1.0000 - recall: 0.9300 - f1_score: 0.9636 - val_loss: 0.1543 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2321/3000\n",
            "300/300 [==============================] - 0s 128us/step - loss: 0.1519 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9688 - val_loss: 0.1542 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2322/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.1517 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9652 - val_loss: 0.1544 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2323/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.1515 - precision: 1.0000 - recall: 0.9367 - f1_score: 0.9672 - val_loss: 0.1544 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2324/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.1516 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9654 - val_loss: 0.1543 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2325/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1515 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9647 - val_loss: 0.1543 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2326/3000\n",
            "300/300 [==============================] - 0s 121us/step - loss: 0.1515 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9654 - val_loss: 0.1544 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2327/3000\n",
            "300/300 [==============================] - 0s 106us/step - loss: 0.1514 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9653 - val_loss: 0.1544 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2328/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.1514 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9651 - val_loss: 0.1545 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2329/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.1513 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9651 - val_loss: 0.1545 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2330/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.1513 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9655 - val_loss: 0.1543 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2331/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1514 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9654 - val_loss: 0.1542 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2332/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.1512 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9654 - val_loss: 0.1542 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2333/3000\n",
            "300/300 [==============================] - 0s 105us/step - loss: 0.1512 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9654 - val_loss: 0.1542 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2334/3000\n",
            "300/300 [==============================] - 0s 108us/step - loss: 0.1512 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9654 - val_loss: 0.1541 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2335/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1512 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9654 - val_loss: 0.1539 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2336/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.1511 - precision: 1.0000 - recall: 0.9367 - f1_score: 0.9671 - val_loss: 0.1539 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2337/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.1510 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9654 - val_loss: 0.1538 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2338/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.1511 - precision: 1.0000 - recall: 0.9367 - f1_score: 0.9666 - val_loss: 0.1539 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2339/3000\n",
            "300/300 [==============================] - 0s 109us/step - loss: 0.1510 - precision: 1.0000 - recall: 0.9367 - f1_score: 0.9672 - val_loss: 0.1538 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2340/3000\n",
            "300/300 [==============================] - 0s 119us/step - loss: 0.1509 - precision: 1.0000 - recall: 0.9367 - f1_score: 0.9669 - val_loss: 0.1539 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2341/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1509 - precision: 1.0000 - recall: 0.9367 - f1_score: 0.9670 - val_loss: 0.1541 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2342/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1508 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9653 - val_loss: 0.1541 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2343/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.1507 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9653 - val_loss: 0.1539 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2344/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.1507 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9654 - val_loss: 0.1537 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2345/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.1507 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9655 - val_loss: 0.1538 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2346/3000\n",
            "300/300 [==============================] - 0s 120us/step - loss: 0.1506 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9654 - val_loss: 0.1538 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2347/3000\n",
            "300/300 [==============================] - 0s 107us/step - loss: 0.1506 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9649 - val_loss: 0.1538 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2348/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1507 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9651 - val_loss: 0.1536 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2349/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.1505 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9654 - val_loss: 0.1535 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2350/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.1505 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9654 - val_loss: 0.1535 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2351/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.1504 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9650 - val_loss: 0.1533 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2352/3000\n",
            "300/300 [==============================] - 0s 131us/step - loss: 0.1505 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9688 - val_loss: 0.1533 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2353/3000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.1505 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9652 - val_loss: 0.1531 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2354/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1503 - precision: 1.0000 - recall: 0.9367 - f1_score: 0.9672 - val_loss: 0.1530 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2355/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.1504 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9689 - val_loss: 0.1532 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2356/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1503 - precision: 1.0000 - recall: 0.9367 - f1_score: 0.9672 - val_loss: 0.1533 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2357/3000\n",
            "300/300 [==============================] - 0s 111us/step - loss: 0.1503 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9652 - val_loss: 0.1532 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2358/3000\n",
            "300/300 [==============================] - 0s 115us/step - loss: 0.1502 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9654 - val_loss: 0.1531 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2359/3000\n",
            "300/300 [==============================] - 0s 119us/step - loss: 0.1502 - precision: 1.0000 - recall: 0.9367 - f1_score: 0.9667 - val_loss: 0.1533 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2360/3000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.1502 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9654 - val_loss: 0.1533 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2361/3000\n",
            "300/300 [==============================] - 0s 147us/step - loss: 0.1501 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9651 - val_loss: 0.1532 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2362/3000\n",
            "300/300 [==============================] - 0s 78us/step - loss: 0.1500 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9651 - val_loss: 0.1532 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2363/3000\n",
            "300/300 [==============================] - 0s 79us/step - loss: 0.1502 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9654 - val_loss: 0.1531 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2364/3000\n",
            "300/300 [==============================] - 0s 134us/step - loss: 0.1500 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9654 - val_loss: 0.1528 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2365/3000\n",
            "300/300 [==============================] - 0s 103us/step - loss: 0.1499 - precision: 1.0000 - recall: 0.9367 - f1_score: 0.9670 - val_loss: 0.1527 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2366/3000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.1499 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9690 - val_loss: 0.1527 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2367/3000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.1498 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9687 - val_loss: 0.1528 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2368/3000\n",
            "300/300 [==============================] - 0s 109us/step - loss: 0.1499 - precision: 1.0000 - recall: 0.9367 - f1_score: 0.9671 - val_loss: 0.1527 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2369/3000\n",
            "300/300 [==============================] - 0s 127us/step - loss: 0.1498 - precision: 1.0000 - recall: 0.9367 - f1_score: 0.9670 - val_loss: 0.1527 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2370/3000\n",
            "300/300 [==============================] - 0s 177us/step - loss: 0.1497 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9687 - val_loss: 0.1528 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2371/3000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.1497 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9654 - val_loss: 0.1526 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2372/3000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.1496 - precision: 1.0000 - recall: 0.9367 - f1_score: 0.9672 - val_loss: 0.1527 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2373/3000\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.1497 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9655 - val_loss: 0.1525 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2374/3000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.1496 - precision: 1.0000 - recall: 0.9367 - f1_score: 0.9670 - val_loss: 0.1525 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2375/3000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.1495 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9690 - val_loss: 0.1524 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2376/3000\n",
            "300/300 [==============================] - 0s 134us/step - loss: 0.1494 - precision: 1.0000 - recall: 0.9367 - f1_score: 0.9672 - val_loss: 0.1525 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2377/3000\n",
            "300/300 [==============================] - 0s 108us/step - loss: 0.1494 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9654 - val_loss: 0.1523 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2378/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.1494 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9688 - val_loss: 0.1523 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2379/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.1493 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9654 - val_loss: 0.1523 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2380/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.1494 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9652 - val_loss: 0.1521 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2381/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1493 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9689 - val_loss: 0.1523 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2382/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1492 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9654 - val_loss: 0.1522 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2383/3000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.1492 - precision: 1.0000 - recall: 0.9367 - f1_score: 0.9673 - val_loss: 0.1522 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2384/3000\n",
            "300/300 [==============================] - 0s 120us/step - loss: 0.1492 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9689 - val_loss: 0.1521 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2385/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.1491 - precision: 1.0000 - recall: 0.9367 - f1_score: 0.9670 - val_loss: 0.1521 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2386/3000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.1491 - precision: 1.0000 - recall: 0.9367 - f1_score: 0.9669 - val_loss: 0.1520 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2387/3000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.1490 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9690 - val_loss: 0.1520 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2388/3000\n",
            "300/300 [==============================] - 0s 117us/step - loss: 0.1490 - precision: 1.0000 - recall: 0.9367 - f1_score: 0.9670 - val_loss: 0.1521 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2389/3000\n",
            "300/300 [==============================] - 0s 118us/step - loss: 0.1490 - precision: 1.0000 - recall: 0.9367 - f1_score: 0.9673 - val_loss: 0.1521 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2390/3000\n",
            "300/300 [==============================] - 0s 141us/step - loss: 0.1490 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9654 - val_loss: 0.1518 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2391/3000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.1490 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9687 - val_loss: 0.1517 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2392/3000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.1488 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9688 - val_loss: 0.1516 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2393/3000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.1488 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9687 - val_loss: 0.1517 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2394/3000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.1488 - precision: 1.0000 - recall: 0.9367 - f1_score: 0.9671 - val_loss: 0.1516 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2395/3000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.1487 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9690 - val_loss: 0.1516 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2396/3000\n",
            "300/300 [==============================] - 0s 171us/step - loss: 0.1487 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9690 - val_loss: 0.1517 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2397/3000\n",
            "300/300 [==============================] - 0s 118us/step - loss: 0.1488 - precision: 1.0000 - recall: 0.9367 - f1_score: 0.9670 - val_loss: 0.1516 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2398/3000\n",
            "300/300 [==============================] - 0s 79us/step - loss: 0.1486 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9690 - val_loss: 0.1516 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2399/3000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.1486 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9654 - val_loss: 0.1515 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2400/3000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.1485 - precision: 1.0000 - recall: 0.9367 - f1_score: 0.9672 - val_loss: 0.1514 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2401/3000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.1485 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9690 - val_loss: 0.1515 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2402/3000\n",
            "300/300 [==============================] - 0s 148us/step - loss: 0.1485 - precision: 1.0000 - recall: 0.9367 - f1_score: 0.9672 - val_loss: 0.1516 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2403/3000\n",
            "300/300 [==============================] - 0s 113us/step - loss: 0.1485 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9687 - val_loss: 0.1515 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2404/3000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.1485 - precision: 1.0000 - recall: 0.9367 - f1_score: 0.9668 - val_loss: 0.1515 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2405/3000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.1484 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9690 - val_loss: 0.1513 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2406/3000\n",
            "300/300 [==============================] - 0s 80us/step - loss: 0.1483 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9689 - val_loss: 0.1513 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2407/3000\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.1482 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9688 - val_loss: 0.1512 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2408/3000\n",
            "300/300 [==============================] - 0s 135us/step - loss: 0.1482 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9690 - val_loss: 0.1513 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2409/3000\n",
            "300/300 [==============================] - 0s 125us/step - loss: 0.1482 - precision: 1.0000 - recall: 0.9367 - f1_score: 0.9672 - val_loss: 0.1511 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2410/3000\n",
            "300/300 [==============================] - 0s 82us/step - loss: 0.1481 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9688 - val_loss: 0.1512 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2411/3000\n",
            "300/300 [==============================] - 0s 78us/step - loss: 0.1481 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9689 - val_loss: 0.1512 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2412/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.1482 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9655 - val_loss: 0.1512 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2413/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.1481 - precision: 1.0000 - recall: 0.9367 - f1_score: 0.9671 - val_loss: 0.1514 - val_precision: 1.0000 - val_recall: 0.9167 - val_f1_score: 0.9565\n",
            "Epoch 2414/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.1480 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9654 - val_loss: 0.1512 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2415/3000\n",
            "300/300 [==============================] - 0s 137us/step - loss: 0.1479 - precision: 1.0000 - recall: 0.9367 - f1_score: 0.9672 - val_loss: 0.1511 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2416/3000\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.1479 - precision: 1.0000 - recall: 0.9367 - f1_score: 0.9670 - val_loss: 0.1510 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2417/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.1479 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9690 - val_loss: 0.1508 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2418/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.1480 - precision: 1.0000 - recall: 0.9367 - f1_score: 0.9671 - val_loss: 0.1508 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2419/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.1478 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9689 - val_loss: 0.1508 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2420/3000\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.1478 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9690 - val_loss: 0.1510 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2421/3000\n",
            "300/300 [==============================] - 0s 134us/step - loss: 0.1477 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9688 - val_loss: 0.1510 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2422/3000\n",
            "300/300 [==============================] - 0s 132us/step - loss: 0.1477 - precision: 1.0000 - recall: 0.9367 - f1_score: 0.9671 - val_loss: 0.1508 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2423/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.1479 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9655 - val_loss: 0.1507 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2424/3000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.1476 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9688 - val_loss: 0.1507 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2425/3000\n",
            "300/300 [==============================] - 0s 79us/step - loss: 0.1477 - precision: 1.0000 - recall: 0.9367 - f1_score: 0.9667 - val_loss: 0.1507 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2426/3000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.1475 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9689 - val_loss: 0.1507 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2427/3000\n",
            "300/300 [==============================] - 0s 132us/step - loss: 0.1475 - precision: 1.0000 - recall: 0.9367 - f1_score: 0.9672 - val_loss: 0.1506 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2428/3000\n",
            "300/300 [==============================] - 0s 112us/step - loss: 0.1475 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9686 - val_loss: 0.1507 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2429/3000\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.1474 - precision: 1.0000 - recall: 0.9367 - f1_score: 0.9670 - val_loss: 0.1506 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2430/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.1473 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9654 - val_loss: 0.1505 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2431/3000\n",
            "300/300 [==============================] - 0s 105us/step - loss: 0.1474 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9688 - val_loss: 0.1504 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2432/3000\n",
            "300/300 [==============================] - 0s 81us/step - loss: 0.1473 - precision: 1.0000 - recall: 0.9367 - f1_score: 0.9669 - val_loss: 0.1504 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2433/3000\n",
            "300/300 [==============================] - 0s 104us/step - loss: 0.1473 - precision: 1.0000 - recall: 0.9367 - f1_score: 0.9672 - val_loss: 0.1503 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2434/3000\n",
            "300/300 [==============================] - 0s 121us/step - loss: 0.1472 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9686 - val_loss: 0.1503 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2435/3000\n",
            "300/300 [==============================] - 0s 78us/step - loss: 0.1473 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9689 - val_loss: 0.1502 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2436/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1471 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9689 - val_loss: 0.1502 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2437/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1472 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9688 - val_loss: 0.1503 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2438/3000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.1471 - precision: 1.0000 - recall: 0.9367 - f1_score: 0.9667 - val_loss: 0.1503 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2439/3000\n",
            "300/300 [==============================] - 0s 121us/step - loss: 0.1470 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9655 - val_loss: 0.1501 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2440/3000\n",
            "300/300 [==============================] - 0s 106us/step - loss: 0.1470 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9686 - val_loss: 0.1500 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2441/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.1470 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9691 - val_loss: 0.1499 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2442/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.1469 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9687 - val_loss: 0.1499 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2443/3000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.1469 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9688 - val_loss: 0.1498 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2444/3000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.1469 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9690 - val_loss: 0.1497 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2445/3000\n",
            "300/300 [==============================] - 0s 144us/step - loss: 0.1468 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9687 - val_loss: 0.1496 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2446/3000\n",
            "300/300 [==============================] - 0s 112us/step - loss: 0.1468 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9687 - val_loss: 0.1497 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2447/3000\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.1467 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9689 - val_loss: 0.1497 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2448/3000\n",
            "300/300 [==============================] - 0s 80us/step - loss: 0.1467 - precision: 1.0000 - recall: 0.9367 - f1_score: 0.9671 - val_loss: 0.1496 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2449/3000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.1467 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9688 - val_loss: 0.1496 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2450/3000\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.1466 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9690 - val_loss: 0.1495 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2451/3000\n",
            "300/300 [==============================] - 0s 135us/step - loss: 0.1467 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9691 - val_loss: 0.1496 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2452/3000\n",
            "300/300 [==============================] - 0s 102us/step - loss: 0.1466 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9688 - val_loss: 0.1497 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2453/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.1466 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9689 - val_loss: 0.1497 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2454/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.1466 - precision: 1.0000 - recall: 0.9367 - f1_score: 0.9670 - val_loss: 0.1495 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2455/3000\n",
            "300/300 [==============================] - 0s 78us/step - loss: 0.1465 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9689 - val_loss: 0.1496 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2456/3000\n",
            "300/300 [==============================] - 0s 81us/step - loss: 0.1465 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9687 - val_loss: 0.1497 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2457/3000\n",
            "300/300 [==============================] - 0s 214us/step - loss: 0.1464 - precision: 1.0000 - recall: 0.9333 - f1_score: 0.9650 - val_loss: 0.1494 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2458/3000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.1464 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9689 - val_loss: 0.1493 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2459/3000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.1463 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9687 - val_loss: 0.1493 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2460/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.1462 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9689 - val_loss: 0.1492 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2461/3000\n",
            "300/300 [==============================] - 0s 82us/step - loss: 0.1463 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9687 - val_loss: 0.1491 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2462/3000\n",
            "300/300 [==============================] - 0s 120us/step - loss: 0.1462 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9688 - val_loss: 0.1491 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2463/3000\n",
            "300/300 [==============================] - 0s 112us/step - loss: 0.1462 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9689 - val_loss: 0.1491 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2464/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.1461 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9687 - val_loss: 0.1491 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2465/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.1461 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9690 - val_loss: 0.1489 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2466/3000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.1460 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9691 - val_loss: 0.1489 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2467/3000\n",
            "300/300 [==============================] - 0s 113us/step - loss: 0.1460 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9687 - val_loss: 0.1490 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2468/3000\n",
            "300/300 [==============================] - 0s 116us/step - loss: 0.1460 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9690 - val_loss: 0.1490 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2469/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.1459 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9690 - val_loss: 0.1490 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2470/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1459 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9690 - val_loss: 0.1489 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2471/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.1458 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9688 - val_loss: 0.1488 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2472/3000\n",
            "300/300 [==============================] - 0s 78us/step - loss: 0.1458 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9687 - val_loss: 0.1487 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2473/3000\n",
            "300/300 [==============================] - 0s 105us/step - loss: 0.1458 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9686 - val_loss: 0.1487 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2474/3000\n",
            "300/300 [==============================] - 0s 136us/step - loss: 0.1457 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9689 - val_loss: 0.1487 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2475/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.1459 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9689 - val_loss: 0.1486 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2476/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.1456 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9690 - val_loss: 0.1486 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2477/3000\n",
            "300/300 [==============================] - 0s 78us/step - loss: 0.1457 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9690 - val_loss: 0.1485 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2478/3000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.1456 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9688 - val_loss: 0.1486 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2479/3000\n",
            "300/300 [==============================] - 0s 174us/step - loss: 0.1456 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9685 - val_loss: 0.1484 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2480/3000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.1456 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1486 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2481/3000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.1455 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9688 - val_loss: 0.1487 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2482/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1454 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9687 - val_loss: 0.1486 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2483/3000\n",
            "300/300 [==============================] - 0s 82us/step - loss: 0.1454 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9690 - val_loss: 0.1485 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2484/3000\n",
            "300/300 [==============================] - 0s 113us/step - loss: 0.1454 - precision: 1.0000 - recall: 0.9367 - f1_score: 0.9671 - val_loss: 0.1483 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2485/3000\n",
            "300/300 [==============================] - 0s 126us/step - loss: 0.1455 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9688 - val_loss: 0.1484 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2486/3000\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.1453 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9690 - val_loss: 0.1484 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2487/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1452 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9689 - val_loss: 0.1484 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2488/3000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.1452 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9688 - val_loss: 0.1484 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2489/3000\n",
            "300/300 [==============================] - 0s 164us/step - loss: 0.1452 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9689 - val_loss: 0.1484 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2490/3000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.1452 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9687 - val_loss: 0.1483 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2491/3000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.1452 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9690 - val_loss: 0.1484 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2492/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.1451 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9687 - val_loss: 0.1483 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2493/3000\n",
            "300/300 [==============================] - 0s 80us/step - loss: 0.1450 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9690 - val_loss: 0.1483 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2494/3000\n",
            "300/300 [==============================] - 0s 141us/step - loss: 0.1450 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9690 - val_loss: 0.1484 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2495/3000\n",
            "300/300 [==============================] - 0s 107us/step - loss: 0.1449 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9688 - val_loss: 0.1482 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2496/3000\n",
            "300/300 [==============================] - 0s 82us/step - loss: 0.1449 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9690 - val_loss: 0.1481 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2497/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1449 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9690 - val_loss: 0.1479 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2498/3000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.1449 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9688 - val_loss: 0.1480 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2499/3000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.1449 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9690 - val_loss: 0.1479 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2500/3000\n",
            "300/300 [==============================] - 0s 190us/step - loss: 0.1448 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9689 - val_loss: 0.1478 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2501/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.1448 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9690 - val_loss: 0.1477 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2502/3000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.1449 - precision: 1.0000 - recall: 0.9367 - f1_score: 0.9670 - val_loss: 0.1476 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2503/3000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.1447 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9690 - val_loss: 0.1476 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2504/3000\n",
            "300/300 [==============================] - 0s 143us/step - loss: 0.1446 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9689 - val_loss: 0.1476 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2505/3000\n",
            "300/300 [==============================] - 0s 122us/step - loss: 0.1446 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9690 - val_loss: 0.1476 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2506/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.1446 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9688 - val_loss: 0.1476 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2507/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1446 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9689 - val_loss: 0.1477 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2508/3000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.1445 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9689 - val_loss: 0.1477 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2509/3000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.1445 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9689 - val_loss: 0.1474 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2510/3000\n",
            "300/300 [==============================] - 0s 112us/step - loss: 0.1444 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9690 - val_loss: 0.1473 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2511/3000\n",
            "300/300 [==============================] - 0s 113us/step - loss: 0.1444 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9689 - val_loss: 0.1472 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2512/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1443 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9685 - val_loss: 0.1471 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2513/3000\n",
            "300/300 [==============================] - 0s 79us/step - loss: 0.1445 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9687 - val_loss: 0.1471 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2514/3000\n",
            "300/300 [==============================] - 0s 78us/step - loss: 0.1444 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9689 - val_loss: 0.1472 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2515/3000\n",
            "300/300 [==============================] - 0s 104us/step - loss: 0.1444 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9690 - val_loss: 0.1471 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2516/3000\n",
            "300/300 [==============================] - 0s 132us/step - loss: 0.1443 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9689 - val_loss: 0.1469 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2517/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1441 - precision: 1.0000 - recall: 0.9433 - f1_score: 0.9708 - val_loss: 0.1469 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2518/3000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.1442 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9689 - val_loss: 0.1469 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2519/3000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.1441 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9689 - val_loss: 0.1469 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2520/3000\n",
            "300/300 [==============================] - 0s 106us/step - loss: 0.1441 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9726 - val_loss: 0.1470 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2521/3000\n",
            "300/300 [==============================] - 0s 115us/step - loss: 0.1440 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9690 - val_loss: 0.1472 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2522/3000\n",
            "300/300 [==============================] - 0s 79us/step - loss: 0.1440 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9689 - val_loss: 0.1471 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2523/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.1439 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9687 - val_loss: 0.1471 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2524/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.1439 - precision: 1.0000 - recall: 0.9433 - f1_score: 0.9707 - val_loss: 0.1471 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2525/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1439 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9689 - val_loss: 0.1469 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2526/3000\n",
            "300/300 [==============================] - 0s 197us/step - loss: 0.1438 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9689 - val_loss: 0.1469 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2527/3000\n",
            "300/300 [==============================] - 0s 121us/step - loss: 0.1439 - precision: 1.0000 - recall: 0.9433 - f1_score: 0.9708 - val_loss: 0.1469 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2528/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.1438 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9689 - val_loss: 0.1467 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2529/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.1438 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9689 - val_loss: 0.1466 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2530/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.1438 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1465 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2531/3000\n",
            "300/300 [==============================] - 0s 115us/step - loss: 0.1436 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9690 - val_loss: 0.1465 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2532/3000\n",
            "300/300 [==============================] - 0s 109us/step - loss: 0.1436 - precision: 1.0000 - recall: 0.9433 - f1_score: 0.9706 - val_loss: 0.1465 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2533/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.1436 - precision: 1.0000 - recall: 0.9433 - f1_score: 0.9707 - val_loss: 0.1465 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2534/3000\n",
            "300/300 [==============================] - 0s 81us/step - loss: 0.1436 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9689 - val_loss: 0.1464 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2535/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.1436 - precision: 1.0000 - recall: 0.9433 - f1_score: 0.9707 - val_loss: 0.1464 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2536/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.1435 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9686 - val_loss: 0.1463 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2537/3000\n",
            "300/300 [==============================] - 0s 108us/step - loss: 0.1434 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1463 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2538/3000\n",
            "300/300 [==============================] - 0s 107us/step - loss: 0.1434 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1463 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2539/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.1434 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9691 - val_loss: 0.1462 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2540/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.1433 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9689 - val_loss: 0.1462 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2541/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.1433 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1461 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2542/3000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.1433 - precision: 1.0000 - recall: 0.9433 - f1_score: 0.9707 - val_loss: 0.1461 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2543/3000\n",
            "300/300 [==============================] - 0s 191us/step - loss: 0.1433 - precision: 1.0000 - recall: 0.9433 - f1_score: 0.9704 - val_loss: 0.1462 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2544/3000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.1432 - precision: 1.0000 - recall: 0.9433 - f1_score: 0.9707 - val_loss: 0.1463 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2545/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.1431 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9690 - val_loss: 0.1462 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2546/3000\n",
            "300/300 [==============================] - 0s 82us/step - loss: 0.1432 - precision: 1.0000 - recall: 0.9433 - f1_score: 0.9708 - val_loss: 0.1461 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2547/3000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.1432 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9689 - val_loss: 0.1461 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2548/3000\n",
            "300/300 [==============================] - 0s 108us/step - loss: 0.1430 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9689 - val_loss: 0.1461 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2549/3000\n",
            "300/300 [==============================] - 0s 148us/step - loss: 0.1430 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9690 - val_loss: 0.1461 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2550/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.1430 - precision: 1.0000 - recall: 0.9433 - f1_score: 0.9706 - val_loss: 0.1461 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2551/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.1430 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9687 - val_loss: 0.1460 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2552/3000\n",
            "300/300 [==============================] - 0s 109us/step - loss: 0.1431 - precision: 1.0000 - recall: 0.9433 - f1_score: 0.9707 - val_loss: 0.1459 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2553/3000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.1429 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9688 - val_loss: 0.1458 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2554/3000\n",
            "300/300 [==============================] - 0s 258us/step - loss: 0.1428 - precision: 1.0000 - recall: 0.9433 - f1_score: 0.9707 - val_loss: 0.1458 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2555/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.1428 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9685 - val_loss: 0.1459 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2556/3000\n",
            "300/300 [==============================] - 0s 79us/step - loss: 0.1428 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9722 - val_loss: 0.1459 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2557/3000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.1428 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9687 - val_loss: 0.1459 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2558/3000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.1427 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9689 - val_loss: 0.1457 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2559/3000\n",
            "300/300 [==============================] - 0s 218us/step - loss: 0.1427 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9688 - val_loss: 0.1457 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2560/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.1426 - precision: 1.0000 - recall: 0.9433 - f1_score: 0.9705 - val_loss: 0.1457 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2561/3000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.1426 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9688 - val_loss: 0.1457 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2562/3000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.1425 - precision: 1.0000 - recall: 0.9433 - f1_score: 0.9707 - val_loss: 0.1457 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2563/3000\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.1425 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9690 - val_loss: 0.1456 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2564/3000\n",
            "300/300 [==============================] - 0s 231us/step - loss: 0.1426 - precision: 1.0000 - recall: 0.9433 - f1_score: 0.9707 - val_loss: 0.1457 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2565/3000\n",
            "300/300 [==============================] - 0s 153us/step - loss: 0.1424 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9688 - val_loss: 0.1456 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2566/3000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.1424 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9685 - val_loss: 0.1455 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2567/3000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.1424 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9690 - val_loss: 0.1455 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2568/3000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.1424 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9723 - val_loss: 0.1456 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2569/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.1424 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9690 - val_loss: 0.1457 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2570/3000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.1423 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9690 - val_loss: 0.1456 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2571/3000\n",
            "300/300 [==============================] - 0s 165us/step - loss: 0.1422 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9690 - val_loss: 0.1455 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2572/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.1422 - precision: 1.0000 - recall: 0.9433 - f1_score: 0.9708 - val_loss: 0.1455 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2573/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.1423 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9690 - val_loss: 0.1453 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2574/3000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.1421 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9688 - val_loss: 0.1452 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2575/3000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.1421 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9690 - val_loss: 0.1452 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2576/3000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.1420 - precision: 1.0000 - recall: 0.9433 - f1_score: 0.9708 - val_loss: 0.1452 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2577/3000\n",
            "300/300 [==============================] - 0s 212us/step - loss: 0.1420 - precision: 1.0000 - recall: 0.9433 - f1_score: 0.9705 - val_loss: 0.1452 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2578/3000\n",
            "300/300 [==============================] - 0s 114us/step - loss: 0.1421 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9690 - val_loss: 0.1450 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2579/3000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.1420 - precision: 1.0000 - recall: 0.9433 - f1_score: 0.9706 - val_loss: 0.1449 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2580/3000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.1420 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9718 - val_loss: 0.1450 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2581/3000\n",
            "300/300 [==============================] - 0s 122us/step - loss: 0.1419 - precision: 1.0000 - recall: 0.9433 - f1_score: 0.9705 - val_loss: 0.1449 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2582/3000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.1419 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9689 - val_loss: 0.1449 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2583/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.1418 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1448 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2584/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.1418 - precision: 1.0000 - recall: 0.9433 - f1_score: 0.9708 - val_loss: 0.1448 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2585/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1418 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9688 - val_loss: 0.1446 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2586/3000\n",
            "300/300 [==============================] - 0s 78us/step - loss: 0.1417 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1446 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2587/3000\n",
            "300/300 [==============================] - 0s 112us/step - loss: 0.1417 - precision: 1.0000 - recall: 0.9433 - f1_score: 0.9705 - val_loss: 0.1446 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2588/3000\n",
            "300/300 [==============================] - 0s 126us/step - loss: 0.1417 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1445 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2589/3000\n",
            "300/300 [==============================] - 0s 82us/step - loss: 0.1416 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1446 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2590/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1416 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9723 - val_loss: 0.1445 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2591/3000\n",
            "300/300 [==============================] - 0s 79us/step - loss: 0.1415 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1444 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2592/3000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.1416 - precision: 1.0000 - recall: 0.9433 - f1_score: 0.9702 - val_loss: 0.1443 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2593/3000\n",
            "300/300 [==============================] - 0s 135us/step - loss: 0.1416 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1444 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2594/3000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.1414 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1444 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2595/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.1414 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9720 - val_loss: 0.1444 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2596/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.1414 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1443 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2597/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.1413 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9723 - val_loss: 0.1443 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2598/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1413 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1443 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2599/3000\n",
            "300/300 [==============================] - 0s 114us/step - loss: 0.1414 - precision: 1.0000 - recall: 0.9433 - f1_score: 0.9703 - val_loss: 0.1441 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2600/3000\n",
            "300/300 [==============================] - 0s 107us/step - loss: 0.1412 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1442 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2601/3000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.1412 - precision: 1.0000 - recall: 0.9433 - f1_score: 0.9706 - val_loss: 0.1442 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2602/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.1412 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9723 - val_loss: 0.1442 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2603/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1412 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1442 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2604/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1411 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1441 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2605/3000\n",
            "300/300 [==============================] - 0s 167us/step - loss: 0.1410 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1441 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2606/3000\n",
            "300/300 [==============================] - 0s 139us/step - loss: 0.1411 - precision: 1.0000 - recall: 0.9433 - f1_score: 0.9708 - val_loss: 0.1440 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2607/3000\n",
            "300/300 [==============================] - 0s 80us/step - loss: 0.1410 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1439 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2608/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.1410 - precision: 1.0000 - recall: 0.9433 - f1_score: 0.9706 - val_loss: 0.1437 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2609/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1410 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1438 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2610/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.1410 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1438 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2611/3000\n",
            "300/300 [==============================] - 0s 164us/step - loss: 0.1408 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9722 - val_loss: 0.1438 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2612/3000\n",
            "300/300 [==============================] - 0s 127us/step - loss: 0.1408 - precision: 1.0000 - recall: 0.9433 - f1_score: 0.9708 - val_loss: 0.1438 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2613/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.1407 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9723 - val_loss: 0.1437 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2614/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1407 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9718 - val_loss: 0.1437 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2615/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.1407 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9726 - val_loss: 0.1436 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2616/3000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.1408 - precision: 1.0000 - recall: 0.9433 - f1_score: 0.9707 - val_loss: 0.1435 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2617/3000\n",
            "300/300 [==============================] - 0s 133us/step - loss: 0.1406 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1434 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2618/3000\n",
            "300/300 [==============================] - 0s 136us/step - loss: 0.1406 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1434 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2619/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.1406 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1434 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2620/3000\n",
            "300/300 [==============================] - 0s 80us/step - loss: 0.1405 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9723 - val_loss: 0.1435 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2621/3000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.1405 - precision: 1.0000 - recall: 0.9433 - f1_score: 0.9706 - val_loss: 0.1436 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2622/3000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.1404 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9723 - val_loss: 0.1435 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2623/3000\n",
            "300/300 [==============================] - 0s 193us/step - loss: 0.1405 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1433 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2624/3000\n",
            "300/300 [==============================] - 0s 133us/step - loss: 0.1404 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1433 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2625/3000\n",
            "300/300 [==============================] - 0s 78us/step - loss: 0.1404 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1434 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2626/3000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.1403 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1434 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2627/3000\n",
            "300/300 [==============================] - 0s 116us/step - loss: 0.1403 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9722 - val_loss: 0.1434 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2628/3000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.1404 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1435 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2629/3000\n",
            "300/300 [==============================] - 0s 255us/step - loss: 0.1403 - precision: 1.0000 - recall: 0.9433 - f1_score: 0.9707 - val_loss: 0.1434 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2630/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.1403 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9723 - val_loss: 0.1435 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2631/3000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.1401 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9726 - val_loss: 0.1434 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2632/3000\n",
            "300/300 [==============================] - 0s 104us/step - loss: 0.1403 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9690 - val_loss: 0.1431 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2633/3000\n",
            "300/300 [==============================] - 0s 224us/step - loss: 0.1402 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1430 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2634/3000\n",
            "300/300 [==============================] - 0s 110us/step - loss: 0.1401 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1430 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2635/3000\n",
            "300/300 [==============================] - 0s 126us/step - loss: 0.1401 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1428 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2636/3000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.1400 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1428 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2637/3000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.1400 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1429 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2638/3000\n",
            "300/300 [==============================] - 0s 244us/step - loss: 0.1400 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1430 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2639/3000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.1399 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1430 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2640/3000\n",
            "300/300 [==============================] - 0s 105us/step - loss: 0.1399 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1429 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2641/3000\n",
            "300/300 [==============================] - 0s 106us/step - loss: 0.1398 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9726 - val_loss: 0.1428 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2642/3000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.1398 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1428 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2643/3000\n",
            "300/300 [==============================] - 0s 78us/step - loss: 0.1398 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1429 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2644/3000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.1398 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1430 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2645/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.1397 - precision: 1.0000 - recall: 0.9400 - f1_score: 0.9690 - val_loss: 0.1428 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2646/3000\n",
            "300/300 [==============================] - 0s 80us/step - loss: 0.1396 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1427 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2647/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.1396 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1426 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2648/3000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.1396 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9726 - val_loss: 0.1426 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2649/3000\n",
            "300/300 [==============================] - 0s 290us/step - loss: 0.1395 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1426 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2650/3000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.1396 - precision: 1.0000 - recall: 0.9433 - f1_score: 0.9707 - val_loss: 0.1424 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2651/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1395 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1425 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2652/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.1395 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1426 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2653/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1395 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9719 - val_loss: 0.1425 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2654/3000\n",
            "300/300 [==============================] - 0s 79us/step - loss: 0.1394 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1425 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2655/3000\n",
            "300/300 [==============================] - 0s 124us/step - loss: 0.1394 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9723 - val_loss: 0.1425 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2656/3000\n",
            "300/300 [==============================] - 0s 105us/step - loss: 0.1393 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9726 - val_loss: 0.1423 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2657/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.1396 - precision: 1.0000 - recall: 0.9433 - f1_score: 0.9708 - val_loss: 0.1422 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2658/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.1392 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1422 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2659/3000\n",
            "300/300 [==============================] - 0s 81us/step - loss: 0.1393 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1420 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2660/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.1393 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1419 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2661/3000\n",
            "300/300 [==============================] - 0s 126us/step - loss: 0.1392 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1419 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2662/3000\n",
            "300/300 [==============================] - 0s 111us/step - loss: 0.1391 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1420 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2663/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.1391 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1422 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2664/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.1391 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9722 - val_loss: 0.1423 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2665/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.1390 - precision: 1.0000 - recall: 0.9433 - f1_score: 0.9707 - val_loss: 0.1421 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2666/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.1391 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1419 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2667/3000\n",
            "300/300 [==============================] - 0s 149us/step - loss: 0.1390 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1419 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2668/3000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.1389 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1420 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2669/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1390 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1421 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2670/3000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.1388 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1420 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2671/3000\n",
            "300/300 [==============================] - 0s 82us/step - loss: 0.1389 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9723 - val_loss: 0.1419 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2672/3000\n",
            "300/300 [==============================] - 0s 140us/step - loss: 0.1387 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1419 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2673/3000\n",
            "300/300 [==============================] - 0s 105us/step - loss: 0.1387 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1419 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2674/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.1387 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9723 - val_loss: 0.1419 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2675/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1387 - precision: 1.0000 - recall: 0.9433 - f1_score: 0.9708 - val_loss: 0.1417 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2676/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.1386 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9723 - val_loss: 0.1416 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2677/3000\n",
            "300/300 [==============================] - 0s 130us/step - loss: 0.1386 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9722 - val_loss: 0.1416 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2678/3000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.1386 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1415 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2679/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.1386 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9723 - val_loss: 0.1415 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2680/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.1385 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1414 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2681/3000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.1385 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1414 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2682/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.1386 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1413 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2683/3000\n",
            "300/300 [==============================] - 0s 115us/step - loss: 0.1384 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1414 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2684/3000\n",
            "300/300 [==============================] - 0s 113us/step - loss: 0.1383 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9726 - val_loss: 0.1413 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2685/3000\n",
            "300/300 [==============================] - 0s 78us/step - loss: 0.1384 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9723 - val_loss: 0.1414 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2686/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.1384 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9722 - val_loss: 0.1413 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2687/3000\n",
            "300/300 [==============================] - 0s 80us/step - loss: 0.1383 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1414 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2688/3000\n",
            "300/300 [==============================] - 0s 119us/step - loss: 0.1384 - precision: 1.0000 - recall: 0.9433 - f1_score: 0.9707 - val_loss: 0.1413 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2689/3000\n",
            "300/300 [==============================] - 0s 115us/step - loss: 0.1383 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1412 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2690/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.1382 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1412 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2691/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.1382 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9723 - val_loss: 0.1410 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2692/3000\n",
            "300/300 [==============================] - 0s 82us/step - loss: 0.1381 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1411 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2693/3000\n",
            "300/300 [==============================] - 0s 109us/step - loss: 0.1382 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1413 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2694/3000\n",
            "300/300 [==============================] - 0s 128us/step - loss: 0.1382 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1412 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2695/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.1380 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1412 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2696/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.1381 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1411 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2697/3000\n",
            "300/300 [==============================] - 0s 79us/step - loss: 0.1380 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1410 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2698/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.1379 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1410 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2699/3000\n",
            "300/300 [==============================] - 0s 122us/step - loss: 0.1380 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1408 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2700/3000\n",
            "300/300 [==============================] - 0s 159us/step - loss: 0.1379 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1407 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2701/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.1378 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1406 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2702/3000\n",
            "300/300 [==============================] - 0s 81us/step - loss: 0.1379 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9723 - val_loss: 0.1407 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2703/3000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.1377 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9723 - val_loss: 0.1407 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2704/3000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.1378 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1406 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2705/3000\n",
            "300/300 [==============================] - 0s 164us/step - loss: 0.1378 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9723 - val_loss: 0.1404 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2706/3000\n",
            "300/300 [==============================] - 0s 107us/step - loss: 0.1377 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1404 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2707/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.1376 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9726 - val_loss: 0.1404 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2708/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.1376 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1403 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2709/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1376 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1404 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2710/3000\n",
            "300/300 [==============================] - 0s 82us/step - loss: 0.1375 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1403 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2711/3000\n",
            "300/300 [==============================] - 0s 109us/step - loss: 0.1375 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9723 - val_loss: 0.1404 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2712/3000\n",
            "300/300 [==============================] - 0s 117us/step - loss: 0.1375 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1404 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2713/3000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.1376 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9723 - val_loss: 0.1403 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2714/3000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.1374 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1404 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2715/3000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.1375 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1403 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2716/3000\n",
            "300/300 [==============================] - 0s 110us/step - loss: 0.1373 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1403 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2717/3000\n",
            "300/300 [==============================] - 0s 142us/step - loss: 0.1373 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1404 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2718/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.1373 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1404 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2719/3000\n",
            "300/300 [==============================] - 0s 79us/step - loss: 0.1372 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1403 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2720/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.1372 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1403 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2721/3000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.1372 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9722 - val_loss: 0.1403 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2722/3000\n",
            "300/300 [==============================] - 0s 124us/step - loss: 0.1371 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1401 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2723/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1371 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1402 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2724/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.1371 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9726 - val_loss: 0.1401 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2725/3000\n",
            "300/300 [==============================] - 0s 78us/step - loss: 0.1371 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1400 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2726/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1370 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1400 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2727/3000\n",
            "300/300 [==============================] - 0s 118us/step - loss: 0.1371 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1402 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2728/3000\n",
            "300/300 [==============================] - 0s 103us/step - loss: 0.1369 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9723 - val_loss: 0.1401 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2729/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1370 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1401 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2730/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.1369 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1400 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2731/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1368 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9723 - val_loss: 0.1398 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2732/3000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.1368 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1399 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2733/3000\n",
            "300/300 [==============================] - 0s 114us/step - loss: 0.1368 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9726 - val_loss: 0.1400 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2734/3000\n",
            "300/300 [==============================] - 0s 108us/step - loss: 0.1367 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1399 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2735/3000\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.1367 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1399 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2736/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.1368 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1401 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2737/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.1368 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1400 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2738/3000\n",
            "300/300 [==============================] - 0s 101us/step - loss: 0.1366 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1399 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2739/3000\n",
            "300/300 [==============================] - 0s 137us/step - loss: 0.1366 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1399 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2740/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1365 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1397 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2741/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.1365 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1397 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2742/3000\n",
            "300/300 [==============================] - 0s 82us/step - loss: 0.1366 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1398 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2743/3000\n",
            "300/300 [==============================] - 0s 122us/step - loss: 0.1364 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1397 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2744/3000\n",
            "300/300 [==============================] - 0s 121us/step - loss: 0.1365 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1395 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2745/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.1365 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9721 - val_loss: 0.1394 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2746/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1363 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9726 - val_loss: 0.1394 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2747/3000\n",
            "300/300 [==============================] - 0s 81us/step - loss: 0.1364 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1394 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2748/3000\n",
            "300/300 [==============================] - 0s 152us/step - loss: 0.1363 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1394 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2749/3000\n",
            "300/300 [==============================] - 0s 108us/step - loss: 0.1364 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9726 - val_loss: 0.1392 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2750/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.1362 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1392 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2751/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1362 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1392 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2752/3000\n",
            "300/300 [==============================] - 0s 111us/step - loss: 0.1362 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1392 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2753/3000\n",
            "300/300 [==============================] - 0s 116us/step - loss: 0.1362 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9722 - val_loss: 0.1391 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2754/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.1362 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1391 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2755/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.1362 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9723 - val_loss: 0.1390 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2756/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.1361 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9726 - val_loss: 0.1391 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2757/3000\n",
            "300/300 [==============================] - 0s 119us/step - loss: 0.1360 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1391 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2758/3000\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.1360 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9721 - val_loss: 0.1390 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2759/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.1359 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9726 - val_loss: 0.1390 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2760/3000\n",
            "300/300 [==============================] - 0s 112us/step - loss: 0.1360 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1389 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2761/3000\n",
            "300/300 [==============================] - 0s 249us/step - loss: 0.1359 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1390 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2762/3000\n",
            "300/300 [==============================] - 0s 120us/step - loss: 0.1359 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9723 - val_loss: 0.1389 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2763/3000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.1359 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9726 - val_loss: 0.1388 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2764/3000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.1359 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9722 - val_loss: 0.1389 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2765/3000\n",
            "300/300 [==============================] - 0s 161us/step - loss: 0.1358 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1387 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2766/3000\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.1357 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1387 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2767/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.1358 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9723 - val_loss: 0.1388 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2768/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.1356 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9722 - val_loss: 0.1387 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2769/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.1356 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9720 - val_loss: 0.1388 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2770/3000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.1357 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1388 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2771/3000\n",
            "300/300 [==============================] - 0s 115us/step - loss: 0.1356 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1387 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2772/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.1355 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9723 - val_loss: 0.1387 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2773/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1355 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1386 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2774/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.1355 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1386 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2775/3000\n",
            "300/300 [==============================] - 0s 136us/step - loss: 0.1355 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1386 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2776/3000\n",
            "300/300 [==============================] - 0s 123us/step - loss: 0.1354 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1386 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2777/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.1355 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9723 - val_loss: 0.1386 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2778/3000\n",
            "300/300 [==============================] - 0s 78us/step - loss: 0.1353 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9726 - val_loss: 0.1386 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2779/3000\n",
            "300/300 [==============================] - 0s 81us/step - loss: 0.1353 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1385 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2780/3000\n",
            "300/300 [==============================] - 0s 137us/step - loss: 0.1353 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1386 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2781/3000\n",
            "300/300 [==============================] - 0s 114us/step - loss: 0.1353 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9720 - val_loss: 0.1385 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2782/3000\n",
            "300/300 [==============================] - 0s 78us/step - loss: 0.1353 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1385 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2783/3000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.1352 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9723 - val_loss: 0.1384 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2784/3000\n",
            "300/300 [==============================] - 0s 80us/step - loss: 0.1352 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9726 - val_loss: 0.1384 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2785/3000\n",
            "300/300 [==============================] - 0s 121us/step - loss: 0.1352 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9723 - val_loss: 0.1385 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2786/3000\n",
            "300/300 [==============================] - 0s 120us/step - loss: 0.1351 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1384 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2787/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.1350 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1383 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2788/3000\n",
            "300/300 [==============================] - 0s 80us/step - loss: 0.1350 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1383 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2789/3000\n",
            "300/300 [==============================] - 0s 80us/step - loss: 0.1350 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1382 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2790/3000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.1349 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1381 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2791/3000\n",
            "300/300 [==============================] - 0s 127us/step - loss: 0.1350 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1381 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2792/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.1350 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9723 - val_loss: 0.1379 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2793/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1349 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9726 - val_loss: 0.1378 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2794/3000\n",
            "300/300 [==============================] - 0s 79us/step - loss: 0.1351 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1379 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2795/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.1348 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1380 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2796/3000\n",
            "300/300 [==============================] - 0s 110us/step - loss: 0.1348 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9726 - val_loss: 0.1380 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2797/3000\n",
            "300/300 [==============================] - 0s 117us/step - loss: 0.1347 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9723 - val_loss: 0.1378 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2798/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.1348 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9726 - val_loss: 0.1377 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2799/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.1347 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9726 - val_loss: 0.1376 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2800/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.1346 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1376 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2801/3000\n",
            "300/300 [==============================] - 0s 118us/step - loss: 0.1347 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9723 - val_loss: 0.1376 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2802/3000\n",
            "300/300 [==============================] - 0s 102us/step - loss: 0.1346 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9722 - val_loss: 0.1375 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2803/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.1346 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1376 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2804/3000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.1346 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9722 - val_loss: 0.1374 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2805/3000\n",
            "300/300 [==============================] - 0s 82us/step - loss: 0.1345 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1376 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2806/3000\n",
            "300/300 [==============================] - 0s 120us/step - loss: 0.1345 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1375 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2807/3000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.1345 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1375 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2808/3000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.1344 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9726 - val_loss: 0.1374 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2809/3000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.1344 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1373 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2810/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.1344 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1372 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2811/3000\n",
            "300/300 [==============================] - 0s 119us/step - loss: 0.1343 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9722 - val_loss: 0.1372 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2812/3000\n",
            "300/300 [==============================] - 0s 114us/step - loss: 0.1343 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9721 - val_loss: 0.1373 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2813/3000\n",
            "300/300 [==============================] - 0s 80us/step - loss: 0.1342 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1372 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2814/3000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.1342 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1372 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2815/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.1343 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1371 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2816/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.1341 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1372 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2817/3000\n",
            "300/300 [==============================] - 0s 113us/step - loss: 0.1341 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1373 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2818/3000\n",
            "300/300 [==============================] - 0s 117us/step - loss: 0.1341 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9722 - val_loss: 0.1372 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2819/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.1343 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1375 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2820/3000\n",
            "300/300 [==============================] - 0s 82us/step - loss: 0.1341 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1373 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2821/3000\n",
            "300/300 [==============================] - 0s 139us/step - loss: 0.1341 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9723 - val_loss: 0.1371 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2822/3000\n",
            "300/300 [==============================] - 0s 103us/step - loss: 0.1340 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1370 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2823/3000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.1340 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1370 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2824/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.1339 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1369 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2825/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.1340 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9723 - val_loss: 0.1368 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2826/3000\n",
            "300/300 [==============================] - 0s 121us/step - loss: 0.1340 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1368 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2827/3000\n",
            "300/300 [==============================] - 0s 109us/step - loss: 0.1339 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9721 - val_loss: 0.1366 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2828/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.1338 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1367 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2829/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1338 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1369 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2830/3000\n",
            "300/300 [==============================] - 0s 79us/step - loss: 0.1337 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1369 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2831/3000\n",
            "300/300 [==============================] - 0s 145us/step - loss: 0.1337 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1368 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2832/3000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.1338 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1369 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2833/3000\n",
            "300/300 [==============================] - 0s 81us/step - loss: 0.1336 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1370 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2834/3000\n",
            "300/300 [==============================] - 0s 79us/step - loss: 0.1337 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1369 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2835/3000\n",
            "300/300 [==============================] - 0s 81us/step - loss: 0.1335 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1369 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2836/3000\n",
            "300/300 [==============================] - 0s 133us/step - loss: 0.1336 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1369 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2837/3000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.1335 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1367 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2838/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.1335 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1367 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2839/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.1335 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9721 - val_loss: 0.1367 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2840/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.1334 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1366 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2841/3000\n",
            "300/300 [==============================] - 0s 104us/step - loss: 0.1334 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1365 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2842/3000\n",
            "300/300 [==============================] - 0s 122us/step - loss: 0.1333 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1364 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2843/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1334 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1365 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2844/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.1334 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1363 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2845/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1334 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1363 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2846/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.1334 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9723 - val_loss: 0.1363 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2847/3000\n",
            "300/300 [==============================] - 0s 115us/step - loss: 0.1332 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9726 - val_loss: 0.1362 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2848/3000\n",
            "300/300 [==============================] - 0s 105us/step - loss: 0.1333 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1361 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2849/3000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.1331 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1361 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2850/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1332 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9723 - val_loss: 0.1360 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2851/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.1332 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1362 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2852/3000\n",
            "300/300 [==============================] - 0s 113us/step - loss: 0.1330 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1360 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2853/3000\n",
            "300/300 [==============================] - 0s 107us/step - loss: 0.1331 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1360 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2854/3000\n",
            "300/300 [==============================] - 0s 79us/step - loss: 0.1330 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1358 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2855/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.1330 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9726 - val_loss: 0.1358 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2856/3000\n",
            "300/300 [==============================] - 0s 81us/step - loss: 0.1329 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1357 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2857/3000\n",
            "300/300 [==============================] - 0s 138us/step - loss: 0.1329 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9726 - val_loss: 0.1357 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2858/3000\n",
            "300/300 [==============================] - 0s 110us/step - loss: 0.1329 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9723 - val_loss: 0.1356 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2859/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1329 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1357 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2860/3000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.1329 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1357 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2861/3000\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.1328 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1357 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2862/3000\n",
            "300/300 [==============================] - 0s 117us/step - loss: 0.1328 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1359 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2863/3000\n",
            "300/300 [==============================] - 0s 115us/step - loss: 0.1327 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9721 - val_loss: 0.1358 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2864/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.1328 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9723 - val_loss: 0.1357 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2865/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1326 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1357 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2866/3000\n",
            "300/300 [==============================] - 0s 80us/step - loss: 0.1326 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9726 - val_loss: 0.1355 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2867/3000\n",
            "300/300 [==============================] - 0s 82us/step - loss: 0.1326 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1356 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2868/3000\n",
            "300/300 [==============================] - 0s 148us/step - loss: 0.1327 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1357 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2869/3000\n",
            "300/300 [==============================] - 0s 119us/step - loss: 0.1326 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9726 - val_loss: 0.1356 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2870/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1325 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1355 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2871/3000\n",
            "300/300 [==============================] - 0s 79us/step - loss: 0.1326 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9726 - val_loss: 0.1357 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2872/3000\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.1327 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9726 - val_loss: 0.1356 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2873/3000\n",
            "300/300 [==============================] - 0s 115us/step - loss: 0.1324 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1355 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2874/3000\n",
            "300/300 [==============================] - 0s 132us/step - loss: 0.1324 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1355 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2875/3000\n",
            "300/300 [==============================] - 0s 80us/step - loss: 0.1324 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1354 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2876/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1323 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1354 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2877/3000\n",
            "300/300 [==============================] - 0s 108us/step - loss: 0.1323 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1353 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2878/3000\n",
            "300/300 [==============================] - 0s 111us/step - loss: 0.1324 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1354 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2879/3000\n",
            "300/300 [==============================] - 0s 133us/step - loss: 0.1323 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1352 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2880/3000\n",
            "300/300 [==============================] - 0s 78us/step - loss: 0.1323 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1352 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2881/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1321 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1352 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2882/3000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.1322 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9722 - val_loss: 0.1353 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2883/3000\n",
            "300/300 [==============================] - 0s 241us/step - loss: 0.1321 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9723 - val_loss: 0.1352 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2884/3000\n",
            "300/300 [==============================] - 0s 120us/step - loss: 0.1321 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1351 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2885/3000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.1322 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9723 - val_loss: 0.1350 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2886/3000\n",
            "300/300 [==============================] - 0s 117us/step - loss: 0.1321 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1351 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2887/3000\n",
            "300/300 [==============================] - 0s 121us/step - loss: 0.1320 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9723 - val_loss: 0.1351 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2888/3000\n",
            "300/300 [==============================] - 0s 108us/step - loss: 0.1320 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9723 - val_loss: 0.1351 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2889/3000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.1320 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9721 - val_loss: 0.1350 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2890/3000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.1319 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9723 - val_loss: 0.1349 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2891/3000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.1319 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9722 - val_loss: 0.1350 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2892/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.1319 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1349 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2893/3000\n",
            "300/300 [==============================] - 0s 109us/step - loss: 0.1318 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1348 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2894/3000\n",
            "300/300 [==============================] - 0s 103us/step - loss: 0.1318 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1347 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2895/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.1318 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1347 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2896/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.1317 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1347 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2897/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.1318 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1345 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2898/3000\n",
            "300/300 [==============================] - 0s 102us/step - loss: 0.1316 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9726 - val_loss: 0.1346 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2899/3000\n",
            "300/300 [==============================] - 0s 106us/step - loss: 0.1318 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9726 - val_loss: 0.1346 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2900/3000\n",
            "300/300 [==============================] - 0s 79us/step - loss: 0.1316 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9726 - val_loss: 0.1347 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2901/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.1316 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1348 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2902/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.1316 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1346 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2903/3000\n",
            "300/300 [==============================] - 0s 101us/step - loss: 0.1315 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1346 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2904/3000\n",
            "300/300 [==============================] - 0s 121us/step - loss: 0.1315 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9722 - val_loss: 0.1346 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2905/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.1316 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9723 - val_loss: 0.1345 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2906/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.1314 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9723 - val_loss: 0.1344 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2907/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.1315 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1344 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2908/3000\n",
            "300/300 [==============================] - 0s 101us/step - loss: 0.1314 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1344 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2909/3000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.1314 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9726 - val_loss: 0.1343 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2910/3000\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.1313 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9723 - val_loss: 0.1342 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2911/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.1313 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1342 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2912/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.1313 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1341 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2913/3000\n",
            "300/300 [==============================] - 0s 126us/step - loss: 0.1313 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1341 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2914/3000\n",
            "300/300 [==============================] - 0s 110us/step - loss: 0.1313 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1341 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2915/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.1311 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1341 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2916/3000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.1311 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1340 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2917/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.1311 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9723 - val_loss: 0.1340 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2918/3000\n",
            "300/300 [==============================] - 0s 142us/step - loss: 0.1311 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1340 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2919/3000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.1311 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9726 - val_loss: 0.1342 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2920/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1310 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1341 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2921/3000\n",
            "300/300 [==============================] - 0s 79us/step - loss: 0.1310 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1340 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2922/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.1310 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1341 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2923/3000\n",
            "300/300 [==============================] - 0s 145us/step - loss: 0.1310 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9723 - val_loss: 0.1340 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2924/3000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.1309 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1341 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2925/3000\n",
            "300/300 [==============================] - 0s 78us/step - loss: 0.1309 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1340 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2926/3000\n",
            "300/300 [==============================] - 0s 82us/step - loss: 0.1309 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1338 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2927/3000\n",
            "300/300 [==============================] - 0s 119us/step - loss: 0.1308 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1339 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2928/3000\n",
            "300/300 [==============================] - 0s 102us/step - loss: 0.1308 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9723 - val_loss: 0.1339 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2929/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.1308 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1339 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2930/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1308 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1337 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2931/3000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.1307 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1338 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2932/3000\n",
            "300/300 [==============================] - 0s 133us/step - loss: 0.1307 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1337 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2933/3000\n",
            "300/300 [==============================] - 0s 125us/step - loss: 0.1307 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9723 - val_loss: 0.1336 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2934/3000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.1307 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9721 - val_loss: 0.1335 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2935/3000\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.1306 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1334 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2936/3000\n",
            "300/300 [==============================] - 0s 81us/step - loss: 0.1307 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1335 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2937/3000\n",
            "300/300 [==============================] - 0s 101us/step - loss: 0.1306 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1334 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2938/3000\n",
            "300/300 [==============================] - 0s 130us/step - loss: 0.1306 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9721 - val_loss: 0.1332 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2939/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.1305 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9726 - val_loss: 0.1333 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2940/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1305 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1333 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2941/3000\n",
            "300/300 [==============================] - 0s 79us/step - loss: 0.1305 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9723 - val_loss: 0.1332 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2942/3000\n",
            "300/300 [==============================] - 0s 109us/step - loss: 0.1304 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1331 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2943/3000\n",
            "300/300 [==============================] - 0s 119us/step - loss: 0.1303 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1331 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2944/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.1304 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9726 - val_loss: 0.1332 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2945/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.1303 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1332 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2946/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.1303 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9720 - val_loss: 0.1332 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2947/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.1304 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1332 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2948/3000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.1302 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9722 - val_loss: 0.1333 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2949/3000\n",
            "300/300 [==============================] - 0s 107us/step - loss: 0.1302 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1332 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2950/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1301 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1331 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2951/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1301 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9723 - val_loss: 0.1332 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2952/3000\n",
            "300/300 [==============================] - 0s 80us/step - loss: 0.1301 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1332 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2953/3000\n",
            "300/300 [==============================] - 0s 105us/step - loss: 0.1301 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1331 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2954/3000\n",
            "300/300 [==============================] - 0s 107us/step - loss: 0.1301 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1332 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2955/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1301 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9723 - val_loss: 0.1330 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2956/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.1300 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9726 - val_loss: 0.1329 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2957/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.1300 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9726 - val_loss: 0.1330 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2958/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.1299 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1329 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2959/3000\n",
            "300/300 [==============================] - 0s 124us/step - loss: 0.1299 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1327 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2960/3000\n",
            "300/300 [==============================] - 0s 103us/step - loss: 0.1299 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9723 - val_loss: 0.1328 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2961/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.1298 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9723 - val_loss: 0.1328 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2962/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1298 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1327 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2963/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.1299 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1327 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2964/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.1298 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1327 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2965/3000\n",
            "300/300 [==============================] - 0s 106us/step - loss: 0.1297 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1326 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2966/3000\n",
            "300/300 [==============================] - 0s 117us/step - loss: 0.1300 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9720 - val_loss: 0.1328 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2967/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.1297 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9722 - val_loss: 0.1327 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2968/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.1297 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1325 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2969/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.1296 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1325 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2970/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.1296 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1324 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2971/3000\n",
            "300/300 [==============================] - 0s 117us/step - loss: 0.1296 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1325 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2972/3000\n",
            "300/300 [==============================] - 0s 120us/step - loss: 0.1296 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1324 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2973/3000\n",
            "300/300 [==============================] - 0s 80us/step - loss: 0.1295 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1324 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2974/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.1296 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1326 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2975/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.1294 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9726 - val_loss: 0.1326 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2976/3000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.1294 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1327 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2977/3000\n",
            "300/300 [==============================] - 0s 108us/step - loss: 0.1294 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1326 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2978/3000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.1294 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9723 - val_loss: 0.1324 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2979/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.1293 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1325 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2980/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.1293 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1323 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2981/3000\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.1294 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9723 - val_loss: 0.1322 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2982/3000\n",
            "300/300 [==============================] - 0s 107us/step - loss: 0.1292 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1323 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2983/3000\n",
            "300/300 [==============================] - 0s 78us/step - loss: 0.1293 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9718 - val_loss: 0.1321 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2984/3000\n",
            "300/300 [==============================] - 0s 78us/step - loss: 0.1293 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1321 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2985/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1291 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1320 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2986/3000\n",
            "300/300 [==============================] - 0s 112us/step - loss: 0.1291 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9722 - val_loss: 0.1320 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2987/3000\n",
            "300/300 [==============================] - 0s 124us/step - loss: 0.1291 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9726 - val_loss: 0.1319 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2988/3000\n",
            "300/300 [==============================] - 0s 78us/step - loss: 0.1292 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1320 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2989/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.1292 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9722 - val_loss: 0.1321 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2990/3000\n",
            "300/300 [==============================] - 0s 81us/step - loss: 0.1291 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9726 - val_loss: 0.1319 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2991/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.1290 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1319 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2992/3000\n",
            "300/300 [==============================] - 0s 114us/step - loss: 0.1290 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9726 - val_loss: 0.1320 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2993/3000\n",
            "300/300 [==============================] - 0s 110us/step - loss: 0.1289 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1319 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2994/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1289 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1318 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2995/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.1289 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9722 - val_loss: 0.1320 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2996/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.1289 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9726 - val_loss: 0.1318 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2997/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.1288 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1318 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2998/3000\n",
            "300/300 [==============================] - 0s 118us/step - loss: 0.1288 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9725 - val_loss: 0.1318 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 2999/3000\n",
            "300/300 [==============================] - 0s 125us/step - loss: 0.1289 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9718 - val_loss: 0.1319 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n",
            "Epoch 3000/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.1288 - precision: 1.0000 - recall: 0.9467 - f1_score: 0.9724 - val_loss: 0.1319 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9655\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "v18B9tYZAPEN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We now plot the training history."
      ]
    },
    {
      "metadata": {
        "id": "01kabwyOALRx",
        "colab_type": "code",
        "outputId": "1ac5647d-6fe9-485c-a1da-a73a5880b7c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "plt.plot(history_sgd.history['f1_score'])\n",
        "plt.plot(history_sgd.history['val_f1_score'])\n",
        "plt.title('model f1 score')\n",
        "plt.ylabel('f1 score')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history_sgd.history['loss'])\n",
        "plt.plot(history_sgd.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "PIxsNwI74erS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Adam optimizer\n",
        "We train our model with Adam optimizer"
      ]
    },
    {
      "metadata": {
        "id": "5Om6YXQD4ghf",
        "colab_type": "code",
        "outputId": "ef5e7e3b-b561-4f09-c2da-6df655863e4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "optimizer = Adam(0.001)\n",
        "loss = 'binary_crossentropy'\n",
        "metrics = [get_metrics(0.5)['precision'], get_metrics(0.5)['recall'], get_metrics(0.5)['f1_score']]\n",
        "\n",
        "model_adam = get_model(optimizer, loss, metrics)\n",
        "\n",
        "history_adam = model_adam.fit(X_train, Y_train,\n",
        "          epochs=100,\n",
        "          batch_size=32,\n",
        "          validation_data=(X_valid, Y_valid)\n",
        "         )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_2 (Dense)              (None, 3)                 15555     \n",
            "=================================================================\n",
            "Total params: 15,555\n",
            "Trainable params: 15,555\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 300 samples, validate on 60 samples\n",
            "Epoch 1/100\n",
            "300/300 [==============================] - 1s 2ms/step - loss: 1.3109 - precision: 0.2870 - recall: 0.2800 - f1_score: 0.2831 - val_loss: 0.8754 - val_precision: 0.3496 - val_recall: 0.3333 - val_f1_score: 0.3413\n",
            "Epoch 2/100\n",
            "300/300 [==============================] - 0s 126us/step - loss: 0.6922 - precision: 0.5894 - recall: 0.5367 - f1_score: 0.5579 - val_loss: 0.4479 - val_precision: 0.5931 - val_recall: 0.4667 - val_f1_score: 0.5214\n",
            "Epoch 3/100\n",
            "300/300 [==============================] - 0s 136us/step - loss: 0.4622 - precision: 0.7333 - recall: 0.6133 - f1_score: 0.6600 - val_loss: 0.3823 - val_precision: 0.6167 - val_recall: 0.6167 - val_f1_score: 0.6167\n",
            "Epoch 4/100\n",
            "300/300 [==============================] - 0s 140us/step - loss: 0.3415 - precision: 0.7851 - recall: 0.7233 - f1_score: 0.7511 - val_loss: 0.3155 - val_precision: 0.7658 - val_recall: 0.6000 - val_f1_score: 0.6728\n",
            "Epoch 5/100\n",
            "300/300 [==============================] - 0s 135us/step - loss: 0.2786 - precision: 0.8326 - recall: 0.7600 - f1_score: 0.7916 - val_loss: 0.2230 - val_precision: 0.9133 - val_recall: 0.8833 - val_f1_score: 0.8978\n",
            "Epoch 6/100\n",
            "300/300 [==============================] - 0s 124us/step - loss: 0.2199 - precision: 0.8997 - recall: 0.8267 - f1_score: 0.8610 - val_loss: 0.1953 - val_precision: 0.9833 - val_recall: 0.9833 - val_f1_score: 0.9833\n",
            "Epoch 7/100\n",
            "300/300 [==============================] - 0s 117us/step - loss: 0.1826 - precision: 0.9641 - recall: 0.9000 - f1_score: 0.9302 - val_loss: 0.1664 - val_precision: 0.9833 - val_recall: 0.9833 - val_f1_score: 0.9833\n",
            "Epoch 8/100\n",
            "300/300 [==============================] - 0s 130us/step - loss: 0.1650 - precision: 0.9563 - recall: 0.9367 - f1_score: 0.9462 - val_loss: 0.1569 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1_score: 0.9653\n",
            "Epoch 9/100\n",
            "300/300 [==============================] - 0s 149us/step - loss: 0.1493 - precision: 0.9898 - recall: 0.9500 - f1_score: 0.9688 - val_loss: 0.2160 - val_precision: 0.7969 - val_recall: 0.7833 - val_f1_score: 0.7900\n",
            "Epoch 10/100\n",
            "300/300 [==============================] - 0s 129us/step - loss: 0.1577 - precision: 0.9592 - recall: 0.9167 - f1_score: 0.9365 - val_loss: 0.1167 - val_precision: 1.0000 - val_recall: 0.9833 - val_f1_score: 0.9915\n",
            "Epoch 11/100\n",
            "300/300 [==============================] - 0s 117us/step - loss: 0.1106 - precision: 0.9933 - recall: 0.9867 - f1_score: 0.9899 - val_loss: 0.1217 - val_precision: 1.0000 - val_recall: 0.9833 - val_f1_score: 0.9915\n",
            "Epoch 12/100\n",
            "300/300 [==============================] - 0s 116us/step - loss: 0.1028 - precision: 1.0000 - recall: 0.9767 - f1_score: 0.9880 - val_loss: 0.0996 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 13/100\n",
            "300/300 [==============================] - 0s 116us/step - loss: 0.0995 - precision: 0.9964 - recall: 0.9833 - f1_score: 0.9897 - val_loss: 0.0848 - val_precision: 0.9833 - val_recall: 0.9833 - val_f1_score: 0.9833\n",
            "Epoch 14/100\n",
            "300/300 [==============================] - 0s 119us/step - loss: 0.0848 - precision: 1.0000 - recall: 0.9933 - f1_score: 0.9966 - val_loss: 0.0916 - val_precision: 1.0000 - val_recall: 0.9833 - val_f1_score: 0.9915\n",
            "Epoch 15/100\n",
            "300/300 [==============================] - 0s 120us/step - loss: 0.0865 - precision: 0.9867 - recall: 0.9833 - f1_score: 0.9850 - val_loss: 0.0833 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 16/100\n",
            "300/300 [==============================] - 0s 131us/step - loss: 0.0868 - precision: 0.9700 - recall: 0.9700 - f1_score: 0.9700 - val_loss: 0.0765 - val_precision: 1.0000 - val_recall: 0.9833 - val_f1_score: 0.9915\n",
            "Epoch 17/100\n",
            "300/300 [==============================] - 0s 130us/step - loss: 0.0725 - precision: 1.0000 - recall: 0.9833 - f1_score: 0.9915 - val_loss: 0.0672 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 18/100\n",
            "300/300 [==============================] - 0s 129us/step - loss: 0.0599 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0582 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 19/100\n",
            "300/300 [==============================] - 0s 129us/step - loss: 0.0550 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0560 - val_precision: 0.9833 - val_recall: 0.9833 - val_f1_score: 0.9833\n",
            "Epoch 20/100\n",
            "300/300 [==============================] - 0s 118us/step - loss: 0.0538 - precision: 0.9967 - recall: 0.9967 - f1_score: 0.9967 - val_loss: 0.0505 - val_precision: 0.9833 - val_recall: 0.9833 - val_f1_score: 0.9833\n",
            "Epoch 21/100\n",
            "300/300 [==============================] - 0s 120us/step - loss: 0.0503 - precision: 0.9967 - recall: 0.9967 - f1_score: 0.9967 - val_loss: 0.0472 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 22/100\n",
            "300/300 [==============================] - 0s 120us/step - loss: 0.0571 - precision: 1.0000 - recall: 0.9967 - f1_score: 0.9983 - val_loss: 0.0589 - val_precision: 0.9833 - val_recall: 0.9833 - val_f1_score: 0.9833\n",
            "Epoch 23/100\n",
            "300/300 [==============================] - 0s 117us/step - loss: 0.0688 - precision: 0.9800 - recall: 0.9800 - f1_score: 0.9800 - val_loss: 0.0510 - val_precision: 0.9833 - val_recall: 0.9833 - val_f1_score: 0.9833\n",
            "Epoch 24/100\n",
            "300/300 [==============================] - 0s 122us/step - loss: 0.0595 - precision: 0.9900 - recall: 0.9867 - f1_score: 0.9883 - val_loss: 0.0404 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 25/100\n",
            "300/300 [==============================] - 0s 115us/step - loss: 0.0498 - precision: 0.9933 - recall: 0.9933 - f1_score: 0.9933 - val_loss: 0.0380 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 26/100\n",
            "300/300 [==============================] - 0s 114us/step - loss: 0.0359 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0428 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 27/100\n",
            "300/300 [==============================] - 0s 118us/step - loss: 0.0348 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0473 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 28/100\n",
            "300/300 [==============================] - 0s 125us/step - loss: 0.0353 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0325 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 29/100\n",
            "300/300 [==============================] - 0s 114us/step - loss: 0.0298 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0307 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 30/100\n",
            "300/300 [==============================] - 0s 112us/step - loss: 0.0281 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0290 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 31/100\n",
            "300/300 [==============================] - 0s 111us/step - loss: 0.0286 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0330 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 32/100\n",
            "300/300 [==============================] - 0s 119us/step - loss: 0.0286 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0268 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 33/100\n",
            "300/300 [==============================] - 0s 121us/step - loss: 0.0244 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0291 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 34/100\n",
            "300/300 [==============================] - 0s 116us/step - loss: 0.0231 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0248 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 35/100\n",
            "300/300 [==============================] - 0s 128us/step - loss: 0.0221 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0276 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 36/100\n",
            "300/300 [==============================] - 0s 121us/step - loss: 0.0219 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0231 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 37/100\n",
            "300/300 [==============================] - 0s 119us/step - loss: 0.0214 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0219 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 38/100\n",
            "300/300 [==============================] - 0s 119us/step - loss: 0.0210 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0210 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 39/100\n",
            "300/300 [==============================] - 0s 115us/step - loss: 0.0195 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0207 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 40/100\n",
            "300/300 [==============================] - 0s 127us/step - loss: 0.0183 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0203 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 41/100\n",
            "300/300 [==============================] - 0s 123us/step - loss: 0.0179 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0193 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 42/100\n",
            "300/300 [==============================] - 0s 132us/step - loss: 0.0180 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0181 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 43/100\n",
            "300/300 [==============================] - 0s 125us/step - loss: 0.0168 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0177 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 44/100\n",
            "300/300 [==============================] - 0s 127us/step - loss: 0.0173 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0173 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 45/100\n",
            "300/300 [==============================] - 0s 120us/step - loss: 0.0175 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0175 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 46/100\n",
            "300/300 [==============================] - 0s 132us/step - loss: 0.0155 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0215 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 47/100\n",
            "300/300 [==============================] - 0s 127us/step - loss: 0.0173 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0213 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 48/100\n",
            "300/300 [==============================] - 0s 120us/step - loss: 0.0144 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0154 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 49/100\n",
            "300/300 [==============================] - 0s 127us/step - loss: 0.0141 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0147 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 50/100\n",
            "300/300 [==============================] - 0s 135us/step - loss: 0.0137 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0149 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 51/100\n",
            "300/300 [==============================] - 0s 124us/step - loss: 0.0143 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0143 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 52/100\n",
            "300/300 [==============================] - 0s 117us/step - loss: 0.0123 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0143 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 53/100\n",
            "300/300 [==============================] - 0s 125us/step - loss: 0.0119 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0132 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 54/100\n",
            "300/300 [==============================] - 0s 126us/step - loss: 0.0114 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0140 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 55/100\n",
            "300/300 [==============================] - 0s 120us/step - loss: 0.0116 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0139 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 56/100\n",
            "300/300 [==============================] - 0s 122us/step - loss: 0.0114 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0122 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 57/100\n",
            "300/300 [==============================] - 0s 123us/step - loss: 0.0109 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0121 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 58/100\n",
            "300/300 [==============================] - 0s 122us/step - loss: 0.0113 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0123 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 59/100\n",
            "300/300 [==============================] - 0s 136us/step - loss: 0.0102 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0112 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 60/100\n",
            "300/300 [==============================] - 0s 146us/step - loss: 0.0099 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0117 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 61/100\n",
            "300/300 [==============================] - 0s 125us/step - loss: 0.0100 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0118 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 62/100\n",
            "300/300 [==============================] - 0s 127us/step - loss: 0.0108 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0122 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 63/100\n",
            "300/300 [==============================] - 0s 128us/step - loss: 0.0097 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0113 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 64/100\n",
            "300/300 [==============================] - 0s 123us/step - loss: 0.0092 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0105 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 65/100\n",
            "300/300 [==============================] - 0s 130us/step - loss: 0.0088 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0096 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 66/100\n",
            "300/300 [==============================] - 0s 120us/step - loss: 0.0085 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0100 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 67/100\n",
            "300/300 [==============================] - 0s 126us/step - loss: 0.0088 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0092 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 68/100\n",
            "300/300 [==============================] - 0s 131us/step - loss: 0.0085 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0091 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 69/100\n",
            "300/300 [==============================] - 0s 129us/step - loss: 0.0081 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0088 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 70/100\n",
            "300/300 [==============================] - 0s 138us/step - loss: 0.0079 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0103 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 71/100\n",
            "300/300 [==============================] - 0s 139us/step - loss: 0.0080 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0085 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 72/100\n",
            "300/300 [==============================] - 0s 130us/step - loss: 0.0074 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0086 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 73/100\n",
            "300/300 [==============================] - 0s 126us/step - loss: 0.0073 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0084 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 74/100\n",
            "300/300 [==============================] - 0s 131us/step - loss: 0.0071 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0080 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 75/100\n",
            "300/300 [==============================] - 0s 135us/step - loss: 0.0070 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0078 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 76/100\n",
            "300/300 [==============================] - 0s 132us/step - loss: 0.0070 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0080 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 77/100\n",
            "300/300 [==============================] - 0s 124us/step - loss: 0.0069 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0081 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 78/100\n",
            "300/300 [==============================] - 0s 133us/step - loss: 0.0066 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0074 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 79/100\n",
            "300/300 [==============================] - 0s 124us/step - loss: 0.0064 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0074 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 80/100\n",
            "300/300 [==============================] - 0s 125us/step - loss: 0.0064 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0074 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 81/100\n",
            "300/300 [==============================] - 0s 121us/step - loss: 0.0066 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0076 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 82/100\n",
            "300/300 [==============================] - 0s 122us/step - loss: 0.0061 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0069 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 83/100\n",
            "300/300 [==============================] - 0s 130us/step - loss: 0.0062 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0069 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 84/100\n",
            "300/300 [==============================] - 0s 129us/step - loss: 0.0060 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0066 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 85/100\n",
            "300/300 [==============================] - 0s 128us/step - loss: 0.0058 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0065 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 86/100\n",
            "300/300 [==============================] - 0s 122us/step - loss: 0.0058 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0064 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 87/100\n",
            "300/300 [==============================] - 0s 121us/step - loss: 0.0057 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0065 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 88/100\n",
            "300/300 [==============================] - 0s 116us/step - loss: 0.0056 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0064 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 89/100\n",
            "300/300 [==============================] - 0s 118us/step - loss: 0.0054 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0062 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 90/100\n",
            "300/300 [==============================] - 0s 116us/step - loss: 0.0057 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0073 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 91/100\n",
            "300/300 [==============================] - 0s 120us/step - loss: 0.0056 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0059 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 92/100\n",
            "300/300 [==============================] - 0s 148us/step - loss: 0.0050 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0061 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 93/100\n",
            "300/300 [==============================] - 0s 116us/step - loss: 0.0050 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0057 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 94/100\n",
            "300/300 [==============================] - 0s 118us/step - loss: 0.0049 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0056 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 95/100\n",
            "300/300 [==============================] - 0s 115us/step - loss: 0.0049 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0059 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 96/100\n",
            "300/300 [==============================] - 0s 126us/step - loss: 0.0049 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0054 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 97/100\n",
            "300/300 [==============================] - 0s 130us/step - loss: 0.0046 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0054 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 98/100\n",
            "300/300 [==============================] - 0s 123us/step - loss: 0.0046 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0052 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 99/100\n",
            "300/300 [==============================] - 0s 118us/step - loss: 0.0047 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0056 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n",
            "Epoch 100/100\n",
            "300/300 [==============================] - 0s 119us/step - loss: 0.0044 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000 - val_loss: 0.0050 - val_precision: 1.0000 - val_recall: 1.0000 - val_f1_score: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "ny-RqSHuB41C"
      },
      "cell_type": "markdown",
      "source": [
        "We now plot the training history."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "BlCWcUl7B41D",
        "outputId": "1b4a35cb-8b28-4be8-ca99-c6e68e8c249c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "plt.plot(history_adam.history['f1_score'])\n",
        "plt.plot(history_adam.history['val_f1_score'])\n",
        "plt.title('model f1 score')\n",
        "plt.ylabel('f1 score')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history_adam.history['loss'])\n",
        "plt.plot(history_adam.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "ZjtCfj465HoA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Visualization of solution"
      ]
    },
    {
      "metadata": {
        "id": "VI3ZCWZGnsRZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### SGD"
      ]
    },
    {
      "metadata": {
        "id": "OjxbuPKW5KWS",
        "colab_type": "code",
        "outputId": "40d6508e-beb5-403b-a807-2125959240e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "weights = model_sgd.get_weights()[0]\n",
        "weights = weights.reshape(IMAGE_SIZE, IMAGE_SIZE, weights.shape[1])\n",
        "_, [ax0, ax1, ax2] = plt.subplots(1, 3)\n",
        "ax0.imshow(weights[:,:,0], cmap='gray')\n",
        "ax1.imshow(weights[:,:,1], cmap='gray')\n",
        "ax2.imshow(weights[:,:,2], cmap='gray')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0xb3c390e10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "L7263erinwAh"
      },
      "cell_type": "markdown",
      "source": [
        "#### Adam"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "df0dpCmGnwAh",
        "outputId": "524b4f82-abbf-459d-9719-6ebcc1707249",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "weights = model_adam.get_weights()[0]\n",
        "weights = weights.reshape(IMAGE_SIZE, IMAGE_SIZE, weights.shape[1])\n",
        "_, [ax0, ax1, ax2] = plt.subplots(1, 3)\n",
        "ax0.imshow(weights[:,:,0], cmap='gray')\n",
        "ax1.imshow(weights[:,:,1], cmap='gray')\n",
        "ax2.imshow(weights[:,:,2], cmap='gray')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0xb37587a58>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "vhU0Og7RA_Oi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## A More Difficult Classification Problem"
      ]
    },
    {
      "metadata": {
        "id": "3kaahExhBIhT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Train and validation data\n",
        "We generate training and validation sets with shapes of different size and positions."
      ]
    },
    {
      "metadata": {
        "id": "YESUnKbSBAof",
        "colab_type": "code",
        "outputId": "3d11957c-1ced-4832-a9e6-bf20d694ba5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "[X_train, Y_train] = generate_dataset_classification(300, 20, True)\n",
        "[X_valid, Y_valid] = generate_dataset_classification(60, 20, True)\n",
        "Y_train = np_utils.to_categorical(Y_train)\n",
        "Y_valid = np_utils.to_categorical(Y_valid)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating data:\n",
            "0\n",
            "10\n",
            "20\n",
            "30\n",
            "40\n",
            "50\n",
            "60\n",
            "70\n",
            "80\n",
            "90\n",
            "100\n",
            "110\n",
            "120\n",
            "130\n",
            "140\n",
            "150\n",
            "160\n",
            "170\n",
            "180\n",
            "190\n",
            "200\n",
            "210\n",
            "220\n",
            "230\n",
            "240\n",
            "250\n",
            "260\n",
            "270\n",
            "280\n",
            "290\n",
            "Creating data:\n",
            "0\n",
            "10\n",
            "20\n",
            "30\n",
            "40\n",
            "50\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KMpQXKMvLaWV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Test Data\n",
        "We generate a test dataset to compare the models."
      ]
    },
    {
      "metadata": {
        "id": "Np7MGsSyLcRy",
        "colab_type": "code",
        "outputId": "8e1d6f52-0cf0-4e0b-d037-b8fd4bb8c6cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "[X_test, Y_test] = generate_test_set_classification()\n",
        "X_test = X_test.reshape(X_test.shape[0], IMAGE_SIZE*IMAGE_SIZE,)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating data:\n",
            "0\n",
            "10\n",
            "20\n",
            "30\n",
            "40\n",
            "50\n",
            "60\n",
            "70\n",
            "80\n",
            "90\n",
            "100\n",
            "110\n",
            "120\n",
            "130\n",
            "140\n",
            "150\n",
            "160\n",
            "170\n",
            "180\n",
            "190\n",
            "200\n",
            "210\n",
            "220\n",
            "230\n",
            "240\n",
            "250\n",
            "260\n",
            "270\n",
            "280\n",
            "290\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yvvk8IUDLiZt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Dense model train on moving shapes\n",
        "Lets train the previous models on this new data"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "f--PtPhFRhy8"
      },
      "cell_type": "markdown",
      "source": [
        "#### Stochastic gradient descent\n",
        "We train our model with SGD"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "NPoNUiuPRhy8",
        "outputId": "04ee5aae-946e-4be0-9abf-0a0a23772c25",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "optimizer = SGD(lr=0.001, momentum=0.0, decay=0.0, nesterov=False) # 0.001 learning rate without modifications during gradient descent\n",
        "loss = 'binary_crossentropy'\n",
        "metrics = [get_metrics(0.5)['precision'], get_metrics(0.5)['recall'], get_metrics(0.5)['f1_score']]\n",
        "\n",
        "model_sgd = get_model(optimizer, loss, metrics)\n",
        "\n",
        "history_sgd = model_sgd.fit(X_train, Y_train,\n",
        "          epochs=3000,\n",
        "          batch_size=64,\n",
        "          validation_data=(X_valid, Y_valid)\n",
        "         )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_3 (Dense)              (None, 3)                 15555     \n",
            "=================================================================\n",
            "Total params: 15,555\n",
            "Trainable params: 15,555\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 300 samples, validate on 60 samples\n",
            "Epoch 1/3000\n",
            "300/300 [==============================] - 1s 2ms/step - loss: 0.6627 - precision: 0.1269 - recall: 0.0767 - f1_score: 0.0935 - val_loss: 0.6487 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00\n",
            "Epoch 2/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.6398 - precision: 0.1200 - recall: 0.0067 - f1_score: 0.0126 - val_loss: 0.6496 - val_precision: 0.3333 - val_recall: 0.0333 - val_f1_score: 0.0606\n",
            "Epoch 3/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.6422 - precision: 0.2916 - recall: 0.0100 - f1_score: 0.0188 - val_loss: 0.6461 - val_precision: 0.5000 - val_recall: 0.0167 - val_f1_score: 0.0323\n",
            "Epoch 4/3000\n",
            "300/300 [==============================] - 0s 1ms/step - loss: 0.6340 - precision: 0.3720 - recall: 0.0133 - f1_score: 0.0253 - val_loss: 0.6446 - val_precision: 0.7500 - val_recall: 0.0500 - val_f1_score: 0.0937\n",
            "Epoch 5/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.6276 - precision: 0.3973 - recall: 0.0233 - f1_score: 0.0438 - val_loss: 0.6328 - val_precision: 1.0000 - val_recall: 0.0167 - val_f1_score: 0.0328\n",
            "Epoch 6/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.6214 - precision: 0.4289 - recall: 0.0167 - f1_score: 0.0315 - val_loss: 0.6332 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00\n",
            "Epoch 7/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.6212 - precision: 0.5000 - recall: 0.0200 - f1_score: 0.0379 - val_loss: 0.6239 - val_precision: 1.0000 - val_recall: 0.0333 - val_f1_score: 0.0645\n",
            "Epoch 8/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.6163 - precision: 0.5733 - recall: 0.0267 - f1_score: 0.0502 - val_loss: 0.6265 - val_precision: 0.3333 - val_recall: 0.0333 - val_f1_score: 0.0606\n",
            "Epoch 9/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.6144 - precision: 0.6279 - recall: 0.0400 - f1_score: 0.0736 - val_loss: 0.6280 - val_precision: 0.6000 - val_recall: 0.0500 - val_f1_score: 0.0923\n",
            "Epoch 10/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.6070 - precision: 0.4800 - recall: 0.0467 - f1_score: 0.0840 - val_loss: 0.6169 - val_precision: 1.0000 - val_recall: 0.0333 - val_f1_score: 0.0645\n",
            "Epoch 11/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.6125 - precision: 0.6019 - recall: 0.0333 - f1_score: 0.0620 - val_loss: 0.6155 - val_precision: 0.5000 - val_recall: 0.0500 - val_f1_score: 0.0909\n",
            "Epoch 12/3000\n",
            "300/300 [==============================] - 0s 82us/step - loss: 0.6015 - precision: 0.7003 - recall: 0.0433 - f1_score: 0.0805 - val_loss: 0.6111 - val_precision: 0.7500 - val_recall: 0.0500 - val_f1_score: 0.0937\n",
            "Epoch 13/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.5990 - precision: 0.7301 - recall: 0.0633 - f1_score: 0.1134 - val_loss: 0.6133 - val_precision: 0.6667 - val_recall: 0.0667 - val_f1_score: 0.1212\n",
            "Epoch 14/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.5975 - precision: 0.5164 - recall: 0.0567 - f1_score: 0.0979 - val_loss: 0.6092 - val_precision: 0.7500 - val_recall: 0.0500 - val_f1_score: 0.0937\n",
            "Epoch 15/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.5969 - precision: 0.7896 - recall: 0.0800 - f1_score: 0.1375 - val_loss: 0.6174 - val_precision: 0.5333 - val_recall: 0.1333 - val_f1_score: 0.2133\n",
            "Epoch 16/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.5941 - precision: 0.5850 - recall: 0.0733 - f1_score: 0.1281 - val_loss: 0.6094 - val_precision: 0.6667 - val_recall: 0.1000 - val_f1_score: 0.1739\n",
            "Epoch 17/3000\n",
            "300/300 [==============================] - 0s 58us/step - loss: 0.5881 - precision: 0.7476 - recall: 0.1100 - f1_score: 0.1847 - val_loss: 0.6017 - val_precision: 0.3750 - val_recall: 0.0500 - val_f1_score: 0.0882\n",
            "Epoch 18/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.5857 - precision: 0.6464 - recall: 0.0800 - f1_score: 0.1393 - val_loss: 0.6030 - val_precision: 0.7857 - val_recall: 0.1833 - val_f1_score: 0.2973\n",
            "Epoch 19/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.5862 - precision: 0.7538 - recall: 0.1000 - f1_score: 0.1754 - val_loss: 0.5957 - val_precision: 0.8333 - val_recall: 0.0833 - val_f1_score: 0.1515\n",
            "Epoch 20/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.5842 - precision: 0.7820 - recall: 0.1100 - f1_score: 0.1914 - val_loss: 0.5939 - val_precision: 0.8000 - val_recall: 0.1333 - val_f1_score: 0.2286\n",
            "Epoch 21/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.5817 - precision: 0.6996 - recall: 0.1200 - f1_score: 0.2035 - val_loss: 0.5920 - val_precision: 0.7778 - val_recall: 0.1167 - val_f1_score: 0.2029\n",
            "Epoch 22/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.5800 - precision: 0.8385 - recall: 0.1200 - f1_score: 0.2067 - val_loss: 0.5936 - val_precision: 0.7143 - val_recall: 0.1667 - val_f1_score: 0.2703\n",
            "Epoch 23/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.5818 - precision: 0.7695 - recall: 0.1367 - f1_score: 0.2301 - val_loss: 0.5894 - val_precision: 0.8571 - val_recall: 0.1000 - val_f1_score: 0.1791\n",
            "Epoch 24/3000\n",
            "300/300 [==============================] - 0s 78us/step - loss: 0.5754 - precision: 0.6854 - recall: 0.1567 - f1_score: 0.2496 - val_loss: 0.5877 - val_precision: 0.7500 - val_recall: 0.1000 - val_f1_score: 0.1765\n",
            "Epoch 25/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.5707 - precision: 0.8030 - recall: 0.1200 - f1_score: 0.2082 - val_loss: 0.5865 - val_precision: 0.8333 - val_recall: 0.1667 - val_f1_score: 0.2778\n",
            "Epoch 26/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.5673 - precision: 0.8034 - recall: 0.1433 - f1_score: 0.2408 - val_loss: 0.5888 - val_precision: 0.6923 - val_recall: 0.1500 - val_f1_score: 0.2466\n",
            "Epoch 27/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.5744 - precision: 0.7671 - recall: 0.1967 - f1_score: 0.3103 - val_loss: 0.5836 - val_precision: 0.7143 - val_recall: 0.1667 - val_f1_score: 0.2703\n",
            "Epoch 28/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.5639 - precision: 0.8051 - recall: 0.1467 - f1_score: 0.2468 - val_loss: 0.5810 - val_precision: 0.7692 - val_recall: 0.1667 - val_f1_score: 0.2740\n",
            "Epoch 29/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.5653 - precision: 0.8228 - recall: 0.1533 - f1_score: 0.2568 - val_loss: 0.5798 - val_precision: 0.7143 - val_recall: 0.1667 - val_f1_score: 0.2703\n",
            "Epoch 30/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.5627 - precision: 0.7563 - recall: 0.1433 - f1_score: 0.2401 - val_loss: 0.5802 - val_precision: 0.7333 - val_recall: 0.1833 - val_f1_score: 0.2933\n",
            "Epoch 31/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.5618 - precision: 0.7817 - recall: 0.1800 - f1_score: 0.2846 - val_loss: 0.5793 - val_precision: 0.7333 - val_recall: 0.1833 - val_f1_score: 0.2933\n",
            "Epoch 32/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.5627 - precision: 0.8471 - recall: 0.1733 - f1_score: 0.2844 - val_loss: 0.5768 - val_precision: 0.8889 - val_recall: 0.1333 - val_f1_score: 0.2319\n",
            "Epoch 33/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.5602 - precision: 0.7661 - recall: 0.1667 - f1_score: 0.2686 - val_loss: 0.5743 - val_precision: 0.9091 - val_recall: 0.1667 - val_f1_score: 0.2817\n",
            "Epoch 34/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.5564 - precision: 0.8734 - recall: 0.1767 - f1_score: 0.2884 - val_loss: 0.5758 - val_precision: 0.6875 - val_recall: 0.1833 - val_f1_score: 0.2895\n",
            "Epoch 35/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.5556 - precision: 0.8138 - recall: 0.1833 - f1_score: 0.2947 - val_loss: 0.5763 - val_precision: 0.7333 - val_recall: 0.1833 - val_f1_score: 0.2933\n",
            "Epoch 36/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.5529 - precision: 0.8094 - recall: 0.1800 - f1_score: 0.2877 - val_loss: 0.5709 - val_precision: 0.7333 - val_recall: 0.1833 - val_f1_score: 0.2933\n",
            "Epoch 37/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.5523 - precision: 0.7615 - recall: 0.1700 - f1_score: 0.2748 - val_loss: 0.5771 - val_precision: 0.6522 - val_recall: 0.2500 - val_f1_score: 0.3614\n",
            "Epoch 38/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.5552 - precision: 0.7559 - recall: 0.1967 - f1_score: 0.3079 - val_loss: 0.5737 - val_precision: 0.7647 - val_recall: 0.2167 - val_f1_score: 0.3377\n",
            "Epoch 39/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.5527 - precision: 0.7570 - recall: 0.2167 - f1_score: 0.3348 - val_loss: 0.5701 - val_precision: 0.7500 - val_recall: 0.2000 - val_f1_score: 0.3158\n",
            "Epoch 40/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.5489 - precision: 0.8181 - recall: 0.1833 - f1_score: 0.2974 - val_loss: 0.5669 - val_precision: 0.7333 - val_recall: 0.1833 - val_f1_score: 0.2933\n",
            "Epoch 41/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.5457 - precision: 0.8073 - recall: 0.2100 - f1_score: 0.3328 - val_loss: 0.5651 - val_precision: 0.7333 - val_recall: 0.1833 - val_f1_score: 0.2933\n",
            "Epoch 42/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.5479 - precision: 0.7654 - recall: 0.2033 - f1_score: 0.3170 - val_loss: 0.5700 - val_precision: 0.7222 - val_recall: 0.2167 - val_f1_score: 0.3333\n",
            "Epoch 43/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.5426 - precision: 0.8370 - recall: 0.2033 - f1_score: 0.3211 - val_loss: 0.5633 - val_precision: 0.7333 - val_recall: 0.1833 - val_f1_score: 0.2933\n",
            "Epoch 44/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.5457 - precision: 0.8171 - recall: 0.1800 - f1_score: 0.2932 - val_loss: 0.5618 - val_precision: 0.6471 - val_recall: 0.1833 - val_f1_score: 0.2857\n",
            "Epoch 45/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.5427 - precision: 0.8489 - recall: 0.2200 - f1_score: 0.3434 - val_loss: 0.5606 - val_precision: 0.7333 - val_recall: 0.1833 - val_f1_score: 0.2933\n",
            "Epoch 46/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.5418 - precision: 0.8106 - recall: 0.1933 - f1_score: 0.3099 - val_loss: 0.5729 - val_precision: 0.6250 - val_recall: 0.3333 - val_f1_score: 0.4348\n",
            "Epoch 47/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.5394 - precision: 0.7078 - recall: 0.2633 - f1_score: 0.3695 - val_loss: 0.5642 - val_precision: 0.6667 - val_recall: 0.2333 - val_f1_score: 0.3457\n",
            "Epoch 48/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.5399 - precision: 0.8162 - recall: 0.2433 - f1_score: 0.3612 - val_loss: 0.5757 - val_precision: 0.6842 - val_recall: 0.2167 - val_f1_score: 0.3291\n",
            "Epoch 49/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.5397 - precision: 0.8003 - recall: 0.2167 - f1_score: 0.3404 - val_loss: 0.5599 - val_precision: 0.7500 - val_recall: 0.2000 - val_f1_score: 0.3158\n",
            "Epoch 50/3000\n",
            "300/300 [==============================] - 0s 57us/step - loss: 0.5366 - precision: 0.7954 - recall: 0.2400 - f1_score: 0.3680 - val_loss: 0.5699 - val_precision: 0.5135 - val_recall: 0.3167 - val_f1_score: 0.3918\n",
            "Epoch 51/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.5434 - precision: 0.7595 - recall: 0.2433 - f1_score: 0.3573 - val_loss: 0.5564 - val_precision: 0.7333 - val_recall: 0.1833 - val_f1_score: 0.2933\n",
            "Epoch 52/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.5328 - precision: 0.7719 - recall: 0.2067 - f1_score: 0.3245 - val_loss: 0.5545 - val_precision: 0.6471 - val_recall: 0.1833 - val_f1_score: 0.2857\n",
            "Epoch 53/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.5342 - precision: 0.8548 - recall: 0.2200 - f1_score: 0.3471 - val_loss: 0.5555 - val_precision: 0.7059 - val_recall: 0.2000 - val_f1_score: 0.3117\n",
            "Epoch 54/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.5304 - precision: 0.8285 - recall: 0.2200 - f1_score: 0.3462 - val_loss: 0.5540 - val_precision: 0.7333 - val_recall: 0.1833 - val_f1_score: 0.2933\n",
            "Epoch 55/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.5296 - precision: 0.8497 - recall: 0.2267 - f1_score: 0.3571 - val_loss: 0.5533 - val_precision: 0.6471 - val_recall: 0.1833 - val_f1_score: 0.2857\n",
            "Epoch 56/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.5386 - precision: 0.7477 - recall: 0.2567 - f1_score: 0.3794 - val_loss: 0.5601 - val_precision: 0.6452 - val_recall: 0.3333 - val_f1_score: 0.4396\n",
            "Epoch 57/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.5305 - precision: 0.7886 - recall: 0.2767 - f1_score: 0.3994 - val_loss: 0.5616 - val_precision: 0.6667 - val_recall: 0.3667 - val_f1_score: 0.4731\n",
            "Epoch 58/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.5300 - precision: 0.7871 - recall: 0.2667 - f1_score: 0.3854 - val_loss: 0.5506 - val_precision: 0.7500 - val_recall: 0.2000 - val_f1_score: 0.3158\n",
            "Epoch 59/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.5335 - precision: 0.7620 - recall: 0.2833 - f1_score: 0.3997 - val_loss: 0.5558 - val_precision: 0.6250 - val_recall: 0.2500 - val_f1_score: 0.3571\n",
            "Epoch 60/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.5302 - precision: 0.7740 - recall: 0.2500 - f1_score: 0.3712 - val_loss: 0.5476 - val_precision: 0.7500 - val_recall: 0.2000 - val_f1_score: 0.3158\n",
            "Epoch 61/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.5262 - precision: 0.8448 - recall: 0.2433 - f1_score: 0.3735 - val_loss: 0.5486 - val_precision: 0.7059 - val_recall: 0.2000 - val_f1_score: 0.3117\n",
            "Epoch 62/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.5229 - precision: 0.8595 - recall: 0.2400 - f1_score: 0.3698 - val_loss: 0.5543 - val_precision: 0.6897 - val_recall: 0.3333 - val_f1_score: 0.4494\n",
            "Epoch 63/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.5227 - precision: 0.8091 - recall: 0.3367 - f1_score: 0.4658 - val_loss: 0.5505 - val_precision: 0.6154 - val_recall: 0.2667 - val_f1_score: 0.3721\n",
            "Epoch 64/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.5235 - precision: 0.7886 - recall: 0.2500 - f1_score: 0.3788 - val_loss: 0.5554 - val_precision: 0.6562 - val_recall: 0.3500 - val_f1_score: 0.4565\n",
            "Epoch 65/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.5229 - precision: 0.7766 - recall: 0.2600 - f1_score: 0.3782 - val_loss: 0.5518 - val_precision: 0.6774 - val_recall: 0.3500 - val_f1_score: 0.4615\n",
            "Epoch 66/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.5223 - precision: 0.7630 - recall: 0.2633 - f1_score: 0.3856 - val_loss: 0.5469 - val_precision: 0.6667 - val_recall: 0.2667 - val_f1_score: 0.3810\n",
            "Epoch 67/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.5225 - precision: 0.8346 - recall: 0.2667 - f1_score: 0.3976 - val_loss: 0.5468 - val_precision: 0.6522 - val_recall: 0.2500 - val_f1_score: 0.3614\n",
            "Epoch 68/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.5175 - precision: 0.8496 - recall: 0.2767 - f1_score: 0.4132 - val_loss: 0.5483 - val_precision: 0.7368 - val_recall: 0.2333 - val_f1_score: 0.3544\n",
            "Epoch 69/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.5199 - precision: 0.7977 - recall: 0.2400 - f1_score: 0.3675 - val_loss: 0.5477 - val_precision: 0.7368 - val_recall: 0.2333 - val_f1_score: 0.3544\n",
            "Epoch 70/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.5233 - precision: 0.8054 - recall: 0.2533 - f1_score: 0.3789 - val_loss: 0.5493 - val_precision: 0.7222 - val_recall: 0.2167 - val_f1_score: 0.3333\n",
            "Epoch 71/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.5229 - precision: 0.7336 - recall: 0.2633 - f1_score: 0.3855 - val_loss: 0.5411 - val_precision: 0.7778 - val_recall: 0.2333 - val_f1_score: 0.3590\n",
            "Epoch 72/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.5156 - precision: 0.8006 - recall: 0.2433 - f1_score: 0.3686 - val_loss: 0.5398 - val_precision: 0.7647 - val_recall: 0.2167 - val_f1_score: 0.3377\n",
            "Epoch 73/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.5138 - precision: 0.8280 - recall: 0.2567 - f1_score: 0.3905 - val_loss: 0.5424 - val_precision: 0.6500 - val_recall: 0.2167 - val_f1_score: 0.3250\n",
            "Epoch 74/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.5156 - precision: 0.7976 - recall: 0.2433 - f1_score: 0.3701 - val_loss: 0.5412 - val_precision: 0.7222 - val_recall: 0.2167 - val_f1_score: 0.3333\n",
            "Epoch 75/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.5151 - precision: 0.8579 - recall: 0.2733 - f1_score: 0.4089 - val_loss: 0.5389 - val_precision: 0.7000 - val_recall: 0.2333 - val_f1_score: 0.3500\n",
            "Epoch 76/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.5115 - precision: 0.8505 - recall: 0.2733 - f1_score: 0.4118 - val_loss: 0.5438 - val_precision: 0.7083 - val_recall: 0.2833 - val_f1_score: 0.4048\n",
            "Epoch 77/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.5156 - precision: 0.7815 - recall: 0.2867 - f1_score: 0.4148 - val_loss: 0.5406 - val_precision: 0.6923 - val_recall: 0.3000 - val_f1_score: 0.4186\n",
            "Epoch 78/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.5098 - precision: 0.8502 - recall: 0.2767 - f1_score: 0.4149 - val_loss: 0.5346 - val_precision: 0.7647 - val_recall: 0.2167 - val_f1_score: 0.3377\n",
            "Epoch 79/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.5096 - precision: 0.8181 - recall: 0.2800 - f1_score: 0.4145 - val_loss: 0.5356 - val_precision: 0.6667 - val_recall: 0.2000 - val_f1_score: 0.3077\n",
            "Epoch 80/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.5127 - precision: 0.7984 - recall: 0.2800 - f1_score: 0.4133 - val_loss: 0.5356 - val_precision: 0.7273 - val_recall: 0.2667 - val_f1_score: 0.3902\n",
            "Epoch 81/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.5116 - precision: 0.7513 - recall: 0.3200 - f1_score: 0.4450 - val_loss: 0.5344 - val_precision: 0.7000 - val_recall: 0.2333 - val_f1_score: 0.3500\n",
            "Epoch 82/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.5072 - precision: 0.8298 - recall: 0.2700 - f1_score: 0.4025 - val_loss: 0.5363 - val_precision: 0.6500 - val_recall: 0.2167 - val_f1_score: 0.3250\n",
            "Epoch 83/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.5091 - precision: 0.7928 - recall: 0.3033 - f1_score: 0.4381 - val_loss: 0.5329 - val_precision: 0.7778 - val_recall: 0.2333 - val_f1_score: 0.3590\n",
            "Epoch 84/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.5061 - precision: 0.7949 - recall: 0.2500 - f1_score: 0.3783 - val_loss: 0.5398 - val_precision: 0.6970 - val_recall: 0.3833 - val_f1_score: 0.4946\n",
            "Epoch 85/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.5072 - precision: 0.7947 - recall: 0.2833 - f1_score: 0.4140 - val_loss: 0.5306 - val_precision: 0.7059 - val_recall: 0.2000 - val_f1_score: 0.3117\n",
            "Epoch 86/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.5090 - precision: 0.8201 - recall: 0.2700 - f1_score: 0.4051 - val_loss: 0.5327 - val_precision: 0.6667 - val_recall: 0.2333 - val_f1_score: 0.3457\n",
            "Epoch 87/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.5056 - precision: 0.8088 - recall: 0.3300 - f1_score: 0.4646 - val_loss: 0.5315 - val_precision: 0.6667 - val_recall: 0.2333 - val_f1_score: 0.3457\n",
            "Epoch 88/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.5029 - precision: 0.8201 - recall: 0.3033 - f1_score: 0.4423 - val_loss: 0.5327 - val_precision: 0.6667 - val_recall: 0.2667 - val_f1_score: 0.3810\n",
            "Epoch 89/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.5078 - precision: 0.7805 - recall: 0.2733 - f1_score: 0.4007 - val_loss: 0.5279 - val_precision: 0.7778 - val_recall: 0.2333 - val_f1_score: 0.3590\n",
            "Epoch 90/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.5023 - precision: 0.8354 - recall: 0.2800 - f1_score: 0.4169 - val_loss: 0.5282 - val_precision: 0.6842 - val_recall: 0.2167 - val_f1_score: 0.3291\n",
            "Epoch 91/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.5015 - precision: 0.8359 - recall: 0.2767 - f1_score: 0.4143 - val_loss: 0.5324 - val_precision: 0.6500 - val_recall: 0.2167 - val_f1_score: 0.3250\n",
            "Epoch 92/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.5032 - precision: 0.8141 - recall: 0.2800 - f1_score: 0.4141 - val_loss: 0.5285 - val_precision: 0.7000 - val_recall: 0.2333 - val_f1_score: 0.3500\n",
            "Epoch 93/3000\n",
            "300/300 [==============================] - 0s 58us/step - loss: 0.5012 - precision: 0.8249 - recall: 0.3000 - f1_score: 0.4375 - val_loss: 0.5310 - val_precision: 0.6522 - val_recall: 0.2500 - val_f1_score: 0.3614\n",
            "Epoch 94/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.5006 - precision: 0.7710 - recall: 0.2833 - f1_score: 0.4114 - val_loss: 0.5315 - val_precision: 0.7333 - val_recall: 0.3667 - val_f1_score: 0.4889\n",
            "Epoch 95/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.4987 - precision: 0.7962 - recall: 0.2967 - f1_score: 0.4227 - val_loss: 0.5252 - val_precision: 0.7222 - val_recall: 0.2167 - val_f1_score: 0.3333\n",
            "Epoch 96/3000\n",
            "300/300 [==============================] - 0s 59us/step - loss: 0.5011 - precision: 0.8039 - recall: 0.2933 - f1_score: 0.4294 - val_loss: 0.5256 - val_precision: 0.7000 - val_recall: 0.2333 - val_f1_score: 0.3500\n",
            "Epoch 97/3000\n",
            "300/300 [==============================] - 0s 59us/step - loss: 0.4970 - precision: 0.8218 - recall: 0.2800 - f1_score: 0.4165 - val_loss: 0.5275 - val_precision: 0.7778 - val_recall: 0.2333 - val_f1_score: 0.3590\n",
            "Epoch 98/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.5053 - precision: 0.8112 - recall: 0.3233 - f1_score: 0.4589 - val_loss: 0.5236 - val_precision: 0.7368 - val_recall: 0.2333 - val_f1_score: 0.3544\n",
            "Epoch 99/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.4951 - precision: 0.8190 - recall: 0.2900 - f1_score: 0.4280 - val_loss: 0.5266 - val_precision: 0.7222 - val_recall: 0.2167 - val_f1_score: 0.3333\n",
            "Epoch 100/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.4968 - precision: 0.8091 - recall: 0.3033 - f1_score: 0.4358 - val_loss: 0.5225 - val_precision: 0.7368 - val_recall: 0.2333 - val_f1_score: 0.3544\n",
            "Epoch 101/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.4945 - precision: 0.7951 - recall: 0.3000 - f1_score: 0.4328 - val_loss: 0.5246 - val_precision: 0.6842 - val_recall: 0.2167 - val_f1_score: 0.3291\n",
            "Epoch 102/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.4947 - precision: 0.8245 - recall: 0.2833 - f1_score: 0.4192 - val_loss: 0.5245 - val_precision: 0.6522 - val_recall: 0.2500 - val_f1_score: 0.3614\n",
            "Epoch 103/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.4951 - precision: 0.8511 - recall: 0.2867 - f1_score: 0.4274 - val_loss: 0.5236 - val_precision: 0.6667 - val_recall: 0.2333 - val_f1_score: 0.3457\n",
            "Epoch 104/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.4952 - precision: 0.7768 - recall: 0.3533 - f1_score: 0.4826 - val_loss: 0.5389 - val_precision: 0.6667 - val_recall: 0.3333 - val_f1_score: 0.4444\n",
            "Epoch 105/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.4975 - precision: 0.7990 - recall: 0.3400 - f1_score: 0.4738 - val_loss: 0.5198 - val_precision: 0.7778 - val_recall: 0.2333 - val_f1_score: 0.3590\n",
            "Epoch 106/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.4912 - precision: 0.8207 - recall: 0.2967 - f1_score: 0.4350 - val_loss: 0.5235 - val_precision: 0.6818 - val_recall: 0.2500 - val_f1_score: 0.3659\n",
            "Epoch 107/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.5003 - precision: 0.7665 - recall: 0.3433 - f1_score: 0.4630 - val_loss: 0.5225 - val_precision: 0.6842 - val_recall: 0.2167 - val_f1_score: 0.3291\n",
            "Epoch 108/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.4899 - precision: 0.8401 - recall: 0.3033 - f1_score: 0.4438 - val_loss: 0.5237 - val_precision: 0.7000 - val_recall: 0.3500 - val_f1_score: 0.4667\n",
            "Epoch 109/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.4914 - precision: 0.7730 - recall: 0.3433 - f1_score: 0.4672 - val_loss: 0.5198 - val_precision: 0.7778 - val_recall: 0.2333 - val_f1_score: 0.3590\n",
            "Epoch 110/3000\n",
            "300/300 [==============================] - 0s 59us/step - loss: 0.4961 - precision: 0.7624 - recall: 0.3733 - f1_score: 0.4981 - val_loss: 0.5263 - val_precision: 0.7000 - val_recall: 0.3500 - val_f1_score: 0.4667\n",
            "Epoch 111/3000\n",
            "300/300 [==============================] - 0s 59us/step - loss: 0.4941 - precision: 0.8266 - recall: 0.3233 - f1_score: 0.4606 - val_loss: 0.5176 - val_precision: 0.7222 - val_recall: 0.2167 - val_f1_score: 0.3333\n",
            "Epoch 112/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.4943 - precision: 0.7863 - recall: 0.3333 - f1_score: 0.4630 - val_loss: 0.5173 - val_precision: 0.7000 - val_recall: 0.2333 - val_f1_score: 0.3500\n",
            "Epoch 113/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.4922 - precision: 0.7981 - recall: 0.3300 - f1_score: 0.4635 - val_loss: 0.5158 - val_precision: 0.7368 - val_recall: 0.2333 - val_f1_score: 0.3544\n",
            "Epoch 114/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.4903 - precision: 0.8151 - recall: 0.3267 - f1_score: 0.4636 - val_loss: 0.5240 - val_precision: 0.5429 - val_recall: 0.3167 - val_f1_score: 0.4000\n",
            "Epoch 115/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.4961 - precision: 0.7354 - recall: 0.3467 - f1_score: 0.4660 - val_loss: 0.5174 - val_precision: 0.7407 - val_recall: 0.3333 - val_f1_score: 0.4598\n",
            "Epoch 116/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.4875 - precision: 0.8158 - recall: 0.3700 - f1_score: 0.5028 - val_loss: 0.5184 - val_precision: 0.7222 - val_recall: 0.2167 - val_f1_score: 0.3333\n",
            "Epoch 117/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.4868 - precision: 0.8354 - recall: 0.3267 - f1_score: 0.4677 - val_loss: 0.5193 - val_precision: 0.6667 - val_recall: 0.2333 - val_f1_score: 0.3457\n",
            "Epoch 118/3000\n",
            "300/300 [==============================] - 0s 59us/step - loss: 0.4894 - precision: 0.8014 - recall: 0.3367 - f1_score: 0.4733 - val_loss: 0.5269 - val_precision: 0.6757 - val_recall: 0.4167 - val_f1_score: 0.5155\n",
            "Epoch 119/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.4873 - precision: 0.7780 - recall: 0.3567 - f1_score: 0.4789 - val_loss: 0.5151 - val_precision: 0.6800 - val_recall: 0.2833 - val_f1_score: 0.4000\n",
            "Epoch 120/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.4904 - precision: 0.7977 - recall: 0.3600 - f1_score: 0.4903 - val_loss: 0.5137 - val_precision: 0.7391 - val_recall: 0.2833 - val_f1_score: 0.4096\n",
            "Epoch 121/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.4874 - precision: 0.8145 - recall: 0.3567 - f1_score: 0.4956 - val_loss: 0.5135 - val_precision: 0.7778 - val_recall: 0.2333 - val_f1_score: 0.3590\n",
            "Epoch 122/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.4849 - precision: 0.8339 - recall: 0.3133 - f1_score: 0.4547 - val_loss: 0.5133 - val_precision: 0.7407 - val_recall: 0.3333 - val_f1_score: 0.4598\n",
            "Epoch 123/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.4844 - precision: 0.8176 - recall: 0.3467 - f1_score: 0.4837 - val_loss: 0.5214 - val_precision: 0.7500 - val_recall: 0.2500 - val_f1_score: 0.3750\n",
            "Epoch 124/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.4840 - precision: 0.8057 - recall: 0.3167 - f1_score: 0.4529 - val_loss: 0.5120 - val_precision: 0.7778 - val_recall: 0.2333 - val_f1_score: 0.3590\n",
            "Epoch 125/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.4896 - precision: 0.7747 - recall: 0.3700 - f1_score: 0.4968 - val_loss: 0.5108 - val_precision: 0.7368 - val_recall: 0.2333 - val_f1_score: 0.3544\n",
            "Epoch 126/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.4836 - precision: 0.8139 - recall: 0.3133 - f1_score: 0.4520 - val_loss: 0.5216 - val_precision: 0.6944 - val_recall: 0.4167 - val_f1_score: 0.5208\n",
            "Epoch 127/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.4927 - precision: 0.7485 - recall: 0.4000 - f1_score: 0.5139 - val_loss: 0.5195 - val_precision: 0.6800 - val_recall: 0.2833 - val_f1_score: 0.4000\n",
            "Epoch 128/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.4827 - precision: 0.7961 - recall: 0.3233 - f1_score: 0.4574 - val_loss: 0.5114 - val_precision: 0.7407 - val_recall: 0.3333 - val_f1_score: 0.4598\n",
            "Epoch 129/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.4798 - precision: 0.8292 - recall: 0.3400 - f1_score: 0.4802 - val_loss: 0.5158 - val_precision: 0.7097 - val_recall: 0.3667 - val_f1_score: 0.4835\n",
            "Epoch 130/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.4799 - precision: 0.7922 - recall: 0.3433 - f1_score: 0.4773 - val_loss: 0.5140 - val_precision: 0.7333 - val_recall: 0.3667 - val_f1_score: 0.4889\n",
            "Epoch 131/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.4794 - precision: 0.7855 - recall: 0.3800 - f1_score: 0.5105 - val_loss: 0.5099 - val_precision: 0.6818 - val_recall: 0.2500 - val_f1_score: 0.3659\n",
            "Epoch 132/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.4789 - precision: 0.8123 - recall: 0.3433 - f1_score: 0.4808 - val_loss: 0.5107 - val_precision: 0.7273 - val_recall: 0.2667 - val_f1_score: 0.3902\n",
            "Epoch 133/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.4783 - precision: 0.8227 - recall: 0.3400 - f1_score: 0.4796 - val_loss: 0.5083 - val_precision: 0.7273 - val_recall: 0.2667 - val_f1_score: 0.3902\n",
            "Epoch 134/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.4856 - precision: 0.8155 - recall: 0.3467 - f1_score: 0.4842 - val_loss: 0.5254 - val_precision: 0.5238 - val_recall: 0.3667 - val_f1_score: 0.4314\n",
            "Epoch 135/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.4869 - precision: 0.7653 - recall: 0.3467 - f1_score: 0.4714 - val_loss: 0.5066 - val_precision: 0.7368 - val_recall: 0.2333 - val_f1_score: 0.3544\n",
            "Epoch 136/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.4821 - precision: 0.8017 - recall: 0.3800 - f1_score: 0.5138 - val_loss: 0.5094 - val_precision: 0.7368 - val_recall: 0.2333 - val_f1_score: 0.3544\n",
            "Epoch 137/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.4761 - precision: 0.8088 - recall: 0.3267 - f1_score: 0.4638 - val_loss: 0.5061 - val_precision: 0.7391 - val_recall: 0.2833 - val_f1_score: 0.4096\n",
            "Epoch 138/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.4790 - precision: 0.8161 - recall: 0.3700 - f1_score: 0.5089 - val_loss: 0.5073 - val_precision: 0.7273 - val_recall: 0.2667 - val_f1_score: 0.3902\n",
            "Epoch 139/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.4759 - precision: 0.8338 - recall: 0.3567 - f1_score: 0.4969 - val_loss: 0.5057 - val_precision: 0.6957 - val_recall: 0.2667 - val_f1_score: 0.3855\n",
            "Epoch 140/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.4751 - precision: 0.8205 - recall: 0.3433 - f1_score: 0.4830 - val_loss: 0.5120 - val_precision: 0.6875 - val_recall: 0.3667 - val_f1_score: 0.4783\n",
            "Epoch 141/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.4777 - precision: 0.8142 - recall: 0.3767 - f1_score: 0.5126 - val_loss: 0.5046 - val_precision: 0.7000 - val_recall: 0.2333 - val_f1_score: 0.3500\n",
            "Epoch 142/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.4729 - precision: 0.8255 - recall: 0.3467 - f1_score: 0.4861 - val_loss: 0.5057 - val_precision: 0.7600 - val_recall: 0.3167 - val_f1_score: 0.4471\n",
            "Epoch 143/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.4751 - precision: 0.8321 - recall: 0.3467 - f1_score: 0.4852 - val_loss: 0.5047 - val_precision: 0.7600 - val_recall: 0.3167 - val_f1_score: 0.4471\n",
            "Epoch 144/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.4752 - precision: 0.8424 - recall: 0.3967 - f1_score: 0.5366 - val_loss: 0.5148 - val_precision: 0.6944 - val_recall: 0.4167 - val_f1_score: 0.5208\n",
            "Epoch 145/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.4794 - precision: 0.7561 - recall: 0.4267 - f1_score: 0.5419 - val_loss: 0.5061 - val_precision: 0.7500 - val_recall: 0.2500 - val_f1_score: 0.3750\n",
            "Epoch 146/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.4718 - precision: 0.8302 - recall: 0.3733 - f1_score: 0.5105 - val_loss: 0.5058 - val_precision: 0.6538 - val_recall: 0.2833 - val_f1_score: 0.3953\n",
            "Epoch 147/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.4700 - precision: 0.8255 - recall: 0.4033 - f1_score: 0.5396 - val_loss: 0.5071 - val_precision: 0.7097 - val_recall: 0.3667 - val_f1_score: 0.4835\n",
            "Epoch 148/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.4727 - precision: 0.8292 - recall: 0.3933 - f1_score: 0.5286 - val_loss: 0.5094 - val_precision: 0.7353 - val_recall: 0.4167 - val_f1_score: 0.5319\n",
            "Epoch 149/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.4756 - precision: 0.7527 - recall: 0.4333 - f1_score: 0.5454 - val_loss: 0.5090 - val_precision: 0.7353 - val_recall: 0.4167 - val_f1_score: 0.5319\n",
            "Epoch 150/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.4736 - precision: 0.7892 - recall: 0.3700 - f1_score: 0.4970 - val_loss: 0.5013 - val_precision: 0.7368 - val_recall: 0.2333 - val_f1_score: 0.3544\n",
            "Epoch 151/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.4701 - precision: 0.8295 - recall: 0.3533 - f1_score: 0.4901 - val_loss: 0.5070 - val_precision: 0.5588 - val_recall: 0.3167 - val_f1_score: 0.4043\n",
            "Epoch 152/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.4819 - precision: 0.7466 - recall: 0.4367 - f1_score: 0.5479 - val_loss: 0.5010 - val_precision: 0.6957 - val_recall: 0.2667 - val_f1_score: 0.3855\n",
            "Epoch 153/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.4696 - precision: 0.8211 - recall: 0.3800 - f1_score: 0.5150 - val_loss: 0.5002 - val_precision: 0.7368 - val_recall: 0.2333 - val_f1_score: 0.3544\n",
            "Epoch 154/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.4702 - precision: 0.7848 - recall: 0.3567 - f1_score: 0.4896 - val_loss: 0.5001 - val_precision: 0.6957 - val_recall: 0.2667 - val_f1_score: 0.3855\n",
            "Epoch 155/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.4706 - precision: 0.8134 - recall: 0.3867 - f1_score: 0.5203 - val_loss: 0.5024 - val_precision: 0.7500 - val_recall: 0.3500 - val_f1_score: 0.4773\n",
            "Epoch 156/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.4706 - precision: 0.8178 - recall: 0.4133 - f1_score: 0.5415 - val_loss: 0.5021 - val_precision: 0.6957 - val_recall: 0.2667 - val_f1_score: 0.3855\n",
            "Epoch 157/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.4708 - precision: 0.7976 - recall: 0.3767 - f1_score: 0.5049 - val_loss: 0.5005 - val_precision: 0.7308 - val_recall: 0.3167 - val_f1_score: 0.4419\n",
            "Epoch 158/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.4663 - precision: 0.8149 - recall: 0.3833 - f1_score: 0.5181 - val_loss: 0.5014 - val_precision: 0.7895 - val_recall: 0.2500 - val_f1_score: 0.3797\n",
            "Epoch 159/3000\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.4761 - precision: 0.7822 - recall: 0.3967 - f1_score: 0.5141 - val_loss: 0.4992 - val_precision: 0.7407 - val_recall: 0.3333 - val_f1_score: 0.4598\n",
            "Epoch 160/3000\n",
            "300/300 [==============================] - 0s 135us/step - loss: 0.4660 - precision: 0.8407 - recall: 0.3833 - f1_score: 0.5193 - val_loss: 0.4984 - val_precision: 0.6957 - val_recall: 0.2667 - val_f1_score: 0.3855\n",
            "Epoch 161/3000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.4683 - precision: 0.7806 - recall: 0.3833 - f1_score: 0.5113 - val_loss: 0.5089 - val_precision: 0.6757 - val_recall: 0.4167 - val_f1_score: 0.5155\n",
            "Epoch 162/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.4710 - precision: 0.7959 - recall: 0.4000 - f1_score: 0.5284 - val_loss: 0.4981 - val_precision: 0.7500 - val_recall: 0.2500 - val_f1_score: 0.3750\n",
            "Epoch 163/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.4663 - precision: 0.8145 - recall: 0.4067 - f1_score: 0.5395 - val_loss: 0.5005 - val_precision: 0.6667 - val_recall: 0.2667 - val_f1_score: 0.3810\n",
            "Epoch 164/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.4671 - precision: 0.8194 - recall: 0.3800 - f1_score: 0.5143 - val_loss: 0.4989 - val_precision: 0.7241 - val_recall: 0.3500 - val_f1_score: 0.4719\n",
            "Epoch 165/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.4635 - precision: 0.8265 - recall: 0.4233 - f1_score: 0.5577 - val_loss: 0.4975 - val_precision: 0.7083 - val_recall: 0.2833 - val_f1_score: 0.4048\n",
            "Epoch 166/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.4661 - precision: 0.7960 - recall: 0.3967 - f1_score: 0.5282 - val_loss: 0.4991 - val_precision: 0.7895 - val_recall: 0.2500 - val_f1_score: 0.3797\n",
            "Epoch 167/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.4692 - precision: 0.7788 - recall: 0.3967 - f1_score: 0.5249 - val_loss: 0.5007 - val_precision: 0.7188 - val_recall: 0.3833 - val_f1_score: 0.5000\n",
            "Epoch 168/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.4628 - precision: 0.7978 - recall: 0.3967 - f1_score: 0.5268 - val_loss: 0.4993 - val_precision: 0.6296 - val_recall: 0.2833 - val_f1_score: 0.3908\n",
            "Epoch 169/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.4630 - precision: 0.8014 - recall: 0.3767 - f1_score: 0.5095 - val_loss: 0.4977 - val_precision: 0.7241 - val_recall: 0.3500 - val_f1_score: 0.4719\n",
            "Epoch 170/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.4644 - precision: 0.7915 - recall: 0.4300 - f1_score: 0.5560 - val_loss: 0.4957 - val_precision: 0.6957 - val_recall: 0.2667 - val_f1_score: 0.3855\n",
            "Epoch 171/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.4630 - precision: 0.8188 - recall: 0.4300 - f1_score: 0.5598 - val_loss: 0.4967 - val_precision: 0.6818 - val_recall: 0.2500 - val_f1_score: 0.3659\n",
            "Epoch 172/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.4617 - precision: 0.8230 - recall: 0.3833 - f1_score: 0.5189 - val_loss: 0.4944 - val_precision: 0.6786 - val_recall: 0.3167 - val_f1_score: 0.4318\n",
            "Epoch 173/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.4620 - precision: 0.8146 - recall: 0.4267 - f1_score: 0.5568 - val_loss: 0.4958 - val_precision: 0.7273 - val_recall: 0.2667 - val_f1_score: 0.3902\n",
            "Epoch 174/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.4668 - precision: 0.7705 - recall: 0.4167 - f1_score: 0.5395 - val_loss: 0.4957 - val_precision: 0.7273 - val_recall: 0.2667 - val_f1_score: 0.3902\n",
            "Epoch 175/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.4638 - precision: 0.8057 - recall: 0.4167 - f1_score: 0.5440 - val_loss: 0.4941 - val_precision: 0.7037 - val_recall: 0.3167 - val_f1_score: 0.4368\n",
            "Epoch 176/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.4618 - precision: 0.8176 - recall: 0.4467 - f1_score: 0.5767 - val_loss: 0.5049 - val_precision: 0.7429 - val_recall: 0.4333 - val_f1_score: 0.5474\n",
            "Epoch 177/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.4728 - precision: 0.7607 - recall: 0.4133 - f1_score: 0.5305 - val_loss: 0.5011 - val_precision: 0.7429 - val_recall: 0.4333 - val_f1_score: 0.5474\n",
            "Epoch 178/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.4596 - precision: 0.7593 - recall: 0.4467 - f1_score: 0.5592 - val_loss: 0.4942 - val_precision: 0.7143 - val_recall: 0.2500 - val_f1_score: 0.3704\n",
            "Epoch 179/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.4587 - precision: 0.8363 - recall: 0.3833 - f1_score: 0.5254 - val_loss: 0.4929 - val_precision: 0.6400 - val_recall: 0.2667 - val_f1_score: 0.3765\n",
            "Epoch 180/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.4585 - precision: 0.7936 - recall: 0.4600 - f1_score: 0.5788 - val_loss: 0.4959 - val_precision: 0.8000 - val_recall: 0.2667 - val_f1_score: 0.4000\n",
            "Epoch 181/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.4590 - precision: 0.7960 - recall: 0.4167 - f1_score: 0.5432 - val_loss: 0.4933 - val_precision: 0.7273 - val_recall: 0.2667 - val_f1_score: 0.3902\n",
            "Epoch 182/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.4589 - precision: 0.7893 - recall: 0.4200 - f1_score: 0.5443 - val_loss: 0.4950 - val_precision: 0.7083 - val_recall: 0.2833 - val_f1_score: 0.4048\n",
            "Epoch 183/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.4583 - precision: 0.8203 - recall: 0.3900 - f1_score: 0.5236 - val_loss: 0.4931 - val_precision: 0.7241 - val_recall: 0.3500 - val_f1_score: 0.4719\n",
            "Epoch 184/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.4615 - precision: 0.7669 - recall: 0.4267 - f1_score: 0.5453 - val_loss: 0.4930 - val_precision: 0.7333 - val_recall: 0.3667 - val_f1_score: 0.4889\n",
            "Epoch 185/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.4619 - precision: 0.7940 - recall: 0.4267 - f1_score: 0.5537 - val_loss: 0.4915 - val_precision: 0.6818 - val_recall: 0.2500 - val_f1_score: 0.3659\n",
            "Epoch 186/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.4546 - precision: 0.8384 - recall: 0.4100 - f1_score: 0.5504 - val_loss: 0.4993 - val_precision: 0.7429 - val_recall: 0.4333 - val_f1_score: 0.5474\n",
            "Epoch 187/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.4595 - precision: 0.7890 - recall: 0.4100 - f1_score: 0.5360 - val_loss: 0.4937 - val_precision: 0.7692 - val_recall: 0.3333 - val_f1_score: 0.4651\n",
            "Epoch 188/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.4586 - precision: 0.8236 - recall: 0.4033 - f1_score: 0.5386 - val_loss: 0.4900 - val_precision: 0.6786 - val_recall: 0.3167 - val_f1_score: 0.4318\n",
            "Epoch 189/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.4644 - precision: 0.7666 - recall: 0.4267 - f1_score: 0.5457 - val_loss: 0.4925 - val_precision: 0.7419 - val_recall: 0.3833 - val_f1_score: 0.5055\n",
            "Epoch 190/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.4558 - precision: 0.7908 - recall: 0.4333 - f1_score: 0.5575 - val_loss: 0.4957 - val_precision: 0.7188 - val_recall: 0.3833 - val_f1_score: 0.5000\n",
            "Epoch 191/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.4586 - precision: 0.7777 - recall: 0.4433 - f1_score: 0.5593 - val_loss: 0.4997 - val_precision: 0.7273 - val_recall: 0.4000 - val_f1_score: 0.5161\n",
            "Epoch 192/3000\n",
            "300/300 [==============================] - 0s 81us/step - loss: 0.4566 - precision: 0.7774 - recall: 0.4267 - f1_score: 0.5488 - val_loss: 0.4892 - val_precision: 0.6923 - val_recall: 0.3000 - val_f1_score: 0.4186\n",
            "Epoch 193/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.4523 - precision: 0.8404 - recall: 0.4033 - f1_score: 0.5442 - val_loss: 0.4894 - val_precision: 0.7083 - val_recall: 0.2833 - val_f1_score: 0.4048\n",
            "Epoch 194/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.4552 - precision: 0.8380 - recall: 0.4267 - f1_score: 0.5618 - val_loss: 0.4901 - val_precision: 0.7273 - val_recall: 0.2667 - val_f1_score: 0.3902\n",
            "Epoch 195/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.4554 - precision: 0.8000 - recall: 0.4233 - f1_score: 0.5518 - val_loss: 0.4892 - val_precision: 0.7083 - val_recall: 0.2833 - val_f1_score: 0.4048\n",
            "Epoch 196/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.4507 - precision: 0.8032 - recall: 0.4100 - f1_score: 0.5405 - val_loss: 0.4930 - val_precision: 0.7586 - val_recall: 0.3667 - val_f1_score: 0.4944\n",
            "Epoch 197/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.4636 - precision: 0.7565 - recall: 0.4300 - f1_score: 0.5460 - val_loss: 0.4878 - val_precision: 0.7143 - val_recall: 0.3333 - val_f1_score: 0.4545\n",
            "Epoch 198/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.4505 - precision: 0.8310 - recall: 0.4033 - f1_score: 0.5408 - val_loss: 0.4887 - val_precision: 0.7391 - val_recall: 0.2833 - val_f1_score: 0.4096\n",
            "Epoch 199/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.4524 - precision: 0.8006 - recall: 0.4467 - f1_score: 0.5721 - val_loss: 0.4888 - val_precision: 0.6538 - val_recall: 0.2833 - val_f1_score: 0.3953\n",
            "Epoch 200/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.4546 - precision: 0.7758 - recall: 0.4733 - f1_score: 0.5849 - val_loss: 0.4890 - val_precision: 0.7407 - val_recall: 0.3333 - val_f1_score: 0.4598\n",
            "Epoch 201/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.4527 - precision: 0.8105 - recall: 0.4333 - f1_score: 0.5624 - val_loss: 0.4882 - val_precision: 0.7083 - val_recall: 0.2833 - val_f1_score: 0.4048\n",
            "Epoch 202/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.4522 - precision: 0.8100 - recall: 0.4100 - f1_score: 0.5422 - val_loss: 0.4882 - val_precision: 0.7083 - val_recall: 0.2833 - val_f1_score: 0.4048\n",
            "Epoch 203/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.4521 - precision: 0.7866 - recall: 0.4400 - f1_score: 0.5633 - val_loss: 0.4884 - val_precision: 0.7391 - val_recall: 0.2833 - val_f1_score: 0.4096\n",
            "Epoch 204/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.4489 - precision: 0.8194 - recall: 0.4067 - f1_score: 0.5427 - val_loss: 0.4871 - val_precision: 0.6800 - val_recall: 0.2833 - val_f1_score: 0.4000\n",
            "Epoch 205/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.4492 - precision: 0.8328 - recall: 0.4433 - f1_score: 0.5762 - val_loss: 0.4969 - val_precision: 0.7429 - val_recall: 0.4333 - val_f1_score: 0.5474\n",
            "Epoch 206/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.4494 - precision: 0.8180 - recall: 0.4500 - f1_score: 0.5787 - val_loss: 0.4863 - val_precision: 0.7037 - val_recall: 0.3167 - val_f1_score: 0.4368\n",
            "Epoch 207/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.4489 - precision: 0.7726 - recall: 0.4467 - f1_score: 0.5638 - val_loss: 0.4869 - val_precision: 0.7083 - val_recall: 0.2833 - val_f1_score: 0.4048\n",
            "Epoch 208/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.4556 - precision: 0.7723 - recall: 0.4833 - f1_score: 0.5939 - val_loss: 0.4872 - val_precision: 0.7083 - val_recall: 0.2833 - val_f1_score: 0.4048\n",
            "Epoch 209/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.4543 - precision: 0.8032 - recall: 0.4267 - f1_score: 0.5530 - val_loss: 0.4980 - val_precision: 0.6923 - val_recall: 0.4500 - val_f1_score: 0.5455\n",
            "Epoch 210/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.4472 - precision: 0.7818 - recall: 0.4700 - f1_score: 0.5799 - val_loss: 0.4909 - val_precision: 0.7391 - val_recall: 0.2833 - val_f1_score: 0.4096\n",
            "Epoch 211/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.4496 - precision: 0.8227 - recall: 0.4200 - f1_score: 0.5534 - val_loss: 0.4848 - val_precision: 0.7143 - val_recall: 0.3333 - val_f1_score: 0.4545\n",
            "Epoch 212/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.4457 - precision: 0.8278 - recall: 0.4833 - f1_score: 0.6097 - val_loss: 0.4988 - val_precision: 0.6905 - val_recall: 0.4833 - val_f1_score: 0.5686\n",
            "Epoch 213/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.4560 - precision: 0.7740 - recall: 0.4433 - f1_score: 0.5612 - val_loss: 0.4883 - val_precision: 0.7391 - val_recall: 0.2833 - val_f1_score: 0.4096\n",
            "Epoch 214/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.4462 - precision: 0.8435 - recall: 0.4333 - f1_score: 0.5701 - val_loss: 0.4892 - val_precision: 0.6207 - val_recall: 0.3000 - val_f1_score: 0.4045\n",
            "Epoch 215/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.4478 - precision: 0.8121 - recall: 0.4700 - f1_score: 0.5930 - val_loss: 0.4877 - val_precision: 0.5625 - val_recall: 0.3000 - val_f1_score: 0.3913\n",
            "Epoch 216/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.4474 - precision: 0.8006 - recall: 0.4467 - f1_score: 0.5722 - val_loss: 0.4842 - val_precision: 0.6923 - val_recall: 0.3000 - val_f1_score: 0.4186\n",
            "Epoch 217/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.4457 - precision: 0.8204 - recall: 0.4567 - f1_score: 0.5847 - val_loss: 0.4864 - val_precision: 0.7188 - val_recall: 0.3833 - val_f1_score: 0.5000\n",
            "Epoch 218/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.4498 - precision: 0.8033 - recall: 0.4633 - f1_score: 0.5859 - val_loss: 0.4882 - val_precision: 0.7188 - val_recall: 0.3833 - val_f1_score: 0.5000\n",
            "Epoch 219/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.4437 - precision: 0.7980 - recall: 0.4800 - f1_score: 0.5950 - val_loss: 0.4863 - val_precision: 0.6957 - val_recall: 0.2667 - val_f1_score: 0.3855\n",
            "Epoch 220/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.4441 - precision: 0.8347 - recall: 0.4400 - f1_score: 0.5755 - val_loss: 0.4833 - val_precision: 0.6897 - val_recall: 0.3333 - val_f1_score: 0.4494\n",
            "Epoch 221/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.4488 - precision: 0.8086 - recall: 0.4667 - f1_score: 0.5886 - val_loss: 0.4911 - val_precision: 0.7353 - val_recall: 0.4167 - val_f1_score: 0.5319\n",
            "Epoch 222/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.4470 - precision: 0.8230 - recall: 0.4467 - f1_score: 0.5771 - val_loss: 0.4846 - val_precision: 0.6970 - val_recall: 0.3833 - val_f1_score: 0.4946\n",
            "Epoch 223/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.4440 - precision: 0.8180 - recall: 0.4500 - f1_score: 0.5791 - val_loss: 0.4823 - val_precision: 0.7143 - val_recall: 0.3333 - val_f1_score: 0.4545\n",
            "Epoch 224/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.4483 - precision: 0.7851 - recall: 0.4533 - f1_score: 0.5723 - val_loss: 0.4875 - val_precision: 0.6000 - val_recall: 0.3500 - val_f1_score: 0.4421\n",
            "Epoch 225/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.4431 - precision: 0.8291 - recall: 0.4733 - f1_score: 0.5965 - val_loss: 0.4820 - val_precision: 0.7143 - val_recall: 0.3333 - val_f1_score: 0.4545\n",
            "Epoch 226/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.4428 - precision: 0.7863 - recall: 0.4400 - f1_score: 0.5624 - val_loss: 0.4840 - val_precision: 0.5926 - val_recall: 0.2667 - val_f1_score: 0.3678\n",
            "Epoch 227/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.4467 - precision: 0.7930 - recall: 0.4700 - f1_score: 0.5891 - val_loss: 0.4923 - val_precision: 0.8636 - val_recall: 0.3167 - val_f1_score: 0.4634\n",
            "Epoch 228/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.4480 - precision: 0.7918 - recall: 0.4533 - f1_score: 0.5738 - val_loss: 0.4816 - val_precision: 0.7143 - val_recall: 0.3333 - val_f1_score: 0.4545\n",
            "Epoch 229/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.4405 - precision: 0.8490 - recall: 0.4300 - f1_score: 0.5676 - val_loss: 0.4813 - val_precision: 0.6897 - val_recall: 0.3333 - val_f1_score: 0.4494\n",
            "Epoch 230/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.4426 - precision: 0.8006 - recall: 0.4400 - f1_score: 0.5652 - val_loss: 0.4860 - val_precision: 0.6250 - val_recall: 0.3333 - val_f1_score: 0.4348\n",
            "Epoch 231/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.4466 - precision: 0.7656 - recall: 0.4767 - f1_score: 0.5844 - val_loss: 0.4826 - val_precision: 0.6800 - val_recall: 0.2833 - val_f1_score: 0.4000\n",
            "Epoch 232/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.4435 - precision: 0.8064 - recall: 0.4567 - f1_score: 0.5828 - val_loss: 0.4810 - val_precision: 0.6897 - val_recall: 0.3333 - val_f1_score: 0.4494\n",
            "Epoch 233/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.4402 - precision: 0.8285 - recall: 0.4433 - f1_score: 0.5764 - val_loss: 0.4861 - val_precision: 0.7143 - val_recall: 0.4167 - val_f1_score: 0.5263\n",
            "Epoch 234/3000\n",
            "300/300 [==============================] - 0s 58us/step - loss: 0.4423 - precision: 0.8247 - recall: 0.4633 - f1_score: 0.5907 - val_loss: 0.4817 - val_precision: 0.7097 - val_recall: 0.3667 - val_f1_score: 0.4835\n",
            "Epoch 235/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.4400 - precision: 0.8340 - recall: 0.4700 - f1_score: 0.6005 - val_loss: 0.4809 - val_precision: 0.7037 - val_recall: 0.3167 - val_f1_score: 0.4368\n",
            "Epoch 236/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.4383 - precision: 0.8368 - recall: 0.4733 - f1_score: 0.6029 - val_loss: 0.4849 - val_precision: 0.7059 - val_recall: 0.4000 - val_f1_score: 0.5106\n",
            "Epoch 237/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.4397 - precision: 0.8481 - recall: 0.4767 - f1_score: 0.6089 - val_loss: 0.4817 - val_precision: 0.6923 - val_recall: 0.3000 - val_f1_score: 0.4186\n",
            "Epoch 238/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.4390 - precision: 0.8338 - recall: 0.4600 - f1_score: 0.5920 - val_loss: 0.4898 - val_precision: 0.7297 - val_recall: 0.4500 - val_f1_score: 0.5567\n",
            "Epoch 239/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.4401 - precision: 0.7823 - recall: 0.4733 - f1_score: 0.5879 - val_loss: 0.4874 - val_precision: 0.6216 - val_recall: 0.3833 - val_f1_score: 0.4742\n",
            "Epoch 240/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.4416 - precision: 0.8258 - recall: 0.4400 - f1_score: 0.5721 - val_loss: 0.4813 - val_precision: 0.6296 - val_recall: 0.2833 - val_f1_score: 0.3908\n",
            "Epoch 241/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.4426 - precision: 0.8087 - recall: 0.4500 - f1_score: 0.5755 - val_loss: 0.4844 - val_precision: 0.6000 - val_recall: 0.3500 - val_f1_score: 0.4421\n",
            "Epoch 242/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.4390 - precision: 0.8385 - recall: 0.4833 - f1_score: 0.6103 - val_loss: 0.4796 - val_precision: 0.6897 - val_recall: 0.3333 - val_f1_score: 0.4494\n",
            "Epoch 243/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.4413 - precision: 0.8175 - recall: 0.4833 - f1_score: 0.6063 - val_loss: 0.5101 - val_precision: 0.6304 - val_recall: 0.4833 - val_f1_score: 0.5472\n",
            "Epoch 244/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.4475 - precision: 0.7789 - recall: 0.4867 - f1_score: 0.5927 - val_loss: 0.4791 - val_precision: 0.6897 - val_recall: 0.3333 - val_f1_score: 0.4494\n",
            "Epoch 245/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.4360 - precision: 0.8406 - recall: 0.4900 - f1_score: 0.6173 - val_loss: 0.4818 - val_precision: 0.6765 - val_recall: 0.3833 - val_f1_score: 0.4894\n",
            "Epoch 246/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.4387 - precision: 0.8107 - recall: 0.4867 - f1_score: 0.6069 - val_loss: 0.4806 - val_precision: 0.7097 - val_recall: 0.3667 - val_f1_score: 0.4835\n",
            "Epoch 247/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.4385 - precision: 0.8035 - recall: 0.4633 - f1_score: 0.5842 - val_loss: 0.4812 - val_precision: 0.6667 - val_recall: 0.2667 - val_f1_score: 0.3810\n",
            "Epoch 248/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.4376 - precision: 0.7930 - recall: 0.4833 - f1_score: 0.6002 - val_loss: 0.4825 - val_precision: 0.7083 - val_recall: 0.2833 - val_f1_score: 0.4048\n",
            "Epoch 249/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.4440 - precision: 0.7826 - recall: 0.4700 - f1_score: 0.5843 - val_loss: 0.4786 - val_precision: 0.7143 - val_recall: 0.3333 - val_f1_score: 0.4545\n",
            "Epoch 250/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.4351 - precision: 0.8324 - recall: 0.4633 - f1_score: 0.5941 - val_loss: 0.4814 - val_precision: 0.7097 - val_recall: 0.3667 - val_f1_score: 0.4835\n",
            "Epoch 251/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.4349 - precision: 0.8208 - recall: 0.4700 - f1_score: 0.5967 - val_loss: 0.4807 - val_precision: 0.7097 - val_recall: 0.3667 - val_f1_score: 0.4835\n",
            "Epoch 252/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.4350 - precision: 0.8145 - recall: 0.4533 - f1_score: 0.5814 - val_loss: 0.4778 - val_precision: 0.6897 - val_recall: 0.3333 - val_f1_score: 0.4494\n",
            "Epoch 253/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.4345 - precision: 0.8338 - recall: 0.4833 - f1_score: 0.6084 - val_loss: 0.4898 - val_precision: 0.6667 - val_recall: 0.4667 - val_f1_score: 0.5490\n",
            "Epoch 254/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.4420 - precision: 0.8038 - recall: 0.4933 - f1_score: 0.6071 - val_loss: 0.4820 - val_precision: 0.7027 - val_recall: 0.4333 - val_f1_score: 0.5361\n",
            "Epoch 255/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.4383 - precision: 0.8024 - recall: 0.4967 - f1_score: 0.6130 - val_loss: 0.4778 - val_precision: 0.7037 - val_recall: 0.3167 - val_f1_score: 0.4368\n",
            "Epoch 256/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.4354 - precision: 0.8335 - recall: 0.4800 - f1_score: 0.6091 - val_loss: 0.4852 - val_precision: 0.7353 - val_recall: 0.4167 - val_f1_score: 0.5319\n",
            "Epoch 257/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.4377 - precision: 0.7833 - recall: 0.4833 - f1_score: 0.5957 - val_loss: 0.4774 - val_precision: 0.6667 - val_recall: 0.3333 - val_f1_score: 0.4444\n",
            "Epoch 258/3000\n",
            "300/300 [==============================] - 0s 59us/step - loss: 0.4340 - precision: 0.8291 - recall: 0.4700 - f1_score: 0.5984 - val_loss: 0.4784 - val_precision: 0.6800 - val_recall: 0.2833 - val_f1_score: 0.4000\n",
            "Epoch 259/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.4348 - precision: 0.7991 - recall: 0.4933 - f1_score: 0.6082 - val_loss: 0.4783 - val_precision: 0.6923 - val_recall: 0.3000 - val_f1_score: 0.4186\n",
            "Epoch 260/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.4354 - precision: 0.8302 - recall: 0.4833 - f1_score: 0.6073 - val_loss: 0.4823 - val_precision: 0.7188 - val_recall: 0.3833 - val_f1_score: 0.5000\n",
            "Epoch 261/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.4339 - precision: 0.8031 - recall: 0.4300 - f1_score: 0.5573 - val_loss: 0.4853 - val_precision: 0.6585 - val_recall: 0.4500 - val_f1_score: 0.5347\n",
            "Epoch 262/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.4367 - precision: 0.7858 - recall: 0.4667 - f1_score: 0.5839 - val_loss: 0.4802 - val_precision: 0.6944 - val_recall: 0.4167 - val_f1_score: 0.5208\n",
            "Epoch 263/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.4360 - precision: 0.7820 - recall: 0.4967 - f1_score: 0.6032 - val_loss: 0.4776 - val_precision: 0.7097 - val_recall: 0.3667 - val_f1_score: 0.4835\n",
            "Epoch 264/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.4345 - precision: 0.7967 - recall: 0.5000 - f1_score: 0.6126 - val_loss: 0.4804 - val_precision: 0.7027 - val_recall: 0.4333 - val_f1_score: 0.5361\n",
            "Epoch 265/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.4310 - precision: 0.8087 - recall: 0.4900 - f1_score: 0.6074 - val_loss: 0.4762 - val_precision: 0.6667 - val_recall: 0.3333 - val_f1_score: 0.4444\n",
            "Epoch 266/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.4302 - precision: 0.8198 - recall: 0.5000 - f1_score: 0.6189 - val_loss: 0.4980 - val_precision: 0.5532 - val_recall: 0.4333 - val_f1_score: 0.4860\n",
            "Epoch 267/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.4449 - precision: 0.7576 - recall: 0.4700 - f1_score: 0.5780 - val_loss: 0.4768 - val_precision: 0.6774 - val_recall: 0.3500 - val_f1_score: 0.4615\n",
            "Epoch 268/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.4329 - precision: 0.8038 - recall: 0.5133 - f1_score: 0.6250 - val_loss: 0.4900 - val_precision: 0.5714 - val_recall: 0.4000 - val_f1_score: 0.4706\n",
            "Epoch 269/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.4385 - precision: 0.7698 - recall: 0.5000 - f1_score: 0.6060 - val_loss: 0.4755 - val_precision: 0.6111 - val_recall: 0.3667 - val_f1_score: 0.4583\n",
            "Epoch 270/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.4297 - precision: 0.8277 - recall: 0.4867 - f1_score: 0.6123 - val_loss: 0.4765 - val_precision: 0.7143 - val_recall: 0.3333 - val_f1_score: 0.4545\n",
            "Epoch 271/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.4278 - precision: 0.8306 - recall: 0.4867 - f1_score: 0.6107 - val_loss: 0.4797 - val_precision: 0.6176 - val_recall: 0.3500 - val_f1_score: 0.4468\n",
            "Epoch 272/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.4325 - precision: 0.7949 - recall: 0.5067 - f1_score: 0.6172 - val_loss: 0.4749 - val_precision: 0.6774 - val_recall: 0.3500 - val_f1_score: 0.4615\n",
            "Epoch 273/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.4293 - precision: 0.8291 - recall: 0.5067 - f1_score: 0.6259 - val_loss: 0.4772 - val_precision: 0.7308 - val_recall: 0.3167 - val_f1_score: 0.4419\n",
            "Epoch 274/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.4295 - precision: 0.8267 - recall: 0.4700 - f1_score: 0.5972 - val_loss: 0.4750 - val_precision: 0.6667 - val_recall: 0.3333 - val_f1_score: 0.4444\n",
            "Epoch 275/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.4294 - precision: 0.8430 - recall: 0.5200 - f1_score: 0.6417 - val_loss: 0.4802 - val_precision: 0.7600 - val_recall: 0.3167 - val_f1_score: 0.4471\n",
            "Epoch 276/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.4303 - precision: 0.8320 - recall: 0.4633 - f1_score: 0.5946 - val_loss: 0.4745 - val_precision: 0.7000 - val_recall: 0.3500 - val_f1_score: 0.4667\n",
            "Epoch 277/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.4306 - precision: 0.8204 - recall: 0.5067 - f1_score: 0.6245 - val_loss: 0.4777 - val_precision: 0.7308 - val_recall: 0.3167 - val_f1_score: 0.4419\n",
            "Epoch 278/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.4281 - precision: 0.8369 - recall: 0.4667 - f1_score: 0.5984 - val_loss: 0.4771 - val_precision: 0.6923 - val_recall: 0.3000 - val_f1_score: 0.4186\n",
            "Epoch 279/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.4334 - precision: 0.7964 - recall: 0.5000 - f1_score: 0.6134 - val_loss: 0.4749 - val_precision: 0.6897 - val_recall: 0.3333 - val_f1_score: 0.4494\n",
            "Epoch 280/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.4301 - precision: 0.8174 - recall: 0.4867 - f1_score: 0.6077 - val_loss: 0.4793 - val_precision: 0.6944 - val_recall: 0.4167 - val_f1_score: 0.5208\n",
            "Epoch 281/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.4310 - precision: 0.8069 - recall: 0.5067 - f1_score: 0.6203 - val_loss: 0.4757 - val_precision: 0.7037 - val_recall: 0.3167 - val_f1_score: 0.4368\n",
            "Epoch 282/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.4326 - precision: 0.8144 - recall: 0.5033 - f1_score: 0.6214 - val_loss: 0.4789 - val_precision: 0.7027 - val_recall: 0.4333 - val_f1_score: 0.5361\n",
            "Epoch 283/3000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.4325 - precision: 0.7996 - recall: 0.5033 - f1_score: 0.6139 - val_loss: 0.4749 - val_precision: 0.6765 - val_recall: 0.3833 - val_f1_score: 0.4894\n",
            "Epoch 284/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.4290 - precision: 0.8037 - recall: 0.4967 - f1_score: 0.6133 - val_loss: 0.4807 - val_precision: 0.7143 - val_recall: 0.4167 - val_f1_score: 0.5263\n",
            "Epoch 285/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.4262 - precision: 0.8191 - recall: 0.4800 - f1_score: 0.6036 - val_loss: 0.4749 - val_precision: 0.6786 - val_recall: 0.3167 - val_f1_score: 0.4318\n",
            "Epoch 286/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.4291 - precision: 0.8207 - recall: 0.4733 - f1_score: 0.5969 - val_loss: 0.4796 - val_precision: 0.6216 - val_recall: 0.3833 - val_f1_score: 0.4742\n",
            "Epoch 287/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.4267 - precision: 0.8168 - recall: 0.5067 - f1_score: 0.6230 - val_loss: 0.4742 - val_precision: 0.6897 - val_recall: 0.3333 - val_f1_score: 0.4494\n",
            "Epoch 288/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.4258 - precision: 0.8259 - recall: 0.5033 - f1_score: 0.6252 - val_loss: 0.4757 - val_precision: 0.6970 - val_recall: 0.3833 - val_f1_score: 0.4946\n",
            "Epoch 289/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.4313 - precision: 0.7823 - recall: 0.4933 - f1_score: 0.6016 - val_loss: 0.4733 - val_precision: 0.7000 - val_recall: 0.3500 - val_f1_score: 0.4667\n",
            "Epoch 290/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.4260 - precision: 0.8089 - recall: 0.5033 - f1_score: 0.6203 - val_loss: 0.4759 - val_precision: 0.6286 - val_recall: 0.3667 - val_f1_score: 0.4632\n",
            "Epoch 291/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.4282 - precision: 0.7809 - recall: 0.4967 - f1_score: 0.6049 - val_loss: 0.4733 - val_precision: 0.6471 - val_recall: 0.3667 - val_f1_score: 0.4681\n",
            "Epoch 292/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.4239 - precision: 0.8314 - recall: 0.5033 - f1_score: 0.6241 - val_loss: 0.4725 - val_precision: 0.6111 - val_recall: 0.3667 - val_f1_score: 0.4583\n",
            "Epoch 293/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.4261 - precision: 0.8271 - recall: 0.5033 - f1_score: 0.6245 - val_loss: 0.4722 - val_precision: 0.6111 - val_recall: 0.3667 - val_f1_score: 0.4583\n",
            "Epoch 294/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.4238 - precision: 0.7986 - recall: 0.5100 - f1_score: 0.6180 - val_loss: 0.4771 - val_precision: 0.7027 - val_recall: 0.4333 - val_f1_score: 0.5361\n",
            "Epoch 295/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.4286 - precision: 0.7799 - recall: 0.5067 - f1_score: 0.6127 - val_loss: 0.4719 - val_precision: 0.6875 - val_recall: 0.3667 - val_f1_score: 0.4783\n",
            "Epoch 296/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.4232 - precision: 0.8350 - recall: 0.5000 - f1_score: 0.6245 - val_loss: 0.4744 - val_precision: 0.6944 - val_recall: 0.4167 - val_f1_score: 0.5208\n",
            "Epoch 297/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.4295 - precision: 0.7759 - recall: 0.5067 - f1_score: 0.6115 - val_loss: 0.4750 - val_precision: 0.6944 - val_recall: 0.4167 - val_f1_score: 0.5208\n",
            "Epoch 298/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.4267 - precision: 0.8146 - recall: 0.4967 - f1_score: 0.6169 - val_loss: 0.4715 - val_precision: 0.6176 - val_recall: 0.3500 - val_f1_score: 0.4468\n",
            "Epoch 299/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.4238 - precision: 0.8113 - recall: 0.5000 - f1_score: 0.6186 - val_loss: 0.4749 - val_precision: 0.6562 - val_recall: 0.3500 - val_f1_score: 0.4565\n",
            "Epoch 300/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.4271 - precision: 0.7770 - recall: 0.5633 - f1_score: 0.6525 - val_loss: 0.4741 - val_precision: 0.6875 - val_recall: 0.3667 - val_f1_score: 0.4783\n",
            "Epoch 301/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.4277 - precision: 0.8117 - recall: 0.5067 - f1_score: 0.6200 - val_loss: 0.4748 - val_precision: 0.6857 - val_recall: 0.4000 - val_f1_score: 0.5053\n",
            "Epoch 302/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.4230 - precision: 0.8135 - recall: 0.4833 - f1_score: 0.6030 - val_loss: 0.4771 - val_precision: 0.7105 - val_recall: 0.4500 - val_f1_score: 0.5510\n",
            "Epoch 303/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.4255 - precision: 0.7721 - recall: 0.5167 - f1_score: 0.6165 - val_loss: 0.4725 - val_precision: 0.6857 - val_recall: 0.4000 - val_f1_score: 0.5053\n",
            "Epoch 304/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.4227 - precision: 0.7929 - recall: 0.5233 - f1_score: 0.6293 - val_loss: 0.4727 - val_precision: 0.7241 - val_recall: 0.3500 - val_f1_score: 0.4719\n",
            "Epoch 305/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.4222 - precision: 0.8393 - recall: 0.5067 - f1_score: 0.6312 - val_loss: 0.4727 - val_precision: 0.6562 - val_recall: 0.3500 - val_f1_score: 0.4565\n",
            "Epoch 306/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.4219 - precision: 0.8324 - recall: 0.5067 - f1_score: 0.6276 - val_loss: 0.4714 - val_precision: 0.7097 - val_recall: 0.3667 - val_f1_score: 0.4835\n",
            "Epoch 307/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.4194 - precision: 0.8163 - recall: 0.5667 - f1_score: 0.6674 - val_loss: 0.4769 - val_precision: 0.7105 - val_recall: 0.4500 - val_f1_score: 0.5510\n",
            "Epoch 308/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.4262 - precision: 0.7625 - recall: 0.5000 - f1_score: 0.6022 - val_loss: 0.4711 - val_precision: 0.7000 - val_recall: 0.3500 - val_f1_score: 0.4667\n",
            "Epoch 309/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.4204 - precision: 0.8216 - recall: 0.5233 - f1_score: 0.6393 - val_loss: 0.4706 - val_precision: 0.6286 - val_recall: 0.3667 - val_f1_score: 0.4632\n",
            "Epoch 310/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.4205 - precision: 0.8241 - recall: 0.5100 - f1_score: 0.6275 - val_loss: 0.4734 - val_precision: 0.7037 - val_recall: 0.3167 - val_f1_score: 0.4368\n",
            "Epoch 311/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.4223 - precision: 0.8248 - recall: 0.4867 - f1_score: 0.6096 - val_loss: 0.4734 - val_precision: 0.6176 - val_recall: 0.3500 - val_f1_score: 0.4468\n",
            "Epoch 312/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.4245 - precision: 0.7903 - recall: 0.5133 - f1_score: 0.6211 - val_loss: 0.4757 - val_precision: 0.6286 - val_recall: 0.3667 - val_f1_score: 0.4632\n",
            "Epoch 313/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.4241 - precision: 0.8093 - recall: 0.5100 - f1_score: 0.6256 - val_loss: 0.4700 - val_precision: 0.6216 - val_recall: 0.3833 - val_f1_score: 0.4742\n",
            "Epoch 314/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.4207 - precision: 0.8339 - recall: 0.5267 - f1_score: 0.6435 - val_loss: 0.4797 - val_precision: 0.7179 - val_recall: 0.4667 - val_f1_score: 0.5657\n",
            "Epoch 315/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.4232 - precision: 0.8064 - recall: 0.5200 - f1_score: 0.6293 - val_loss: 0.4715 - val_precision: 0.7241 - val_recall: 0.3500 - val_f1_score: 0.4719\n",
            "Epoch 316/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.4202 - precision: 0.8266 - recall: 0.5133 - f1_score: 0.6326 - val_loss: 0.4699 - val_precision: 0.6875 - val_recall: 0.3667 - val_f1_score: 0.4783\n",
            "Epoch 317/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.4207 - precision: 0.8362 - recall: 0.5033 - f1_score: 0.6252 - val_loss: 0.4705 - val_precision: 0.6571 - val_recall: 0.3833 - val_f1_score: 0.4842\n",
            "Epoch 318/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.4191 - precision: 0.8015 - recall: 0.5400 - f1_score: 0.6435 - val_loss: 0.4695 - val_precision: 0.6286 - val_recall: 0.3667 - val_f1_score: 0.4632\n",
            "Epoch 319/3000\n",
            "300/300 [==============================] - 0s 80us/step - loss: 0.4201 - precision: 0.8363 - recall: 0.5067 - f1_score: 0.6304 - val_loss: 0.4703 - val_precision: 0.7097 - val_recall: 0.3667 - val_f1_score: 0.4835\n",
            "Epoch 320/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.4227 - precision: 0.8176 - recall: 0.5200 - f1_score: 0.6332 - val_loss: 0.4711 - val_precision: 0.6571 - val_recall: 0.3833 - val_f1_score: 0.4842\n",
            "Epoch 321/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.4235 - precision: 0.7968 - recall: 0.5233 - f1_score: 0.6285 - val_loss: 0.4733 - val_precision: 0.6667 - val_recall: 0.3333 - val_f1_score: 0.4444\n",
            "Epoch 322/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.4191 - precision: 0.8271 - recall: 0.5233 - f1_score: 0.6403 - val_loss: 0.4746 - val_precision: 0.7105 - val_recall: 0.4500 - val_f1_score: 0.5510\n",
            "Epoch 323/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.4191 - precision: 0.8038 - recall: 0.5233 - f1_score: 0.6313 - val_loss: 0.4735 - val_precision: 0.6875 - val_recall: 0.3667 - val_f1_score: 0.4783\n",
            "Epoch 324/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.4223 - precision: 0.8159 - recall: 0.5300 - f1_score: 0.6415 - val_loss: 0.4697 - val_precision: 0.6471 - val_recall: 0.3667 - val_f1_score: 0.4681\n",
            "Epoch 325/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.4250 - precision: 0.7740 - recall: 0.5400 - f1_score: 0.6346 - val_loss: 0.4749 - val_precision: 0.6842 - val_recall: 0.4333 - val_f1_score: 0.5306\n",
            "Epoch 326/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.4268 - precision: 0.7512 - recall: 0.5167 - f1_score: 0.6119 - val_loss: 0.4708 - val_precision: 0.6857 - val_recall: 0.4000 - val_f1_score: 0.5053\n",
            "Epoch 327/3000\n",
            "300/300 [==============================] - 0s 59us/step - loss: 0.4172 - precision: 0.8152 - recall: 0.5133 - f1_score: 0.6292 - val_loss: 0.4789 - val_precision: 0.7073 - val_recall: 0.4833 - val_f1_score: 0.5743\n",
            "Epoch 328/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.4203 - precision: 0.7938 - recall: 0.5233 - f1_score: 0.6292 - val_loss: 0.4711 - val_precision: 0.6944 - val_recall: 0.4167 - val_f1_score: 0.5208\n",
            "Epoch 329/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.4175 - precision: 0.8110 - recall: 0.5200 - f1_score: 0.6320 - val_loss: 0.4694 - val_precision: 0.7097 - val_recall: 0.3667 - val_f1_score: 0.4835\n",
            "Epoch 330/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.4178 - precision: 0.8254 - recall: 0.5400 - f1_score: 0.6508 - val_loss: 0.4687 - val_precision: 0.6389 - val_recall: 0.3833 - val_f1_score: 0.4792\n",
            "Epoch 331/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.4256 - precision: 0.7866 - recall: 0.5300 - f1_score: 0.6320 - val_loss: 0.4749 - val_precision: 0.7105 - val_recall: 0.4500 - val_f1_score: 0.5510\n",
            "Epoch 332/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.4257 - precision: 0.7783 - recall: 0.5567 - f1_score: 0.6478 - val_loss: 0.4703 - val_precision: 0.6667 - val_recall: 0.3667 - val_f1_score: 0.4731\n",
            "Epoch 333/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.4179 - precision: 0.8122 - recall: 0.5000 - f1_score: 0.6173 - val_loss: 0.4696 - val_precision: 0.6471 - val_recall: 0.3667 - val_f1_score: 0.4681\n",
            "Epoch 334/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.4175 - precision: 0.8180 - recall: 0.5200 - f1_score: 0.6348 - val_loss: 0.4686 - val_precision: 0.6216 - val_recall: 0.3833 - val_f1_score: 0.4742\n",
            "Epoch 335/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.4183 - precision: 0.8021 - recall: 0.5400 - f1_score: 0.6449 - val_loss: 0.4685 - val_precision: 0.6111 - val_recall: 0.3667 - val_f1_score: 0.4583\n",
            "Epoch 336/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.4203 - precision: 0.8098 - recall: 0.5267 - f1_score: 0.6382 - val_loss: 0.4718 - val_precision: 0.7027 - val_recall: 0.4333 - val_f1_score: 0.5361\n",
            "Epoch 337/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.4141 - precision: 0.8204 - recall: 0.5333 - f1_score: 0.6442 - val_loss: 0.4691 - val_precision: 0.6471 - val_recall: 0.3667 - val_f1_score: 0.4681\n",
            "Epoch 338/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.4168 - precision: 0.8302 - recall: 0.5300 - f1_score: 0.6447 - val_loss: 0.4681 - val_precision: 0.6389 - val_recall: 0.3833 - val_f1_score: 0.4792\n",
            "Epoch 339/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.4150 - precision: 0.8279 - recall: 0.5233 - f1_score: 0.6408 - val_loss: 0.4686 - val_precision: 0.7059 - val_recall: 0.4000 - val_f1_score: 0.5106\n",
            "Epoch 340/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.4155 - precision: 0.8224 - recall: 0.5300 - f1_score: 0.6434 - val_loss: 0.4691 - val_precision: 0.6176 - val_recall: 0.3500 - val_f1_score: 0.4468\n",
            "Epoch 341/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.4143 - precision: 0.8332 - recall: 0.5333 - f1_score: 0.6467 - val_loss: 0.4678 - val_precision: 0.6316 - val_recall: 0.4000 - val_f1_score: 0.4898\n",
            "Epoch 342/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.4172 - precision: 0.7974 - recall: 0.5167 - f1_score: 0.6256 - val_loss: 0.4686 - val_precision: 0.6970 - val_recall: 0.3833 - val_f1_score: 0.4946\n",
            "Epoch 343/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.4135 - precision: 0.8526 - recall: 0.5433 - f1_score: 0.6624 - val_loss: 0.4693 - val_precision: 0.7097 - val_recall: 0.3667 - val_f1_score: 0.4835\n",
            "Epoch 344/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.4125 - precision: 0.8649 - recall: 0.5367 - f1_score: 0.6619 - val_loss: 0.4678 - val_precision: 0.6571 - val_recall: 0.3833 - val_f1_score: 0.4842\n",
            "Epoch 345/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.4194 - precision: 0.7787 - recall: 0.5300 - f1_score: 0.6303 - val_loss: 0.4725 - val_precision: 0.6875 - val_recall: 0.3667 - val_f1_score: 0.4783\n",
            "Epoch 346/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.4142 - precision: 0.8373 - recall: 0.5433 - f1_score: 0.6581 - val_loss: 0.4696 - val_precision: 0.6857 - val_recall: 0.4000 - val_f1_score: 0.5053\n",
            "Epoch 347/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.4172 - precision: 0.8031 - recall: 0.5133 - f1_score: 0.6243 - val_loss: 0.4751 - val_precision: 0.6486 - val_recall: 0.4000 - val_f1_score: 0.4948\n",
            "Epoch 348/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.4178 - precision: 0.8126 - recall: 0.5300 - f1_score: 0.6399 - val_loss: 0.4761 - val_precision: 0.7000 - val_recall: 0.4667 - val_f1_score: 0.5600\n",
            "Epoch 349/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.4180 - precision: 0.7657 - recall: 0.5133 - f1_score: 0.6134 - val_loss: 0.4679 - val_precision: 0.6216 - val_recall: 0.3833 - val_f1_score: 0.4742\n",
            "Epoch 350/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.4128 - precision: 0.8285 - recall: 0.5300 - f1_score: 0.6434 - val_loss: 0.4692 - val_precision: 0.6842 - val_recall: 0.4333 - val_f1_score: 0.5306\n",
            "Epoch 351/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.4148 - precision: 0.7928 - recall: 0.5367 - f1_score: 0.6390 - val_loss: 0.4677 - val_precision: 0.6765 - val_recall: 0.3833 - val_f1_score: 0.4894\n",
            "Epoch 352/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.4185 - precision: 0.8093 - recall: 0.5200 - f1_score: 0.6315 - val_loss: 0.4686 - val_precision: 0.6765 - val_recall: 0.3833 - val_f1_score: 0.4894\n",
            "Epoch 353/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.4146 - precision: 0.8244 - recall: 0.5300 - f1_score: 0.6430 - val_loss: 0.4674 - val_precision: 0.6316 - val_recall: 0.4000 - val_f1_score: 0.4898\n",
            "Epoch 354/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.4235 - precision: 0.7829 - recall: 0.5267 - f1_score: 0.6284 - val_loss: 0.4671 - val_precision: 0.6500 - val_recall: 0.4333 - val_f1_score: 0.5200\n",
            "Epoch 355/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.4189 - precision: 0.7821 - recall: 0.5233 - f1_score: 0.6255 - val_loss: 0.4696 - val_precision: 0.7027 - val_recall: 0.4333 - val_f1_score: 0.5361\n",
            "Epoch 356/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.4115 - precision: 0.8243 - recall: 0.5533 - f1_score: 0.6605 - val_loss: 0.4683 - val_precision: 0.6857 - val_recall: 0.4000 - val_f1_score: 0.5053\n",
            "Epoch 357/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.4121 - precision: 0.8423 - recall: 0.5533 - f1_score: 0.6671 - val_loss: 0.4700 - val_precision: 0.7333 - val_recall: 0.3667 - val_f1_score: 0.4889\n",
            "Epoch 358/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.4137 - precision: 0.8264 - recall: 0.5233 - f1_score: 0.6400 - val_loss: 0.4673 - val_precision: 0.6857 - val_recall: 0.4000 - val_f1_score: 0.5053\n",
            "Epoch 359/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.4131 - precision: 0.8103 - recall: 0.5300 - f1_score: 0.6405 - val_loss: 0.4689 - val_precision: 0.7027 - val_recall: 0.4333 - val_f1_score: 0.5361\n",
            "Epoch 360/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.4107 - precision: 0.8407 - recall: 0.5167 - f1_score: 0.6379 - val_loss: 0.4686 - val_precision: 0.6216 - val_recall: 0.3833 - val_f1_score: 0.4742\n",
            "Epoch 361/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.4108 - precision: 0.8370 - recall: 0.5500 - f1_score: 0.6632 - val_loss: 0.4754 - val_precision: 0.6750 - val_recall: 0.4500 - val_f1_score: 0.5400\n",
            "Epoch 362/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.4137 - precision: 0.8142 - recall: 0.5567 - f1_score: 0.6593 - val_loss: 0.4748 - val_precision: 0.7105 - val_recall: 0.4500 - val_f1_score: 0.5510\n",
            "Epoch 363/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.4104 - precision: 0.8271 - recall: 0.5500 - f1_score: 0.6596 - val_loss: 0.4684 - val_precision: 0.6774 - val_recall: 0.3500 - val_f1_score: 0.4615\n",
            "Epoch 364/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.4089 - precision: 0.8236 - recall: 0.5400 - f1_score: 0.6520 - val_loss: 0.4712 - val_precision: 0.7105 - val_recall: 0.4500 - val_f1_score: 0.5510\n",
            "Epoch 365/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.4114 - precision: 0.7944 - recall: 0.5767 - f1_score: 0.6670 - val_loss: 0.4692 - val_precision: 0.6471 - val_recall: 0.3667 - val_f1_score: 0.4681\n",
            "Epoch 366/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.4088 - precision: 0.8365 - recall: 0.5733 - f1_score: 0.6794 - val_loss: 0.4663 - val_precision: 0.6316 - val_recall: 0.4000 - val_f1_score: 0.4898\n",
            "Epoch 367/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.4121 - precision: 0.8352 - recall: 0.5433 - f1_score: 0.6571 - val_loss: 0.4698 - val_precision: 0.6944 - val_recall: 0.4167 - val_f1_score: 0.5208\n",
            "Epoch 368/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.4199 - precision: 0.7846 - recall: 0.5267 - f1_score: 0.6271 - val_loss: 0.4704 - val_precision: 0.6897 - val_recall: 0.3333 - val_f1_score: 0.4494\n",
            "Epoch 369/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.4086 - precision: 0.8347 - recall: 0.5367 - f1_score: 0.6529 - val_loss: 0.4695 - val_precision: 0.6944 - val_recall: 0.4167 - val_f1_score: 0.5208\n",
            "Epoch 370/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.4101 - precision: 0.8440 - recall: 0.5600 - f1_score: 0.6721 - val_loss: 0.4691 - val_precision: 0.6765 - val_recall: 0.3833 - val_f1_score: 0.4894\n",
            "Epoch 371/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.4102 - precision: 0.8242 - recall: 0.5267 - f1_score: 0.6422 - val_loss: 0.4741 - val_precision: 0.5897 - val_recall: 0.3833 - val_f1_score: 0.4646\n",
            "Epoch 372/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.4104 - precision: 0.8027 - recall: 0.5633 - f1_score: 0.6611 - val_loss: 0.4716 - val_precision: 0.6842 - val_recall: 0.4333 - val_f1_score: 0.5306\n",
            "Epoch 373/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.4098 - precision: 0.8172 - recall: 0.5600 - f1_score: 0.6618 - val_loss: 0.4658 - val_precision: 0.6410 - val_recall: 0.4167 - val_f1_score: 0.5051\n",
            "Epoch 374/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.4150 - precision: 0.8120 - recall: 0.5433 - f1_score: 0.6502 - val_loss: 0.4659 - val_precision: 0.6486 - val_recall: 0.4000 - val_f1_score: 0.4948\n",
            "Epoch 375/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.4094 - precision: 0.8305 - recall: 0.5567 - f1_score: 0.6660 - val_loss: 0.4656 - val_precision: 0.6410 - val_recall: 0.4167 - val_f1_score: 0.5051\n",
            "Epoch 376/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.4065 - precision: 0.8361 - recall: 0.5333 - f1_score: 0.6492 - val_loss: 0.4681 - val_precision: 0.6410 - val_recall: 0.4167 - val_f1_score: 0.5051\n",
            "Epoch 377/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.4123 - precision: 0.8053 - recall: 0.5333 - f1_score: 0.6398 - val_loss: 0.4660 - val_precision: 0.6857 - val_recall: 0.4000 - val_f1_score: 0.5053\n",
            "Epoch 378/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.4132 - precision: 0.7877 - recall: 0.5433 - f1_score: 0.6424 - val_loss: 0.4655 - val_precision: 0.6500 - val_recall: 0.4333 - val_f1_score: 0.5200\n",
            "Epoch 379/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.4083 - precision: 0.8253 - recall: 0.5633 - f1_score: 0.6683 - val_loss: 0.4710 - val_precision: 0.6286 - val_recall: 0.3667 - val_f1_score: 0.4632\n",
            "Epoch 380/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.4079 - precision: 0.8239 - recall: 0.5600 - f1_score: 0.6652 - val_loss: 0.4672 - val_precision: 0.6667 - val_recall: 0.4000 - val_f1_score: 0.5000\n",
            "Epoch 381/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.4080 - precision: 0.8271 - recall: 0.5400 - f1_score: 0.6517 - val_loss: 0.4667 - val_precision: 0.6667 - val_recall: 0.4333 - val_f1_score: 0.5253\n",
            "Epoch 382/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.4061 - precision: 0.8397 - recall: 0.5567 - f1_score: 0.6692 - val_loss: 0.4660 - val_precision: 0.6579 - val_recall: 0.4167 - val_f1_score: 0.5102\n",
            "Epoch 383/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.4077 - precision: 0.8100 - recall: 0.5433 - f1_score: 0.6465 - val_loss: 0.4692 - val_precision: 0.6667 - val_recall: 0.3667 - val_f1_score: 0.4731\n",
            "Epoch 384/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.4090 - precision: 0.8212 - recall: 0.5600 - f1_score: 0.6647 - val_loss: 0.4676 - val_precision: 0.7059 - val_recall: 0.4000 - val_f1_score: 0.5106\n",
            "Epoch 385/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.4076 - precision: 0.8370 - recall: 0.5367 - f1_score: 0.6521 - val_loss: 0.4655 - val_precision: 0.6316 - val_recall: 0.4000 - val_f1_score: 0.4898\n",
            "Epoch 386/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.4113 - precision: 0.8072 - recall: 0.5433 - f1_score: 0.6477 - val_loss: 0.4671 - val_precision: 0.6970 - val_recall: 0.3833 - val_f1_score: 0.4946\n",
            "Epoch 387/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.4071 - precision: 0.8221 - recall: 0.5400 - f1_score: 0.6516 - val_loss: 0.4658 - val_precision: 0.6857 - val_recall: 0.4000 - val_f1_score: 0.5053\n",
            "Epoch 388/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.4094 - precision: 0.8161 - recall: 0.5167 - f1_score: 0.6312 - val_loss: 0.4687 - val_precision: 0.6842 - val_recall: 0.4333 - val_f1_score: 0.5306\n",
            "Epoch 389/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.4096 - precision: 0.8091 - recall: 0.5567 - f1_score: 0.6585 - val_loss: 0.4710 - val_precision: 0.6842 - val_recall: 0.4333 - val_f1_score: 0.5306\n",
            "Epoch 390/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.4090 - precision: 0.8210 - recall: 0.5500 - f1_score: 0.6572 - val_loss: 0.4671 - val_precision: 0.6341 - val_recall: 0.4333 - val_f1_score: 0.5149\n",
            "Epoch 391/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.4039 - precision: 0.8293 - recall: 0.5667 - f1_score: 0.6720 - val_loss: 0.4697 - val_precision: 0.6471 - val_recall: 0.3667 - val_f1_score: 0.4681\n",
            "Epoch 392/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.4041 - precision: 0.8216 - recall: 0.5433 - f1_score: 0.6510 - val_loss: 0.4662 - val_precision: 0.6341 - val_recall: 0.4333 - val_f1_score: 0.5149\n",
            "Epoch 393/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.4089 - precision: 0.8003 - recall: 0.5633 - f1_score: 0.6603 - val_loss: 0.4684 - val_precision: 0.6842 - val_recall: 0.4333 - val_f1_score: 0.5306\n",
            "Epoch 394/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.4045 - precision: 0.8292 - recall: 0.5433 - f1_score: 0.6543 - val_loss: 0.4756 - val_precision: 0.6905 - val_recall: 0.4833 - val_f1_score: 0.5686\n",
            "Epoch 395/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.4131 - precision: 0.7728 - recall: 0.5600 - f1_score: 0.6476 - val_loss: 0.4666 - val_precision: 0.6842 - val_recall: 0.4333 - val_f1_score: 0.5306\n",
            "Epoch 396/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.4047 - precision: 0.8359 - recall: 0.5333 - f1_score: 0.6500 - val_loss: 0.4690 - val_precision: 0.6842 - val_recall: 0.4333 - val_f1_score: 0.5306\n",
            "Epoch 397/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.4067 - precision: 0.8307 - recall: 0.5633 - f1_score: 0.6696 - val_loss: 0.4648 - val_precision: 0.6500 - val_recall: 0.4333 - val_f1_score: 0.5200\n",
            "Epoch 398/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.4047 - precision: 0.8332 - recall: 0.5600 - f1_score: 0.6668 - val_loss: 0.4654 - val_precision: 0.6410 - val_recall: 0.4167 - val_f1_score: 0.5051\n",
            "Epoch 399/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.4036 - precision: 0.8471 - recall: 0.5567 - f1_score: 0.6703 - val_loss: 0.4659 - val_precision: 0.6279 - val_recall: 0.4500 - val_f1_score: 0.5243\n",
            "Epoch 400/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.4048 - precision: 0.8172 - recall: 0.5667 - f1_score: 0.6675 - val_loss: 0.4677 - val_precision: 0.6667 - val_recall: 0.3667 - val_f1_score: 0.4731\n",
            "Epoch 401/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.4012 - precision: 0.8257 - recall: 0.5700 - f1_score: 0.6723 - val_loss: 0.4739 - val_precision: 0.6829 - val_recall: 0.4667 - val_f1_score: 0.5545\n",
            "Epoch 402/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.4046 - precision: 0.8113 - recall: 0.5667 - f1_score: 0.6636 - val_loss: 0.4682 - val_precision: 0.6842 - val_recall: 0.4333 - val_f1_score: 0.5306\n",
            "Epoch 403/3000\n",
            "300/300 [==============================] - 0s 59us/step - loss: 0.4015 - precision: 0.8378 - recall: 0.5800 - f1_score: 0.6840 - val_loss: 0.4654 - val_precision: 0.6857 - val_recall: 0.4000 - val_f1_score: 0.5053\n",
            "Epoch 404/3000\n",
            "300/300 [==============================] - 0s 58us/step - loss: 0.4036 - precision: 0.8206 - recall: 0.5567 - f1_score: 0.6632 - val_loss: 0.4691 - val_precision: 0.6486 - val_recall: 0.4000 - val_f1_score: 0.4948\n",
            "Epoch 405/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.4096 - precision: 0.7971 - recall: 0.5467 - f1_score: 0.6463 - val_loss: 0.4686 - val_precision: 0.6667 - val_recall: 0.3667 - val_f1_score: 0.4731\n",
            "Epoch 406/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.4011 - precision: 0.8216 - recall: 0.5800 - f1_score: 0.6786 - val_loss: 0.4779 - val_precision: 0.6744 - val_recall: 0.4833 - val_f1_score: 0.5631\n",
            "Epoch 407/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.4034 - precision: 0.8178 - recall: 0.5633 - f1_score: 0.6645 - val_loss: 0.4652 - val_precision: 0.6500 - val_recall: 0.4333 - val_f1_score: 0.5200\n",
            "Epoch 408/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.4026 - precision: 0.8377 - recall: 0.5433 - f1_score: 0.6585 - val_loss: 0.4644 - val_precision: 0.6410 - val_recall: 0.4167 - val_f1_score: 0.5051\n",
            "Epoch 409/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.4008 - precision: 0.8607 - recall: 0.5767 - f1_score: 0.6892 - val_loss: 0.4648 - val_precision: 0.6579 - val_recall: 0.4167 - val_f1_score: 0.5102\n",
            "Epoch 410/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.4080 - precision: 0.8255 - recall: 0.5567 - f1_score: 0.6624 - val_loss: 0.4741 - val_precision: 0.7105 - val_recall: 0.4500 - val_f1_score: 0.5510\n",
            "Epoch 411/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.4085 - precision: 0.7961 - recall: 0.5367 - f1_score: 0.6400 - val_loss: 0.4650 - val_precision: 0.6585 - val_recall: 0.4500 - val_f1_score: 0.5347\n",
            "Epoch 412/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.4005 - precision: 0.8403 - recall: 0.5733 - f1_score: 0.6812 - val_loss: 0.4754 - val_precision: 0.6744 - val_recall: 0.4833 - val_f1_score: 0.5631\n",
            "Epoch 413/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.4124 - precision: 0.7598 - recall: 0.5567 - f1_score: 0.6420 - val_loss: 0.4651 - val_precision: 0.6410 - val_recall: 0.4167 - val_f1_score: 0.5051\n",
            "Epoch 414/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.4026 - precision: 0.8307 - recall: 0.5633 - f1_score: 0.6707 - val_loss: 0.4672 - val_precision: 0.6389 - val_recall: 0.3833 - val_f1_score: 0.4792\n",
            "Epoch 415/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.4016 - precision: 0.8507 - recall: 0.5633 - f1_score: 0.6766 - val_loss: 0.4642 - val_precision: 0.6500 - val_recall: 0.4333 - val_f1_score: 0.5200\n",
            "Epoch 416/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.4016 - precision: 0.8365 - recall: 0.5767 - f1_score: 0.6817 - val_loss: 0.4650 - val_precision: 0.6757 - val_recall: 0.4167 - val_f1_score: 0.5155\n",
            "Epoch 417/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.4031 - precision: 0.8070 - recall: 0.5667 - f1_score: 0.6653 - val_loss: 0.4676 - val_precision: 0.6571 - val_recall: 0.3833 - val_f1_score: 0.4842\n",
            "Epoch 418/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.3998 - precision: 0.8258 - recall: 0.6000 - f1_score: 0.6944 - val_loss: 0.4662 - val_precision: 0.7059 - val_recall: 0.4000 - val_f1_score: 0.5106\n",
            "Epoch 419/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.4022 - precision: 0.8151 - recall: 0.5367 - f1_score: 0.6465 - val_loss: 0.4641 - val_precision: 0.6410 - val_recall: 0.4167 - val_f1_score: 0.5051\n",
            "Epoch 420/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.4005 - precision: 0.8317 - recall: 0.5867 - f1_score: 0.6877 - val_loss: 0.4673 - val_precision: 0.7059 - val_recall: 0.4000 - val_f1_score: 0.5106\n",
            "Epoch 421/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.4028 - precision: 0.8298 - recall: 0.5600 - f1_score: 0.6663 - val_loss: 0.4680 - val_precision: 0.6944 - val_recall: 0.4167 - val_f1_score: 0.5208\n",
            "Epoch 422/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3973 - precision: 0.8553 - recall: 0.5567 - f1_score: 0.6730 - val_loss: 0.4659 - val_precision: 0.6410 - val_recall: 0.4167 - val_f1_score: 0.5051\n",
            "Epoch 423/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.3988 - precision: 0.8578 - recall: 0.5733 - f1_score: 0.6856 - val_loss: 0.4649 - val_precision: 0.6500 - val_recall: 0.4333 - val_f1_score: 0.5200\n",
            "Epoch 424/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3989 - precision: 0.8285 - recall: 0.5800 - f1_score: 0.6817 - val_loss: 0.4641 - val_precision: 0.6429 - val_recall: 0.4500 - val_f1_score: 0.5294\n",
            "Epoch 425/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3980 - precision: 0.8559 - recall: 0.5867 - f1_score: 0.6960 - val_loss: 0.4636 - val_precision: 0.6410 - val_recall: 0.4167 - val_f1_score: 0.5051\n",
            "Epoch 426/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3980 - precision: 0.8402 - recall: 0.5733 - f1_score: 0.6811 - val_loss: 0.4637 - val_precision: 0.6410 - val_recall: 0.4167 - val_f1_score: 0.5051\n",
            "Epoch 427/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3974 - precision: 0.8413 - recall: 0.5800 - f1_score: 0.6850 - val_loss: 0.4639 - val_precision: 0.6410 - val_recall: 0.4167 - val_f1_score: 0.5051\n",
            "Epoch 428/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.3984 - precision: 0.8445 - recall: 0.5700 - f1_score: 0.6796 - val_loss: 0.4646 - val_precision: 0.6757 - val_recall: 0.4167 - val_f1_score: 0.5155\n",
            "Epoch 429/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3981 - precision: 0.8399 - recall: 0.5633 - f1_score: 0.6739 - val_loss: 0.4640 - val_precision: 0.6410 - val_recall: 0.4167 - val_f1_score: 0.5051\n",
            "Epoch 430/3000\n",
            "300/300 [==============================] - 0s 59us/step - loss: 0.3979 - precision: 0.8328 - recall: 0.5633 - f1_score: 0.6707 - val_loss: 0.4648 - val_precision: 0.6585 - val_recall: 0.4500 - val_f1_score: 0.5347\n",
            "Epoch 431/3000\n",
            "300/300 [==============================] - 0s 80us/step - loss: 0.4071 - precision: 0.7894 - recall: 0.5667 - f1_score: 0.6593 - val_loss: 0.4635 - val_precision: 0.6410 - val_recall: 0.4167 - val_f1_score: 0.5051\n",
            "Epoch 432/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3977 - precision: 0.8396 - recall: 0.5633 - f1_score: 0.6721 - val_loss: 0.4640 - val_precision: 0.6410 - val_recall: 0.4167 - val_f1_score: 0.5051\n",
            "Epoch 433/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3966 - precision: 0.8279 - recall: 0.5500 - f1_score: 0.6597 - val_loss: 0.4668 - val_precision: 0.6389 - val_recall: 0.3833 - val_f1_score: 0.4792\n",
            "Epoch 434/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3966 - precision: 0.8094 - recall: 0.6067 - f1_score: 0.6873 - val_loss: 0.4654 - val_precision: 0.6923 - val_recall: 0.4500 - val_f1_score: 0.5455\n",
            "Epoch 435/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3973 - precision: 0.8354 - recall: 0.5800 - f1_score: 0.6825 - val_loss: 0.4653 - val_precision: 0.6667 - val_recall: 0.4667 - val_f1_score: 0.5490\n",
            "Epoch 436/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3974 - precision: 0.8316 - recall: 0.5900 - f1_score: 0.6884 - val_loss: 0.4688 - val_precision: 0.6216 - val_recall: 0.3833 - val_f1_score: 0.4742\n",
            "Epoch 437/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3966 - precision: 0.8039 - recall: 0.5933 - f1_score: 0.6798 - val_loss: 0.4650 - val_precision: 0.6512 - val_recall: 0.4667 - val_f1_score: 0.5437\n",
            "Epoch 438/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3949 - precision: 0.8271 - recall: 0.6133 - f1_score: 0.7032 - val_loss: 0.4671 - val_precision: 0.7097 - val_recall: 0.3667 - val_f1_score: 0.4835\n",
            "Epoch 439/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3971 - precision: 0.8483 - recall: 0.5700 - f1_score: 0.6795 - val_loss: 0.4642 - val_precision: 0.6757 - val_recall: 0.4167 - val_f1_score: 0.5155\n",
            "Epoch 440/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.4003 - precision: 0.8135 - recall: 0.5533 - f1_score: 0.6558 - val_loss: 0.4711 - val_precision: 0.6000 - val_recall: 0.4000 - val_f1_score: 0.4800\n",
            "Epoch 441/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.3991 - precision: 0.8345 - recall: 0.5700 - f1_score: 0.6768 - val_loss: 0.4656 - val_precision: 0.6579 - val_recall: 0.4167 - val_f1_score: 0.5102\n",
            "Epoch 442/3000\n",
            "300/300 [==============================] - 0s 59us/step - loss: 0.4003 - precision: 0.8126 - recall: 0.5633 - f1_score: 0.6632 - val_loss: 0.4632 - val_precision: 0.6410 - val_recall: 0.4167 - val_f1_score: 0.5051\n",
            "Epoch 443/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3975 - precision: 0.8091 - recall: 0.5500 - f1_score: 0.6534 - val_loss: 0.4631 - val_precision: 0.6500 - val_recall: 0.4333 - val_f1_score: 0.5200\n",
            "Epoch 444/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3951 - precision: 0.8491 - recall: 0.5933 - f1_score: 0.6964 - val_loss: 0.4813 - val_precision: 0.6596 - val_recall: 0.5167 - val_f1_score: 0.5794\n",
            "Epoch 445/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.4074 - precision: 0.7677 - recall: 0.6000 - f1_score: 0.6734 - val_loss: 0.4645 - val_precision: 0.6579 - val_recall: 0.4167 - val_f1_score: 0.5102\n",
            "Epoch 446/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.3967 - precision: 0.8270 - recall: 0.5700 - f1_score: 0.6731 - val_loss: 0.4659 - val_precision: 0.7059 - val_recall: 0.4000 - val_f1_score: 0.5106\n",
            "Epoch 447/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3960 - precision: 0.8205 - recall: 0.5633 - f1_score: 0.6666 - val_loss: 0.4632 - val_precision: 0.6500 - val_recall: 0.4333 - val_f1_score: 0.5200\n",
            "Epoch 448/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3976 - precision: 0.8330 - recall: 0.5767 - f1_score: 0.6807 - val_loss: 0.4697 - val_precision: 0.6098 - val_recall: 0.4167 - val_f1_score: 0.4950\n",
            "Epoch 449/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3994 - precision: 0.7895 - recall: 0.5967 - f1_score: 0.6784 - val_loss: 0.4633 - val_precision: 0.6341 - val_recall: 0.4333 - val_f1_score: 0.5149\n",
            "Epoch 450/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3946 - precision: 0.8324 - recall: 0.5733 - f1_score: 0.6782 - val_loss: 0.4631 - val_precision: 0.6190 - val_recall: 0.4333 - val_f1_score: 0.5098\n",
            "Epoch 451/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3931 - precision: 0.8276 - recall: 0.5900 - f1_score: 0.6886 - val_loss: 0.4642 - val_precision: 0.6757 - val_recall: 0.4167 - val_f1_score: 0.5155\n",
            "Epoch 452/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3976 - precision: 0.8242 - recall: 0.5800 - f1_score: 0.6807 - val_loss: 0.4634 - val_precision: 0.6750 - val_recall: 0.4500 - val_f1_score: 0.5400\n",
            "Epoch 453/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3954 - precision: 0.8436 - recall: 0.5733 - f1_score: 0.6822 - val_loss: 0.4632 - val_precision: 0.6341 - val_recall: 0.4333 - val_f1_score: 0.5149\n",
            "Epoch 454/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3932 - precision: 0.8393 - recall: 0.5900 - f1_score: 0.6912 - val_loss: 0.4631 - val_precision: 0.6410 - val_recall: 0.4167 - val_f1_score: 0.5051\n",
            "Epoch 455/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3970 - precision: 0.8153 - recall: 0.5900 - f1_score: 0.6836 - val_loss: 0.4636 - val_precision: 0.6410 - val_recall: 0.4167 - val_f1_score: 0.5051\n",
            "Epoch 456/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3974 - precision: 0.8477 - recall: 0.5800 - f1_score: 0.6876 - val_loss: 0.4701 - val_precision: 0.6829 - val_recall: 0.4667 - val_f1_score: 0.5545\n",
            "Epoch 457/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3962 - precision: 0.8028 - recall: 0.5900 - f1_score: 0.6780 - val_loss: 0.4632 - val_precision: 0.6410 - val_recall: 0.4167 - val_f1_score: 0.5051\n",
            "Epoch 458/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.3999 - precision: 0.7783 - recall: 0.6000 - f1_score: 0.6765 - val_loss: 0.4629 - val_precision: 0.6585 - val_recall: 0.4500 - val_f1_score: 0.5347\n",
            "Epoch 459/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3958 - precision: 0.8347 - recall: 0.5933 - f1_score: 0.6921 - val_loss: 0.4663 - val_precision: 0.7000 - val_recall: 0.4667 - val_f1_score: 0.5600\n",
            "Epoch 460/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.3927 - precision: 0.8405 - recall: 0.6000 - f1_score: 0.6991 - val_loss: 0.4637 - val_precision: 0.6410 - val_recall: 0.4167 - val_f1_score: 0.5051\n",
            "Epoch 461/3000\n",
            "300/300 [==============================] - 0s 58us/step - loss: 0.3964 - precision: 0.7966 - recall: 0.5967 - f1_score: 0.6811 - val_loss: 0.4645 - val_precision: 0.6944 - val_recall: 0.4167 - val_f1_score: 0.5208\n",
            "Epoch 462/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3961 - precision: 0.8349 - recall: 0.5900 - f1_score: 0.6901 - val_loss: 0.4636 - val_precision: 0.6667 - val_recall: 0.4333 - val_f1_score: 0.5253\n",
            "Epoch 463/3000\n",
            "300/300 [==============================] - 0s 78us/step - loss: 0.3924 - precision: 0.8249 - recall: 0.5900 - f1_score: 0.6869 - val_loss: 0.4654 - val_precision: 0.6765 - val_recall: 0.3833 - val_f1_score: 0.4894\n",
            "Epoch 464/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3916 - precision: 0.8656 - recall: 0.5800 - f1_score: 0.6935 - val_loss: 0.4626 - val_precision: 0.6410 - val_recall: 0.4167 - val_f1_score: 0.5051\n",
            "Epoch 465/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3912 - precision: 0.8526 - recall: 0.5967 - f1_score: 0.7015 - val_loss: 0.4625 - val_precision: 0.6585 - val_recall: 0.4500 - val_f1_score: 0.5347\n",
            "Epoch 466/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3912 - precision: 0.8502 - recall: 0.5900 - f1_score: 0.6961 - val_loss: 0.4651 - val_precision: 0.6500 - val_recall: 0.4333 - val_f1_score: 0.5200\n",
            "Epoch 467/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.4038 - precision: 0.7819 - recall: 0.5600 - f1_score: 0.6519 - val_loss: 0.4719 - val_precision: 0.5854 - val_recall: 0.4000 - val_f1_score: 0.4752\n",
            "Epoch 468/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3947 - precision: 0.8096 - recall: 0.5800 - f1_score: 0.6742 - val_loss: 0.4765 - val_precision: 0.6818 - val_recall: 0.5000 - val_f1_score: 0.5769\n",
            "Epoch 469/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.4025 - precision: 0.7556 - recall: 0.5667 - f1_score: 0.6468 - val_loss: 0.4650 - val_precision: 0.6857 - val_recall: 0.4000 - val_f1_score: 0.5053\n",
            "Epoch 470/3000\n",
            "300/300 [==============================] - 0s 79us/step - loss: 0.3908 - precision: 0.8478 - recall: 0.5833 - f1_score: 0.6898 - val_loss: 0.4633 - val_precision: 0.6944 - val_recall: 0.4167 - val_f1_score: 0.5208\n",
            "Epoch 471/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3899 - precision: 0.8245 - recall: 0.5667 - f1_score: 0.6707 - val_loss: 0.4650 - val_precision: 0.6667 - val_recall: 0.4667 - val_f1_score: 0.5490\n",
            "Epoch 472/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3927 - precision: 0.8266 - recall: 0.5700 - f1_score: 0.6736 - val_loss: 0.4659 - val_precision: 0.6829 - val_recall: 0.4667 - val_f1_score: 0.5545\n",
            "Epoch 473/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3921 - precision: 0.8135 - recall: 0.5933 - f1_score: 0.6845 - val_loss: 0.4637 - val_precision: 0.6667 - val_recall: 0.4333 - val_f1_score: 0.5253\n",
            "Epoch 474/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3918 - precision: 0.8197 - recall: 0.5833 - f1_score: 0.6812 - val_loss: 0.4635 - val_precision: 0.6579 - val_recall: 0.4167 - val_f1_score: 0.5102\n",
            "Epoch 475/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.3949 - precision: 0.8216 - recall: 0.5600 - f1_score: 0.6645 - val_loss: 0.4642 - val_precision: 0.6667 - val_recall: 0.4667 - val_f1_score: 0.5490\n",
            "Epoch 476/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3915 - precision: 0.8443 - recall: 0.5533 - f1_score: 0.6679 - val_loss: 0.4790 - val_precision: 0.6667 - val_recall: 0.5000 - val_f1_score: 0.5714\n",
            "Epoch 477/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3956 - precision: 0.8028 - recall: 0.6067 - f1_score: 0.6909 - val_loss: 0.4640 - val_precision: 0.6579 - val_recall: 0.4167 - val_f1_score: 0.5102\n",
            "Epoch 478/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3925 - precision: 0.8242 - recall: 0.5667 - f1_score: 0.6693 - val_loss: 0.4649 - val_precision: 0.6410 - val_recall: 0.4167 - val_f1_score: 0.5051\n",
            "Epoch 479/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3893 - precision: 0.8663 - recall: 0.6367 - f1_score: 0.7333 - val_loss: 0.4635 - val_precision: 0.6512 - val_recall: 0.4667 - val_f1_score: 0.5437\n",
            "Epoch 480/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3893 - precision: 0.8271 - recall: 0.5833 - f1_score: 0.6834 - val_loss: 0.4624 - val_precision: 0.6429 - val_recall: 0.4500 - val_f1_score: 0.5294\n",
            "Epoch 481/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3889 - precision: 0.8490 - recall: 0.6033 - f1_score: 0.7046 - val_loss: 0.4669 - val_precision: 0.7188 - val_recall: 0.3833 - val_f1_score: 0.5000\n",
            "Epoch 482/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3905 - precision: 0.8433 - recall: 0.5800 - f1_score: 0.6864 - val_loss: 0.4694 - val_precision: 0.6389 - val_recall: 0.3833 - val_f1_score: 0.4792\n",
            "Epoch 483/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.3946 - precision: 0.7929 - recall: 0.6167 - f1_score: 0.6932 - val_loss: 0.4658 - val_precision: 0.6389 - val_recall: 0.3833 - val_f1_score: 0.4792\n",
            "Epoch 484/3000\n",
            "300/300 [==============================] - 0s 80us/step - loss: 0.3900 - precision: 0.8237 - recall: 0.5967 - f1_score: 0.6911 - val_loss: 0.4643 - val_precision: 0.6579 - val_recall: 0.4167 - val_f1_score: 0.5102\n",
            "Epoch 485/3000\n",
            "300/300 [==============================] - 0s 80us/step - loss: 0.3958 - precision: 0.7649 - recall: 0.5733 - f1_score: 0.6543 - val_loss: 0.4627 - val_precision: 0.6500 - val_recall: 0.4333 - val_f1_score: 0.5200\n",
            "Epoch 486/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.3897 - precision: 0.8198 - recall: 0.5733 - f1_score: 0.6745 - val_loss: 0.4626 - val_precision: 0.6250 - val_recall: 0.4167 - val_f1_score: 0.5000\n",
            "Epoch 487/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.3907 - precision: 0.8359 - recall: 0.6367 - f1_score: 0.7223 - val_loss: 0.4643 - val_precision: 0.6757 - val_recall: 0.4167 - val_f1_score: 0.5155\n",
            "Epoch 488/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3880 - precision: 0.8503 - recall: 0.5833 - f1_score: 0.6913 - val_loss: 0.4627 - val_precision: 0.6410 - val_recall: 0.4167 - val_f1_score: 0.5051\n",
            "Epoch 489/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3899 - precision: 0.8420 - recall: 0.5933 - f1_score: 0.6944 - val_loss: 0.4624 - val_precision: 0.6500 - val_recall: 0.4333 - val_f1_score: 0.5200\n",
            "Epoch 490/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3897 - precision: 0.8313 - recall: 0.6167 - f1_score: 0.7077 - val_loss: 0.4634 - val_precision: 0.6579 - val_recall: 0.4167 - val_f1_score: 0.5102\n",
            "Epoch 491/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.3927 - precision: 0.8505 - recall: 0.6133 - f1_score: 0.7118 - val_loss: 0.4628 - val_precision: 0.6585 - val_recall: 0.4500 - val_f1_score: 0.5347\n",
            "Epoch 492/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3881 - precision: 0.8378 - recall: 0.5833 - f1_score: 0.6865 - val_loss: 0.4675 - val_precision: 0.6571 - val_recall: 0.3833 - val_f1_score: 0.4842\n",
            "Epoch 493/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3884 - precision: 0.8427 - recall: 0.5967 - f1_score: 0.6977 - val_loss: 0.4633 - val_precision: 0.6512 - val_recall: 0.4667 - val_f1_score: 0.5437\n",
            "Epoch 494/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3884 - precision: 0.8522 - recall: 0.5900 - f1_score: 0.6956 - val_loss: 0.4635 - val_precision: 0.6750 - val_recall: 0.4500 - val_f1_score: 0.5400\n",
            "Epoch 495/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3887 - precision: 0.8031 - recall: 0.6300 - f1_score: 0.7048 - val_loss: 0.4684 - val_precision: 0.6667 - val_recall: 0.3667 - val_f1_score: 0.4731\n",
            "Epoch 496/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3958 - precision: 0.8065 - recall: 0.5933 - f1_score: 0.6818 - val_loss: 0.4695 - val_precision: 0.6571 - val_recall: 0.3833 - val_f1_score: 0.4842\n",
            "Epoch 497/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3881 - precision: 0.8360 - recall: 0.6067 - f1_score: 0.7023 - val_loss: 0.4685 - val_precision: 0.7073 - val_recall: 0.4833 - val_f1_score: 0.5743\n",
            "Epoch 498/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.3872 - precision: 0.8303 - recall: 0.6067 - f1_score: 0.7007 - val_loss: 0.4639 - val_precision: 0.6750 - val_recall: 0.4500 - val_f1_score: 0.5400\n",
            "Epoch 499/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3894 - precision: 0.8429 - recall: 0.5933 - f1_score: 0.6947 - val_loss: 0.4632 - val_precision: 0.6585 - val_recall: 0.4500 - val_f1_score: 0.5347\n",
            "Epoch 500/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.3892 - precision: 0.8150 - recall: 0.6033 - f1_score: 0.6922 - val_loss: 0.4646 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 501/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3873 - precision: 0.8286 - recall: 0.5800 - f1_score: 0.6820 - val_loss: 0.4655 - val_precision: 0.6744 - val_recall: 0.4833 - val_f1_score: 0.5631\n",
            "Epoch 502/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.3903 - precision: 0.8093 - recall: 0.5900 - f1_score: 0.6812 - val_loss: 0.4631 - val_precision: 0.6512 - val_recall: 0.4667 - val_f1_score: 0.5437\n",
            "Epoch 503/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3911 - precision: 0.7879 - recall: 0.6000 - f1_score: 0.6808 - val_loss: 0.4626 - val_precision: 0.6410 - val_recall: 0.4167 - val_f1_score: 0.5051\n",
            "Epoch 504/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3866 - precision: 0.8460 - recall: 0.6033 - f1_score: 0.7038 - val_loss: 0.4637 - val_precision: 0.6512 - val_recall: 0.4667 - val_f1_score: 0.5437\n",
            "Epoch 505/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.3887 - precision: 0.8430 - recall: 0.5900 - f1_score: 0.6936 - val_loss: 0.4636 - val_precision: 0.6579 - val_recall: 0.4167 - val_f1_score: 0.5102\n",
            "Epoch 506/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3863 - precision: 0.8289 - recall: 0.6033 - f1_score: 0.6971 - val_loss: 0.4641 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 507/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.3867 - precision: 0.8258 - recall: 0.6067 - f1_score: 0.6980 - val_loss: 0.4662 - val_precision: 0.6571 - val_recall: 0.3833 - val_f1_score: 0.4842\n",
            "Epoch 508/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.3867 - precision: 0.8416 - recall: 0.5833 - f1_score: 0.6889 - val_loss: 0.4647 - val_precision: 0.6250 - val_recall: 0.4167 - val_f1_score: 0.5000\n",
            "Epoch 509/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3852 - precision: 0.8278 - recall: 0.6333 - f1_score: 0.7172 - val_loss: 0.4628 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 510/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3845 - precision: 0.8580 - recall: 0.6167 - f1_score: 0.7171 - val_loss: 0.4646 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 511/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.3862 - precision: 0.8304 - recall: 0.6067 - f1_score: 0.7001 - val_loss: 0.4633 - val_precision: 0.6579 - val_recall: 0.4167 - val_f1_score: 0.5102\n",
            "Epoch 512/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3849 - precision: 0.8315 - recall: 0.5767 - f1_score: 0.6796 - val_loss: 0.4625 - val_precision: 0.6250 - val_recall: 0.4167 - val_f1_score: 0.5000\n",
            "Epoch 513/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3926 - precision: 0.8171 - recall: 0.6000 - f1_score: 0.6912 - val_loss: 0.4639 - val_precision: 0.6585 - val_recall: 0.4500 - val_f1_score: 0.5347\n",
            "Epoch 514/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.3839 - precision: 0.8606 - recall: 0.5867 - f1_score: 0.6963 - val_loss: 0.4623 - val_precision: 0.6190 - val_recall: 0.4333 - val_f1_score: 0.5098\n",
            "Epoch 515/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3840 - precision: 0.8409 - recall: 0.6300 - f1_score: 0.7188 - val_loss: 0.4747 - val_precision: 0.6818 - val_recall: 0.5000 - val_f1_score: 0.5769\n",
            "Epoch 516/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3871 - precision: 0.8328 - recall: 0.5900 - f1_score: 0.6901 - val_loss: 0.4638 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 517/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3851 - precision: 0.8649 - recall: 0.6100 - f1_score: 0.7150 - val_loss: 0.4625 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 518/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.3932 - precision: 0.8028 - recall: 0.5767 - f1_score: 0.6708 - val_loss: 0.4774 - val_precision: 0.6818 - val_recall: 0.5000 - val_f1_score: 0.5769\n",
            "Epoch 519/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3890 - precision: 0.8084 - recall: 0.5967 - f1_score: 0.6855 - val_loss: 0.4667 - val_precision: 0.6857 - val_recall: 0.4000 - val_f1_score: 0.5053\n",
            "Epoch 520/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3875 - precision: 0.8203 - recall: 0.5967 - f1_score: 0.6895 - val_loss: 0.4636 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 521/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.3833 - precision: 0.8335 - recall: 0.6167 - f1_score: 0.7088 - val_loss: 0.4647 - val_precision: 0.6053 - val_recall: 0.3833 - val_f1_score: 0.4694\n",
            "Epoch 522/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.3826 - precision: 0.8330 - recall: 0.6067 - f1_score: 0.7009 - val_loss: 0.4621 - val_precision: 0.6429 - val_recall: 0.4500 - val_f1_score: 0.5294\n",
            "Epoch 523/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.3828 - precision: 0.8454 - recall: 0.5867 - f1_score: 0.6910 - val_loss: 0.4624 - val_precision: 0.6667 - val_recall: 0.4667 - val_f1_score: 0.5490\n",
            "Epoch 524/3000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.3818 - precision: 0.8485 - recall: 0.6433 - f1_score: 0.7301 - val_loss: 0.4655 - val_precision: 0.6216 - val_recall: 0.3833 - val_f1_score: 0.4742\n",
            "Epoch 525/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3835 - precision: 0.8345 - recall: 0.6133 - f1_score: 0.7040 - val_loss: 0.4725 - val_precision: 0.7000 - val_recall: 0.4667 - val_f1_score: 0.5600\n",
            "Epoch 526/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3864 - precision: 0.8248 - recall: 0.6100 - f1_score: 0.7013 - val_loss: 0.4625 - val_precision: 0.6279 - val_recall: 0.4500 - val_f1_score: 0.5243\n",
            "Epoch 527/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3845 - precision: 0.8300 - recall: 0.6067 - f1_score: 0.7005 - val_loss: 0.4640 - val_precision: 0.6579 - val_recall: 0.4167 - val_f1_score: 0.5102\n",
            "Epoch 528/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.3811 - precision: 0.8355 - recall: 0.6300 - f1_score: 0.7177 - val_loss: 0.4781 - val_precision: 0.6667 - val_recall: 0.5000 - val_f1_score: 0.5714\n",
            "Epoch 529/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3858 - precision: 0.8071 - recall: 0.6100 - f1_score: 0.6940 - val_loss: 0.4626 - val_precision: 0.6279 - val_recall: 0.4500 - val_f1_score: 0.5243\n",
            "Epoch 530/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3833 - precision: 0.8179 - recall: 0.6133 - f1_score: 0.7007 - val_loss: 0.4671 - val_precision: 0.6316 - val_recall: 0.4000 - val_f1_score: 0.4898\n",
            "Epoch 531/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3862 - precision: 0.8207 - recall: 0.6100 - f1_score: 0.6991 - val_loss: 0.4625 - val_precision: 0.6279 - val_recall: 0.4500 - val_f1_score: 0.5243\n",
            "Epoch 532/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3808 - precision: 0.8431 - recall: 0.6467 - f1_score: 0.7309 - val_loss: 0.4686 - val_precision: 0.7000 - val_recall: 0.4667 - val_f1_score: 0.5600\n",
            "Epoch 533/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3864 - precision: 0.8232 - recall: 0.6100 - f1_score: 0.6997 - val_loss: 0.4622 - val_precision: 0.6429 - val_recall: 0.4500 - val_f1_score: 0.5294\n",
            "Epoch 534/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3811 - precision: 0.8628 - recall: 0.6300 - f1_score: 0.7279 - val_loss: 0.4665 - val_precision: 0.6486 - val_recall: 0.4000 - val_f1_score: 0.4948\n",
            "Epoch 535/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.3987 - precision: 0.7797 - recall: 0.5867 - f1_score: 0.6694 - val_loss: 0.4663 - val_precision: 0.6389 - val_recall: 0.3833 - val_f1_score: 0.4792\n",
            "Epoch 536/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3840 - precision: 0.8449 - recall: 0.6033 - f1_score: 0.7031 - val_loss: 0.4624 - val_precision: 0.6500 - val_recall: 0.4333 - val_f1_score: 0.5200\n",
            "Epoch 537/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.3843 - precision: 0.8448 - recall: 0.6033 - f1_score: 0.7034 - val_loss: 0.4632 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 538/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3826 - precision: 0.8460 - recall: 0.6167 - f1_score: 0.7127 - val_loss: 0.4623 - val_precision: 0.6500 - val_recall: 0.4333 - val_f1_score: 0.5200\n",
            "Epoch 539/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.3854 - precision: 0.8185 - recall: 0.6133 - f1_score: 0.7008 - val_loss: 0.4622 - val_precision: 0.6512 - val_recall: 0.4667 - val_f1_score: 0.5437\n",
            "Epoch 540/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3837 - precision: 0.8398 - recall: 0.6267 - f1_score: 0.7175 - val_loss: 0.4808 - val_precision: 0.6596 - val_recall: 0.5167 - val_f1_score: 0.5794\n",
            "Epoch 541/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.3819 - precision: 0.8192 - recall: 0.6300 - f1_score: 0.7104 - val_loss: 0.4637 - val_precision: 0.6579 - val_recall: 0.4167 - val_f1_score: 0.5102\n",
            "Epoch 542/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3789 - precision: 0.8413 - recall: 0.6233 - f1_score: 0.7148 - val_loss: 0.4659 - val_precision: 0.6818 - val_recall: 0.5000 - val_f1_score: 0.5769\n",
            "Epoch 543/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.3805 - precision: 0.8480 - recall: 0.6067 - f1_score: 0.7062 - val_loss: 0.4654 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 544/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3880 - precision: 0.8202 - recall: 0.5933 - f1_score: 0.6878 - val_loss: 0.4644 - val_precision: 0.6316 - val_recall: 0.4000 - val_f1_score: 0.4898\n",
            "Epoch 545/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3825 - precision: 0.8298 - recall: 0.6133 - f1_score: 0.7051 - val_loss: 0.4645 - val_precision: 0.6667 - val_recall: 0.4333 - val_f1_score: 0.5253\n",
            "Epoch 546/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3809 - precision: 0.8542 - recall: 0.6067 - f1_score: 0.7091 - val_loss: 0.4668 - val_precision: 0.6486 - val_recall: 0.4000 - val_f1_score: 0.4948\n",
            "Epoch 547/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3805 - precision: 0.8602 - recall: 0.6233 - f1_score: 0.7219 - val_loss: 0.4624 - val_precision: 0.6429 - val_recall: 0.4500 - val_f1_score: 0.5294\n",
            "Epoch 548/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.3806 - precision: 0.8452 - recall: 0.5967 - f1_score: 0.6980 - val_loss: 0.4631 - val_precision: 0.6047 - val_recall: 0.4333 - val_f1_score: 0.5049\n",
            "Epoch 549/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3812 - precision: 0.8656 - recall: 0.6133 - f1_score: 0.7172 - val_loss: 0.4631 - val_precision: 0.6512 - val_recall: 0.4667 - val_f1_score: 0.5437\n",
            "Epoch 550/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.3832 - precision: 0.8337 - recall: 0.6100 - f1_score: 0.7035 - val_loss: 0.4663 - val_precision: 0.6744 - val_recall: 0.4833 - val_f1_score: 0.5631\n",
            "Epoch 551/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.3811 - precision: 0.8342 - recall: 0.6300 - f1_score: 0.7174 - val_loss: 0.4654 - val_precision: 0.6053 - val_recall: 0.3833 - val_f1_score: 0.4694\n",
            "Epoch 552/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.3809 - precision: 0.8459 - recall: 0.6133 - f1_score: 0.7109 - val_loss: 0.4660 - val_precision: 0.6818 - val_recall: 0.5000 - val_f1_score: 0.5769\n",
            "Epoch 553/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3854 - precision: 0.8179 - recall: 0.6400 - f1_score: 0.7177 - val_loss: 0.4630 - val_precision: 0.6429 - val_recall: 0.4500 - val_f1_score: 0.5294\n",
            "Epoch 554/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.3806 - precision: 0.8652 - recall: 0.6267 - f1_score: 0.7258 - val_loss: 0.4624 - val_precision: 0.6429 - val_recall: 0.4500 - val_f1_score: 0.5294\n",
            "Epoch 555/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.3792 - precision: 0.8761 - recall: 0.6233 - f1_score: 0.7274 - val_loss: 0.4634 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 556/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3807 - precision: 0.8442 - recall: 0.6367 - f1_score: 0.7248 - val_loss: 0.4627 - val_precision: 0.6279 - val_recall: 0.4500 - val_f1_score: 0.5243\n",
            "Epoch 557/3000\n",
            "300/300 [==============================] - 0s 59us/step - loss: 0.3784 - precision: 0.8567 - recall: 0.6100 - f1_score: 0.7119 - val_loss: 0.4632 - val_precision: 0.6410 - val_recall: 0.4167 - val_f1_score: 0.5051\n",
            "Epoch 558/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.3808 - precision: 0.8194 - recall: 0.6133 - f1_score: 0.7002 - val_loss: 0.4743 - val_precision: 0.5814 - val_recall: 0.4167 - val_f1_score: 0.4854\n",
            "Epoch 559/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3828 - precision: 0.8175 - recall: 0.5967 - f1_score: 0.6892 - val_loss: 0.4627 - val_precision: 0.6429 - val_recall: 0.4500 - val_f1_score: 0.5294\n",
            "Epoch 560/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.3785 - precision: 0.8411 - recall: 0.6467 - f1_score: 0.7305 - val_loss: 0.4629 - val_precision: 0.6410 - val_recall: 0.4167 - val_f1_score: 0.5051\n",
            "Epoch 561/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3820 - precision: 0.8363 - recall: 0.6200 - f1_score: 0.7115 - val_loss: 0.4813 - val_precision: 0.6739 - val_recall: 0.5167 - val_f1_score: 0.5849\n",
            "Epoch 562/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3796 - precision: 0.8144 - recall: 0.6167 - f1_score: 0.7009 - val_loss: 0.4626 - val_precision: 0.6667 - val_recall: 0.4667 - val_f1_score: 0.5490\n",
            "Epoch 563/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.3795 - precision: 0.8125 - recall: 0.6433 - f1_score: 0.7172 - val_loss: 0.4642 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 564/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.3809 - precision: 0.8492 - recall: 0.6200 - f1_score: 0.7162 - val_loss: 0.4625 - val_precision: 0.6500 - val_recall: 0.4333 - val_f1_score: 0.5200\n",
            "Epoch 565/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3769 - precision: 0.8657 - recall: 0.6233 - f1_score: 0.7243 - val_loss: 0.4747 - val_precision: 0.6829 - val_recall: 0.4667 - val_f1_score: 0.5545\n",
            "Epoch 566/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.3821 - precision: 0.8054 - recall: 0.6233 - f1_score: 0.7015 - val_loss: 0.4651 - val_precision: 0.6000 - val_recall: 0.4000 - val_f1_score: 0.4800\n",
            "Epoch 567/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.3815 - precision: 0.8364 - recall: 0.6267 - f1_score: 0.7140 - val_loss: 0.4628 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 568/3000\n",
            "300/300 [==============================] - 0s 57us/step - loss: 0.3810 - precision: 0.8445 - recall: 0.6267 - f1_score: 0.7172 - val_loss: 0.4720 - val_precision: 0.6667 - val_recall: 0.5000 - val_f1_score: 0.5714\n",
            "Epoch 569/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.3821 - precision: 0.8167 - recall: 0.6100 - f1_score: 0.6980 - val_loss: 0.4638 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 570/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3793 - precision: 0.8319 - recall: 0.6100 - f1_score: 0.7032 - val_loss: 0.4628 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 571/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.3763 - precision: 0.8425 - recall: 0.6267 - f1_score: 0.7185 - val_loss: 0.4672 - val_precision: 0.6486 - val_recall: 0.4000 - val_f1_score: 0.4948\n",
            "Epoch 572/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.3777 - precision: 0.8440 - recall: 0.6500 - f1_score: 0.7326 - val_loss: 0.4630 - val_precision: 0.6500 - val_recall: 0.4333 - val_f1_score: 0.5200\n",
            "Epoch 573/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3758 - precision: 0.8625 - recall: 0.6033 - f1_score: 0.7085 - val_loss: 0.4624 - val_precision: 0.6429 - val_recall: 0.4500 - val_f1_score: 0.5294\n",
            "Epoch 574/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.3819 - precision: 0.8111 - recall: 0.6400 - f1_score: 0.7152 - val_loss: 0.4641 - val_precision: 0.6579 - val_recall: 0.4167 - val_f1_score: 0.5102\n",
            "Epoch 575/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3797 - precision: 0.8433 - recall: 0.6100 - f1_score: 0.7061 - val_loss: 0.4678 - val_precision: 0.6905 - val_recall: 0.4833 - val_f1_score: 0.5686\n",
            "Epoch 576/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.3765 - precision: 0.8518 - recall: 0.6333 - f1_score: 0.7256 - val_loss: 0.4689 - val_precision: 0.6000 - val_recall: 0.4000 - val_f1_score: 0.4800\n",
            "Epoch 577/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3756 - precision: 0.8509 - recall: 0.6233 - f1_score: 0.7189 - val_loss: 0.4656 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 578/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3785 - precision: 0.8178 - recall: 0.6433 - f1_score: 0.7197 - val_loss: 0.4702 - val_precision: 0.6098 - val_recall: 0.4167 - val_f1_score: 0.4950\n",
            "Epoch 579/3000\n",
            "300/300 [==============================] - 0s 59us/step - loss: 0.3808 - precision: 0.8161 - recall: 0.6267 - f1_score: 0.7082 - val_loss: 0.4660 - val_precision: 0.6757 - val_recall: 0.4167 - val_f1_score: 0.5155\n",
            "Epoch 580/3000\n",
            "300/300 [==============================] - 0s 59us/step - loss: 0.3776 - precision: 0.8524 - recall: 0.6300 - f1_score: 0.7234 - val_loss: 0.4626 - val_precision: 0.6279 - val_recall: 0.4500 - val_f1_score: 0.5243\n",
            "Epoch 581/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3761 - precision: 0.8673 - recall: 0.6433 - f1_score: 0.7372 - val_loss: 0.4648 - val_precision: 0.6512 - val_recall: 0.4667 - val_f1_score: 0.5437\n",
            "Epoch 582/3000\n",
            "300/300 [==============================] - 0s 59us/step - loss: 0.3766 - precision: 0.8527 - recall: 0.6167 - f1_score: 0.7141 - val_loss: 0.4643 - val_precision: 0.6667 - val_recall: 0.4333 - val_f1_score: 0.5253\n",
            "Epoch 583/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3766 - precision: 0.8496 - recall: 0.6600 - f1_score: 0.7427 - val_loss: 0.4705 - val_precision: 0.6905 - val_recall: 0.4833 - val_f1_score: 0.5686\n",
            "Epoch 584/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3780 - precision: 0.8204 - recall: 0.6233 - f1_score: 0.7080 - val_loss: 0.4626 - val_precision: 0.6512 - val_recall: 0.4667 - val_f1_score: 0.5437\n",
            "Epoch 585/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.3791 - precision: 0.8125 - recall: 0.6300 - f1_score: 0.7094 - val_loss: 0.4631 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 586/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3824 - precision: 0.8329 - recall: 0.6200 - f1_score: 0.7078 - val_loss: 0.4665 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 587/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.3757 - precision: 0.8666 - recall: 0.6300 - f1_score: 0.7292 - val_loss: 0.4672 - val_precision: 0.6818 - val_recall: 0.5000 - val_f1_score: 0.5769\n",
            "Epoch 588/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.3762 - precision: 0.8361 - recall: 0.6333 - f1_score: 0.7198 - val_loss: 0.4658 - val_precision: 0.6000 - val_recall: 0.4000 - val_f1_score: 0.4800\n",
            "Epoch 589/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.3774 - precision: 0.8592 - recall: 0.6300 - f1_score: 0.7256 - val_loss: 0.4644 - val_precision: 0.6667 - val_recall: 0.4333 - val_f1_score: 0.5253\n",
            "Epoch 590/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.3768 - precision: 0.8519 - recall: 0.5967 - f1_score: 0.7006 - val_loss: 0.4638 - val_precision: 0.6512 - val_recall: 0.4667 - val_f1_score: 0.5437\n",
            "Epoch 591/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.3784 - precision: 0.8373 - recall: 0.6700 - f1_score: 0.7434 - val_loss: 0.4641 - val_precision: 0.6667 - val_recall: 0.4333 - val_f1_score: 0.5253\n",
            "Epoch 592/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.3742 - precision: 0.8537 - recall: 0.6233 - f1_score: 0.7198 - val_loss: 0.4651 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 593/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3772 - precision: 0.8314 - recall: 0.6267 - f1_score: 0.7129 - val_loss: 0.4633 - val_precision: 0.6098 - val_recall: 0.4167 - val_f1_score: 0.4950\n",
            "Epoch 594/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.3733 - precision: 0.8510 - recall: 0.6433 - f1_score: 0.7319 - val_loss: 0.4633 - val_precision: 0.6279 - val_recall: 0.4500 - val_f1_score: 0.5243\n",
            "Epoch 595/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.3747 - precision: 0.8616 - recall: 0.6433 - f1_score: 0.7362 - val_loss: 0.4635 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 596/3000\n",
            "300/300 [==============================] - 0s 59us/step - loss: 0.3720 - precision: 0.8588 - recall: 0.6567 - f1_score: 0.7436 - val_loss: 0.4637 - val_precision: 0.6341 - val_recall: 0.4333 - val_f1_score: 0.5149\n",
            "Epoch 597/3000\n",
            "300/300 [==============================] - 0s 59us/step - loss: 0.3736 - precision: 0.8598 - recall: 0.6233 - f1_score: 0.7218 - val_loss: 0.4640 - val_precision: 0.6429 - val_recall: 0.4500 - val_f1_score: 0.5294\n",
            "Epoch 598/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.3774 - precision: 0.8495 - recall: 0.6300 - f1_score: 0.7211 - val_loss: 0.4661 - val_precision: 0.6667 - val_recall: 0.5000 - val_f1_score: 0.5714\n",
            "Epoch 599/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3769 - precision: 0.8224 - recall: 0.6200 - f1_score: 0.7066 - val_loss: 0.4641 - val_precision: 0.6512 - val_recall: 0.4667 - val_f1_score: 0.5437\n",
            "Epoch 600/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3738 - precision: 0.8223 - recall: 0.6400 - f1_score: 0.7194 - val_loss: 0.4648 - val_precision: 0.6316 - val_recall: 0.4000 - val_f1_score: 0.4898\n",
            "Epoch 601/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3744 - precision: 0.8367 - recall: 0.6400 - f1_score: 0.7244 - val_loss: 0.4651 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 602/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.3730 - precision: 0.8381 - recall: 0.6333 - f1_score: 0.7205 - val_loss: 0.4632 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 603/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.3775 - precision: 0.8299 - recall: 0.6133 - f1_score: 0.7046 - val_loss: 0.4638 - val_precision: 0.6250 - val_recall: 0.4167 - val_f1_score: 0.5000\n",
            "Epoch 604/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.3800 - precision: 0.8102 - recall: 0.6233 - f1_score: 0.7035 - val_loss: 0.4681 - val_precision: 0.6667 - val_recall: 0.4000 - val_f1_score: 0.5000\n",
            "Epoch 605/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3753 - precision: 0.8574 - recall: 0.6500 - f1_score: 0.7390 - val_loss: 0.4644 - val_precision: 0.6667 - val_recall: 0.4333 - val_f1_score: 0.5253\n",
            "Epoch 606/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3725 - precision: 0.8697 - recall: 0.6433 - f1_score: 0.7385 - val_loss: 0.4632 - val_precision: 0.6279 - val_recall: 0.4500 - val_f1_score: 0.5243\n",
            "Epoch 607/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3730 - precision: 0.8857 - recall: 0.6333 - f1_score: 0.7368 - val_loss: 0.4643 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 608/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3769 - precision: 0.8502 - recall: 0.6667 - f1_score: 0.7463 - val_loss: 0.4652 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 609/3000\n",
            "300/300 [==============================] - 0s 59us/step - loss: 0.3735 - precision: 0.8181 - recall: 0.6567 - f1_score: 0.7276 - val_loss: 0.4695 - val_precision: 0.7073 - val_recall: 0.4833 - val_f1_score: 0.5743\n",
            "Epoch 610/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3787 - precision: 0.8162 - recall: 0.5900 - f1_score: 0.6843 - val_loss: 0.4867 - val_precision: 0.6458 - val_recall: 0.5167 - val_f1_score: 0.5741\n",
            "Epoch 611/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.3733 - precision: 0.8369 - recall: 0.6333 - f1_score: 0.7206 - val_loss: 0.4665 - val_precision: 0.6216 - val_recall: 0.3833 - val_f1_score: 0.4742\n",
            "Epoch 612/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3726 - precision: 0.8423 - recall: 0.6500 - f1_score: 0.7322 - val_loss: 0.4652 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 613/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3710 - precision: 0.8474 - recall: 0.6133 - f1_score: 0.7095 - val_loss: 0.4634 - val_precision: 0.6279 - val_recall: 0.4500 - val_f1_score: 0.5243\n",
            "Epoch 614/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.3745 - precision: 0.8144 - recall: 0.6367 - f1_score: 0.7130 - val_loss: 0.4634 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 615/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3738 - precision: 0.8296 - recall: 0.6233 - f1_score: 0.7108 - val_loss: 0.4636 - val_precision: 0.6047 - val_recall: 0.4333 - val_f1_score: 0.5049\n",
            "Epoch 616/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.3718 - precision: 0.8547 - recall: 0.6667 - f1_score: 0.7479 - val_loss: 0.4642 - val_precision: 0.6512 - val_recall: 0.4667 - val_f1_score: 0.5437\n",
            "Epoch 617/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3763 - precision: 0.8457 - recall: 0.6567 - f1_score: 0.7383 - val_loss: 0.4704 - val_precision: 0.7000 - val_recall: 0.4667 - val_f1_score: 0.5600\n",
            "Epoch 618/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.3741 - precision: 0.8272 - recall: 0.6433 - f1_score: 0.7232 - val_loss: 0.4645 - val_precision: 0.6667 - val_recall: 0.4333 - val_f1_score: 0.5253\n",
            "Epoch 619/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3717 - precision: 0.8528 - recall: 0.6167 - f1_score: 0.7152 - val_loss: 0.4630 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 620/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.3714 - precision: 0.8581 - recall: 0.6167 - f1_score: 0.7163 - val_loss: 0.4631 - val_precision: 0.6429 - val_recall: 0.4500 - val_f1_score: 0.5294\n",
            "Epoch 621/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3700 - precision: 0.8689 - recall: 0.6467 - f1_score: 0.7412 - val_loss: 0.4630 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 622/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.3705 - precision: 0.8432 - recall: 0.6267 - f1_score: 0.7185 - val_loss: 0.4638 - val_precision: 0.5909 - val_recall: 0.4333 - val_f1_score: 0.5000\n",
            "Epoch 623/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.3746 - precision: 0.8502 - recall: 0.6533 - f1_score: 0.7381 - val_loss: 0.4690 - val_precision: 0.6667 - val_recall: 0.5000 - val_f1_score: 0.5714\n",
            "Epoch 624/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3769 - precision: 0.8107 - recall: 0.6700 - f1_score: 0.7329 - val_loss: 0.4657 - val_precision: 0.6744 - val_recall: 0.4833 - val_f1_score: 0.5631\n",
            "Epoch 625/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3704 - precision: 0.8537 - recall: 0.6567 - f1_score: 0.7405 - val_loss: 0.4631 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 626/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3709 - precision: 0.8496 - recall: 0.6400 - f1_score: 0.7287 - val_loss: 0.4690 - val_precision: 0.6667 - val_recall: 0.5000 - val_f1_score: 0.5714\n",
            "Epoch 627/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.3750 - precision: 0.8147 - recall: 0.6500 - f1_score: 0.7225 - val_loss: 0.4662 - val_precision: 0.6744 - val_recall: 0.4833 - val_f1_score: 0.5631\n",
            "Epoch 628/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3717 - precision: 0.8578 - recall: 0.6833 - f1_score: 0.7590 - val_loss: 0.4641 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 629/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.3696 - precision: 0.8525 - recall: 0.6500 - f1_score: 0.7373 - val_loss: 0.4667 - val_precision: 0.6154 - val_recall: 0.4000 - val_f1_score: 0.4848\n",
            "Epoch 630/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.3709 - precision: 0.8455 - recall: 0.6533 - f1_score: 0.7352 - val_loss: 0.4631 - val_precision: 0.6512 - val_recall: 0.4667 - val_f1_score: 0.5437\n",
            "Epoch 631/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3710 - precision: 0.8508 - recall: 0.6300 - f1_score: 0.7230 - val_loss: 0.4631 - val_precision: 0.6429 - val_recall: 0.4500 - val_f1_score: 0.5294\n",
            "Epoch 632/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3699 - precision: 0.8609 - recall: 0.6533 - f1_score: 0.7422 - val_loss: 0.4646 - val_precision: 0.6154 - val_recall: 0.4000 - val_f1_score: 0.4848\n",
            "Epoch 633/3000\n",
            "300/300 [==============================] - 0s 59us/step - loss: 0.3720 - precision: 0.8530 - recall: 0.6433 - f1_score: 0.7333 - val_loss: 0.4654 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 634/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.3714 - precision: 0.8422 - recall: 0.6367 - f1_score: 0.7245 - val_loss: 0.4650 - val_precision: 0.6579 - val_recall: 0.4167 - val_f1_score: 0.5102\n",
            "Epoch 635/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3727 - precision: 0.8274 - recall: 0.6267 - f1_score: 0.7118 - val_loss: 0.4669 - val_precision: 0.6667 - val_recall: 0.5000 - val_f1_score: 0.5714\n",
            "Epoch 636/3000\n",
            "300/300 [==============================] - 0s 59us/step - loss: 0.3700 - precision: 0.8411 - recall: 0.6467 - f1_score: 0.7307 - val_loss: 0.4643 - val_precision: 0.5814 - val_recall: 0.4167 - val_f1_score: 0.4854\n",
            "Epoch 637/3000\n",
            "300/300 [==============================] - 0s 57us/step - loss: 0.3696 - precision: 0.8273 - recall: 0.6433 - f1_score: 0.7231 - val_loss: 0.4632 - val_precision: 0.6512 - val_recall: 0.4667 - val_f1_score: 0.5437\n",
            "Epoch 638/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3681 - precision: 0.8433 - recall: 0.6400 - f1_score: 0.7258 - val_loss: 0.4636 - val_precision: 0.6512 - val_recall: 0.4667 - val_f1_score: 0.5437\n",
            "Epoch 639/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3680 - precision: 0.8715 - recall: 0.6533 - f1_score: 0.7455 - val_loss: 0.4644 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 640/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.3670 - precision: 0.8706 - recall: 0.6533 - f1_score: 0.7459 - val_loss: 0.4706 - val_precision: 0.6818 - val_recall: 0.5000 - val_f1_score: 0.5769\n",
            "Epoch 641/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3677 - precision: 0.8465 - recall: 0.6567 - f1_score: 0.7393 - val_loss: 0.4709 - val_precision: 0.6098 - val_recall: 0.4167 - val_f1_score: 0.4950\n",
            "Epoch 642/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3699 - precision: 0.8686 - recall: 0.6400 - f1_score: 0.7368 - val_loss: 0.4636 - val_precision: 0.6512 - val_recall: 0.4667 - val_f1_score: 0.5437\n",
            "Epoch 643/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3698 - precision: 0.8507 - recall: 0.6433 - f1_score: 0.7309 - val_loss: 0.4697 - val_precision: 0.6667 - val_recall: 0.5000 - val_f1_score: 0.5714\n",
            "Epoch 644/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.3681 - precision: 0.8368 - recall: 0.6667 - f1_score: 0.7406 - val_loss: 0.4664 - val_precision: 0.6667 - val_recall: 0.5000 - val_f1_score: 0.5714\n",
            "Epoch 645/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3681 - precision: 0.8319 - recall: 0.6433 - f1_score: 0.7247 - val_loss: 0.4681 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 646/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.3672 - precision: 0.8670 - recall: 0.6400 - f1_score: 0.7352 - val_loss: 0.4635 - val_precision: 0.6279 - val_recall: 0.4500 - val_f1_score: 0.5243\n",
            "Epoch 647/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3697 - precision: 0.8378 - recall: 0.6700 - f1_score: 0.7438 - val_loss: 0.4679 - val_precision: 0.6667 - val_recall: 0.5000 - val_f1_score: 0.5714\n",
            "Epoch 648/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.3728 - precision: 0.8277 - recall: 0.6400 - f1_score: 0.7215 - val_loss: 0.4646 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 649/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3682 - precision: 0.8434 - recall: 0.6600 - f1_score: 0.7384 - val_loss: 0.4638 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 650/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.3677 - precision: 0.8536 - recall: 0.6600 - f1_score: 0.7437 - val_loss: 0.4649 - val_precision: 0.6341 - val_recall: 0.4333 - val_f1_score: 0.5149\n",
            "Epoch 651/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.3685 - precision: 0.8562 - recall: 0.6533 - f1_score: 0.7403 - val_loss: 0.4675 - val_precision: 0.6667 - val_recall: 0.5000 - val_f1_score: 0.5714\n",
            "Epoch 652/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3695 - precision: 0.8393 - recall: 0.6300 - f1_score: 0.7196 - val_loss: 0.4638 - val_precision: 0.6512 - val_recall: 0.4667 - val_f1_score: 0.5437\n",
            "Epoch 653/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3687 - precision: 0.8422 - recall: 0.6433 - f1_score: 0.7282 - val_loss: 0.4637 - val_precision: 0.6512 - val_recall: 0.4667 - val_f1_score: 0.5437\n",
            "Epoch 654/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.3678 - precision: 0.8493 - recall: 0.6767 - f1_score: 0.7524 - val_loss: 0.4652 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 655/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3671 - precision: 0.8635 - recall: 0.6567 - f1_score: 0.7459 - val_loss: 0.4643 - val_precision: 0.5952 - val_recall: 0.4167 - val_f1_score: 0.4902\n",
            "Epoch 656/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.3679 - precision: 0.8563 - recall: 0.6600 - f1_score: 0.7451 - val_loss: 0.4658 - val_precision: 0.6154 - val_recall: 0.4000 - val_f1_score: 0.4848\n",
            "Epoch 657/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3664 - precision: 0.8614 - recall: 0.6633 - f1_score: 0.7494 - val_loss: 0.4639 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 658/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3686 - precision: 0.8347 - recall: 0.6533 - f1_score: 0.7327 - val_loss: 0.4646 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 659/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3696 - precision: 0.8204 - recall: 0.6500 - f1_score: 0.7246 - val_loss: 0.4650 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 660/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3648 - precision: 0.8525 - recall: 0.6600 - f1_score: 0.7435 - val_loss: 0.4765 - val_precision: 0.6042 - val_recall: 0.4833 - val_f1_score: 0.5370\n",
            "Epoch 661/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3763 - precision: 0.7993 - recall: 0.6300 - f1_score: 0.7045 - val_loss: 0.4644 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 662/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3660 - precision: 0.8635 - recall: 0.6567 - f1_score: 0.7455 - val_loss: 0.4658 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 663/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.3671 - precision: 0.8537 - recall: 0.6767 - f1_score: 0.7548 - val_loss: 0.4648 - val_precision: 0.6512 - val_recall: 0.4667 - val_f1_score: 0.5437\n",
            "Epoch 664/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3653 - precision: 0.8748 - recall: 0.6500 - f1_score: 0.7443 - val_loss: 0.4658 - val_precision: 0.6512 - val_recall: 0.4667 - val_f1_score: 0.5437\n",
            "Epoch 665/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3662 - precision: 0.8448 - recall: 0.6267 - f1_score: 0.7179 - val_loss: 0.4642 - val_precision: 0.6279 - val_recall: 0.4500 - val_f1_score: 0.5243\n",
            "Epoch 666/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.3653 - precision: 0.8610 - recall: 0.6633 - f1_score: 0.7493 - val_loss: 0.4662 - val_precision: 0.6000 - val_recall: 0.4000 - val_f1_score: 0.4800\n",
            "Epoch 667/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3669 - precision: 0.8332 - recall: 0.6333 - f1_score: 0.7194 - val_loss: 0.4667 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 668/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.3676 - precision: 0.8306 - recall: 0.6533 - f1_score: 0.7312 - val_loss: 0.4660 - val_precision: 0.6667 - val_recall: 0.4333 - val_f1_score: 0.5253\n",
            "Epoch 669/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3680 - precision: 0.8425 - recall: 0.6367 - f1_score: 0.7250 - val_loss: 0.4650 - val_precision: 0.6341 - val_recall: 0.4333 - val_f1_score: 0.5149\n",
            "Epoch 670/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.3646 - precision: 0.8688 - recall: 0.6367 - f1_score: 0.7343 - val_loss: 0.4646 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 671/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3641 - precision: 0.8676 - recall: 0.6767 - f1_score: 0.7602 - val_loss: 0.4643 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 672/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3660 - precision: 0.8280 - recall: 0.6733 - f1_score: 0.7426 - val_loss: 0.4651 - val_precision: 0.6512 - val_recall: 0.4667 - val_f1_score: 0.5437\n",
            "Epoch 673/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3641 - precision: 0.8419 - recall: 0.6567 - f1_score: 0.7362 - val_loss: 0.4643 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 674/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3644 - precision: 0.8649 - recall: 0.6667 - f1_score: 0.7524 - val_loss: 0.4652 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 675/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3630 - precision: 0.8481 - recall: 0.6700 - f1_score: 0.7479 - val_loss: 0.4648 - val_precision: 0.6279 - val_recall: 0.4500 - val_f1_score: 0.5243\n",
            "Epoch 676/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3758 - precision: 0.7956 - recall: 0.6033 - f1_score: 0.6858 - val_loss: 0.4676 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 677/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3641 - precision: 0.8538 - recall: 0.6633 - f1_score: 0.7451 - val_loss: 0.4670 - val_precision: 0.6667 - val_recall: 0.5000 - val_f1_score: 0.5714\n",
            "Epoch 678/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3693 - precision: 0.8390 - recall: 0.6633 - f1_score: 0.7396 - val_loss: 0.4649 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 679/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3631 - precision: 0.8684 - recall: 0.6833 - f1_score: 0.7646 - val_loss: 0.4661 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 680/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3618 - precision: 0.8490 - recall: 0.6633 - f1_score: 0.7442 - val_loss: 0.4659 - val_precision: 0.5854 - val_recall: 0.4000 - val_f1_score: 0.4752\n",
            "Epoch 681/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3642 - precision: 0.8463 - recall: 0.6733 - f1_score: 0.7497 - val_loss: 0.4664 - val_precision: 0.6154 - val_recall: 0.4000 - val_f1_score: 0.4848\n",
            "Epoch 682/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3652 - precision: 0.8464 - recall: 0.6700 - f1_score: 0.7473 - val_loss: 0.4662 - val_precision: 0.6579 - val_recall: 0.4167 - val_f1_score: 0.5102\n",
            "Epoch 683/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3629 - precision: 0.8624 - recall: 0.6533 - f1_score: 0.7429 - val_loss: 0.4684 - val_precision: 0.5854 - val_recall: 0.4000 - val_f1_score: 0.4752\n",
            "Epoch 684/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3650 - precision: 0.8623 - recall: 0.6700 - f1_score: 0.7535 - val_loss: 0.4643 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 685/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3666 - precision: 0.8413 - recall: 0.6533 - f1_score: 0.7354 - val_loss: 0.4655 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 686/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3615 - precision: 0.8308 - recall: 0.6767 - f1_score: 0.7452 - val_loss: 0.4737 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 687/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3722 - precision: 0.7980 - recall: 0.6300 - f1_score: 0.7039 - val_loss: 0.4647 - val_precision: 0.6429 - val_recall: 0.4500 - val_f1_score: 0.5294\n",
            "Epoch 688/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3617 - precision: 0.8556 - recall: 0.6833 - f1_score: 0.7595 - val_loss: 0.4656 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 689/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3713 - precision: 0.8355 - recall: 0.6333 - f1_score: 0.7192 - val_loss: 0.4657 - val_precision: 0.6190 - val_recall: 0.4333 - val_f1_score: 0.5098\n",
            "Epoch 690/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3643 - precision: 0.8532 - recall: 0.6467 - f1_score: 0.7349 - val_loss: 0.4653 - val_precision: 0.6341 - val_recall: 0.4333 - val_f1_score: 0.5149\n",
            "Epoch 691/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.3611 - precision: 0.8737 - recall: 0.6600 - f1_score: 0.7511 - val_loss: 0.4651 - val_precision: 0.5814 - val_recall: 0.4167 - val_f1_score: 0.4854\n",
            "Epoch 692/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3620 - precision: 0.8771 - recall: 0.6433 - f1_score: 0.7415 - val_loss: 0.4721 - val_precision: 0.6190 - val_recall: 0.4333 - val_f1_score: 0.5098\n",
            "Epoch 693/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3619 - precision: 0.8486 - recall: 0.6533 - f1_score: 0.7379 - val_loss: 0.4668 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 694/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3641 - precision: 0.8540 - recall: 0.6533 - f1_score: 0.7397 - val_loss: 0.4649 - val_precision: 0.6512 - val_recall: 0.4667 - val_f1_score: 0.5437\n",
            "Epoch 695/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3618 - precision: 0.8579 - recall: 0.6800 - f1_score: 0.7580 - val_loss: 0.4812 - val_precision: 0.7045 - val_recall: 0.5167 - val_f1_score: 0.5962\n",
            "Epoch 696/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3726 - precision: 0.8029 - recall: 0.6533 - f1_score: 0.7200 - val_loss: 0.4673 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 697/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.3656 - precision: 0.8397 - recall: 0.6467 - f1_score: 0.7306 - val_loss: 0.4652 - val_precision: 0.6512 - val_recall: 0.4667 - val_f1_score: 0.5437\n",
            "Epoch 698/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3612 - precision: 0.8725 - recall: 0.6600 - f1_score: 0.7504 - val_loss: 0.4659 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 699/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.3636 - precision: 0.8543 - recall: 0.6333 - f1_score: 0.7244 - val_loss: 0.4646 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 700/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3603 - precision: 0.8629 - recall: 0.6733 - f1_score: 0.7561 - val_loss: 0.4649 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 701/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.3638 - precision: 0.8532 - recall: 0.6567 - f1_score: 0.7418 - val_loss: 0.4655 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 702/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.3600 - precision: 0.8763 - recall: 0.6800 - f1_score: 0.7651 - val_loss: 0.4665 - val_precision: 0.5854 - val_recall: 0.4000 - val_f1_score: 0.4752\n",
            "Epoch 703/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.3615 - precision: 0.8608 - recall: 0.6667 - f1_score: 0.7511 - val_loss: 0.4657 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 704/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.3657 - precision: 0.8470 - recall: 0.6533 - f1_score: 0.7374 - val_loss: 0.4718 - val_precision: 0.6667 - val_recall: 0.5000 - val_f1_score: 0.5714\n",
            "Epoch 705/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.3682 - precision: 0.8234 - recall: 0.6433 - f1_score: 0.7218 - val_loss: 0.4667 - val_precision: 0.6154 - val_recall: 0.4000 - val_f1_score: 0.4848\n",
            "Epoch 706/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.3625 - precision: 0.8534 - recall: 0.6800 - f1_score: 0.7567 - val_loss: 0.4673 - val_precision: 0.6000 - val_recall: 0.4000 - val_f1_score: 0.4800\n",
            "Epoch 707/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.3625 - precision: 0.8588 - recall: 0.7000 - f1_score: 0.7708 - val_loss: 0.4657 - val_precision: 0.5778 - val_recall: 0.4333 - val_f1_score: 0.4952\n",
            "Epoch 708/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3668 - precision: 0.8434 - recall: 0.6600 - f1_score: 0.7404 - val_loss: 0.4679 - val_precision: 0.5854 - val_recall: 0.4000 - val_f1_score: 0.4752\n",
            "Epoch 709/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3591 - precision: 0.8706 - recall: 0.6567 - f1_score: 0.7477 - val_loss: 0.4666 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 710/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3597 - precision: 0.8526 - recall: 0.6600 - f1_score: 0.7434 - val_loss: 0.4655 - val_precision: 0.6429 - val_recall: 0.4500 - val_f1_score: 0.5294\n",
            "Epoch 711/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3638 - precision: 0.8455 - recall: 0.6600 - f1_score: 0.7410 - val_loss: 0.4689 - val_precision: 0.6000 - val_recall: 0.4000 - val_f1_score: 0.4800\n",
            "Epoch 712/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3647 - precision: 0.8604 - recall: 0.6667 - f1_score: 0.7503 - val_loss: 0.4667 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 713/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3592 - precision: 0.8763 - recall: 0.6833 - f1_score: 0.7665 - val_loss: 0.4678 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 714/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3602 - precision: 0.8684 - recall: 0.7000 - f1_score: 0.7749 - val_loss: 0.4651 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 715/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3615 - precision: 0.8778 - recall: 0.6667 - f1_score: 0.7573 - val_loss: 0.4655 - val_precision: 0.5870 - val_recall: 0.4500 - val_f1_score: 0.5094\n",
            "Epoch 716/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3592 - precision: 0.8626 - recall: 0.6867 - f1_score: 0.7641 - val_loss: 0.4653 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 717/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3578 - precision: 0.8670 - recall: 0.6933 - f1_score: 0.7696 - val_loss: 0.4802 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 718/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3629 - precision: 0.8500 - recall: 0.6467 - f1_score: 0.7339 - val_loss: 0.4668 - val_precision: 0.5854 - val_recall: 0.4000 - val_f1_score: 0.4752\n",
            "Epoch 719/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3619 - precision: 0.8407 - recall: 0.6633 - f1_score: 0.7412 - val_loss: 0.4659 - val_precision: 0.6429 - val_recall: 0.4500 - val_f1_score: 0.5294\n",
            "Epoch 720/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.3595 - precision: 0.8587 - recall: 0.6600 - f1_score: 0.7453 - val_loss: 0.4675 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 721/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.3626 - precision: 0.8393 - recall: 0.6633 - f1_score: 0.7410 - val_loss: 0.4665 - val_precision: 0.6429 - val_recall: 0.4500 - val_f1_score: 0.5294\n",
            "Epoch 722/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3627 - precision: 0.8463 - recall: 0.6700 - f1_score: 0.7474 - val_loss: 0.4654 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 723/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3585 - precision: 0.8722 - recall: 0.6767 - f1_score: 0.7619 - val_loss: 0.4652 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 724/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3573 - precision: 0.8694 - recall: 0.6700 - f1_score: 0.7565 - val_loss: 0.4699 - val_precision: 0.6316 - val_recall: 0.4000 - val_f1_score: 0.4898\n",
            "Epoch 725/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3636 - precision: 0.8398 - recall: 0.6400 - f1_score: 0.7258 - val_loss: 0.4668 - val_precision: 0.5814 - val_recall: 0.4167 - val_f1_score: 0.4854\n",
            "Epoch 726/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.3619 - precision: 0.8289 - recall: 0.6767 - f1_score: 0.7448 - val_loss: 0.4659 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 727/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.3589 - precision: 0.8735 - recall: 0.7067 - f1_score: 0.7808 - val_loss: 0.4656 - val_precision: 0.6512 - val_recall: 0.4667 - val_f1_score: 0.5437\n",
            "Epoch 728/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3624 - precision: 0.8511 - recall: 0.6667 - f1_score: 0.7474 - val_loss: 0.4674 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 729/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3644 - precision: 0.8269 - recall: 0.6700 - f1_score: 0.7401 - val_loss: 0.4666 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 730/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.3568 - precision: 0.8742 - recall: 0.6667 - f1_score: 0.7557 - val_loss: 0.4653 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 731/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3576 - precision: 0.8801 - recall: 0.6833 - f1_score: 0.7667 - val_loss: 0.4653 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 732/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.3631 - precision: 0.8342 - recall: 0.6700 - f1_score: 0.7429 - val_loss: 0.4663 - val_precision: 0.6512 - val_recall: 0.4667 - val_f1_score: 0.5437\n",
            "Epoch 733/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.3581 - precision: 0.8543 - recall: 0.6667 - f1_score: 0.7481 - val_loss: 0.4751 - val_precision: 0.6818 - val_recall: 0.5000 - val_f1_score: 0.5769\n",
            "Epoch 734/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.3577 - precision: 0.8446 - recall: 0.6833 - f1_score: 0.7544 - val_loss: 0.4661 - val_precision: 0.5778 - val_recall: 0.4333 - val_f1_score: 0.4952\n",
            "Epoch 735/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.3584 - precision: 0.8578 - recall: 0.6733 - f1_score: 0.7526 - val_loss: 0.4668 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 736/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.3565 - precision: 0.8471 - recall: 0.6900 - f1_score: 0.7599 - val_loss: 0.4738 - val_precision: 0.6190 - val_recall: 0.4333 - val_f1_score: 0.5098\n",
            "Epoch 737/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3683 - precision: 0.8289 - recall: 0.6500 - f1_score: 0.7265 - val_loss: 0.4658 - val_precision: 0.6512 - val_recall: 0.4667 - val_f1_score: 0.5437\n",
            "Epoch 738/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.3580 - precision: 0.8639 - recall: 0.6733 - f1_score: 0.7565 - val_loss: 0.4669 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 739/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.3566 - precision: 0.8589 - recall: 0.6967 - f1_score: 0.7670 - val_loss: 0.4700 - val_precision: 0.6667 - val_recall: 0.5000 - val_f1_score: 0.5714\n",
            "Epoch 740/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3621 - precision: 0.8300 - recall: 0.6467 - f1_score: 0.7267 - val_loss: 0.4712 - val_precision: 0.6154 - val_recall: 0.4000 - val_f1_score: 0.4848\n",
            "Epoch 741/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3618 - precision: 0.8468 - recall: 0.6533 - f1_score: 0.7374 - val_loss: 0.4718 - val_precision: 0.6667 - val_recall: 0.5000 - val_f1_score: 0.5714\n",
            "Epoch 742/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3572 - precision: 0.8406 - recall: 0.6833 - f1_score: 0.7537 - val_loss: 0.4663 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 743/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3553 - precision: 0.8823 - recall: 0.6767 - f1_score: 0.7653 - val_loss: 0.4688 - val_precision: 0.6000 - val_recall: 0.4000 - val_f1_score: 0.4800\n",
            "Epoch 744/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.3605 - precision: 0.8393 - recall: 0.6833 - f1_score: 0.7526 - val_loss: 0.4665 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 745/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.3570 - precision: 0.8675 - recall: 0.6800 - f1_score: 0.7615 - val_loss: 0.4664 - val_precision: 0.6512 - val_recall: 0.4667 - val_f1_score: 0.5437\n",
            "Epoch 746/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.3561 - precision: 0.8620 - recall: 0.6733 - f1_score: 0.7559 - val_loss: 0.4670 - val_precision: 0.6512 - val_recall: 0.4667 - val_f1_score: 0.5437\n",
            "Epoch 747/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.3564 - precision: 0.8780 - recall: 0.7000 - f1_score: 0.7781 - val_loss: 0.4671 - val_precision: 0.5682 - val_recall: 0.4167 - val_f1_score: 0.4808\n",
            "Epoch 748/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3614 - precision: 0.8259 - recall: 0.6567 - f1_score: 0.7305 - val_loss: 0.4712 - val_precision: 0.6250 - val_recall: 0.4167 - val_f1_score: 0.5000\n",
            "Epoch 749/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3566 - precision: 0.8435 - recall: 0.6800 - f1_score: 0.7526 - val_loss: 0.4675 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 750/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3591 - precision: 0.8336 - recall: 0.6667 - f1_score: 0.7404 - val_loss: 0.4747 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 751/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3590 - precision: 0.8405 - recall: 0.6767 - f1_score: 0.7490 - val_loss: 0.4658 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 752/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3543 - precision: 0.8697 - recall: 0.6700 - f1_score: 0.7560 - val_loss: 0.4661 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 753/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3595 - precision: 0.8409 - recall: 0.6700 - f1_score: 0.7454 - val_loss: 0.4659 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 754/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3546 - precision: 0.8773 - recall: 0.6900 - f1_score: 0.7724 - val_loss: 0.4677 - val_precision: 0.5952 - val_recall: 0.4167 - val_f1_score: 0.4902\n",
            "Epoch 755/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3585 - precision: 0.8599 - recall: 0.6767 - f1_score: 0.7571 - val_loss: 0.4661 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 756/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3560 - precision: 0.8546 - recall: 0.6700 - f1_score: 0.7501 - val_loss: 0.4873 - val_precision: 0.5714 - val_recall: 0.4667 - val_f1_score: 0.5138\n",
            "Epoch 757/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3696 - precision: 0.8025 - recall: 0.6267 - f1_score: 0.7029 - val_loss: 0.4663 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 758/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3628 - precision: 0.8211 - recall: 0.6767 - f1_score: 0.7414 - val_loss: 0.4889 - val_precision: 0.5714 - val_recall: 0.4667 - val_f1_score: 0.5138\n",
            "Epoch 759/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3603 - precision: 0.8150 - recall: 0.6700 - f1_score: 0.7352 - val_loss: 0.4688 - val_precision: 0.6410 - val_recall: 0.4167 - val_f1_score: 0.5051\n",
            "Epoch 760/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3612 - precision: 0.8419 - recall: 0.6600 - f1_score: 0.7393 - val_loss: 0.4689 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 761/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3557 - precision: 0.8688 - recall: 0.6633 - f1_score: 0.7517 - val_loss: 0.4665 - val_precision: 0.6512 - val_recall: 0.4667 - val_f1_score: 0.5437\n",
            "Epoch 762/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.3535 - precision: 0.8754 - recall: 0.6867 - f1_score: 0.7689 - val_loss: 0.4670 - val_precision: 0.5778 - val_recall: 0.4333 - val_f1_score: 0.4952\n",
            "Epoch 763/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.3550 - precision: 0.8705 - recall: 0.6733 - f1_score: 0.7588 - val_loss: 0.4674 - val_precision: 0.6341 - val_recall: 0.4333 - val_f1_score: 0.5149\n",
            "Epoch 764/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3552 - precision: 0.8601 - recall: 0.6967 - f1_score: 0.7697 - val_loss: 0.4666 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 765/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.3538 - precision: 0.8723 - recall: 0.7000 - f1_score: 0.7765 - val_loss: 0.4662 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 766/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.3557 - precision: 0.8563 - recall: 0.6933 - f1_score: 0.7660 - val_loss: 0.4733 - val_precision: 0.6667 - val_recall: 0.5000 - val_f1_score: 0.5714\n",
            "Epoch 767/3000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.3534 - precision: 0.8489 - recall: 0.6733 - f1_score: 0.7503 - val_loss: 0.4748 - val_precision: 0.5957 - val_recall: 0.4667 - val_f1_score: 0.5234\n",
            "Epoch 768/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.3581 - precision: 0.8343 - recall: 0.6800 - f1_score: 0.7486 - val_loss: 0.4865 - val_precision: 0.5714 - val_recall: 0.4667 - val_f1_score: 0.5138\n",
            "Epoch 769/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3775 - precision: 0.7872 - recall: 0.6267 - f1_score: 0.6967 - val_loss: 0.4697 - val_precision: 0.5952 - val_recall: 0.4167 - val_f1_score: 0.4902\n",
            "Epoch 770/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.3569 - precision: 0.8267 - recall: 0.6767 - f1_score: 0.7440 - val_loss: 0.4702 - val_precision: 0.6585 - val_recall: 0.4500 - val_f1_score: 0.5347\n",
            "Epoch 771/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.3574 - precision: 0.8540 - recall: 0.6667 - f1_score: 0.7482 - val_loss: 0.4687 - val_precision: 0.5854 - val_recall: 0.4000 - val_f1_score: 0.4752\n",
            "Epoch 772/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.3545 - precision: 0.8746 - recall: 0.6767 - f1_score: 0.7618 - val_loss: 0.4761 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 773/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3562 - precision: 0.8259 - recall: 0.6800 - f1_score: 0.7459 - val_loss: 0.4762 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 774/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.3548 - precision: 0.8290 - recall: 0.6567 - f1_score: 0.7312 - val_loss: 0.4697 - val_precision: 0.5854 - val_recall: 0.4000 - val_f1_score: 0.4752\n",
            "Epoch 775/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3536 - precision: 0.8817 - recall: 0.6867 - f1_score: 0.7712 - val_loss: 0.4667 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 776/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3530 - precision: 0.8752 - recall: 0.6800 - f1_score: 0.7643 - val_loss: 0.4666 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 777/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.3516 - precision: 0.8705 - recall: 0.6867 - f1_score: 0.7670 - val_loss: 0.4680 - val_precision: 0.6512 - val_recall: 0.4667 - val_f1_score: 0.5437\n",
            "Epoch 778/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.3523 - precision: 0.8524 - recall: 0.6567 - f1_score: 0.7412 - val_loss: 0.4668 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 779/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.3537 - precision: 0.8553 - recall: 0.6967 - f1_score: 0.7675 - val_loss: 0.4677 - val_precision: 0.6279 - val_recall: 0.4500 - val_f1_score: 0.5243\n",
            "Epoch 780/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.3540 - precision: 0.8912 - recall: 0.6800 - f1_score: 0.7708 - val_loss: 0.4679 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 781/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.3522 - precision: 0.8737 - recall: 0.6867 - f1_score: 0.7682 - val_loss: 0.4674 - val_precision: 0.6512 - val_recall: 0.4667 - val_f1_score: 0.5437\n",
            "Epoch 782/3000\n",
            "300/300 [==============================] - 0s 109us/step - loss: 0.3543 - precision: 0.8570 - recall: 0.6900 - f1_score: 0.7631 - val_loss: 0.4674 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 783/3000\n",
            "300/300 [==============================] - 0s 84us/step - loss: 0.3532 - precision: 0.8639 - recall: 0.6767 - f1_score: 0.7585 - val_loss: 0.4697 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 784/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3525 - precision: 0.8692 - recall: 0.6867 - f1_score: 0.7670 - val_loss: 0.4669 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 785/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.3581 - precision: 0.8151 - recall: 0.6567 - f1_score: 0.7264 - val_loss: 0.4749 - val_precision: 0.6818 - val_recall: 0.5000 - val_f1_score: 0.5769\n",
            "Epoch 786/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3557 - precision: 0.8287 - recall: 0.6767 - f1_score: 0.7437 - val_loss: 0.4682 - val_precision: 0.6512 - val_recall: 0.4667 - val_f1_score: 0.5437\n",
            "Epoch 787/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.3517 - precision: 0.8700 - recall: 0.6733 - f1_score: 0.7582 - val_loss: 0.4736 - val_precision: 0.5952 - val_recall: 0.4167 - val_f1_score: 0.4902\n",
            "Epoch 788/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3496 - precision: 0.8512 - recall: 0.6900 - f1_score: 0.7614 - val_loss: 0.4733 - val_precision: 0.6522 - val_recall: 0.5000 - val_f1_score: 0.5660\n",
            "Epoch 789/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.3541 - precision: 0.8274 - recall: 0.6667 - f1_score: 0.7374 - val_loss: 0.4709 - val_precision: 0.6000 - val_recall: 0.4000 - val_f1_score: 0.4800\n",
            "Epoch 790/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.3518 - precision: 0.8652 - recall: 0.6733 - f1_score: 0.7567 - val_loss: 0.4686 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 791/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.3549 - precision: 0.8545 - recall: 0.6900 - f1_score: 0.7631 - val_loss: 0.4678 - val_precision: 0.6512 - val_recall: 0.4667 - val_f1_score: 0.5437\n",
            "Epoch 792/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.3519 - precision: 0.8619 - recall: 0.6667 - f1_score: 0.7516 - val_loss: 0.4672 - val_precision: 0.6279 - val_recall: 0.4500 - val_f1_score: 0.5243\n",
            "Epoch 793/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3504 - precision: 0.8657 - recall: 0.6967 - f1_score: 0.7715 - val_loss: 0.4673 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 794/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.3494 - precision: 0.8678 - recall: 0.6967 - f1_score: 0.7721 - val_loss: 0.4747 - val_precision: 0.6000 - val_recall: 0.4000 - val_f1_score: 0.4800\n",
            "Epoch 795/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3534 - precision: 0.8765 - recall: 0.6833 - f1_score: 0.7672 - val_loss: 0.4685 - val_precision: 0.5682 - val_recall: 0.4167 - val_f1_score: 0.4808\n",
            "Epoch 796/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.3514 - precision: 0.8530 - recall: 0.6967 - f1_score: 0.7666 - val_loss: 0.4681 - val_precision: 0.6429 - val_recall: 0.4500 - val_f1_score: 0.5294\n",
            "Epoch 797/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3522 - precision: 0.8720 - recall: 0.6833 - f1_score: 0.7658 - val_loss: 0.4674 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 798/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.3516 - precision: 0.8726 - recall: 0.7100 - f1_score: 0.7827 - val_loss: 0.4680 - val_precision: 0.6512 - val_recall: 0.4667 - val_f1_score: 0.5437\n",
            "Epoch 799/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3502 - precision: 0.8631 - recall: 0.7033 - f1_score: 0.7746 - val_loss: 0.4677 - val_precision: 0.6512 - val_recall: 0.4667 - val_f1_score: 0.5437\n",
            "Epoch 800/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.3504 - precision: 0.8733 - recall: 0.6900 - f1_score: 0.7709 - val_loss: 0.4683 - val_precision: 0.5909 - val_recall: 0.4333 - val_f1_score: 0.5000\n",
            "Epoch 801/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3533 - precision: 0.8525 - recall: 0.6900 - f1_score: 0.7616 - val_loss: 0.4686 - val_precision: 0.5682 - val_recall: 0.4167 - val_f1_score: 0.4808\n",
            "Epoch 802/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3590 - precision: 0.8492 - recall: 0.6567 - f1_score: 0.7393 - val_loss: 0.4680 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 803/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3514 - precision: 0.8741 - recall: 0.7067 - f1_score: 0.7804 - val_loss: 0.4692 - val_precision: 0.5714 - val_recall: 0.4000 - val_f1_score: 0.4706\n",
            "Epoch 804/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3534 - precision: 0.8432 - recall: 0.6800 - f1_score: 0.7521 - val_loss: 0.4673 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 805/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.3508 - precision: 0.8707 - recall: 0.6833 - f1_score: 0.7655 - val_loss: 0.4676 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 806/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3574 - precision: 0.8345 - recall: 0.6600 - f1_score: 0.7368 - val_loss: 0.4697 - val_precision: 0.5952 - val_recall: 0.4167 - val_f1_score: 0.4902\n",
            "Epoch 807/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3495 - precision: 0.8785 - recall: 0.7033 - f1_score: 0.7807 - val_loss: 0.4694 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 808/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.3524 - precision: 0.8430 - recall: 0.6733 - f1_score: 0.7482 - val_loss: 0.4685 - val_precision: 0.5682 - val_recall: 0.4167 - val_f1_score: 0.4808\n",
            "Epoch 809/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3540 - precision: 0.8452 - recall: 0.6700 - f1_score: 0.7463 - val_loss: 0.4720 - val_precision: 0.6000 - val_recall: 0.4000 - val_f1_score: 0.4800\n",
            "Epoch 810/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.3529 - precision: 0.8562 - recall: 0.6800 - f1_score: 0.7577 - val_loss: 0.4738 - val_precision: 0.5952 - val_recall: 0.4167 - val_f1_score: 0.4902\n",
            "Epoch 811/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3599 - precision: 0.8102 - recall: 0.6467 - f1_score: 0.7173 - val_loss: 0.4706 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 812/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.3509 - precision: 0.8667 - recall: 0.6900 - f1_score: 0.7676 - val_loss: 0.4695 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 813/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3540 - precision: 0.8452 - recall: 0.7000 - f1_score: 0.7650 - val_loss: 0.4729 - val_precision: 0.6154 - val_recall: 0.4000 - val_f1_score: 0.4848\n",
            "Epoch 814/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.3507 - precision: 0.8512 - recall: 0.6700 - f1_score: 0.7495 - val_loss: 0.4903 - val_precision: 0.5882 - val_recall: 0.5000 - val_f1_score: 0.5405\n",
            "Epoch 815/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.3557 - precision: 0.8565 - recall: 0.6933 - f1_score: 0.7661 - val_loss: 0.4685 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 816/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3490 - precision: 0.8710 - recall: 0.7067 - f1_score: 0.7799 - val_loss: 0.4681 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 817/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.3524 - precision: 0.8642 - recall: 0.6767 - f1_score: 0.7582 - val_loss: 0.4720 - val_precision: 0.6667 - val_recall: 0.5000 - val_f1_score: 0.5714\n",
            "Epoch 818/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3489 - precision: 0.8676 - recall: 0.6800 - f1_score: 0.7621 - val_loss: 0.4690 - val_precision: 0.5778 - val_recall: 0.4333 - val_f1_score: 0.4952\n",
            "Epoch 819/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.3519 - precision: 0.8299 - recall: 0.6833 - f1_score: 0.7494 - val_loss: 0.4680 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 820/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.3478 - precision: 0.8833 - recall: 0.6733 - f1_score: 0.7638 - val_loss: 0.4752 - val_precision: 0.5870 - val_recall: 0.4500 - val_f1_score: 0.5094\n",
            "Epoch 821/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.3486 - precision: 0.8807 - recall: 0.6833 - f1_score: 0.7691 - val_loss: 0.4710 - val_precision: 0.6744 - val_recall: 0.4833 - val_f1_score: 0.5631\n",
            "Epoch 822/3000\n",
            "300/300 [==============================] - 0s 59us/step - loss: 0.3540 - precision: 0.8525 - recall: 0.7000 - f1_score: 0.7683 - val_loss: 0.4682 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 823/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3472 - precision: 0.8749 - recall: 0.7033 - f1_score: 0.7791 - val_loss: 0.4723 - val_precision: 0.6522 - val_recall: 0.5000 - val_f1_score: 0.5660\n",
            "Epoch 824/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3503 - precision: 0.8524 - recall: 0.6733 - f1_score: 0.7523 - val_loss: 0.4744 - val_precision: 0.6047 - val_recall: 0.4333 - val_f1_score: 0.5049\n",
            "Epoch 825/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3513 - precision: 0.8518 - recall: 0.6900 - f1_score: 0.7619 - val_loss: 0.4746 - val_precision: 0.5952 - val_recall: 0.4167 - val_f1_score: 0.4902\n",
            "Epoch 826/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.3468 - precision: 0.8569 - recall: 0.6967 - f1_score: 0.7683 - val_loss: 0.4777 - val_precision: 0.6889 - val_recall: 0.5167 - val_f1_score: 0.5905\n",
            "Epoch 827/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3503 - precision: 0.8392 - recall: 0.6700 - f1_score: 0.7445 - val_loss: 0.4679 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 828/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3503 - precision: 0.8439 - recall: 0.6900 - f1_score: 0.7577 - val_loss: 0.4700 - val_precision: 0.5952 - val_recall: 0.4167 - val_f1_score: 0.4902\n",
            "Epoch 829/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.3532 - precision: 0.8280 - recall: 0.6900 - f1_score: 0.7523 - val_loss: 0.4704 - val_precision: 0.6512 - val_recall: 0.4667 - val_f1_score: 0.5437\n",
            "Epoch 830/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3531 - precision: 0.8419 - recall: 0.6800 - f1_score: 0.7520 - val_loss: 0.4723 - val_precision: 0.6667 - val_recall: 0.5000 - val_f1_score: 0.5714\n",
            "Epoch 831/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3484 - precision: 0.8500 - recall: 0.6933 - f1_score: 0.7633 - val_loss: 0.4691 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 832/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3490 - precision: 0.8595 - recall: 0.6867 - f1_score: 0.7628 - val_loss: 0.4682 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 833/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3488 - precision: 0.8584 - recall: 0.7100 - f1_score: 0.7771 - val_loss: 0.4686 - val_precision: 0.5957 - val_recall: 0.4667 - val_f1_score: 0.5234\n",
            "Epoch 834/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3481 - precision: 0.8914 - recall: 0.6867 - f1_score: 0.7753 - val_loss: 0.4681 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 835/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3464 - precision: 0.8728 - recall: 0.6933 - f1_score: 0.7712 - val_loss: 0.4862 - val_precision: 0.6531 - val_recall: 0.5333 - val_f1_score: 0.5872\n",
            "Epoch 836/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3527 - precision: 0.8237 - recall: 0.6633 - f1_score: 0.7346 - val_loss: 0.4688 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 837/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3485 - precision: 0.8734 - recall: 0.7100 - f1_score: 0.7820 - val_loss: 0.4687 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 838/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3476 - precision: 0.8726 - recall: 0.6867 - f1_score: 0.7672 - val_loss: 0.4722 - val_precision: 0.6512 - val_recall: 0.4667 - val_f1_score: 0.5437\n",
            "Epoch 839/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3481 - precision: 0.8606 - recall: 0.6867 - f1_score: 0.7629 - val_loss: 0.4685 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 840/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3537 - precision: 0.8576 - recall: 0.6833 - f1_score: 0.7606 - val_loss: 0.4819 - val_precision: 0.6596 - val_recall: 0.5167 - val_f1_score: 0.5794\n",
            "Epoch 841/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3520 - precision: 0.8435 - recall: 0.6667 - f1_score: 0.7431 - val_loss: 0.4684 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 842/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3499 - precision: 0.8590 - recall: 0.6800 - f1_score: 0.7577 - val_loss: 0.4690 - val_precision: 0.6304 - val_recall: 0.4833 - val_f1_score: 0.5472\n",
            "Epoch 843/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.3481 - precision: 0.8780 - recall: 0.7067 - f1_score: 0.7823 - val_loss: 0.4697 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 844/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3474 - precision: 0.8688 - recall: 0.7033 - f1_score: 0.7766 - val_loss: 0.4720 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 845/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.3480 - precision: 0.8563 - recall: 0.6833 - f1_score: 0.7587 - val_loss: 0.4693 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 846/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.3474 - precision: 0.8796 - recall: 0.7067 - f1_score: 0.7831 - val_loss: 0.4721 - val_precision: 0.6667 - val_recall: 0.5000 - val_f1_score: 0.5714\n",
            "Epoch 847/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3481 - precision: 0.8642 - recall: 0.6933 - f1_score: 0.7691 - val_loss: 0.4700 - val_precision: 0.5957 - val_recall: 0.4667 - val_f1_score: 0.5234\n",
            "Epoch 848/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3444 - precision: 0.8712 - recall: 0.7167 - f1_score: 0.7853 - val_loss: 0.4737 - val_precision: 0.6667 - val_recall: 0.5000 - val_f1_score: 0.5714\n",
            "Epoch 849/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3446 - precision: 0.8635 - recall: 0.6900 - f1_score: 0.7661 - val_loss: 0.4734 - val_precision: 0.6000 - val_recall: 0.4000 - val_f1_score: 0.4800\n",
            "Epoch 850/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3475 - precision: 0.8400 - recall: 0.7167 - f1_score: 0.7732 - val_loss: 0.4702 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 851/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3467 - precision: 0.8723 - recall: 0.6967 - f1_score: 0.7741 - val_loss: 0.4729 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 852/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.3475 - precision: 0.8607 - recall: 0.6633 - f1_score: 0.7489 - val_loss: 0.4739 - val_precision: 0.6667 - val_recall: 0.5000 - val_f1_score: 0.5714\n",
            "Epoch 853/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3493 - precision: 0.8655 - recall: 0.7000 - f1_score: 0.7736 - val_loss: 0.4691 - val_precision: 0.5957 - val_recall: 0.4667 - val_f1_score: 0.5234\n",
            "Epoch 854/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.3458 - precision: 0.8772 - recall: 0.7167 - f1_score: 0.7887 - val_loss: 0.4718 - val_precision: 0.6667 - val_recall: 0.5000 - val_f1_score: 0.5714\n",
            "Epoch 855/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3450 - precision: 0.8570 - recall: 0.6900 - f1_score: 0.7634 - val_loss: 0.4688 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 856/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3454 - precision: 0.8587 - recall: 0.6967 - f1_score: 0.7691 - val_loss: 0.4690 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 857/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3464 - precision: 0.8613 - recall: 0.7000 - f1_score: 0.7718 - val_loss: 0.4704 - val_precision: 0.6744 - val_recall: 0.4833 - val_f1_score: 0.5631\n",
            "Epoch 858/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3440 - precision: 0.8637 - recall: 0.7100 - f1_score: 0.7789 - val_loss: 0.4690 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 859/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3446 - precision: 0.8736 - recall: 0.6967 - f1_score: 0.7735 - val_loss: 0.4714 - val_precision: 0.5682 - val_recall: 0.4167 - val_f1_score: 0.4808\n",
            "Epoch 860/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.3470 - precision: 0.8511 - recall: 0.7000 - f1_score: 0.7679 - val_loss: 0.4698 - val_precision: 0.5814 - val_recall: 0.4167 - val_f1_score: 0.4854\n",
            "Epoch 861/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3476 - precision: 0.8627 - recall: 0.6900 - f1_score: 0.7663 - val_loss: 0.4690 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 862/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3455 - precision: 0.8611 - recall: 0.7067 - f1_score: 0.7757 - val_loss: 0.4690 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 863/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.3445 - precision: 0.8706 - recall: 0.7133 - f1_score: 0.7839 - val_loss: 0.4703 - val_precision: 0.5778 - val_recall: 0.4333 - val_f1_score: 0.4952\n",
            "Epoch 864/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.3449 - precision: 0.8753 - recall: 0.7000 - f1_score: 0.7768 - val_loss: 0.4699 - val_precision: 0.5957 - val_recall: 0.4667 - val_f1_score: 0.5234\n",
            "Epoch 865/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3461 - precision: 0.8714 - recall: 0.7000 - f1_score: 0.7757 - val_loss: 0.4697 - val_precision: 0.6304 - val_recall: 0.4833 - val_f1_score: 0.5472\n",
            "Epoch 866/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3435 - precision: 0.8666 - recall: 0.7167 - f1_score: 0.7843 - val_loss: 0.4696 - val_precision: 0.6042 - val_recall: 0.4833 - val_f1_score: 0.5370\n",
            "Epoch 867/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.3490 - precision: 0.8624 - recall: 0.6900 - f1_score: 0.7662 - val_loss: 0.4769 - val_precision: 0.6383 - val_recall: 0.5000 - val_f1_score: 0.5607\n",
            "Epoch 868/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.3486 - precision: 0.8443 - recall: 0.6867 - f1_score: 0.7562 - val_loss: 0.4696 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 869/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3433 - precision: 0.8779 - recall: 0.7067 - f1_score: 0.7812 - val_loss: 0.4761 - val_precision: 0.6522 - val_recall: 0.5000 - val_f1_score: 0.5660\n",
            "Epoch 870/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3444 - precision: 0.8471 - recall: 0.7100 - f1_score: 0.7721 - val_loss: 0.4702 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 871/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3433 - precision: 0.8841 - recall: 0.7200 - f1_score: 0.7929 - val_loss: 0.4703 - val_precision: 0.5814 - val_recall: 0.4167 - val_f1_score: 0.4854\n",
            "Epoch 872/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3462 - precision: 0.8730 - recall: 0.6967 - f1_score: 0.7742 - val_loss: 0.4701 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 873/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3461 - precision: 0.8538 - recall: 0.6867 - f1_score: 0.7609 - val_loss: 0.4721 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 874/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3435 - precision: 0.8722 - recall: 0.7033 - f1_score: 0.7786 - val_loss: 0.4704 - val_precision: 0.6512 - val_recall: 0.4667 - val_f1_score: 0.5437\n",
            "Epoch 875/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.3508 - precision: 0.8388 - recall: 0.6900 - f1_score: 0.7569 - val_loss: 0.4695 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 876/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.3437 - precision: 0.8662 - recall: 0.6967 - f1_score: 0.7721 - val_loss: 0.4755 - val_precision: 0.5897 - val_recall: 0.3833 - val_f1_score: 0.4646\n",
            "Epoch 877/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3460 - precision: 0.8823 - recall: 0.7167 - f1_score: 0.7903 - val_loss: 0.4721 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 878/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3469 - precision: 0.8363 - recall: 0.7000 - f1_score: 0.7619 - val_loss: 0.4710 - val_precision: 0.6512 - val_recall: 0.4667 - val_f1_score: 0.5437\n",
            "Epoch 879/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.3423 - precision: 0.8820 - recall: 0.6967 - f1_score: 0.7782 - val_loss: 0.4707 - val_precision: 0.5778 - val_recall: 0.4333 - val_f1_score: 0.4952\n",
            "Epoch 880/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3446 - precision: 0.8694 - recall: 0.7000 - f1_score: 0.7746 - val_loss: 0.4699 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 881/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.3446 - precision: 0.8556 - recall: 0.7067 - f1_score: 0.7737 - val_loss: 0.4702 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 882/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3454 - precision: 0.8655 - recall: 0.7067 - f1_score: 0.7776 - val_loss: 0.4718 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 883/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.3443 - precision: 0.8832 - recall: 0.7133 - f1_score: 0.7881 - val_loss: 0.4720 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 884/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3431 - precision: 0.8575 - recall: 0.6967 - f1_score: 0.7684 - val_loss: 0.4723 - val_precision: 0.5952 - val_recall: 0.4167 - val_f1_score: 0.4902\n",
            "Epoch 885/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3445 - precision: 0.8825 - recall: 0.7200 - f1_score: 0.7919 - val_loss: 0.4708 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 886/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.3431 - precision: 0.8795 - recall: 0.7033 - f1_score: 0.7809 - val_loss: 0.4698 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 887/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3468 - precision: 0.8489 - recall: 0.6933 - f1_score: 0.7630 - val_loss: 0.4698 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 888/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3421 - precision: 0.8727 - recall: 0.7133 - f1_score: 0.7847 - val_loss: 0.4730 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 889/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3483 - precision: 0.8579 - recall: 0.6800 - f1_score: 0.7583 - val_loss: 0.4708 - val_precision: 0.6512 - val_recall: 0.4667 - val_f1_score: 0.5437\n",
            "Epoch 890/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.3412 - precision: 0.8840 - recall: 0.7167 - f1_score: 0.7914 - val_loss: 0.4730 - val_precision: 0.5952 - val_recall: 0.4167 - val_f1_score: 0.4902\n",
            "Epoch 891/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3416 - precision: 0.8767 - recall: 0.7133 - f1_score: 0.7851 - val_loss: 0.4700 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 892/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3414 - precision: 0.8722 - recall: 0.7233 - f1_score: 0.7902 - val_loss: 0.4735 - val_precision: 0.6667 - val_recall: 0.5000 - val_f1_score: 0.5714\n",
            "Epoch 893/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.3418 - precision: 0.8692 - recall: 0.7000 - f1_score: 0.7744 - val_loss: 0.4724 - val_precision: 0.5952 - val_recall: 0.4167 - val_f1_score: 0.4902\n",
            "Epoch 894/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3425 - precision: 0.8768 - recall: 0.7100 - f1_score: 0.7845 - val_loss: 0.4734 - val_precision: 0.5854 - val_recall: 0.4000 - val_f1_score: 0.4752\n",
            "Epoch 895/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3417 - precision: 0.8805 - recall: 0.7067 - f1_score: 0.7839 - val_loss: 0.4705 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 896/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3409 - precision: 0.8794 - recall: 0.7000 - f1_score: 0.7787 - val_loss: 0.4730 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 897/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3415 - precision: 0.8785 - recall: 0.7067 - f1_score: 0.7825 - val_loss: 0.4707 - val_precision: 0.6512 - val_recall: 0.4667 - val_f1_score: 0.5437\n",
            "Epoch 898/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3413 - precision: 0.8834 - recall: 0.7067 - f1_score: 0.7847 - val_loss: 0.4722 - val_precision: 0.6304 - val_recall: 0.4833 - val_f1_score: 0.5472\n",
            "Epoch 899/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3422 - precision: 0.8702 - recall: 0.7033 - f1_score: 0.7765 - val_loss: 0.4714 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 900/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3475 - precision: 0.8519 - recall: 0.6933 - f1_score: 0.7634 - val_loss: 0.4787 - val_precision: 0.6522 - val_recall: 0.5000 - val_f1_score: 0.5660\n",
            "Epoch 901/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3434 - precision: 0.8456 - recall: 0.6867 - f1_score: 0.7575 - val_loss: 0.4747 - val_precision: 0.6000 - val_recall: 0.4000 - val_f1_score: 0.4800\n",
            "Epoch 902/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3439 - precision: 0.8650 - recall: 0.7067 - f1_score: 0.7773 - val_loss: 0.4714 - val_precision: 0.5778 - val_recall: 0.4333 - val_f1_score: 0.4952\n",
            "Epoch 903/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3406 - precision: 0.8691 - recall: 0.7133 - f1_score: 0.7827 - val_loss: 0.4712 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 904/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3414 - precision: 0.8966 - recall: 0.7233 - f1_score: 0.8004 - val_loss: 0.4724 - val_precision: 0.6429 - val_recall: 0.4500 - val_f1_score: 0.5294\n",
            "Epoch 905/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3421 - precision: 0.8602 - recall: 0.7033 - f1_score: 0.7737 - val_loss: 0.4723 - val_precision: 0.5778 - val_recall: 0.4333 - val_f1_score: 0.4952\n",
            "Epoch 906/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3420 - precision: 0.8725 - recall: 0.7067 - f1_score: 0.7804 - val_loss: 0.4724 - val_precision: 0.5778 - val_recall: 0.4333 - val_f1_score: 0.4952\n",
            "Epoch 907/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.3440 - precision: 0.8572 - recall: 0.7167 - f1_score: 0.7796 - val_loss: 0.4718 - val_precision: 0.5814 - val_recall: 0.4167 - val_f1_score: 0.4854\n",
            "Epoch 908/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.3392 - precision: 0.8824 - recall: 0.7200 - f1_score: 0.7925 - val_loss: 0.4836 - val_precision: 0.6522 - val_recall: 0.5000 - val_f1_score: 0.5660\n",
            "Epoch 909/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3420 - precision: 0.8633 - recall: 0.7133 - f1_score: 0.7801 - val_loss: 0.4724 - val_precision: 0.5778 - val_recall: 0.4333 - val_f1_score: 0.4952\n",
            "Epoch 910/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.3406 - precision: 0.8641 - recall: 0.7133 - f1_score: 0.7802 - val_loss: 0.4720 - val_precision: 0.5778 - val_recall: 0.4333 - val_f1_score: 0.4952\n",
            "Epoch 911/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3393 - precision: 0.8885 - recall: 0.7267 - f1_score: 0.7991 - val_loss: 0.4714 - val_precision: 0.6522 - val_recall: 0.5000 - val_f1_score: 0.5660\n",
            "Epoch 912/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.3390 - precision: 0.8781 - recall: 0.7033 - f1_score: 0.7806 - val_loss: 0.4712 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 913/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3392 - precision: 0.8746 - recall: 0.6967 - f1_score: 0.7753 - val_loss: 0.4710 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 914/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3439 - precision: 0.8558 - recall: 0.7000 - f1_score: 0.7693 - val_loss: 0.4717 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 915/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3405 - precision: 0.8602 - recall: 0.6967 - f1_score: 0.7697 - val_loss: 0.4756 - val_precision: 0.6000 - val_recall: 0.4000 - val_f1_score: 0.4800\n",
            "Epoch 916/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.3485 - precision: 0.8458 - recall: 0.6967 - f1_score: 0.7622 - val_loss: 0.4716 - val_precision: 0.5778 - val_recall: 0.4333 - val_f1_score: 0.4952\n",
            "Epoch 917/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.3401 - precision: 0.8596 - recall: 0.7100 - f1_score: 0.7774 - val_loss: 0.4720 - val_precision: 0.6512 - val_recall: 0.4667 - val_f1_score: 0.5437\n",
            "Epoch 918/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3402 - precision: 0.8753 - recall: 0.7033 - f1_score: 0.7795 - val_loss: 0.4727 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 919/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3413 - precision: 0.8531 - recall: 0.7033 - f1_score: 0.7698 - val_loss: 0.4725 - val_precision: 0.5778 - val_recall: 0.4333 - val_f1_score: 0.4952\n",
            "Epoch 920/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.3374 - precision: 0.8711 - recall: 0.7133 - f1_score: 0.7840 - val_loss: 0.4740 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 921/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3403 - precision: 0.8805 - recall: 0.7167 - f1_score: 0.7897 - val_loss: 0.4733 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 922/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3412 - precision: 0.8672 - recall: 0.7133 - f1_score: 0.7822 - val_loss: 0.4717 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 923/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3400 - precision: 0.8741 - recall: 0.6933 - f1_score: 0.7726 - val_loss: 0.4715 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 924/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3442 - precision: 0.8697 - recall: 0.7067 - f1_score: 0.7792 - val_loss: 0.4731 - val_precision: 0.5870 - val_recall: 0.4500 - val_f1_score: 0.5094\n",
            "Epoch 925/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3503 - precision: 0.8336 - recall: 0.7033 - f1_score: 0.7629 - val_loss: 0.4715 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 926/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3387 - precision: 0.8857 - recall: 0.7000 - f1_score: 0.7809 - val_loss: 0.4743 - val_precision: 0.5682 - val_recall: 0.4167 - val_f1_score: 0.4808\n",
            "Epoch 927/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3378 - precision: 0.8729 - recall: 0.7500 - f1_score: 0.8067 - val_loss: 0.4780 - val_precision: 0.6522 - val_recall: 0.5000 - val_f1_score: 0.5660\n",
            "Epoch 928/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3428 - precision: 0.8383 - recall: 0.6900 - f1_score: 0.7566 - val_loss: 0.4730 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 929/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3393 - precision: 0.8668 - recall: 0.7100 - f1_score: 0.7805 - val_loss: 0.4763 - val_precision: 0.6522 - val_recall: 0.5000 - val_f1_score: 0.5660\n",
            "Epoch 930/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3418 - precision: 0.8627 - recall: 0.7067 - f1_score: 0.7763 - val_loss: 0.4737 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 931/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.3402 - precision: 0.8617 - recall: 0.7100 - f1_score: 0.7782 - val_loss: 0.4730 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 932/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3410 - precision: 0.8710 - recall: 0.6867 - f1_score: 0.7666 - val_loss: 0.4715 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 933/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3400 - precision: 0.8784 - recall: 0.7167 - f1_score: 0.7884 - val_loss: 0.4742 - val_precision: 0.5682 - val_recall: 0.4167 - val_f1_score: 0.4808\n",
            "Epoch 934/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.3490 - precision: 0.8277 - recall: 0.6933 - f1_score: 0.7541 - val_loss: 0.4745 - val_precision: 0.5952 - val_recall: 0.4167 - val_f1_score: 0.4902\n",
            "Epoch 935/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3410 - precision: 0.8568 - recall: 0.6900 - f1_score: 0.7641 - val_loss: 0.4751 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 936/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3398 - precision: 0.8572 - recall: 0.6933 - f1_score: 0.7663 - val_loss: 0.4748 - val_precision: 0.5952 - val_recall: 0.4167 - val_f1_score: 0.4902\n",
            "Epoch 937/3000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.3396 - precision: 0.8614 - recall: 0.7167 - f1_score: 0.7818 - val_loss: 0.4847 - val_precision: 0.5686 - val_recall: 0.4833 - val_f1_score: 0.5225\n",
            "Epoch 938/3000\n",
            "300/300 [==============================] - 0s 113us/step - loss: 0.3389 - precision: 0.8440 - recall: 0.6933 - f1_score: 0.7609 - val_loss: 0.4826 - val_precision: 0.6458 - val_recall: 0.5167 - val_f1_score: 0.5741\n",
            "Epoch 939/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3381 - precision: 0.8718 - recall: 0.7033 - f1_score: 0.7785 - val_loss: 0.4719 - val_precision: 0.6304 - val_recall: 0.4833 - val_f1_score: 0.5472\n",
            "Epoch 940/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3371 - precision: 0.8812 - recall: 0.7167 - f1_score: 0.7897 - val_loss: 0.4733 - val_precision: 0.5778 - val_recall: 0.4333 - val_f1_score: 0.4952\n",
            "Epoch 941/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3372 - precision: 0.8735 - recall: 0.6967 - f1_score: 0.7738 - val_loss: 0.4727 - val_precision: 0.5778 - val_recall: 0.4333 - val_f1_score: 0.4952\n",
            "Epoch 942/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3373 - precision: 0.8864 - recall: 0.7033 - f1_score: 0.7841 - val_loss: 0.4773 - val_precision: 0.6667 - val_recall: 0.5000 - val_f1_score: 0.5714\n",
            "Epoch 943/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3410 - precision: 0.8647 - recall: 0.7033 - f1_score: 0.7753 - val_loss: 0.4765 - val_precision: 0.6000 - val_recall: 0.4000 - val_f1_score: 0.4800\n",
            "Epoch 944/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3396 - precision: 0.8763 - recall: 0.7067 - f1_score: 0.7821 - val_loss: 0.4737 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 945/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3422 - precision: 0.8681 - recall: 0.7100 - f1_score: 0.7810 - val_loss: 0.4751 - val_precision: 0.6098 - val_recall: 0.4167 - val_f1_score: 0.4950\n",
            "Epoch 946/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3385 - precision: 0.8893 - recall: 0.7067 - f1_score: 0.7872 - val_loss: 0.4823 - val_precision: 0.6327 - val_recall: 0.5167 - val_f1_score: 0.5688\n",
            "Epoch 947/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3400 - precision: 0.8474 - recall: 0.7067 - f1_score: 0.7703 - val_loss: 0.4734 - val_precision: 0.5778 - val_recall: 0.4333 - val_f1_score: 0.4952\n",
            "Epoch 948/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3373 - precision: 0.8741 - recall: 0.7133 - f1_score: 0.7849 - val_loss: 0.4724 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 949/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3391 - precision: 0.8632 - recall: 0.7233 - f1_score: 0.7868 - val_loss: 0.4772 - val_precision: 0.6522 - val_recall: 0.5000 - val_f1_score: 0.5660\n",
            "Epoch 950/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.3383 - precision: 0.8731 - recall: 0.7100 - f1_score: 0.7829 - val_loss: 0.4736 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 951/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.3365 - precision: 0.8804 - recall: 0.7167 - f1_score: 0.7894 - val_loss: 0.4744 - val_precision: 0.5682 - val_recall: 0.4167 - val_f1_score: 0.4808\n",
            "Epoch 952/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.3392 - precision: 0.8574 - recall: 0.7067 - f1_score: 0.7745 - val_loss: 0.4723 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 953/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3367 - precision: 0.8711 - recall: 0.7367 - f1_score: 0.7977 - val_loss: 0.4764 - val_precision: 0.6000 - val_recall: 0.4000 - val_f1_score: 0.4800\n",
            "Epoch 954/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3354 - precision: 0.8738 - recall: 0.7200 - f1_score: 0.7887 - val_loss: 0.4750 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 955/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3337 - precision: 0.8549 - recall: 0.7400 - f1_score: 0.7926 - val_loss: 0.4803 - val_precision: 0.5909 - val_recall: 0.4333 - val_f1_score: 0.5000\n",
            "Epoch 956/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3374 - precision: 0.8601 - recall: 0.7033 - f1_score: 0.7733 - val_loss: 0.4733 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 957/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3371 - precision: 0.8889 - recall: 0.7133 - f1_score: 0.7904 - val_loss: 0.4734 - val_precision: 0.6512 - val_recall: 0.4667 - val_f1_score: 0.5437\n",
            "Epoch 958/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3367 - precision: 0.8783 - recall: 0.6967 - f1_score: 0.7766 - val_loss: 0.4728 - val_precision: 0.6042 - val_recall: 0.4833 - val_f1_score: 0.5370\n",
            "Epoch 959/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3357 - precision: 0.8998 - recall: 0.7167 - f1_score: 0.7973 - val_loss: 0.4727 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 960/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3347 - precision: 0.8801 - recall: 0.7300 - f1_score: 0.7977 - val_loss: 0.4744 - val_precision: 0.6512 - val_recall: 0.4667 - val_f1_score: 0.5437\n",
            "Epoch 961/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3378 - precision: 0.8481 - recall: 0.7233 - f1_score: 0.7807 - val_loss: 0.4748 - val_precision: 0.5682 - val_recall: 0.4167 - val_f1_score: 0.4808\n",
            "Epoch 962/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3337 - precision: 0.8796 - recall: 0.7167 - f1_score: 0.7895 - val_loss: 0.4803 - val_precision: 0.6250 - val_recall: 0.5000 - val_f1_score: 0.5556\n",
            "Epoch 963/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3401 - precision: 0.8490 - recall: 0.7033 - f1_score: 0.7688 - val_loss: 0.4758 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 964/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3411 - precision: 0.8639 - recall: 0.7133 - f1_score: 0.7810 - val_loss: 0.4747 - val_precision: 0.5909 - val_recall: 0.4333 - val_f1_score: 0.5000\n",
            "Epoch 965/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.3356 - precision: 0.8850 - recall: 0.7200 - f1_score: 0.7939 - val_loss: 0.4741 - val_precision: 0.6512 - val_recall: 0.4667 - val_f1_score: 0.5437\n",
            "Epoch 966/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3361 - precision: 0.8768 - recall: 0.7133 - f1_score: 0.7863 - val_loss: 0.4730 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 967/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3350 - precision: 0.8869 - recall: 0.7267 - f1_score: 0.7982 - val_loss: 0.4746 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 968/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3374 - precision: 0.8749 - recall: 0.6967 - f1_score: 0.7749 - val_loss: 0.4749 - val_precision: 0.5682 - val_recall: 0.4167 - val_f1_score: 0.4808\n",
            "Epoch 969/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3367 - precision: 0.8650 - recall: 0.7333 - f1_score: 0.7931 - val_loss: 0.4746 - val_precision: 0.5778 - val_recall: 0.4333 - val_f1_score: 0.4952\n",
            "Epoch 970/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3351 - precision: 0.8718 - recall: 0.7200 - f1_score: 0.7878 - val_loss: 0.4734 - val_precision: 0.5833 - val_recall: 0.4667 - val_f1_score: 0.5185\n",
            "Epoch 971/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3349 - precision: 0.8768 - recall: 0.7300 - f1_score: 0.7963 - val_loss: 0.4735 - val_precision: 0.6512 - val_recall: 0.4667 - val_f1_score: 0.5437\n",
            "Epoch 972/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.3363 - precision: 0.8625 - recall: 0.7200 - f1_score: 0.7845 - val_loss: 0.4744 - val_precision: 0.6429 - val_recall: 0.4500 - val_f1_score: 0.5294\n",
            "Epoch 973/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3346 - precision: 0.8716 - recall: 0.7167 - f1_score: 0.7857 - val_loss: 0.4757 - val_precision: 0.5682 - val_recall: 0.4167 - val_f1_score: 0.4808\n",
            "Epoch 974/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.3336 - precision: 0.8936 - recall: 0.7267 - f1_score: 0.8014 - val_loss: 0.4745 - val_precision: 0.6304 - val_recall: 0.4833 - val_f1_score: 0.5472\n",
            "Epoch 975/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3428 - precision: 0.8454 - recall: 0.7100 - f1_score: 0.7716 - val_loss: 0.4733 - val_precision: 0.6042 - val_recall: 0.4833 - val_f1_score: 0.5370\n",
            "Epoch 976/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3351 - precision: 0.8714 - recall: 0.7133 - f1_score: 0.7836 - val_loss: 0.4757 - val_precision: 0.5556 - val_recall: 0.4167 - val_f1_score: 0.4762\n",
            "Epoch 977/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3343 - precision: 0.8767 - recall: 0.7333 - f1_score: 0.7983 - val_loss: 0.4744 - val_precision: 0.5814 - val_recall: 0.4167 - val_f1_score: 0.4854\n",
            "Epoch 978/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3332 - precision: 0.8855 - recall: 0.7433 - f1_score: 0.8079 - val_loss: 0.4740 - val_precision: 0.6512 - val_recall: 0.4667 - val_f1_score: 0.5437\n",
            "Epoch 979/3000\n",
            "300/300 [==============================] - 0s 59us/step - loss: 0.3339 - precision: 0.8775 - recall: 0.7067 - f1_score: 0.7821 - val_loss: 0.4734 - val_precision: 0.6304 - val_recall: 0.4833 - val_f1_score: 0.5472\n",
            "Epoch 980/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3436 - precision: 0.8415 - recall: 0.7000 - f1_score: 0.7623 - val_loss: 0.4740 - val_precision: 0.6512 - val_recall: 0.4667 - val_f1_score: 0.5437\n",
            "Epoch 981/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.3392 - precision: 0.8451 - recall: 0.7267 - f1_score: 0.7798 - val_loss: 0.4754 - val_precision: 0.6512 - val_recall: 0.4667 - val_f1_score: 0.5437\n",
            "Epoch 982/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3372 - precision: 0.8763 - recall: 0.6967 - f1_score: 0.7758 - val_loss: 0.4752 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 983/3000\n",
            "300/300 [==============================] - 0s 59us/step - loss: 0.3372 - precision: 0.8554 - recall: 0.7133 - f1_score: 0.7777 - val_loss: 0.4772 - val_precision: 0.5952 - val_recall: 0.4167 - val_f1_score: 0.4902\n",
            "Epoch 984/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3413 - precision: 0.8570 - recall: 0.7000 - f1_score: 0.7701 - val_loss: 0.4749 - val_precision: 0.6512 - val_recall: 0.4667 - val_f1_score: 0.5437\n",
            "Epoch 985/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.3343 - precision: 0.8768 - recall: 0.7067 - f1_score: 0.7814 - val_loss: 0.4767 - val_precision: 0.5682 - val_recall: 0.4167 - val_f1_score: 0.4808\n",
            "Epoch 986/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3358 - precision: 0.8696 - recall: 0.7100 - f1_score: 0.7816 - val_loss: 0.4737 - val_precision: 0.6304 - val_recall: 0.4833 - val_f1_score: 0.5472\n",
            "Epoch 987/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.3358 - precision: 0.8771 - recall: 0.7167 - f1_score: 0.7879 - val_loss: 0.4742 - val_precision: 0.6522 - val_recall: 0.5000 - val_f1_score: 0.5660\n",
            "Epoch 988/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3350 - precision: 0.8815 - recall: 0.6967 - f1_score: 0.7780 - val_loss: 0.4736 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 989/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3358 - precision: 0.8842 - recall: 0.7133 - f1_score: 0.7895 - val_loss: 0.4756 - val_precision: 0.5682 - val_recall: 0.4167 - val_f1_score: 0.4808\n",
            "Epoch 990/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.3345 - precision: 0.8729 - recall: 0.7233 - f1_score: 0.7909 - val_loss: 0.4738 - val_precision: 0.6304 - val_recall: 0.4833 - val_f1_score: 0.5472\n",
            "Epoch 991/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.3345 - precision: 0.8808 - recall: 0.7167 - f1_score: 0.7899 - val_loss: 0.4739 - val_precision: 0.6304 - val_recall: 0.4833 - val_f1_score: 0.5472\n",
            "Epoch 992/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.3328 - precision: 0.8833 - recall: 0.7233 - f1_score: 0.7951 - val_loss: 0.4744 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 993/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.3324 - precision: 0.8979 - recall: 0.7300 - f1_score: 0.8050 - val_loss: 0.4740 - val_precision: 0.6042 - val_recall: 0.4833 - val_f1_score: 0.5370\n",
            "Epoch 994/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3321 - precision: 0.8905 - recall: 0.7200 - f1_score: 0.7955 - val_loss: 0.4746 - val_precision: 0.5778 - val_recall: 0.4333 - val_f1_score: 0.4952\n",
            "Epoch 995/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3331 - precision: 0.8787 - recall: 0.7000 - f1_score: 0.7789 - val_loss: 0.4760 - val_precision: 0.5556 - val_recall: 0.4167 - val_f1_score: 0.4762\n",
            "Epoch 996/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.3329 - precision: 0.8922 - recall: 0.7267 - f1_score: 0.8004 - val_loss: 0.4773 - val_precision: 0.5814 - val_recall: 0.4167 - val_f1_score: 0.4854\n",
            "Epoch 997/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3364 - precision: 0.8756 - recall: 0.7067 - f1_score: 0.7818 - val_loss: 0.4749 - val_precision: 0.6512 - val_recall: 0.4667 - val_f1_score: 0.5437\n",
            "Epoch 998/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.3333 - precision: 0.8725 - recall: 0.7100 - f1_score: 0.7828 - val_loss: 0.4753 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 999/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.3318 - precision: 0.8728 - recall: 0.7267 - f1_score: 0.7928 - val_loss: 0.4773 - val_precision: 0.5682 - val_recall: 0.4167 - val_f1_score: 0.4808\n",
            "Epoch 1000/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3351 - precision: 0.8767 - recall: 0.7367 - f1_score: 0.8004 - val_loss: 0.4771 - val_precision: 0.5814 - val_recall: 0.4167 - val_f1_score: 0.4854\n",
            "Epoch 1001/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3322 - precision: 0.8659 - recall: 0.7167 - f1_score: 0.7830 - val_loss: 0.4755 - val_precision: 0.5778 - val_recall: 0.4333 - val_f1_score: 0.4952\n",
            "Epoch 1002/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3328 - precision: 0.8771 - recall: 0.7067 - f1_score: 0.7816 - val_loss: 0.4746 - val_precision: 0.5957 - val_recall: 0.4667 - val_f1_score: 0.5234\n",
            "Epoch 1003/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3318 - precision: 0.8792 - recall: 0.7500 - f1_score: 0.8093 - val_loss: 0.4859 - val_precision: 0.6458 - val_recall: 0.5167 - val_f1_score: 0.5741\n",
            "Epoch 1004/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3388 - precision: 0.8495 - recall: 0.7033 - f1_score: 0.7684 - val_loss: 0.4779 - val_precision: 0.5952 - val_recall: 0.4167 - val_f1_score: 0.4902\n",
            "Epoch 1005/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3315 - precision: 0.8951 - recall: 0.7300 - f1_score: 0.8038 - val_loss: 0.4761 - val_precision: 0.6512 - val_recall: 0.4667 - val_f1_score: 0.5437\n",
            "Epoch 1006/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3331 - precision: 0.8757 - recall: 0.7200 - f1_score: 0.7890 - val_loss: 0.4748 - val_precision: 0.5870 - val_recall: 0.4500 - val_f1_score: 0.5094\n",
            "Epoch 1007/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.3314 - precision: 0.8875 - recall: 0.7300 - f1_score: 0.8000 - val_loss: 0.4752 - val_precision: 0.5778 - val_recall: 0.4333 - val_f1_score: 0.4952\n",
            "Epoch 1008/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.3311 - precision: 0.8808 - recall: 0.7167 - f1_score: 0.7900 - val_loss: 0.4757 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 1009/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3336 - precision: 0.8689 - recall: 0.7300 - f1_score: 0.7932 - val_loss: 0.4749 - val_precision: 0.6667 - val_recall: 0.5000 - val_f1_score: 0.5714\n",
            "Epoch 1010/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3335 - precision: 0.8729 - recall: 0.6967 - f1_score: 0.7743 - val_loss: 0.4744 - val_precision: 0.6304 - val_recall: 0.4833 - val_f1_score: 0.5472\n",
            "Epoch 1011/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3326 - precision: 0.8773 - recall: 0.7367 - f1_score: 0.8003 - val_loss: 0.4755 - val_precision: 0.5778 - val_recall: 0.4333 - val_f1_score: 0.4952\n",
            "Epoch 1012/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3313 - precision: 0.8716 - recall: 0.7267 - f1_score: 0.7924 - val_loss: 0.4762 - val_precision: 0.5778 - val_recall: 0.4333 - val_f1_score: 0.4952\n",
            "Epoch 1013/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.3333 - precision: 0.8772 - recall: 0.7167 - f1_score: 0.7887 - val_loss: 0.4753 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 1014/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3299 - precision: 0.8907 - recall: 0.7233 - f1_score: 0.7978 - val_loss: 0.4751 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 1015/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.3308 - precision: 0.8857 - recall: 0.7267 - f1_score: 0.7982 - val_loss: 0.4785 - val_precision: 0.6000 - val_recall: 0.4000 - val_f1_score: 0.4800\n",
            "Epoch 1016/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3294 - precision: 0.8925 - recall: 0.7500 - f1_score: 0.8149 - val_loss: 0.4809 - val_precision: 0.6522 - val_recall: 0.5000 - val_f1_score: 0.5660\n",
            "Epoch 1017/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.3321 - precision: 0.8763 - recall: 0.7033 - f1_score: 0.7795 - val_loss: 0.4764 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 1018/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3361 - precision: 0.8636 - recall: 0.7100 - f1_score: 0.7789 - val_loss: 0.4750 - val_precision: 0.6512 - val_recall: 0.4667 - val_f1_score: 0.5437\n",
            "Epoch 1019/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3307 - precision: 0.8688 - recall: 0.7233 - f1_score: 0.7890 - val_loss: 0.4757 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1020/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3311 - precision: 0.8859 - recall: 0.7233 - f1_score: 0.7952 - val_loss: 0.4752 - val_precision: 0.6512 - val_recall: 0.4667 - val_f1_score: 0.5437\n",
            "Epoch 1021/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3308 - precision: 0.8809 - recall: 0.7200 - f1_score: 0.7916 - val_loss: 0.4767 - val_precision: 0.5556 - val_recall: 0.4167 - val_f1_score: 0.4762\n",
            "Epoch 1022/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3312 - precision: 0.8866 - recall: 0.7333 - f1_score: 0.8027 - val_loss: 0.4751 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 1023/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3309 - precision: 0.8702 - recall: 0.7200 - f1_score: 0.7870 - val_loss: 0.4788 - val_precision: 0.6522 - val_recall: 0.5000 - val_f1_score: 0.5660\n",
            "Epoch 1024/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.3345 - precision: 0.8572 - recall: 0.7100 - f1_score: 0.7763 - val_loss: 0.4835 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 1025/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3375 - precision: 0.8570 - recall: 0.7033 - f1_score: 0.7719 - val_loss: 0.4761 - val_precision: 0.6512 - val_recall: 0.4667 - val_f1_score: 0.5437\n",
            "Epoch 1026/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3331 - precision: 0.8633 - recall: 0.7167 - f1_score: 0.7827 - val_loss: 0.4772 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 1027/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3300 - precision: 0.8848 - recall: 0.7167 - f1_score: 0.7912 - val_loss: 0.4758 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 1028/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3321 - precision: 0.8803 - recall: 0.7367 - f1_score: 0.8020 - val_loss: 0.4758 - val_precision: 0.6512 - val_recall: 0.4667 - val_f1_score: 0.5437\n",
            "Epoch 1029/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.3343 - precision: 0.8784 - recall: 0.7033 - f1_score: 0.7808 - val_loss: 0.4754 - val_precision: 0.5957 - val_recall: 0.4667 - val_f1_score: 0.5234\n",
            "Epoch 1030/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.3312 - precision: 0.8860 - recall: 0.7200 - f1_score: 0.7939 - val_loss: 0.4750 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 1031/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3294 - precision: 0.8876 - recall: 0.7367 - f1_score: 0.8038 - val_loss: 0.4753 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 1032/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3322 - precision: 0.8561 - recall: 0.7167 - f1_score: 0.7797 - val_loss: 0.4767 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 1033/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3330 - precision: 0.8733 - recall: 0.7167 - f1_score: 0.7866 - val_loss: 0.4753 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 1034/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3302 - precision: 0.8884 - recall: 0.7400 - f1_score: 0.8070 - val_loss: 0.4755 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1035/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3298 - precision: 0.8887 - recall: 0.7233 - f1_score: 0.7970 - val_loss: 0.4752 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 1036/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3315 - precision: 0.8733 - recall: 0.7300 - f1_score: 0.7949 - val_loss: 0.4774 - val_precision: 0.5682 - val_recall: 0.4167 - val_f1_score: 0.4808\n",
            "Epoch 1037/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.3286 - precision: 0.8909 - recall: 0.7300 - f1_score: 0.8021 - val_loss: 0.4763 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 1038/3000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.3275 - precision: 0.8595 - recall: 0.7300 - f1_score: 0.7883 - val_loss: 0.4867 - val_precision: 0.5918 - val_recall: 0.4833 - val_f1_score: 0.5321\n",
            "Epoch 1039/3000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.3359 - precision: 0.8660 - recall: 0.7167 - f1_score: 0.7837 - val_loss: 0.4789 - val_precision: 0.6667 - val_recall: 0.5000 - val_f1_score: 0.5714\n",
            "Epoch 1040/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3312 - precision: 0.8436 - recall: 0.7167 - f1_score: 0.7738 - val_loss: 0.4773 - val_precision: 0.6512 - val_recall: 0.4667 - val_f1_score: 0.5437\n",
            "Epoch 1041/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3319 - precision: 0.8728 - recall: 0.7133 - f1_score: 0.7844 - val_loss: 0.4752 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1042/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3313 - precision: 0.8765 - recall: 0.7300 - f1_score: 0.7965 - val_loss: 0.4807 - val_precision: 0.6522 - val_recall: 0.5000 - val_f1_score: 0.5660\n",
            "Epoch 1043/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3301 - precision: 0.8747 - recall: 0.7167 - f1_score: 0.7877 - val_loss: 0.4772 - val_precision: 0.5778 - val_recall: 0.4333 - val_f1_score: 0.4952\n",
            "Epoch 1044/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3323 - precision: 0.8725 - recall: 0.7233 - f1_score: 0.7907 - val_loss: 0.4796 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 1045/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3306 - precision: 0.8643 - recall: 0.7267 - f1_score: 0.7890 - val_loss: 0.4753 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 1046/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3283 - precision: 0.8903 - recall: 0.7267 - f1_score: 0.7995 - val_loss: 0.4778 - val_precision: 0.5652 - val_recall: 0.4333 - val_f1_score: 0.4906\n",
            "Epoch 1047/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3354 - precision: 0.8551 - recall: 0.7133 - f1_score: 0.7776 - val_loss: 0.4792 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 1048/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3276 - precision: 0.8704 - recall: 0.7200 - f1_score: 0.7871 - val_loss: 0.4831 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 1049/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3301 - precision: 0.8838 - recall: 0.7067 - f1_score: 0.7847 - val_loss: 0.4754 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 1050/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3309 - precision: 0.8868 - recall: 0.7267 - f1_score: 0.7987 - val_loss: 0.4879 - val_precision: 0.5918 - val_recall: 0.4833 - val_f1_score: 0.5321\n",
            "Epoch 1051/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3309 - precision: 0.8693 - recall: 0.7333 - f1_score: 0.7951 - val_loss: 0.4802 - val_precision: 0.6098 - val_recall: 0.4167 - val_f1_score: 0.4950\n",
            "Epoch 1052/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3322 - precision: 0.8596 - recall: 0.6967 - f1_score: 0.7692 - val_loss: 0.4763 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 1053/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.3290 - precision: 0.8822 - recall: 0.7167 - f1_score: 0.7899 - val_loss: 0.4765 - val_precision: 0.6512 - val_recall: 0.4667 - val_f1_score: 0.5437\n",
            "Epoch 1054/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3280 - precision: 0.8844 - recall: 0.7300 - f1_score: 0.7997 - val_loss: 0.4820 - val_precision: 0.6047 - val_recall: 0.4333 - val_f1_score: 0.5049\n",
            "Epoch 1055/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.3322 - precision: 0.8805 - recall: 0.7100 - f1_score: 0.7859 - val_loss: 0.4821 - val_precision: 0.5909 - val_recall: 0.4333 - val_f1_score: 0.5000\n",
            "Epoch 1056/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3291 - precision: 0.8769 - recall: 0.7433 - f1_score: 0.8042 - val_loss: 0.4779 - val_precision: 0.6667 - val_recall: 0.5000 - val_f1_score: 0.5714\n",
            "Epoch 1057/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.3262 - precision: 0.8929 - recall: 0.7267 - f1_score: 0.8011 - val_loss: 0.4770 - val_precision: 0.5778 - val_recall: 0.4333 - val_f1_score: 0.4952\n",
            "Epoch 1058/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3272 - precision: 0.8900 - recall: 0.7500 - f1_score: 0.8134 - val_loss: 0.4758 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 1059/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3286 - precision: 0.8732 - recall: 0.7200 - f1_score: 0.7889 - val_loss: 0.4773 - val_precision: 0.5778 - val_recall: 0.4333 - val_f1_score: 0.4952\n",
            "Epoch 1060/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3286 - precision: 0.8981 - recall: 0.7300 - f1_score: 0.8046 - val_loss: 0.4758 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 1061/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3263 - precision: 0.8803 - recall: 0.7300 - f1_score: 0.7979 - val_loss: 0.4784 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 1062/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.3275 - precision: 0.8970 - recall: 0.7300 - f1_score: 0.8049 - val_loss: 0.4763 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 1063/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.3295 - precision: 0.8749 - recall: 0.7033 - f1_score: 0.7797 - val_loss: 0.4760 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 1064/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.3327 - precision: 0.8622 - recall: 0.7133 - f1_score: 0.7804 - val_loss: 0.4776 - val_precision: 0.6512 - val_recall: 0.4667 - val_f1_score: 0.5437\n",
            "Epoch 1065/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3269 - precision: 0.8895 - recall: 0.7300 - f1_score: 0.8014 - val_loss: 0.4765 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 1066/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.3267 - precision: 0.8815 - recall: 0.7200 - f1_score: 0.7919 - val_loss: 0.4800 - val_precision: 0.5952 - val_recall: 0.4167 - val_f1_score: 0.4902\n",
            "Epoch 1067/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3287 - precision: 0.8659 - recall: 0.7300 - f1_score: 0.7921 - val_loss: 0.4773 - val_precision: 0.5909 - val_recall: 0.4333 - val_f1_score: 0.5000\n",
            "Epoch 1068/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3303 - precision: 0.8615 - recall: 0.7133 - f1_score: 0.7802 - val_loss: 0.4771 - val_precision: 0.6512 - val_recall: 0.4667 - val_f1_score: 0.5437\n",
            "Epoch 1069/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3276 - precision: 0.8851 - recall: 0.7133 - f1_score: 0.7889 - val_loss: 0.4799 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 1070/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.3296 - precision: 0.8571 - recall: 0.7033 - f1_score: 0.7725 - val_loss: 0.4772 - val_precision: 0.5909 - val_recall: 0.4333 - val_f1_score: 0.5000\n",
            "Epoch 1071/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3278 - precision: 0.8820 - recall: 0.7233 - f1_score: 0.7942 - val_loss: 0.4766 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1072/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.3260 - precision: 0.8884 - recall: 0.7400 - f1_score: 0.8067 - val_loss: 0.4784 - val_precision: 0.5652 - val_recall: 0.4333 - val_f1_score: 0.4906\n",
            "Epoch 1073/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3260 - precision: 0.8982 - recall: 0.7433 - f1_score: 0.8128 - val_loss: 0.4772 - val_precision: 0.5778 - val_recall: 0.4333 - val_f1_score: 0.4952\n",
            "Epoch 1074/3000\n",
            "300/300 [==============================] - 0s 59us/step - loss: 0.3323 - precision: 0.8221 - recall: 0.7133 - f1_score: 0.7637 - val_loss: 0.4785 - val_precision: 0.6512 - val_recall: 0.4667 - val_f1_score: 0.5437\n",
            "Epoch 1075/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.3279 - precision: 0.8680 - recall: 0.7267 - f1_score: 0.7906 - val_loss: 0.4781 - val_precision: 0.5778 - val_recall: 0.4333 - val_f1_score: 0.4952\n",
            "Epoch 1076/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.3293 - precision: 0.8752 - recall: 0.7367 - f1_score: 0.7995 - val_loss: 0.4776 - val_precision: 0.5778 - val_recall: 0.4333 - val_f1_score: 0.4952\n",
            "Epoch 1077/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.3257 - precision: 0.8848 - recall: 0.7467 - f1_score: 0.8094 - val_loss: 0.4828 - val_precision: 0.6522 - val_recall: 0.5000 - val_f1_score: 0.5660\n",
            "Epoch 1078/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3308 - precision: 0.8763 - recall: 0.7167 - f1_score: 0.7882 - val_loss: 0.4996 - val_precision: 0.6667 - val_recall: 0.5333 - val_f1_score: 0.5926\n",
            "Epoch 1079/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3333 - precision: 0.8517 - recall: 0.6933 - f1_score: 0.7638 - val_loss: 0.4764 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1080/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3266 - precision: 0.8847 - recall: 0.7333 - f1_score: 0.8011 - val_loss: 0.4765 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 1081/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.3248 - precision: 0.8846 - recall: 0.7400 - f1_score: 0.8057 - val_loss: 0.4826 - val_precision: 0.6190 - val_recall: 0.4333 - val_f1_score: 0.5098\n",
            "Epoch 1082/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3316 - precision: 0.8813 - recall: 0.7133 - f1_score: 0.7882 - val_loss: 0.4797 - val_precision: 0.5814 - val_recall: 0.4167 - val_f1_score: 0.4854\n",
            "Epoch 1083/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3259 - precision: 0.8735 - recall: 0.7233 - f1_score: 0.7899 - val_loss: 0.4770 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 1084/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3260 - precision: 0.8965 - recall: 0.7433 - f1_score: 0.8123 - val_loss: 0.4786 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 1085/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3253 - precision: 0.8785 - recall: 0.7300 - f1_score: 0.7971 - val_loss: 0.4768 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1086/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3255 - precision: 0.8829 - recall: 0.7433 - f1_score: 0.8065 - val_loss: 0.4774 - val_precision: 0.5870 - val_recall: 0.4500 - val_f1_score: 0.5094\n",
            "Epoch 1087/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3267 - precision: 0.8545 - recall: 0.7100 - f1_score: 0.7745 - val_loss: 0.4840 - val_precision: 0.6047 - val_recall: 0.4333 - val_f1_score: 0.5049\n",
            "Epoch 1088/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.3280 - precision: 0.8718 - recall: 0.7267 - f1_score: 0.7926 - val_loss: 0.4768 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1089/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3264 - precision: 0.8814 - recall: 0.7400 - f1_score: 0.8039 - val_loss: 0.4775 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 1090/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3248 - precision: 0.8888 - recall: 0.7300 - f1_score: 0.8007 - val_loss: 0.4770 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 1091/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3236 - precision: 0.8793 - recall: 0.7433 - f1_score: 0.8044 - val_loss: 0.4771 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1092/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3261 - precision: 0.8881 - recall: 0.7400 - f1_score: 0.8056 - val_loss: 0.4809 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 1093/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3285 - precision: 0.8782 - recall: 0.7200 - f1_score: 0.7892 - val_loss: 0.4772 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 1094/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3262 - precision: 0.8834 - recall: 0.7300 - f1_score: 0.7992 - val_loss: 0.4888 - val_precision: 0.6400 - val_recall: 0.5333 - val_f1_score: 0.5818\n",
            "Epoch 1095/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3265 - precision: 0.8373 - recall: 0.7367 - f1_score: 0.7828 - val_loss: 0.4810 - val_precision: 0.5814 - val_recall: 0.4167 - val_f1_score: 0.4854\n",
            "Epoch 1096/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3259 - precision: 0.8692 - recall: 0.7300 - f1_score: 0.7934 - val_loss: 0.4787 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1097/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3239 - precision: 0.8859 - recall: 0.7467 - f1_score: 0.8100 - val_loss: 0.4777 - val_precision: 0.5957 - val_recall: 0.4667 - val_f1_score: 0.5234\n",
            "Epoch 1098/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.3238 - precision: 0.8860 - recall: 0.7500 - f1_score: 0.8120 - val_loss: 0.4817 - val_precision: 0.6522 - val_recall: 0.5000 - val_f1_score: 0.5660\n",
            "Epoch 1099/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.3278 - precision: 0.8693 - recall: 0.7033 - f1_score: 0.7770 - val_loss: 0.4813 - val_precision: 0.5952 - val_recall: 0.4167 - val_f1_score: 0.4902\n",
            "Epoch 1100/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3253 - precision: 0.8820 - recall: 0.7200 - f1_score: 0.7924 - val_loss: 0.4776 - val_precision: 0.5957 - val_recall: 0.4667 - val_f1_score: 0.5234\n",
            "Epoch 1101/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3256 - precision: 0.8711 - recall: 0.7433 - f1_score: 0.8020 - val_loss: 0.4782 - val_precision: 0.5870 - val_recall: 0.4500 - val_f1_score: 0.5094\n",
            "Epoch 1102/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.3227 - precision: 0.8890 - recall: 0.7400 - f1_score: 0.8073 - val_loss: 0.4776 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 1103/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3228 - precision: 0.8695 - recall: 0.7400 - f1_score: 0.7989 - val_loss: 0.4911 - val_precision: 0.5800 - val_recall: 0.4833 - val_f1_score: 0.5273\n",
            "Epoch 1104/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3288 - precision: 0.8689 - recall: 0.7300 - f1_score: 0.7932 - val_loss: 0.4777 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1105/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3242 - precision: 0.8982 - recall: 0.7367 - f1_score: 0.8070 - val_loss: 0.4824 - val_precision: 0.6522 - val_recall: 0.5000 - val_f1_score: 0.5660\n",
            "Epoch 1106/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.3314 - precision: 0.8385 - recall: 0.7100 - f1_score: 0.7687 - val_loss: 0.4789 - val_precision: 0.5778 - val_recall: 0.4333 - val_f1_score: 0.4952\n",
            "Epoch 1107/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3259 - precision: 0.8725 - recall: 0.7267 - f1_score: 0.7925 - val_loss: 0.4800 - val_precision: 0.6279 - val_recall: 0.4500 - val_f1_score: 0.5243\n",
            "Epoch 1108/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3238 - precision: 0.8676 - recall: 0.7433 - f1_score: 0.8001 - val_loss: 0.4791 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 1109/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.3250 - precision: 0.8716 - recall: 0.7333 - f1_score: 0.7959 - val_loss: 0.4795 - val_precision: 0.5652 - val_recall: 0.4333 - val_f1_score: 0.4906\n",
            "Epoch 1110/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3256 - precision: 0.8910 - recall: 0.7600 - f1_score: 0.8197 - val_loss: 0.4807 - val_precision: 0.5952 - val_recall: 0.4167 - val_f1_score: 0.4902\n",
            "Epoch 1111/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.3235 - precision: 0.8910 - recall: 0.7367 - f1_score: 0.8053 - val_loss: 0.4779 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1112/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.3235 - precision: 0.8842 - recall: 0.7600 - f1_score: 0.8170 - val_loss: 0.4782 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 1113/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.3235 - precision: 0.8904 - recall: 0.7333 - f1_score: 0.8036 - val_loss: 0.4875 - val_precision: 0.5918 - val_recall: 0.4833 - val_f1_score: 0.5321\n",
            "Epoch 1114/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3278 - precision: 0.8704 - recall: 0.7233 - f1_score: 0.7891 - val_loss: 0.4782 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 1115/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.3308 - precision: 0.8364 - recall: 0.6933 - f1_score: 0.7573 - val_loss: 0.4790 - val_precision: 0.5556 - val_recall: 0.4167 - val_f1_score: 0.4762\n",
            "Epoch 1116/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.3227 - precision: 0.8833 - recall: 0.7567 - f1_score: 0.8148 - val_loss: 0.4792 - val_precision: 0.6512 - val_recall: 0.4667 - val_f1_score: 0.5437\n",
            "Epoch 1117/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3224 - precision: 0.8952 - recall: 0.7400 - f1_score: 0.8101 - val_loss: 0.4788 - val_precision: 0.6512 - val_recall: 0.4667 - val_f1_score: 0.5437\n",
            "Epoch 1118/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3295 - precision: 0.8716 - recall: 0.6967 - f1_score: 0.7729 - val_loss: 0.4821 - val_precision: 0.5952 - val_recall: 0.4167 - val_f1_score: 0.4902\n",
            "Epoch 1119/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3232 - precision: 0.8715 - recall: 0.7267 - f1_score: 0.7924 - val_loss: 0.4793 - val_precision: 0.5556 - val_recall: 0.4167 - val_f1_score: 0.4762\n",
            "Epoch 1120/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3234 - precision: 0.8723 - recall: 0.7433 - f1_score: 0.8024 - val_loss: 0.4781 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 1121/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3216 - precision: 0.8911 - recall: 0.7467 - f1_score: 0.8122 - val_loss: 0.4782 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 1122/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3261 - precision: 0.8688 - recall: 0.7267 - f1_score: 0.7914 - val_loss: 0.4810 - val_precision: 0.5682 - val_recall: 0.4167 - val_f1_score: 0.4808\n",
            "Epoch 1123/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3217 - precision: 0.8955 - recall: 0.7367 - f1_score: 0.8082 - val_loss: 0.4785 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 1124/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3223 - precision: 0.8779 - recall: 0.7467 - f1_score: 0.8068 - val_loss: 0.4788 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 1125/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3241 - precision: 0.8890 - recall: 0.7433 - f1_score: 0.8088 - val_loss: 0.4783 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 1126/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.3204 - precision: 0.9008 - recall: 0.7400 - f1_score: 0.8116 - val_loss: 0.4806 - val_precision: 0.5778 - val_recall: 0.4333 - val_f1_score: 0.4952\n",
            "Epoch 1127/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3252 - precision: 0.8850 - recall: 0.7433 - f1_score: 0.8078 - val_loss: 0.4797 - val_precision: 0.6279 - val_recall: 0.4500 - val_f1_score: 0.5243\n",
            "Epoch 1128/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3224 - precision: 0.8945 - recall: 0.7333 - f1_score: 0.8055 - val_loss: 0.4809 - val_precision: 0.6512 - val_recall: 0.4667 - val_f1_score: 0.5437\n",
            "Epoch 1129/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3219 - precision: 0.8909 - recall: 0.7333 - f1_score: 0.8044 - val_loss: 0.4784 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1130/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3232 - precision: 0.8866 - recall: 0.7433 - f1_score: 0.8084 - val_loss: 0.4956 - val_precision: 0.6531 - val_recall: 0.5333 - val_f1_score: 0.5872\n",
            "Epoch 1131/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3263 - precision: 0.8832 - recall: 0.7467 - f1_score: 0.8086 - val_loss: 0.4803 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 1132/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3260 - precision: 0.8830 - recall: 0.7267 - f1_score: 0.7971 - val_loss: 0.4796 - val_precision: 0.6522 - val_recall: 0.5000 - val_f1_score: 0.5660\n",
            "Epoch 1133/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.3201 - precision: 0.8875 - recall: 0.7333 - f1_score: 0.8029 - val_loss: 0.4835 - val_precision: 0.6279 - val_recall: 0.4500 - val_f1_score: 0.5243\n",
            "Epoch 1134/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.3238 - precision: 0.8796 - recall: 0.7433 - f1_score: 0.8053 - val_loss: 0.4787 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 1135/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.3237 - precision: 0.8919 - recall: 0.7500 - f1_score: 0.8144 - val_loss: 0.4784 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 1136/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.3230 - precision: 0.8907 - recall: 0.7400 - f1_score: 0.8078 - val_loss: 0.4793 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 1137/3000\n",
            "300/300 [==============================] - 0s 56us/step - loss: 0.3323 - precision: 0.8507 - recall: 0.7067 - f1_score: 0.7710 - val_loss: 0.4786 - val_precision: 0.6304 - val_recall: 0.4833 - val_f1_score: 0.5472\n",
            "Epoch 1138/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.3200 - precision: 0.8959 - recall: 0.7533 - f1_score: 0.8179 - val_loss: 0.4788 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1139/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.3211 - precision: 0.8961 - recall: 0.7467 - f1_score: 0.8143 - val_loss: 0.4789 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 1140/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.3242 - precision: 0.8884 - recall: 0.7167 - f1_score: 0.7931 - val_loss: 0.4823 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 1141/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.3229 - precision: 0.8918 - recall: 0.7300 - f1_score: 0.8022 - val_loss: 0.4786 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 1142/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3242 - precision: 0.8764 - recall: 0.7233 - f1_score: 0.7922 - val_loss: 0.4816 - val_precision: 0.5556 - val_recall: 0.4167 - val_f1_score: 0.4762\n",
            "Epoch 1143/3000\n",
            "300/300 [==============================] - 0s 59us/step - loss: 0.3228 - precision: 0.8759 - recall: 0.7400 - f1_score: 0.8017 - val_loss: 0.4796 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 1144/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.3223 - precision: 0.8893 - recall: 0.7500 - f1_score: 0.8134 - val_loss: 0.4813 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 1145/3000\n",
            "300/300 [==============================] - 0s 59us/step - loss: 0.3215 - precision: 0.8882 - recall: 0.7300 - f1_score: 0.8010 - val_loss: 0.4792 - val_precision: 0.6304 - val_recall: 0.4833 - val_f1_score: 0.5472\n",
            "Epoch 1146/3000\n",
            "300/300 [==============================] - 0s 59us/step - loss: 0.3218 - precision: 0.8702 - recall: 0.7367 - f1_score: 0.7975 - val_loss: 0.4793 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 1147/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.3196 - precision: 0.8874 - recall: 0.7633 - f1_score: 0.8205 - val_loss: 0.4796 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1148/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.3213 - precision: 0.8863 - recall: 0.7333 - f1_score: 0.8024 - val_loss: 0.4820 - val_precision: 0.5909 - val_recall: 0.4333 - val_f1_score: 0.5000\n",
            "Epoch 1149/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3195 - precision: 0.8827 - recall: 0.7533 - f1_score: 0.8123 - val_loss: 0.4795 - val_precision: 0.6304 - val_recall: 0.4833 - val_f1_score: 0.5472\n",
            "Epoch 1150/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3204 - precision: 0.8815 - recall: 0.7400 - f1_score: 0.8039 - val_loss: 0.4795 - val_precision: 0.5870 - val_recall: 0.4500 - val_f1_score: 0.5094\n",
            "Epoch 1151/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.3207 - precision: 0.8971 - recall: 0.7533 - f1_score: 0.8188 - val_loss: 0.4807 - val_precision: 0.6512 - val_recall: 0.4667 - val_f1_score: 0.5437\n",
            "Epoch 1152/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3219 - precision: 0.8856 - recall: 0.7233 - f1_score: 0.7959 - val_loss: 0.4810 - val_precision: 0.5652 - val_recall: 0.4333 - val_f1_score: 0.4906\n",
            "Epoch 1153/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.3203 - precision: 0.8871 - recall: 0.7367 - f1_score: 0.8048 - val_loss: 0.4794 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 1154/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3234 - precision: 0.8768 - recall: 0.7267 - f1_score: 0.7942 - val_loss: 0.4795 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1155/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3248 - precision: 0.8724 - recall: 0.7233 - f1_score: 0.7903 - val_loss: 0.4832 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 1156/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3200 - precision: 0.8878 - recall: 0.7333 - f1_score: 0.8027 - val_loss: 0.4855 - val_precision: 0.6190 - val_recall: 0.4333 - val_f1_score: 0.5098\n",
            "Epoch 1157/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3208 - precision: 0.8780 - recall: 0.7533 - f1_score: 0.8100 - val_loss: 0.4814 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 1158/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3185 - precision: 0.8663 - recall: 0.7467 - f1_score: 0.8018 - val_loss: 0.4850 - val_precision: 0.6279 - val_recall: 0.4500 - val_f1_score: 0.5243\n",
            "Epoch 1159/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3207 - precision: 0.8917 - recall: 0.7367 - f1_score: 0.8065 - val_loss: 0.4850 - val_precision: 0.5870 - val_recall: 0.4500 - val_f1_score: 0.5094\n",
            "Epoch 1160/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3214 - precision: 0.8801 - recall: 0.7400 - f1_score: 0.8034 - val_loss: 0.4799 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 1161/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3251 - precision: 0.8604 - recall: 0.7433 - f1_score: 0.7971 - val_loss: 0.4820 - val_precision: 0.5652 - val_recall: 0.4333 - val_f1_score: 0.4906\n",
            "Epoch 1162/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.3208 - precision: 0.8795 - recall: 0.7533 - f1_score: 0.8112 - val_loss: 0.4794 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1163/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3252 - precision: 0.8646 - recall: 0.7333 - f1_score: 0.7929 - val_loss: 0.4851 - val_precision: 0.6250 - val_recall: 0.5000 - val_f1_score: 0.5556\n",
            "Epoch 1164/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3208 - precision: 0.8593 - recall: 0.7333 - f1_score: 0.7907 - val_loss: 0.4824 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 1165/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3217 - precision: 0.8811 - recall: 0.7200 - f1_score: 0.7922 - val_loss: 0.4805 - val_precision: 0.5833 - val_recall: 0.4667 - val_f1_score: 0.5185\n",
            "Epoch 1166/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.3192 - precision: 0.8852 - recall: 0.7300 - f1_score: 0.7989 - val_loss: 0.4800 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 1167/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3204 - precision: 0.8972 - recall: 0.7267 - f1_score: 0.8027 - val_loss: 0.4811 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 1168/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3187 - precision: 0.9003 - recall: 0.7467 - f1_score: 0.8147 - val_loss: 0.4855 - val_precision: 0.6250 - val_recall: 0.5000 - val_f1_score: 0.5556\n",
            "Epoch 1169/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.3196 - precision: 0.8814 - recall: 0.7533 - f1_score: 0.8118 - val_loss: 0.4803 - val_precision: 0.5957 - val_recall: 0.4667 - val_f1_score: 0.5234\n",
            "Epoch 1170/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3179 - precision: 0.8888 - recall: 0.7500 - f1_score: 0.8134 - val_loss: 0.4803 - val_precision: 0.6279 - val_recall: 0.4500 - val_f1_score: 0.5243\n",
            "Epoch 1171/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3211 - precision: 0.8848 - recall: 0.7367 - f1_score: 0.8038 - val_loss: 0.4799 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 1172/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3184 - precision: 0.8996 - recall: 0.7500 - f1_score: 0.8179 - val_loss: 0.4845 - val_precision: 0.6250 - val_recall: 0.5000 - val_f1_score: 0.5556\n",
            "Epoch 1173/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.3228 - precision: 0.8837 - recall: 0.7233 - f1_score: 0.7952 - val_loss: 0.4831 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 1174/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.3205 - precision: 0.8876 - recall: 0.7433 - f1_score: 0.8088 - val_loss: 0.4813 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 1175/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3226 - precision: 0.8728 - recall: 0.7333 - f1_score: 0.7957 - val_loss: 0.4803 - val_precision: 0.5957 - val_recall: 0.4667 - val_f1_score: 0.5234\n",
            "Epoch 1176/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3220 - precision: 0.8825 - recall: 0.7333 - f1_score: 0.8003 - val_loss: 0.4811 - val_precision: 0.5532 - val_recall: 0.4333 - val_f1_score: 0.4860\n",
            "Epoch 1177/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3181 - precision: 0.8981 - recall: 0.7567 - f1_score: 0.8212 - val_loss: 0.4807 - val_precision: 0.5870 - val_recall: 0.4500 - val_f1_score: 0.5094\n",
            "Epoch 1178/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3182 - precision: 0.8815 - recall: 0.7667 - f1_score: 0.8199 - val_loss: 0.4802 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1179/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.3185 - precision: 0.8828 - recall: 0.7600 - f1_score: 0.8164 - val_loss: 0.4799 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 1180/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3247 - precision: 0.8814 - recall: 0.7300 - f1_score: 0.7973 - val_loss: 0.4805 - val_precision: 0.5870 - val_recall: 0.4500 - val_f1_score: 0.5094\n",
            "Epoch 1181/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.3210 - precision: 0.8777 - recall: 0.7400 - f1_score: 0.8026 - val_loss: 0.4899 - val_precision: 0.5833 - val_recall: 0.4667 - val_f1_score: 0.5185\n",
            "Epoch 1182/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.3213 - precision: 0.8710 - recall: 0.7600 - f1_score: 0.8115 - val_loss: 0.4844 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 1183/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.3190 - precision: 0.8931 - recall: 0.7567 - f1_score: 0.8191 - val_loss: 0.4816 - val_precision: 0.5652 - val_recall: 0.4333 - val_f1_score: 0.4906\n",
            "Epoch 1184/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3218 - precision: 0.8897 - recall: 0.7333 - f1_score: 0.8034 - val_loss: 0.4804 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 1185/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3185 - precision: 0.8869 - recall: 0.7533 - f1_score: 0.8137 - val_loss: 0.4829 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 1186/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.3187 - precision: 0.8964 - recall: 0.7200 - f1_score: 0.7983 - val_loss: 0.4808 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 1187/3000\n",
            "300/300 [==============================] - 0s 59us/step - loss: 0.3166 - precision: 0.8835 - recall: 0.7567 - f1_score: 0.8149 - val_loss: 0.4841 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 1188/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.3207 - precision: 0.8868 - recall: 0.7367 - f1_score: 0.8035 - val_loss: 0.4804 - val_precision: 0.6304 - val_recall: 0.4833 - val_f1_score: 0.5472\n",
            "Epoch 1189/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3212 - precision: 0.8791 - recall: 0.7400 - f1_score: 0.8026 - val_loss: 0.4813 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1190/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3171 - precision: 0.8857 - recall: 0.7533 - f1_score: 0.8140 - val_loss: 0.4807 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1191/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3194 - precision: 0.8897 - recall: 0.7367 - f1_score: 0.8058 - val_loss: 0.4823 - val_precision: 0.6512 - val_recall: 0.4667 - val_f1_score: 0.5437\n",
            "Epoch 1192/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3180 - precision: 0.8783 - recall: 0.7333 - f1_score: 0.7988 - val_loss: 0.4826 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 1193/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3200 - precision: 0.8758 - recall: 0.7433 - f1_score: 0.8033 - val_loss: 0.4816 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1194/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3156 - precision: 0.8834 - recall: 0.7300 - f1_score: 0.7992 - val_loss: 0.4861 - val_precision: 0.6279 - val_recall: 0.4500 - val_f1_score: 0.5243\n",
            "Epoch 1195/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.3218 - precision: 0.8839 - recall: 0.7467 - f1_score: 0.8091 - val_loss: 0.4813 - val_precision: 0.5714 - val_recall: 0.4667 - val_f1_score: 0.5138\n",
            "Epoch 1196/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3194 - precision: 0.8813 - recall: 0.7367 - f1_score: 0.8015 - val_loss: 0.4863 - val_precision: 0.6279 - val_recall: 0.4500 - val_f1_score: 0.5243\n",
            "Epoch 1197/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3186 - precision: 0.9024 - recall: 0.7433 - f1_score: 0.8135 - val_loss: 0.4811 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 1198/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3164 - precision: 0.8930 - recall: 0.7500 - f1_score: 0.8149 - val_loss: 0.4838 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 1199/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.3210 - precision: 0.8531 - recall: 0.7367 - f1_score: 0.7903 - val_loss: 0.4826 - val_precision: 0.5652 - val_recall: 0.4333 - val_f1_score: 0.4906\n",
            "Epoch 1200/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.3184 - precision: 0.8743 - recall: 0.7433 - f1_score: 0.8033 - val_loss: 0.4835 - val_precision: 0.5778 - val_recall: 0.4333 - val_f1_score: 0.4952\n",
            "Epoch 1201/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3260 - precision: 0.8408 - recall: 0.6933 - f1_score: 0.7598 - val_loss: 0.4810 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1202/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3175 - precision: 0.8965 - recall: 0.7433 - f1_score: 0.8114 - val_loss: 0.4809 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1203/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.3181 - precision: 0.8886 - recall: 0.7433 - f1_score: 0.8091 - val_loss: 0.4813 - val_precision: 0.6279 - val_recall: 0.4500 - val_f1_score: 0.5243\n",
            "Epoch 1204/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3162 - precision: 0.8955 - recall: 0.7400 - f1_score: 0.8101 - val_loss: 0.4812 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1205/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3196 - precision: 0.8944 - recall: 0.7267 - f1_score: 0.8015 - val_loss: 0.4826 - val_precision: 0.5652 - val_recall: 0.4333 - val_f1_score: 0.4906\n",
            "Epoch 1206/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.3162 - precision: 0.8942 - recall: 0.7433 - f1_score: 0.8114 - val_loss: 0.4812 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 1207/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3155 - precision: 0.8969 - recall: 0.7500 - f1_score: 0.8155 - val_loss: 0.4812 - val_precision: 0.5870 - val_recall: 0.4500 - val_f1_score: 0.5094\n",
            "Epoch 1208/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3162 - precision: 0.8908 - recall: 0.7467 - f1_score: 0.8115 - val_loss: 0.4816 - val_precision: 0.5833 - val_recall: 0.4667 - val_f1_score: 0.5185\n",
            "Epoch 1209/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3168 - precision: 0.8880 - recall: 0.7500 - f1_score: 0.8122 - val_loss: 0.4833 - val_precision: 0.5778 - val_recall: 0.4333 - val_f1_score: 0.4952\n",
            "Epoch 1210/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3168 - precision: 0.8937 - recall: 0.7533 - f1_score: 0.8171 - val_loss: 0.4812 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 1211/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.3170 - precision: 0.8765 - recall: 0.7433 - f1_score: 0.8042 - val_loss: 0.4870 - val_precision: 0.6383 - val_recall: 0.5000 - val_f1_score: 0.5607\n",
            "Epoch 1212/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.3218 - precision: 0.8656 - recall: 0.7433 - f1_score: 0.7993 - val_loss: 0.4821 - val_precision: 0.5745 - val_recall: 0.4500 - val_f1_score: 0.5047\n",
            "Epoch 1213/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3162 - precision: 0.8991 - recall: 0.7533 - f1_score: 0.8191 - val_loss: 0.4825 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 1214/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.3145 - precision: 0.8828 - recall: 0.7500 - f1_score: 0.8107 - val_loss: 0.4854 - val_precision: 0.6047 - val_recall: 0.4333 - val_f1_score: 0.5049\n",
            "Epoch 1215/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3168 - precision: 0.8870 - recall: 0.7300 - f1_score: 0.7998 - val_loss: 0.4818 - val_precision: 0.5833 - val_recall: 0.4667 - val_f1_score: 0.5185\n",
            "Epoch 1216/3000\n",
            "300/300 [==============================] - 0s 59us/step - loss: 0.3157 - precision: 0.8918 - recall: 0.7433 - f1_score: 0.8106 - val_loss: 0.4816 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1217/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.3144 - precision: 0.8852 - recall: 0.7533 - f1_score: 0.8135 - val_loss: 0.4813 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 1218/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3182 - precision: 0.8823 - recall: 0.7633 - f1_score: 0.8181 - val_loss: 0.4839 - val_precision: 0.5652 - val_recall: 0.4333 - val_f1_score: 0.4906\n",
            "Epoch 1219/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3170 - precision: 0.8692 - recall: 0.7533 - f1_score: 0.8069 - val_loss: 0.4829 - val_precision: 0.5532 - val_recall: 0.4333 - val_f1_score: 0.4860\n",
            "Epoch 1220/3000\n",
            "300/300 [==============================] - 0s 58us/step - loss: 0.3157 - precision: 0.8930 - recall: 0.7533 - f1_score: 0.8166 - val_loss: 0.4830 - val_precision: 0.5532 - val_recall: 0.4333 - val_f1_score: 0.4860\n",
            "Epoch 1221/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3173 - precision: 0.8684 - recall: 0.7467 - f1_score: 0.8027 - val_loss: 0.4890 - val_precision: 0.6279 - val_recall: 0.4500 - val_f1_score: 0.5243\n",
            "Epoch 1222/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.3149 - precision: 0.8921 - recall: 0.7467 - f1_score: 0.8126 - val_loss: 0.4823 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1223/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3149 - precision: 0.8935 - recall: 0.7567 - f1_score: 0.8184 - val_loss: 0.4817 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1224/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3155 - precision: 0.9063 - recall: 0.7533 - f1_score: 0.8219 - val_loss: 0.4820 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 1225/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.3154 - precision: 0.9029 - recall: 0.7467 - f1_score: 0.8156 - val_loss: 0.4816 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 1226/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3149 - precision: 0.8900 - recall: 0.7533 - f1_score: 0.8157 - val_loss: 0.4820 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1227/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3143 - precision: 0.8991 - recall: 0.7567 - f1_score: 0.8210 - val_loss: 0.4883 - val_precision: 0.6047 - val_recall: 0.4333 - val_f1_score: 0.5049\n",
            "Epoch 1228/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3222 - precision: 0.8657 - recall: 0.7333 - f1_score: 0.7928 - val_loss: 0.4845 - val_precision: 0.5682 - val_recall: 0.4167 - val_f1_score: 0.4808\n",
            "Epoch 1229/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.3150 - precision: 0.8931 - recall: 0.7467 - f1_score: 0.8132 - val_loss: 0.4821 - val_precision: 0.6279 - val_recall: 0.4500 - val_f1_score: 0.5243\n",
            "Epoch 1230/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.3143 - precision: 0.9017 - recall: 0.7533 - f1_score: 0.8203 - val_loss: 0.4821 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1231/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3138 - precision: 0.8939 - recall: 0.7467 - f1_score: 0.8133 - val_loss: 0.4846 - val_precision: 0.5778 - val_recall: 0.4333 - val_f1_score: 0.4952\n",
            "Epoch 1232/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.3145 - precision: 0.8932 - recall: 0.7533 - f1_score: 0.8170 - val_loss: 0.4832 - val_precision: 0.5652 - val_recall: 0.4333 - val_f1_score: 0.4906\n",
            "Epoch 1233/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.3152 - precision: 0.8993 - recall: 0.7533 - f1_score: 0.8197 - val_loss: 0.4825 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 1234/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3134 - precision: 0.8936 - recall: 0.7567 - f1_score: 0.8191 - val_loss: 0.4821 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 1235/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.3157 - precision: 0.8793 - recall: 0.7233 - f1_score: 0.7932 - val_loss: 0.4889 - val_precision: 0.6279 - val_recall: 0.4500 - val_f1_score: 0.5243\n",
            "Epoch 1236/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3138 - precision: 0.9052 - recall: 0.7700 - f1_score: 0.8316 - val_loss: 0.4858 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 1237/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3113 - precision: 0.8929 - recall: 0.7433 - f1_score: 0.8104 - val_loss: 0.4894 - val_precision: 0.5909 - val_recall: 0.4333 - val_f1_score: 0.5000\n",
            "Epoch 1238/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3153 - precision: 0.8944 - recall: 0.7367 - f1_score: 0.8069 - val_loss: 0.4875 - val_precision: 0.6279 - val_recall: 0.4500 - val_f1_score: 0.5243\n",
            "Epoch 1239/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3159 - precision: 0.8803 - recall: 0.7400 - f1_score: 0.8038 - val_loss: 0.4833 - val_precision: 0.5625 - val_recall: 0.4500 - val_f1_score: 0.5000\n",
            "Epoch 1240/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3152 - precision: 0.8837 - recall: 0.7467 - f1_score: 0.8086 - val_loss: 0.4848 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 1241/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3133 - precision: 0.8951 - recall: 0.7433 - f1_score: 0.8114 - val_loss: 0.4828 - val_precision: 0.5778 - val_recall: 0.4333 - val_f1_score: 0.4952\n",
            "Epoch 1242/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3132 - precision: 0.8984 - recall: 0.7633 - f1_score: 0.8246 - val_loss: 0.4825 - val_precision: 0.6304 - val_recall: 0.4833 - val_f1_score: 0.5472\n",
            "Epoch 1243/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3156 - precision: 0.8821 - recall: 0.7633 - f1_score: 0.8175 - val_loss: 0.4843 - val_precision: 0.5532 - val_recall: 0.4333 - val_f1_score: 0.4860\n",
            "Epoch 1244/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3136 - precision: 0.8936 - recall: 0.7567 - f1_score: 0.8194 - val_loss: 0.4871 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 1245/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3170 - precision: 0.8826 - recall: 0.7500 - f1_score: 0.8101 - val_loss: 0.4835 - val_precision: 0.5625 - val_recall: 0.4500 - val_f1_score: 0.5000\n",
            "Epoch 1246/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.3125 - precision: 0.8966 - recall: 0.7533 - f1_score: 0.8178 - val_loss: 0.4837 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 1247/3000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.3122 - precision: 0.9044 - recall: 0.7500 - f1_score: 0.8196 - val_loss: 0.4825 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 1248/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.3134 - precision: 0.8986 - recall: 0.7533 - f1_score: 0.8190 - val_loss: 0.4833 - val_precision: 0.5833 - val_recall: 0.4667 - val_f1_score: 0.5185\n",
            "Epoch 1249/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.3153 - precision: 0.8822 - recall: 0.7467 - f1_score: 0.8087 - val_loss: 0.4829 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1250/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.3123 - precision: 0.8971 - recall: 0.7600 - f1_score: 0.8228 - val_loss: 0.4835 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 1251/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3136 - precision: 0.8911 - recall: 0.7500 - f1_score: 0.8137 - val_loss: 0.4839 - val_precision: 0.5745 - val_recall: 0.4500 - val_f1_score: 0.5047\n",
            "Epoch 1252/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3132 - precision: 0.8871 - recall: 0.7567 - f1_score: 0.8164 - val_loss: 0.4831 - val_precision: 0.6304 - val_recall: 0.4833 - val_f1_score: 0.5472\n",
            "Epoch 1253/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.3158 - precision: 0.8835 - recall: 0.7633 - f1_score: 0.8189 - val_loss: 0.4884 - val_precision: 0.6047 - val_recall: 0.4333 - val_f1_score: 0.5049\n",
            "Epoch 1254/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3161 - precision: 0.8802 - recall: 0.7467 - f1_score: 0.8077 - val_loss: 0.4831 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1255/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3128 - precision: 0.8929 - recall: 0.7500 - f1_score: 0.8152 - val_loss: 0.4834 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 1256/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3144 - precision: 0.8617 - recall: 0.7333 - f1_score: 0.7919 - val_loss: 0.4832 - val_precision: 0.5870 - val_recall: 0.4500 - val_f1_score: 0.5094\n",
            "Epoch 1257/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.3151 - precision: 0.8943 - recall: 0.7500 - f1_score: 0.8151 - val_loss: 0.4836 - val_precision: 0.5833 - val_recall: 0.4667 - val_f1_score: 0.5185\n",
            "Epoch 1258/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.3124 - precision: 0.8953 - recall: 0.7633 - f1_score: 0.8239 - val_loss: 0.4839 - val_precision: 0.5833 - val_recall: 0.4667 - val_f1_score: 0.5185\n",
            "Epoch 1259/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.3189 - precision: 0.8770 - recall: 0.7267 - f1_score: 0.7933 - val_loss: 0.4867 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 1260/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.3134 - precision: 0.8856 - recall: 0.7400 - f1_score: 0.8055 - val_loss: 0.4852 - val_precision: 0.5778 - val_recall: 0.4333 - val_f1_score: 0.4952\n",
            "Epoch 1261/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3121 - precision: 0.9031 - recall: 0.7433 - f1_score: 0.8151 - val_loss: 0.4865 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1262/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.3135 - precision: 0.8927 - recall: 0.7533 - f1_score: 0.8167 - val_loss: 0.4830 - val_precision: 0.6304 - val_recall: 0.4833 - val_f1_score: 0.5472\n",
            "Epoch 1263/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3122 - precision: 0.8954 - recall: 0.7467 - f1_score: 0.8139 - val_loss: 0.4867 - val_precision: 0.5909 - val_recall: 0.4333 - val_f1_score: 0.5000\n",
            "Epoch 1264/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.3103 - precision: 0.8881 - recall: 0.7667 - f1_score: 0.8226 - val_loss: 0.4877 - val_precision: 0.6304 - val_recall: 0.4833 - val_f1_score: 0.5472\n",
            "Epoch 1265/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.3136 - precision: 0.8756 - recall: 0.7433 - f1_score: 0.8035 - val_loss: 0.4831 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 1266/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.3123 - precision: 0.8824 - recall: 0.7467 - f1_score: 0.8085 - val_loss: 0.4885 - val_precision: 0.6190 - val_recall: 0.4333 - val_f1_score: 0.5098\n",
            "Epoch 1267/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3165 - precision: 0.8855 - recall: 0.7433 - f1_score: 0.8080 - val_loss: 0.4835 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 1268/3000\n",
            "300/300 [==============================] - 0s 79us/step - loss: 0.3139 - precision: 0.8964 - recall: 0.7533 - f1_score: 0.8184 - val_loss: 0.4907 - val_precision: 0.6383 - val_recall: 0.5000 - val_f1_score: 0.5607\n",
            "Epoch 1269/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3108 - precision: 0.8771 - recall: 0.7700 - f1_score: 0.8192 - val_loss: 0.4909 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1270/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.3195 - precision: 0.8685 - recall: 0.7267 - f1_score: 0.7911 - val_loss: 0.4926 - val_precision: 0.5833 - val_recall: 0.4667 - val_f1_score: 0.5185\n",
            "Epoch 1271/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3137 - precision: 0.8835 - recall: 0.7533 - f1_score: 0.8124 - val_loss: 0.4844 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 1272/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3107 - precision: 0.8906 - recall: 0.7533 - f1_score: 0.8159 - val_loss: 0.4844 - val_precision: 0.5745 - val_recall: 0.4500 - val_f1_score: 0.5047\n",
            "Epoch 1273/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.3102 - precision: 0.8981 - recall: 0.7600 - f1_score: 0.8230 - val_loss: 0.4855 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 1274/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3123 - precision: 0.8977 - recall: 0.7567 - f1_score: 0.8207 - val_loss: 0.4856 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 1275/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.3112 - precision: 0.9041 - recall: 0.7533 - f1_score: 0.8216 - val_loss: 0.4836 - val_precision: 0.5870 - val_recall: 0.4500 - val_f1_score: 0.5094\n",
            "Epoch 1276/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3119 - precision: 0.8990 - recall: 0.7400 - f1_score: 0.8118 - val_loss: 0.4833 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 1277/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3110 - precision: 0.8827 - recall: 0.7500 - f1_score: 0.8108 - val_loss: 0.4833 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 1278/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.3109 - precision: 0.8993 - recall: 0.7500 - f1_score: 0.8176 - val_loss: 0.4837 - val_precision: 0.5745 - val_recall: 0.4500 - val_f1_score: 0.5047\n",
            "Epoch 1279/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3095 - precision: 0.9142 - recall: 0.7600 - f1_score: 0.8290 - val_loss: 0.4833 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 1280/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.3110 - precision: 0.8971 - recall: 0.7567 - f1_score: 0.8208 - val_loss: 0.4850 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1281/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.3116 - precision: 0.8875 - recall: 0.7600 - f1_score: 0.8187 - val_loss: 0.4852 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 1282/3000\n",
            "300/300 [==============================] - 0s 78us/step - loss: 0.3105 - precision: 0.8979 - recall: 0.7667 - f1_score: 0.8266 - val_loss: 0.4838 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 1283/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3112 - precision: 0.8928 - recall: 0.7767 - f1_score: 0.8306 - val_loss: 0.4840 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 1284/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.3118 - precision: 0.8894 - recall: 0.7533 - f1_score: 0.8157 - val_loss: 0.4870 - val_precision: 0.5909 - val_recall: 0.4333 - val_f1_score: 0.5000\n",
            "Epoch 1285/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.3112 - precision: 0.8957 - recall: 0.7700 - f1_score: 0.8277 - val_loss: 0.4926 - val_precision: 0.5918 - val_recall: 0.4833 - val_f1_score: 0.5321\n",
            "Epoch 1286/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.3175 - precision: 0.8796 - recall: 0.7200 - f1_score: 0.7906 - val_loss: 0.4841 - val_precision: 0.5745 - val_recall: 0.4500 - val_f1_score: 0.5047\n",
            "Epoch 1287/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.3122 - precision: 0.9026 - recall: 0.7767 - f1_score: 0.8333 - val_loss: 0.4863 - val_precision: 0.5682 - val_recall: 0.4167 - val_f1_score: 0.4808\n",
            "Epoch 1288/3000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.3127 - precision: 0.8749 - recall: 0.7500 - f1_score: 0.8074 - val_loss: 0.4855 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1289/3000\n",
            "300/300 [==============================] - 0s 59us/step - loss: 0.3119 - precision: 0.8972 - recall: 0.7467 - f1_score: 0.8149 - val_loss: 0.4872 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1290/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.3199 - precision: 0.8641 - recall: 0.7400 - f1_score: 0.7958 - val_loss: 0.4903 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1291/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.3098 - precision: 0.8961 - recall: 0.7500 - f1_score: 0.8164 - val_loss: 0.4840 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 1292/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3097 - precision: 0.8965 - recall: 0.7600 - f1_score: 0.8220 - val_loss: 0.4848 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1293/3000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.3126 - precision: 0.8905 - recall: 0.7567 - f1_score: 0.8178 - val_loss: 0.4850 - val_precision: 0.5745 - val_recall: 0.4500 - val_f1_score: 0.5047\n",
            "Epoch 1294/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3113 - precision: 0.8911 - recall: 0.7633 - f1_score: 0.8220 - val_loss: 0.4846 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 1295/3000\n",
            "300/300 [==============================] - 0s 80us/step - loss: 0.3087 - precision: 0.9062 - recall: 0.7433 - f1_score: 0.8163 - val_loss: 0.4874 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1296/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3115 - precision: 0.8936 - recall: 0.7533 - f1_score: 0.8166 - val_loss: 0.4850 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1297/3000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.3122 - precision: 0.8820 - recall: 0.7467 - f1_score: 0.8082 - val_loss: 0.4968 - val_precision: 0.6000 - val_recall: 0.5000 - val_f1_score: 0.5455\n",
            "Epoch 1298/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3192 - precision: 0.8653 - recall: 0.7400 - f1_score: 0.7968 - val_loss: 0.4849 - val_precision: 0.5625 - val_recall: 0.4500 - val_f1_score: 0.5000\n",
            "Epoch 1299/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3201 - precision: 0.8667 - recall: 0.7433 - f1_score: 0.7994 - val_loss: 0.4861 - val_precision: 0.5652 - val_recall: 0.4333 - val_f1_score: 0.4906\n",
            "Epoch 1300/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3101 - precision: 0.8979 - recall: 0.7767 - f1_score: 0.8325 - val_loss: 0.4843 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 1301/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3095 - precision: 0.9047 - recall: 0.7567 - f1_score: 0.8240 - val_loss: 0.4843 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 1302/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.3130 - precision: 0.8933 - recall: 0.7333 - f1_score: 0.8051 - val_loss: 0.4843 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 1303/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.3084 - precision: 0.9046 - recall: 0.7600 - f1_score: 0.8259 - val_loss: 0.4843 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 1304/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3087 - precision: 0.8978 - recall: 0.7667 - f1_score: 0.8269 - val_loss: 0.4884 - val_precision: 0.6250 - val_recall: 0.5000 - val_f1_score: 0.5556\n",
            "Epoch 1305/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3114 - precision: 0.9008 - recall: 0.7467 - f1_score: 0.8164 - val_loss: 0.4913 - val_precision: 0.5909 - val_recall: 0.4333 - val_f1_score: 0.5000\n",
            "Epoch 1306/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3122 - precision: 0.8840 - recall: 0.7333 - f1_score: 0.8016 - val_loss: 0.4916 - val_precision: 0.6047 - val_recall: 0.4333 - val_f1_score: 0.5049\n",
            "Epoch 1307/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3202 - precision: 0.8564 - recall: 0.7433 - f1_score: 0.7947 - val_loss: 0.4885 - val_precision: 0.5682 - val_recall: 0.4167 - val_f1_score: 0.4808\n",
            "Epoch 1308/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.3103 - precision: 0.8898 - recall: 0.7533 - f1_score: 0.8158 - val_loss: 0.4869 - val_precision: 0.5652 - val_recall: 0.4333 - val_f1_score: 0.4906\n",
            "Epoch 1309/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.3093 - precision: 0.9031 - recall: 0.7700 - f1_score: 0.8311 - val_loss: 0.4869 - val_precision: 0.6512 - val_recall: 0.4667 - val_f1_score: 0.5437\n",
            "Epoch 1310/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3160 - precision: 0.8702 - recall: 0.7133 - f1_score: 0.7833 - val_loss: 0.4921 - val_precision: 0.6250 - val_recall: 0.5000 - val_f1_score: 0.5556\n",
            "Epoch 1311/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.3183 - precision: 0.8602 - recall: 0.7533 - f1_score: 0.8032 - val_loss: 0.4847 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1312/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3087 - precision: 0.8887 - recall: 0.7667 - f1_score: 0.8223 - val_loss: 0.4854 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 1313/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3099 - precision: 0.8833 - recall: 0.7500 - f1_score: 0.8110 - val_loss: 0.4860 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1314/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3102 - precision: 0.9010 - recall: 0.7567 - f1_score: 0.8224 - val_loss: 0.4851 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 1315/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.3111 - precision: 0.8760 - recall: 0.7633 - f1_score: 0.8152 - val_loss: 0.4877 - val_precision: 0.6512 - val_recall: 0.4667 - val_f1_score: 0.5437\n",
            "Epoch 1316/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.3085 - precision: 0.8894 - recall: 0.7533 - f1_score: 0.8154 - val_loss: 0.4859 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1317/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3079 - precision: 0.9033 - recall: 0.7600 - f1_score: 0.8252 - val_loss: 0.4854 - val_precision: 0.5870 - val_recall: 0.4500 - val_f1_score: 0.5094\n",
            "Epoch 1318/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.3075 - precision: 0.9245 - recall: 0.7800 - f1_score: 0.8457 - val_loss: 0.4908 - val_precision: 0.6250 - val_recall: 0.5000 - val_f1_score: 0.5556\n",
            "Epoch 1319/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3115 - precision: 0.8665 - recall: 0.7533 - f1_score: 0.8056 - val_loss: 0.4860 - val_precision: 0.5745 - val_recall: 0.4500 - val_f1_score: 0.5047\n",
            "Epoch 1320/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3088 - precision: 0.9087 - recall: 0.7633 - f1_score: 0.8295 - val_loss: 0.4867 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1321/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3137 - precision: 0.8905 - recall: 0.7433 - f1_score: 0.8093 - val_loss: 0.4866 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 1322/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3080 - precision: 0.8926 - recall: 0.7533 - f1_score: 0.8170 - val_loss: 0.4907 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1323/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3068 - precision: 0.8853 - recall: 0.7533 - f1_score: 0.8137 - val_loss: 0.4858 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 1324/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3075 - precision: 0.8869 - recall: 0.7600 - f1_score: 0.8180 - val_loss: 0.4877 - val_precision: 0.6512 - val_recall: 0.4667 - val_f1_score: 0.5437\n",
            "Epoch 1325/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.3077 - precision: 0.8902 - recall: 0.7533 - f1_score: 0.8158 - val_loss: 0.4877 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 1326/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3073 - precision: 0.8878 - recall: 0.7533 - f1_score: 0.8138 - val_loss: 0.4918 - val_precision: 0.5957 - val_recall: 0.4667 - val_f1_score: 0.5234\n",
            "Epoch 1327/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.3106 - precision: 0.8915 - recall: 0.7633 - f1_score: 0.8223 - val_loss: 0.4942 - val_precision: 0.6250 - val_recall: 0.5000 - val_f1_score: 0.5556\n",
            "Epoch 1328/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3105 - precision: 0.8767 - recall: 0.7400 - f1_score: 0.8021 - val_loss: 0.4864 - val_precision: 0.5833 - val_recall: 0.4667 - val_f1_score: 0.5185\n",
            "Epoch 1329/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3076 - precision: 0.8858 - recall: 0.7700 - f1_score: 0.8229 - val_loss: 0.4928 - val_precision: 0.6279 - val_recall: 0.4500 - val_f1_score: 0.5243\n",
            "Epoch 1330/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.3102 - precision: 0.8809 - recall: 0.7600 - f1_score: 0.8143 - val_loss: 0.4858 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1331/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.3075 - precision: 0.8978 - recall: 0.7700 - f1_score: 0.8288 - val_loss: 0.4898 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1332/3000\n",
            "300/300 [==============================] - 0s 59us/step - loss: 0.3074 - precision: 0.9030 - recall: 0.7700 - f1_score: 0.8303 - val_loss: 0.4860 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 1333/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.3068 - precision: 0.9014 - recall: 0.7600 - f1_score: 0.8243 - val_loss: 0.4868 - val_precision: 0.5625 - val_recall: 0.4500 - val_f1_score: 0.5000\n",
            "Epoch 1334/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3094 - precision: 0.8863 - recall: 0.7633 - f1_score: 0.8198 - val_loss: 0.4929 - val_precision: 0.5870 - val_recall: 0.4500 - val_f1_score: 0.5094\n",
            "Epoch 1335/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3082 - precision: 0.9046 - recall: 0.7667 - f1_score: 0.8296 - val_loss: 0.4860 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 1336/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3064 - precision: 0.8819 - recall: 0.7500 - f1_score: 0.8106 - val_loss: 0.4863 - val_precision: 0.5745 - val_recall: 0.4500 - val_f1_score: 0.5047\n",
            "Epoch 1337/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3063 - precision: 0.9037 - recall: 0.7733 - f1_score: 0.8333 - val_loss: 0.4858 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1338/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3057 - precision: 0.8989 - recall: 0.7700 - f1_score: 0.8288 - val_loss: 0.4858 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 1339/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3072 - precision: 0.9073 - recall: 0.7800 - f1_score: 0.8386 - val_loss: 0.4912 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1340/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3100 - precision: 0.9069 - recall: 0.7600 - f1_score: 0.8262 - val_loss: 0.4863 - val_precision: 0.6279 - val_recall: 0.4500 - val_f1_score: 0.5243\n",
            "Epoch 1341/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3072 - precision: 0.8967 - recall: 0.7567 - f1_score: 0.8205 - val_loss: 0.4861 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 1342/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3054 - precision: 0.9066 - recall: 0.7733 - f1_score: 0.8345 - val_loss: 0.4898 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 1343/3000\n",
            "300/300 [==============================] - 0s 59us/step - loss: 0.3067 - precision: 0.8798 - recall: 0.7500 - f1_score: 0.8094 - val_loss: 0.4863 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 1344/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.3069 - precision: 0.8960 - recall: 0.7733 - f1_score: 0.8297 - val_loss: 0.4885 - val_precision: 0.6512 - val_recall: 0.4667 - val_f1_score: 0.5437\n",
            "Epoch 1345/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3060 - precision: 0.8958 - recall: 0.7700 - f1_score: 0.8279 - val_loss: 0.4897 - val_precision: 0.5778 - val_recall: 0.4333 - val_f1_score: 0.4952\n",
            "Epoch 1346/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.3074 - precision: 0.8933 - recall: 0.7533 - f1_score: 0.8171 - val_loss: 0.4934 - val_precision: 0.6383 - val_recall: 0.5000 - val_f1_score: 0.5607\n",
            "Epoch 1347/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3144 - precision: 0.8687 - recall: 0.7500 - f1_score: 0.8048 - val_loss: 0.4906 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 1348/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.3081 - precision: 0.9031 - recall: 0.7467 - f1_score: 0.8172 - val_loss: 0.4864 - val_precision: 0.5870 - val_recall: 0.4500 - val_f1_score: 0.5094\n",
            "Epoch 1349/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3086 - precision: 0.8822 - recall: 0.7500 - f1_score: 0.8102 - val_loss: 0.4879 - val_precision: 0.5778 - val_recall: 0.4333 - val_f1_score: 0.4952\n",
            "Epoch 1350/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3062 - precision: 0.8845 - recall: 0.7667 - f1_score: 0.8211 - val_loss: 0.4867 - val_precision: 0.5870 - val_recall: 0.4500 - val_f1_score: 0.5094\n",
            "Epoch 1351/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.3076 - precision: 0.8918 - recall: 0.7633 - f1_score: 0.8224 - val_loss: 0.4871 - val_precision: 0.5745 - val_recall: 0.4500 - val_f1_score: 0.5047\n",
            "Epoch 1352/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.3052 - precision: 0.9061 - recall: 0.7700 - f1_score: 0.8324 - val_loss: 0.4878 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1353/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.3054 - precision: 0.9089 - recall: 0.7767 - f1_score: 0.8369 - val_loss: 0.4877 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1354/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3069 - precision: 0.8988 - recall: 0.7567 - f1_score: 0.8213 - val_loss: 0.4936 - val_precision: 0.6250 - val_recall: 0.5000 - val_f1_score: 0.5556\n",
            "Epoch 1355/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.3085 - precision: 0.8753 - recall: 0.7733 - f1_score: 0.8205 - val_loss: 0.4864 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1356/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3046 - precision: 0.9021 - recall: 0.7667 - f1_score: 0.8287 - val_loss: 0.4865 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 1357/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3044 - precision: 0.9021 - recall: 0.7700 - f1_score: 0.8306 - val_loss: 0.4867 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 1358/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.3072 - precision: 0.8836 - recall: 0.7533 - f1_score: 0.8124 - val_loss: 0.4864 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 1359/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3094 - precision: 0.8996 - recall: 0.7567 - f1_score: 0.8213 - val_loss: 0.4877 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 1360/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3091 - precision: 0.8993 - recall: 0.7533 - f1_score: 0.8190 - val_loss: 0.4871 - val_precision: 0.6304 - val_recall: 0.4833 - val_f1_score: 0.5472\n",
            "Epoch 1361/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.3039 - precision: 0.8987 - recall: 0.7700 - f1_score: 0.8287 - val_loss: 0.4919 - val_precision: 0.5870 - val_recall: 0.4500 - val_f1_score: 0.5094\n",
            "Epoch 1362/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.3072 - precision: 0.8978 - recall: 0.7500 - f1_score: 0.8170 - val_loss: 0.4877 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1363/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3157 - precision: 0.8750 - recall: 0.7800 - f1_score: 0.8241 - val_loss: 0.4871 - val_precision: 0.6279 - val_recall: 0.4500 - val_f1_score: 0.5243\n",
            "Epoch 1364/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3067 - precision: 0.9058 - recall: 0.7700 - f1_score: 0.8322 - val_loss: 0.4890 - val_precision: 0.6512 - val_recall: 0.4667 - val_f1_score: 0.5437\n",
            "Epoch 1365/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.3069 - precision: 0.8917 - recall: 0.7700 - f1_score: 0.8261 - val_loss: 0.4967 - val_precision: 0.6458 - val_recall: 0.5167 - val_f1_score: 0.5741\n",
            "Epoch 1366/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.3042 - precision: 0.8765 - recall: 0.7700 - f1_score: 0.8194 - val_loss: 0.4902 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1367/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.3056 - precision: 0.9043 - recall: 0.7500 - f1_score: 0.8196 - val_loss: 0.4885 - val_precision: 0.5652 - val_recall: 0.4333 - val_f1_score: 0.4906\n",
            "Epoch 1368/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3044 - precision: 0.9182 - recall: 0.7767 - f1_score: 0.8408 - val_loss: 0.4870 - val_precision: 0.5870 - val_recall: 0.4500 - val_f1_score: 0.5094\n",
            "Epoch 1369/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.3032 - precision: 0.9168 - recall: 0.7667 - f1_score: 0.8347 - val_loss: 0.5022 - val_precision: 0.5686 - val_recall: 0.4833 - val_f1_score: 0.5225\n",
            "Epoch 1370/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.3102 - precision: 0.8660 - recall: 0.7300 - f1_score: 0.7914 - val_loss: 0.4940 - val_precision: 0.5870 - val_recall: 0.4500 - val_f1_score: 0.5094\n",
            "Epoch 1371/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3065 - precision: 0.8805 - recall: 0.7633 - f1_score: 0.8176 - val_loss: 0.4874 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 1372/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3065 - precision: 0.8981 - recall: 0.7633 - f1_score: 0.8249 - val_loss: 0.4889 - val_precision: 0.5652 - val_recall: 0.4333 - val_f1_score: 0.4906\n",
            "Epoch 1373/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3115 - precision: 0.8833 - recall: 0.7500 - f1_score: 0.8103 - val_loss: 0.4892 - val_precision: 0.6512 - val_recall: 0.4667 - val_f1_score: 0.5437\n",
            "Epoch 1374/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3082 - precision: 0.9072 - recall: 0.7500 - f1_score: 0.8209 - val_loss: 0.4868 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 1375/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3074 - precision: 0.8933 - recall: 0.7400 - f1_score: 0.8087 - val_loss: 0.4982 - val_precision: 0.5600 - val_recall: 0.4667 - val_f1_score: 0.5091\n",
            "Epoch 1376/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3083 - precision: 0.8762 - recall: 0.7500 - f1_score: 0.8079 - val_loss: 0.4876 - val_precision: 0.5833 - val_recall: 0.4667 - val_f1_score: 0.5185\n",
            "Epoch 1377/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3032 - precision: 0.9039 - recall: 0.7767 - f1_score: 0.8352 - val_loss: 0.4871 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 1378/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.3050 - precision: 0.8912 - recall: 0.7633 - f1_score: 0.8219 - val_loss: 0.4896 - val_precision: 0.5556 - val_recall: 0.4167 - val_f1_score: 0.4762\n",
            "Epoch 1379/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3073 - precision: 0.8858 - recall: 0.7467 - f1_score: 0.8092 - val_loss: 0.4909 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 1380/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3095 - precision: 0.8627 - recall: 0.7467 - f1_score: 0.7999 - val_loss: 0.4887 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1381/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3042 - precision: 0.8909 - recall: 0.7567 - f1_score: 0.8181 - val_loss: 0.4876 - val_precision: 0.5870 - val_recall: 0.4500 - val_f1_score: 0.5094\n",
            "Epoch 1382/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.3067 - precision: 0.8847 - recall: 0.7667 - f1_score: 0.8210 - val_loss: 0.4875 - val_precision: 0.5745 - val_recall: 0.4500 - val_f1_score: 0.5047\n",
            "Epoch 1383/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3042 - precision: 0.9010 - recall: 0.7867 - f1_score: 0.8390 - val_loss: 0.4877 - val_precision: 0.5745 - val_recall: 0.4500 - val_f1_score: 0.5047\n",
            "Epoch 1384/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.3037 - precision: 0.8988 - recall: 0.7733 - f1_score: 0.8307 - val_loss: 0.4877 - val_precision: 0.5745 - val_recall: 0.4500 - val_f1_score: 0.5047\n",
            "Epoch 1385/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.3040 - precision: 0.9017 - recall: 0.7800 - f1_score: 0.8359 - val_loss: 0.4893 - val_precision: 0.5652 - val_recall: 0.4333 - val_f1_score: 0.4906\n",
            "Epoch 1386/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3097 - precision: 0.8676 - recall: 0.7533 - f1_score: 0.8059 - val_loss: 0.4875 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 1387/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3041 - precision: 0.9006 - recall: 0.7833 - f1_score: 0.8375 - val_loss: 0.4892 - val_precision: 0.5652 - val_recall: 0.4333 - val_f1_score: 0.4906\n",
            "Epoch 1388/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.3034 - precision: 0.8998 - recall: 0.7767 - f1_score: 0.8337 - val_loss: 0.4899 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 1389/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3056 - precision: 0.8817 - recall: 0.7700 - f1_score: 0.8217 - val_loss: 0.4878 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 1390/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3054 - precision: 0.8907 - recall: 0.7633 - f1_score: 0.8219 - val_loss: 0.4876 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 1391/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3024 - precision: 0.9172 - recall: 0.7733 - f1_score: 0.8387 - val_loss: 0.4883 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1392/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.3032 - precision: 0.9108 - recall: 0.7800 - f1_score: 0.8402 - val_loss: 0.4949 - val_precision: 0.6250 - val_recall: 0.5000 - val_f1_score: 0.5556\n",
            "Epoch 1393/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3041 - precision: 0.8897 - recall: 0.7767 - f1_score: 0.8291 - val_loss: 0.4881 - val_precision: 0.5870 - val_recall: 0.4500 - val_f1_score: 0.5094\n",
            "Epoch 1394/3000\n",
            "300/300 [==============================] - 0s 58us/step - loss: 0.3019 - precision: 0.9165 - recall: 0.7767 - f1_score: 0.8406 - val_loss: 0.4885 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 1395/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.3025 - precision: 0.9154 - recall: 0.7600 - f1_score: 0.8302 - val_loss: 0.4902 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 1396/3000\n",
            "300/300 [==============================] - 0s 59us/step - loss: 0.3089 - precision: 0.8893 - recall: 0.7533 - f1_score: 0.8147 - val_loss: 0.4900 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 1397/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3078 - precision: 0.8854 - recall: 0.7567 - f1_score: 0.8152 - val_loss: 0.4879 - val_precision: 0.6304 - val_recall: 0.4833 - val_f1_score: 0.5472\n",
            "Epoch 1398/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3028 - precision: 0.9078 - recall: 0.7900 - f1_score: 0.8448 - val_loss: 0.4881 - val_precision: 0.5870 - val_recall: 0.4500 - val_f1_score: 0.5094\n",
            "Epoch 1399/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3039 - precision: 0.8909 - recall: 0.7667 - f1_score: 0.8233 - val_loss: 0.4883 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1400/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.3032 - precision: 0.9070 - recall: 0.7767 - f1_score: 0.8364 - val_loss: 0.4892 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1401/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3058 - precision: 0.8986 - recall: 0.7667 - f1_score: 0.8261 - val_loss: 0.4889 - val_precision: 0.5625 - val_recall: 0.4500 - val_f1_score: 0.5000\n",
            "Epoch 1402/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3022 - precision: 0.9032 - recall: 0.7733 - f1_score: 0.8331 - val_loss: 0.4892 - val_precision: 0.5625 - val_recall: 0.4500 - val_f1_score: 0.5000\n",
            "Epoch 1403/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3025 - precision: 0.9033 - recall: 0.7767 - f1_score: 0.8348 - val_loss: 0.4904 - val_precision: 0.5745 - val_recall: 0.4500 - val_f1_score: 0.5047\n",
            "Epoch 1404/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3029 - precision: 0.8940 - recall: 0.7633 - f1_score: 0.8231 - val_loss: 0.4880 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1405/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3057 - precision: 0.8948 - recall: 0.7767 - f1_score: 0.8306 - val_loss: 0.4883 - val_precision: 0.5870 - val_recall: 0.4500 - val_f1_score: 0.5094\n",
            "Epoch 1406/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.3051 - precision: 0.8915 - recall: 0.7667 - f1_score: 0.8240 - val_loss: 0.4893 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 1407/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3025 - precision: 0.9094 - recall: 0.7733 - f1_score: 0.8358 - val_loss: 0.4922 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1408/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3038 - precision: 0.8952 - recall: 0.7733 - f1_score: 0.8290 - val_loss: 0.4897 - val_precision: 0.5778 - val_recall: 0.4333 - val_f1_score: 0.4952\n",
            "Epoch 1409/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3046 - precision: 0.9049 - recall: 0.7667 - f1_score: 0.8298 - val_loss: 0.4915 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 1410/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3081 - precision: 0.8787 - recall: 0.7533 - f1_score: 0.8111 - val_loss: 0.4889 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1411/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3031 - precision: 0.9030 - recall: 0.7667 - f1_score: 0.8280 - val_loss: 0.4892 - val_precision: 0.5625 - val_recall: 0.4500 - val_f1_score: 0.5000\n",
            "Epoch 1412/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3029 - precision: 0.9192 - recall: 0.7733 - f1_score: 0.8387 - val_loss: 0.4892 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1413/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.3032 - precision: 0.8989 - recall: 0.7700 - f1_score: 0.8290 - val_loss: 0.4882 - val_precision: 0.5870 - val_recall: 0.4500 - val_f1_score: 0.5094\n",
            "Epoch 1414/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3020 - precision: 0.8957 - recall: 0.7700 - f1_score: 0.8279 - val_loss: 0.4887 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1415/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3009 - precision: 0.9143 - recall: 0.7800 - f1_score: 0.8413 - val_loss: 0.4882 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1416/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3044 - precision: 0.8863 - recall: 0.7833 - f1_score: 0.8305 - val_loss: 0.4885 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1417/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.3021 - precision: 0.8952 - recall: 0.7600 - f1_score: 0.8217 - val_loss: 0.4887 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1418/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3013 - precision: 0.8962 - recall: 0.7600 - f1_score: 0.8222 - val_loss: 0.4907 - val_precision: 0.5652 - val_recall: 0.4333 - val_f1_score: 0.4906\n",
            "Epoch 1419/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3027 - precision: 0.9054 - recall: 0.7733 - f1_score: 0.8338 - val_loss: 0.4895 - val_precision: 0.5714 - val_recall: 0.4667 - val_f1_score: 0.5138\n",
            "Epoch 1420/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3018 - precision: 0.8857 - recall: 0.7700 - f1_score: 0.8228 - val_loss: 0.4906 - val_precision: 0.5652 - val_recall: 0.4333 - val_f1_score: 0.4906\n",
            "Epoch 1421/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3020 - precision: 0.9025 - recall: 0.7767 - f1_score: 0.8347 - val_loss: 0.4887 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1422/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3007 - precision: 0.9063 - recall: 0.7800 - f1_score: 0.8379 - val_loss: 0.4894 - val_precision: 0.6304 - val_recall: 0.4833 - val_f1_score: 0.5472\n",
            "Epoch 1423/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3049 - precision: 0.8883 - recall: 0.7667 - f1_score: 0.8228 - val_loss: 0.4887 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1424/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3026 - precision: 0.8800 - recall: 0.7833 - f1_score: 0.8285 - val_loss: 0.4912 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 1425/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3005 - precision: 0.8935 - recall: 0.7800 - f1_score: 0.8326 - val_loss: 0.4902 - val_precision: 0.5870 - val_recall: 0.4500 - val_f1_score: 0.5094\n",
            "Epoch 1426/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3023 - precision: 0.9138 - recall: 0.7600 - f1_score: 0.8291 - val_loss: 0.4889 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 1427/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3024 - precision: 0.8917 - recall: 0.7700 - f1_score: 0.8259 - val_loss: 0.4902 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1428/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.3003 - precision: 0.8897 - recall: 0.7567 - f1_score: 0.8175 - val_loss: 0.4933 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 1429/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3008 - precision: 0.8996 - recall: 0.7700 - f1_score: 0.8289 - val_loss: 0.4919 - val_precision: 0.6304 - val_recall: 0.4833 - val_f1_score: 0.5472\n",
            "Epoch 1430/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3024 - precision: 0.8885 - recall: 0.7733 - f1_score: 0.8259 - val_loss: 0.4899 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1431/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3021 - precision: 0.8963 - recall: 0.7467 - f1_score: 0.8145 - val_loss: 0.4897 - val_precision: 0.5745 - val_recall: 0.4500 - val_f1_score: 0.5047\n",
            "Epoch 1432/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.3020 - precision: 0.9070 - recall: 0.7767 - f1_score: 0.8365 - val_loss: 0.4899 - val_precision: 0.6279 - val_recall: 0.4500 - val_f1_score: 0.5243\n",
            "Epoch 1433/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2996 - precision: 0.8973 - recall: 0.7600 - f1_score: 0.8225 - val_loss: 0.4982 - val_precision: 0.6250 - val_recall: 0.5000 - val_f1_score: 0.5556\n",
            "Epoch 1434/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3047 - precision: 0.9019 - recall: 0.7900 - f1_score: 0.8420 - val_loss: 0.4892 - val_precision: 0.6279 - val_recall: 0.4500 - val_f1_score: 0.5243\n",
            "Epoch 1435/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3008 - precision: 0.9121 - recall: 0.7567 - f1_score: 0.8265 - val_loss: 0.4902 - val_precision: 0.5833 - val_recall: 0.4667 - val_f1_score: 0.5185\n",
            "Epoch 1436/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3001 - precision: 0.8935 - recall: 0.7767 - f1_score: 0.8301 - val_loss: 0.4894 - val_precision: 0.5870 - val_recall: 0.4500 - val_f1_score: 0.5094\n",
            "Epoch 1437/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2988 - precision: 0.9152 - recall: 0.7800 - f1_score: 0.8417 - val_loss: 0.4898 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 1438/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.3063 - precision: 0.8951 - recall: 0.7700 - f1_score: 0.8271 - val_loss: 0.4902 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1439/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3012 - precision: 0.8973 - recall: 0.7833 - f1_score: 0.8362 - val_loss: 0.4967 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 1440/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3004 - precision: 0.8893 - recall: 0.7600 - f1_score: 0.8189 - val_loss: 0.4897 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 1441/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.3003 - precision: 0.9145 - recall: 0.7833 - f1_score: 0.8436 - val_loss: 0.4907 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1442/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3016 - precision: 0.8822 - recall: 0.7700 - f1_score: 0.8217 - val_loss: 0.4895 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 1443/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3017 - precision: 0.9150 - recall: 0.7700 - f1_score: 0.8340 - val_loss: 0.4897 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 1444/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2986 - precision: 0.9037 - recall: 0.7800 - f1_score: 0.8371 - val_loss: 0.4897 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1445/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.3020 - precision: 0.8906 - recall: 0.7833 - f1_score: 0.8331 - val_loss: 0.4906 - val_precision: 0.5870 - val_recall: 0.4500 - val_f1_score: 0.5094\n",
            "Epoch 1446/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2995 - precision: 0.8959 - recall: 0.7867 - f1_score: 0.8368 - val_loss: 0.4910 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 1447/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.3002 - precision: 0.9193 - recall: 0.7567 - f1_score: 0.8300 - val_loss: 0.4908 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1448/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3016 - precision: 0.9124 - recall: 0.7700 - f1_score: 0.8340 - val_loss: 0.4900 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1449/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2993 - precision: 0.8900 - recall: 0.7800 - f1_score: 0.8309 - val_loss: 0.4993 - val_precision: 0.5833 - val_recall: 0.4667 - val_f1_score: 0.5185\n",
            "Epoch 1450/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3020 - precision: 0.9052 - recall: 0.7667 - f1_score: 0.8300 - val_loss: 0.4906 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1451/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.3036 - precision: 0.8658 - recall: 0.7533 - f1_score: 0.8055 - val_loss: 0.4898 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 1452/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2991 - precision: 0.9106 - recall: 0.7833 - f1_score: 0.8422 - val_loss: 0.4900 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 1453/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.2995 - precision: 0.9070 - recall: 0.7867 - f1_score: 0.8424 - val_loss: 0.4943 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 1454/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.3039 - precision: 0.8939 - recall: 0.7767 - f1_score: 0.8304 - val_loss: 0.4905 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 1455/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2997 - precision: 0.8943 - recall: 0.7867 - f1_score: 0.8367 - val_loss: 0.5014 - val_precision: 0.6250 - val_recall: 0.5000 - val_f1_score: 0.5556\n",
            "Epoch 1456/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3077 - precision: 0.8801 - recall: 0.7567 - f1_score: 0.8129 - val_loss: 0.4905 - val_precision: 0.5870 - val_recall: 0.4500 - val_f1_score: 0.5094\n",
            "Epoch 1457/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.2982 - precision: 0.9056 - recall: 0.7700 - f1_score: 0.8313 - val_loss: 0.4900 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1458/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.3016 - precision: 0.9113 - recall: 0.7867 - f1_score: 0.8442 - val_loss: 0.4920 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1459/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.2987 - precision: 0.9132 - recall: 0.7767 - f1_score: 0.8393 - val_loss: 0.4908 - val_precision: 0.5833 - val_recall: 0.4667 - val_f1_score: 0.5185\n",
            "Epoch 1460/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.3006 - precision: 0.8922 - recall: 0.7767 - f1_score: 0.8300 - val_loss: 0.4958 - val_precision: 0.6304 - val_recall: 0.4833 - val_f1_score: 0.5472\n",
            "Epoch 1461/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.3008 - precision: 0.9018 - recall: 0.7767 - f1_score: 0.8341 - val_loss: 0.4904 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 1462/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2996 - precision: 0.8901 - recall: 0.7800 - f1_score: 0.8313 - val_loss: 0.4903 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1463/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2980 - precision: 0.9102 - recall: 0.7833 - f1_score: 0.8414 - val_loss: 0.4907 - val_precision: 0.5870 - val_recall: 0.4500 - val_f1_score: 0.5094\n",
            "Epoch 1464/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.3003 - precision: 0.9066 - recall: 0.7733 - f1_score: 0.8342 - val_loss: 0.4926 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1465/3000\n",
            "300/300 [==============================] - 0s 58us/step - loss: 0.3007 - precision: 0.8990 - recall: 0.7800 - f1_score: 0.8349 - val_loss: 0.4932 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 1466/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2983 - precision: 0.9035 - recall: 0.7733 - f1_score: 0.8327 - val_loss: 0.4906 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 1467/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2980 - precision: 0.9009 - recall: 0.7900 - f1_score: 0.8416 - val_loss: 0.4910 - val_precision: 0.6279 - val_recall: 0.4500 - val_f1_score: 0.5243\n",
            "Epoch 1468/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2979 - precision: 0.9116 - recall: 0.7800 - f1_score: 0.8401 - val_loss: 0.4914 - val_precision: 0.6304 - val_recall: 0.4833 - val_f1_score: 0.5472\n",
            "Epoch 1469/3000\n",
            "300/300 [==============================] - 0s 57us/step - loss: 0.3012 - precision: 0.8899 - recall: 0.7600 - f1_score: 0.8198 - val_loss: 0.4937 - val_precision: 0.5870 - val_recall: 0.4500 - val_f1_score: 0.5094\n",
            "Epoch 1470/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.2990 - precision: 0.9165 - recall: 0.7700 - f1_score: 0.8366 - val_loss: 0.4908 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1471/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2976 - precision: 0.9064 - recall: 0.7833 - f1_score: 0.8402 - val_loss: 0.4904 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1472/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2988 - precision: 0.9134 - recall: 0.7733 - f1_score: 0.8368 - val_loss: 0.4906 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 1473/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2989 - precision: 0.9013 - recall: 0.7933 - f1_score: 0.8437 - val_loss: 0.4907 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1474/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2977 - precision: 0.9065 - recall: 0.7767 - f1_score: 0.8365 - val_loss: 0.4933 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 1475/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.3028 - precision: 0.8899 - recall: 0.7700 - f1_score: 0.8252 - val_loss: 0.4929 - val_precision: 0.5625 - val_recall: 0.4500 - val_f1_score: 0.5000\n",
            "Epoch 1476/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2977 - precision: 0.9051 - recall: 0.7933 - f1_score: 0.8452 - val_loss: 0.4915 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 1477/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.3009 - precision: 0.8910 - recall: 0.7867 - f1_score: 0.8352 - val_loss: 0.4956 - val_precision: 0.6250 - val_recall: 0.5000 - val_f1_score: 0.5556\n",
            "Epoch 1478/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.2976 - precision: 0.9029 - recall: 0.7767 - f1_score: 0.8342 - val_loss: 0.4910 - val_precision: 0.5870 - val_recall: 0.4500 - val_f1_score: 0.5094\n",
            "Epoch 1479/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.2966 - precision: 0.9010 - recall: 0.7833 - f1_score: 0.8377 - val_loss: 0.4923 - val_precision: 0.5745 - val_recall: 0.4500 - val_f1_score: 0.5047\n",
            "Epoch 1480/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2976 - precision: 0.9134 - recall: 0.7700 - f1_score: 0.8353 - val_loss: 0.4907 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 1481/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2996 - precision: 0.8936 - recall: 0.7833 - f1_score: 0.8342 - val_loss: 0.4945 - val_precision: 0.5745 - val_recall: 0.4500 - val_f1_score: 0.5047\n",
            "Epoch 1482/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2984 - precision: 0.9162 - recall: 0.7900 - f1_score: 0.8482 - val_loss: 0.4911 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 1483/3000\n",
            "300/300 [==============================] - 0s 59us/step - loss: 0.2988 - precision: 0.9163 - recall: 0.7700 - f1_score: 0.8363 - val_loss: 0.4908 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1484/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2974 - precision: 0.9106 - recall: 0.7800 - f1_score: 0.8400 - val_loss: 0.4909 - val_precision: 0.5870 - val_recall: 0.4500 - val_f1_score: 0.5094\n",
            "Epoch 1485/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2977 - precision: 0.9216 - recall: 0.7833 - f1_score: 0.8465 - val_loss: 0.4909 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1486/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2977 - precision: 0.8995 - recall: 0.7733 - f1_score: 0.8314 - val_loss: 0.4930 - val_precision: 0.5745 - val_recall: 0.4500 - val_f1_score: 0.5047\n",
            "Epoch 1487/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2979 - precision: 0.8900 - recall: 0.7767 - f1_score: 0.8292 - val_loss: 0.4922 - val_precision: 0.5745 - val_recall: 0.4500 - val_f1_score: 0.5047\n",
            "Epoch 1488/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.2971 - precision: 0.9005 - recall: 0.7867 - f1_score: 0.8394 - val_loss: 0.4915 - val_precision: 0.5745 - val_recall: 0.4500 - val_f1_score: 0.5047\n",
            "Epoch 1489/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2963 - precision: 0.9118 - recall: 0.7933 - f1_score: 0.8484 - val_loss: 0.4922 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1490/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2956 - precision: 0.9118 - recall: 0.7867 - f1_score: 0.8439 - val_loss: 0.4927 - val_precision: 0.5652 - val_recall: 0.4333 - val_f1_score: 0.4906\n",
            "Epoch 1491/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2982 - precision: 0.9134 - recall: 0.7767 - f1_score: 0.8380 - val_loss: 0.4915 - val_precision: 0.5745 - val_recall: 0.4500 - val_f1_score: 0.5047\n",
            "Epoch 1492/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.2960 - precision: 0.9006 - recall: 0.7900 - f1_score: 0.8414 - val_loss: 0.4914 - val_precision: 0.5870 - val_recall: 0.4500 - val_f1_score: 0.5094\n",
            "Epoch 1493/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2967 - precision: 0.9146 - recall: 0.7867 - f1_score: 0.8454 - val_loss: 0.5013 - val_precision: 0.5714 - val_recall: 0.4667 - val_f1_score: 0.5138\n",
            "Epoch 1494/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.3015 - precision: 0.8888 - recall: 0.7733 - f1_score: 0.8268 - val_loss: 0.5050 - val_precision: 0.5769 - val_recall: 0.5000 - val_f1_score: 0.5357\n",
            "Epoch 1495/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2967 - precision: 0.8911 - recall: 0.7767 - f1_score: 0.8294 - val_loss: 0.4925 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1496/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.3016 - precision: 0.9026 - recall: 0.7633 - f1_score: 0.8269 - val_loss: 0.4912 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1497/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2964 - precision: 0.9013 - recall: 0.7900 - f1_score: 0.8416 - val_loss: 0.4913 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1498/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.3042 - precision: 0.8845 - recall: 0.7600 - f1_score: 0.8167 - val_loss: 0.4930 - val_precision: 0.6279 - val_recall: 0.4500 - val_f1_score: 0.5243\n",
            "Epoch 1499/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2956 - precision: 0.9077 - recall: 0.7767 - f1_score: 0.8368 - val_loss: 0.4929 - val_precision: 0.5652 - val_recall: 0.4333 - val_f1_score: 0.4906\n",
            "Epoch 1500/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.2965 - precision: 0.9056 - recall: 0.7967 - f1_score: 0.8474 - val_loss: 0.4937 - val_precision: 0.5625 - val_recall: 0.4500 - val_f1_score: 0.5000\n",
            "Epoch 1501/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2955 - precision: 0.9196 - recall: 0.7800 - f1_score: 0.8431 - val_loss: 0.4922 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 1502/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2968 - precision: 0.9050 - recall: 0.7900 - f1_score: 0.8434 - val_loss: 0.4918 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1503/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.3061 - precision: 0.9074 - recall: 0.7733 - f1_score: 0.8338 - val_loss: 0.4952 - val_precision: 0.5870 - val_recall: 0.4500 - val_f1_score: 0.5094\n",
            "Epoch 1504/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2969 - precision: 0.8994 - recall: 0.7467 - f1_score: 0.8159 - val_loss: 0.4923 - val_precision: 0.5833 - val_recall: 0.4667 - val_f1_score: 0.5185\n",
            "Epoch 1505/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2979 - precision: 0.9001 - recall: 0.7767 - f1_score: 0.8332 - val_loss: 0.4918 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1506/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2954 - precision: 0.8994 - recall: 0.7700 - f1_score: 0.8295 - val_loss: 0.4918 - val_precision: 0.5870 - val_recall: 0.4500 - val_f1_score: 0.5094\n",
            "Epoch 1507/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.3028 - precision: 0.8828 - recall: 0.7567 - f1_score: 0.8147 - val_loss: 0.5038 - val_precision: 0.5833 - val_recall: 0.4667 - val_f1_score: 0.5185\n",
            "Epoch 1508/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.3022 - precision: 0.8847 - recall: 0.7500 - f1_score: 0.8113 - val_loss: 0.4933 - val_precision: 0.5652 - val_recall: 0.4333 - val_f1_score: 0.4906\n",
            "Epoch 1509/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2965 - precision: 0.9145 - recall: 0.7800 - f1_score: 0.8413 - val_loss: 0.4931 - val_precision: 0.5652 - val_recall: 0.4333 - val_f1_score: 0.4906\n",
            "Epoch 1510/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2963 - precision: 0.9003 - recall: 0.7800 - f1_score: 0.8355 - val_loss: 0.4968 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 1511/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2986 - precision: 0.8926 - recall: 0.7800 - f1_score: 0.8323 - val_loss: 0.4949 - val_precision: 0.5870 - val_recall: 0.4500 - val_f1_score: 0.5094\n",
            "Epoch 1512/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.2971 - precision: 0.9067 - recall: 0.7767 - f1_score: 0.8366 - val_loss: 0.4918 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 1513/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.2951 - precision: 0.9221 - recall: 0.7933 - f1_score: 0.8524 - val_loss: 0.4921 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1514/3000\n",
            "300/300 [==============================] - 0s 81us/step - loss: 0.2970 - precision: 0.8927 - recall: 0.7733 - f1_score: 0.8286 - val_loss: 0.4946 - val_precision: 0.5745 - val_recall: 0.4500 - val_f1_score: 0.5047\n",
            "Epoch 1515/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2964 - precision: 0.9003 - recall: 0.7833 - f1_score: 0.8374 - val_loss: 0.4934 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 1516/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2941 - precision: 0.9137 - recall: 0.7800 - f1_score: 0.8413 - val_loss: 0.5000 - val_precision: 0.5870 - val_recall: 0.4500 - val_f1_score: 0.5094\n",
            "Epoch 1517/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2976 - precision: 0.9064 - recall: 0.7867 - f1_score: 0.8418 - val_loss: 0.4919 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1518/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2975 - precision: 0.9025 - recall: 0.7767 - f1_score: 0.8346 - val_loss: 0.4926 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1519/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2942 - precision: 0.9262 - recall: 0.7800 - f1_score: 0.8460 - val_loss: 0.4920 - val_precision: 0.5870 - val_recall: 0.4500 - val_f1_score: 0.5094\n",
            "Epoch 1520/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.2949 - precision: 0.9221 - recall: 0.7867 - f1_score: 0.8489 - val_loss: 0.4920 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 1521/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.2954 - precision: 0.9005 - recall: 0.7867 - f1_score: 0.8397 - val_loss: 0.4929 - val_precision: 0.6279 - val_recall: 0.4500 - val_f1_score: 0.5243\n",
            "Epoch 1522/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2959 - precision: 0.8997 - recall: 0.7800 - f1_score: 0.8352 - val_loss: 0.4926 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1523/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2994 - precision: 0.8941 - recall: 0.7667 - f1_score: 0.8253 - val_loss: 0.4931 - val_precision: 0.5957 - val_recall: 0.4667 - val_f1_score: 0.5234\n",
            "Epoch 1524/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.2951 - precision: 0.9041 - recall: 0.7900 - f1_score: 0.8428 - val_loss: 0.4930 - val_precision: 0.5957 - val_recall: 0.4667 - val_f1_score: 0.5234\n",
            "Epoch 1525/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.2966 - precision: 0.8934 - recall: 0.8100 - f1_score: 0.8495 - val_loss: 0.4930 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1526/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2967 - precision: 0.8939 - recall: 0.7633 - f1_score: 0.8234 - val_loss: 0.4936 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1527/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2955 - precision: 0.9044 - recall: 0.7833 - f1_score: 0.8392 - val_loss: 0.4920 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1528/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2944 - precision: 0.9248 - recall: 0.7867 - f1_score: 0.8496 - val_loss: 0.4940 - val_precision: 0.5745 - val_recall: 0.4500 - val_f1_score: 0.5047\n",
            "Epoch 1529/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2951 - precision: 0.8963 - recall: 0.7833 - f1_score: 0.8353 - val_loss: 0.4923 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1530/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2943 - precision: 0.9138 - recall: 0.7867 - f1_score: 0.8451 - val_loss: 0.4928 - val_precision: 0.5833 - val_recall: 0.4667 - val_f1_score: 0.5185\n",
            "Epoch 1531/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2951 - precision: 0.9065 - recall: 0.7800 - f1_score: 0.8383 - val_loss: 0.4941 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1532/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2999 - precision: 0.8858 - recall: 0.7733 - f1_score: 0.8256 - val_loss: 0.4926 - val_precision: 0.5745 - val_recall: 0.4500 - val_f1_score: 0.5047\n",
            "Epoch 1533/3000\n",
            "300/300 [==============================] - 0s 59us/step - loss: 0.2946 - precision: 0.9134 - recall: 0.7733 - f1_score: 0.8374 - val_loss: 0.4922 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1534/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.2946 - precision: 0.9031 - recall: 0.7700 - f1_score: 0.8310 - val_loss: 0.4970 - val_precision: 0.5745 - val_recall: 0.4500 - val_f1_score: 0.5047\n",
            "Epoch 1535/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2953 - precision: 0.9102 - recall: 0.7800 - f1_score: 0.8393 - val_loss: 0.4968 - val_precision: 0.5870 - val_recall: 0.4500 - val_f1_score: 0.5094\n",
            "Epoch 1536/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2982 - precision: 0.8959 - recall: 0.7700 - f1_score: 0.8281 - val_loss: 0.4926 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1537/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2937 - precision: 0.9058 - recall: 0.7900 - f1_score: 0.8430 - val_loss: 0.4922 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 1538/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2935 - precision: 0.9208 - recall: 0.7933 - f1_score: 0.8520 - val_loss: 0.4929 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 1539/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2975 - precision: 0.8881 - recall: 0.7700 - f1_score: 0.8243 - val_loss: 0.4936 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1540/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2958 - precision: 0.9106 - recall: 0.7767 - f1_score: 0.8375 - val_loss: 0.4935 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1541/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.2953 - precision: 0.9083 - recall: 0.7900 - f1_score: 0.8449 - val_loss: 0.4948 - val_precision: 0.6304 - val_recall: 0.4833 - val_f1_score: 0.5472\n",
            "Epoch 1542/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2945 - precision: 0.9109 - recall: 0.7933 - f1_score: 0.8467 - val_loss: 0.4933 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1543/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2955 - precision: 0.8936 - recall: 0.7800 - f1_score: 0.8323 - val_loss: 0.4931 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 1544/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2945 - precision: 0.8947 - recall: 0.7967 - f1_score: 0.8426 - val_loss: 0.4926 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 1545/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2936 - precision: 0.9078 - recall: 0.7900 - f1_score: 0.8444 - val_loss: 0.4939 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1546/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2942 - precision: 0.8970 - recall: 0.7867 - f1_score: 0.8380 - val_loss: 0.4937 - val_precision: 0.5870 - val_recall: 0.4500 - val_f1_score: 0.5094\n",
            "Epoch 1547/3000\n",
            "300/300 [==============================] - 0s 58us/step - loss: 0.2949 - precision: 0.9046 - recall: 0.7933 - f1_score: 0.8449 - val_loss: 0.4929 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 1548/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2961 - precision: 0.9120 - recall: 0.7867 - f1_score: 0.8446 - val_loss: 0.4932 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1549/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2922 - precision: 0.9227 - recall: 0.7933 - f1_score: 0.8528 - val_loss: 0.4926 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1550/3000\n",
            "300/300 [==============================] - 0s 59us/step - loss: 0.2958 - precision: 0.9106 - recall: 0.7633 - f1_score: 0.8301 - val_loss: 0.4943 - val_precision: 0.5745 - val_recall: 0.4500 - val_f1_score: 0.5047\n",
            "Epoch 1551/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2924 - precision: 0.9166 - recall: 0.7833 - f1_score: 0.8440 - val_loss: 0.4930 - val_precision: 0.5870 - val_recall: 0.4500 - val_f1_score: 0.5094\n",
            "Epoch 1552/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2935 - precision: 0.8965 - recall: 0.7933 - f1_score: 0.8413 - val_loss: 0.4930 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 1553/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2953 - precision: 0.8853 - recall: 0.7800 - f1_score: 0.8289 - val_loss: 0.4936 - val_precision: 0.5833 - val_recall: 0.4667 - val_f1_score: 0.5185\n",
            "Epoch 1554/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2942 - precision: 0.9095 - recall: 0.7733 - f1_score: 0.8358 - val_loss: 0.4939 - val_precision: 0.5870 - val_recall: 0.4500 - val_f1_score: 0.5094\n",
            "Epoch 1555/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2915 - precision: 0.9083 - recall: 0.7933 - f1_score: 0.8464 - val_loss: 0.4929 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1556/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2941 - precision: 0.9152 - recall: 0.7767 - f1_score: 0.8397 - val_loss: 0.4950 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 1557/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2941 - precision: 0.8935 - recall: 0.7833 - f1_score: 0.8342 - val_loss: 0.4930 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1558/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2944 - precision: 0.9215 - recall: 0.7833 - f1_score: 0.8467 - val_loss: 0.4952 - val_precision: 0.5745 - val_recall: 0.4500 - val_f1_score: 0.5047\n",
            "Epoch 1559/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.2928 - precision: 0.9120 - recall: 0.8033 - f1_score: 0.8529 - val_loss: 0.4929 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1560/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2939 - precision: 0.9112 - recall: 0.7833 - f1_score: 0.8420 - val_loss: 0.4935 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1561/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2916 - precision: 0.8978 - recall: 0.7900 - f1_score: 0.8400 - val_loss: 0.4946 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1562/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3014 - precision: 0.8781 - recall: 0.7733 - f1_score: 0.8220 - val_loss: 0.4934 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 1563/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2924 - precision: 0.9040 - recall: 0.7900 - f1_score: 0.8429 - val_loss: 0.5054 - val_precision: 0.5714 - val_recall: 0.4667 - val_f1_score: 0.5138\n",
            "Epoch 1564/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2943 - precision: 0.9139 - recall: 0.7767 - f1_score: 0.8392 - val_loss: 0.4932 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1565/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2950 - precision: 0.8884 - recall: 0.7667 - f1_score: 0.8225 - val_loss: 0.5038 - val_precision: 0.5714 - val_recall: 0.4667 - val_f1_score: 0.5138\n",
            "Epoch 1566/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2956 - precision: 0.8954 - recall: 0.7733 - f1_score: 0.8293 - val_loss: 0.4956 - val_precision: 0.6304 - val_recall: 0.4833 - val_f1_score: 0.5472\n",
            "Epoch 1567/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2930 - precision: 0.9096 - recall: 0.8067 - f1_score: 0.8550 - val_loss: 0.4939 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 1568/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2925 - precision: 0.9227 - recall: 0.7800 - f1_score: 0.8449 - val_loss: 0.4946 - val_precision: 0.5870 - val_recall: 0.4500 - val_f1_score: 0.5094\n",
            "Epoch 1569/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2926 - precision: 0.8983 - recall: 0.8000 - f1_score: 0.8461 - val_loss: 0.4967 - val_precision: 0.5745 - val_recall: 0.4500 - val_f1_score: 0.5047\n",
            "Epoch 1570/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2923 - precision: 0.9194 - recall: 0.8033 - f1_score: 0.8573 - val_loss: 0.4939 - val_precision: 0.6279 - val_recall: 0.4500 - val_f1_score: 0.5243\n",
            "Epoch 1571/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2925 - precision: 0.9093 - recall: 0.8000 - f1_score: 0.8507 - val_loss: 0.4962 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 1572/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2960 - precision: 0.8850 - recall: 0.7667 - f1_score: 0.8215 - val_loss: 0.4938 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1573/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2954 - precision: 0.9002 - recall: 0.7767 - f1_score: 0.8337 - val_loss: 0.4934 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1574/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.2975 - precision: 0.9053 - recall: 0.7733 - f1_score: 0.8338 - val_loss: 0.4975 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 1575/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2946 - precision: 0.8876 - recall: 0.7833 - f1_score: 0.8315 - val_loss: 0.4947 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1576/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2917 - precision: 0.9134 - recall: 0.7767 - f1_score: 0.8392 - val_loss: 0.5029 - val_precision: 0.5714 - val_recall: 0.4667 - val_f1_score: 0.5138\n",
            "Epoch 1577/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2954 - precision: 0.9113 - recall: 0.7867 - f1_score: 0.8441 - val_loss: 0.4939 - val_precision: 0.5745 - val_recall: 0.4500 - val_f1_score: 0.5047\n",
            "Epoch 1578/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2918 - precision: 0.9036 - recall: 0.7867 - f1_score: 0.8408 - val_loss: 0.4958 - val_precision: 0.5745 - val_recall: 0.4500 - val_f1_score: 0.5047\n",
            "Epoch 1579/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2941 - precision: 0.9032 - recall: 0.7767 - f1_score: 0.8350 - val_loss: 0.4948 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1580/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2897 - precision: 0.8968 - recall: 0.7833 - f1_score: 0.8360 - val_loss: 0.5008 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1581/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2908 - precision: 0.9102 - recall: 0.7767 - f1_score: 0.8380 - val_loss: 0.4937 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 1582/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2900 - precision: 0.9118 - recall: 0.7900 - f1_score: 0.8465 - val_loss: 0.4976 - val_precision: 0.5833 - val_recall: 0.4667 - val_f1_score: 0.5185\n",
            "Epoch 1583/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2922 - precision: 0.9073 - recall: 0.7800 - f1_score: 0.8388 - val_loss: 0.4942 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1584/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2922 - precision: 0.8988 - recall: 0.8000 - f1_score: 0.8462 - val_loss: 0.4950 - val_precision: 0.5745 - val_recall: 0.4500 - val_f1_score: 0.5047\n",
            "Epoch 1585/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2957 - precision: 0.8842 - recall: 0.7733 - f1_score: 0.8248 - val_loss: 0.4978 - val_precision: 0.5870 - val_recall: 0.4500 - val_f1_score: 0.5094\n",
            "Epoch 1586/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2924 - precision: 0.9132 - recall: 0.7833 - f1_score: 0.8429 - val_loss: 0.4937 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1587/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2912 - precision: 0.9130 - recall: 0.7933 - f1_score: 0.8486 - val_loss: 0.4951 - val_precision: 0.5957 - val_recall: 0.4667 - val_f1_score: 0.5234\n",
            "Epoch 1588/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2945 - precision: 0.9086 - recall: 0.8000 - f1_score: 0.8501 - val_loss: 0.4965 - val_precision: 0.5745 - val_recall: 0.4500 - val_f1_score: 0.5047\n",
            "Epoch 1589/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2895 - precision: 0.9069 - recall: 0.8067 - f1_score: 0.8537 - val_loss: 0.4958 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 1590/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2929 - precision: 0.9021 - recall: 0.7700 - f1_score: 0.8307 - val_loss: 0.4947 - val_precision: 0.6279 - val_recall: 0.4500 - val_f1_score: 0.5243\n",
            "Epoch 1591/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2895 - precision: 0.8888 - recall: 0.7967 - f1_score: 0.8400 - val_loss: 0.4959 - val_precision: 0.5745 - val_recall: 0.4500 - val_f1_score: 0.5047\n",
            "Epoch 1592/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2931 - precision: 0.8969 - recall: 0.7967 - f1_score: 0.8431 - val_loss: 0.4956 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1593/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2913 - precision: 0.9156 - recall: 0.7867 - f1_score: 0.8459 - val_loss: 0.4940 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1594/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2934 - precision: 0.9223 - recall: 0.7867 - f1_score: 0.8489 - val_loss: 0.4945 - val_precision: 0.6279 - val_recall: 0.4500 - val_f1_score: 0.5243\n",
            "Epoch 1595/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.2931 - precision: 0.8957 - recall: 0.7800 - f1_score: 0.8332 - val_loss: 0.4995 - val_precision: 0.5957 - val_recall: 0.4667 - val_f1_score: 0.5234\n",
            "Epoch 1596/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2907 - precision: 0.9265 - recall: 0.7867 - f1_score: 0.8506 - val_loss: 0.4961 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 1597/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2943 - precision: 0.8928 - recall: 0.7800 - f1_score: 0.8323 - val_loss: 0.4962 - val_precision: 0.5745 - val_recall: 0.4500 - val_f1_score: 0.5047\n",
            "Epoch 1598/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.2898 - precision: 0.9062 - recall: 0.7967 - f1_score: 0.8476 - val_loss: 0.4944 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1599/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2900 - precision: 0.8989 - recall: 0.8000 - f1_score: 0.8464 - val_loss: 0.4988 - val_precision: 0.5833 - val_recall: 0.4667 - val_f1_score: 0.5185\n",
            "Epoch 1600/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2977 - precision: 0.8628 - recall: 0.7467 - f1_score: 0.8003 - val_loss: 0.4951 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 1601/3000\n",
            "300/300 [==============================] - 0s 59us/step - loss: 0.2919 - precision: 0.9010 - recall: 0.7933 - f1_score: 0.8437 - val_loss: 0.5040 - val_precision: 0.6250 - val_recall: 0.5000 - val_f1_score: 0.5556\n",
            "Epoch 1602/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.2988 - precision: 0.8688 - recall: 0.7667 - f1_score: 0.8144 - val_loss: 0.4966 - val_precision: 0.5745 - val_recall: 0.4500 - val_f1_score: 0.5047\n",
            "Epoch 1603/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2934 - precision: 0.9221 - recall: 0.7733 - f1_score: 0.8402 - val_loss: 0.4966 - val_precision: 0.5745 - val_recall: 0.4500 - val_f1_score: 0.5047\n",
            "Epoch 1604/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2947 - precision: 0.8991 - recall: 0.7833 - f1_score: 0.8366 - val_loss: 0.4951 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1605/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.2905 - precision: 0.9022 - recall: 0.7967 - f1_score: 0.8458 - val_loss: 0.4950 - val_precision: 0.6279 - val_recall: 0.4500 - val_f1_score: 0.5243\n",
            "Epoch 1606/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2921 - precision: 0.8995 - recall: 0.7800 - f1_score: 0.8353 - val_loss: 0.4952 - val_precision: 0.5745 - val_recall: 0.4500 - val_f1_score: 0.5047\n",
            "Epoch 1607/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2935 - precision: 0.8942 - recall: 0.7933 - f1_score: 0.8407 - val_loss: 0.4955 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 1608/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2911 - precision: 0.9169 - recall: 0.7967 - f1_score: 0.8522 - val_loss: 0.4946 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1609/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2901 - precision: 0.9083 - recall: 0.7967 - f1_score: 0.8485 - val_loss: 0.4949 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1610/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2905 - precision: 0.8902 - recall: 0.7900 - f1_score: 0.8366 - val_loss: 0.4987 - val_precision: 0.5870 - val_recall: 0.4500 - val_f1_score: 0.5094\n",
            "Epoch 1611/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2941 - precision: 0.8981 - recall: 0.7867 - f1_score: 0.8385 - val_loss: 0.4963 - val_precision: 0.5833 - val_recall: 0.4667 - val_f1_score: 0.5185\n",
            "Epoch 1612/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.3030 - precision: 0.8634 - recall: 0.7567 - f1_score: 0.8055 - val_loss: 0.4964 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 1613/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2915 - precision: 0.9060 - recall: 0.7667 - f1_score: 0.8304 - val_loss: 0.4971 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1614/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2899 - precision: 0.8952 - recall: 0.7700 - f1_score: 0.8278 - val_loss: 0.4948 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 1615/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2896 - precision: 0.9152 - recall: 0.7933 - f1_score: 0.8496 - val_loss: 0.4972 - val_precision: 0.5870 - val_recall: 0.4500 - val_f1_score: 0.5094\n",
            "Epoch 1616/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2932 - precision: 0.9071 - recall: 0.7833 - f1_score: 0.8402 - val_loss: 0.4995 - val_precision: 0.5957 - val_recall: 0.4667 - val_f1_score: 0.5234\n",
            "Epoch 1617/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2901 - precision: 0.9111 - recall: 0.7867 - f1_score: 0.8439 - val_loss: 0.4960 - val_precision: 0.5870 - val_recall: 0.4500 - val_f1_score: 0.5094\n",
            "Epoch 1618/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2911 - precision: 0.9055 - recall: 0.8033 - f1_score: 0.8509 - val_loss: 0.4949 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1619/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2886 - precision: 0.9080 - recall: 0.7867 - f1_score: 0.8426 - val_loss: 0.5012 - val_precision: 0.6383 - val_recall: 0.5000 - val_f1_score: 0.5607\n",
            "Epoch 1620/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2921 - precision: 0.8884 - recall: 0.7767 - f1_score: 0.8283 - val_loss: 0.4952 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1621/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2885 - precision: 0.9182 - recall: 0.7900 - f1_score: 0.8483 - val_loss: 0.4971 - val_precision: 0.5745 - val_recall: 0.4500 - val_f1_score: 0.5047\n",
            "Epoch 1622/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2886 - precision: 0.9121 - recall: 0.8000 - f1_score: 0.8522 - val_loss: 0.4988 - val_precision: 0.5625 - val_recall: 0.4500 - val_f1_score: 0.5000\n",
            "Epoch 1623/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2898 - precision: 0.8983 - recall: 0.8000 - f1_score: 0.8459 - val_loss: 0.5030 - val_precision: 0.5957 - val_recall: 0.4667 - val_f1_score: 0.5234\n",
            "Epoch 1624/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2903 - precision: 0.9074 - recall: 0.7833 - f1_score: 0.8408 - val_loss: 0.4954 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1625/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2880 - precision: 0.9158 - recall: 0.8033 - f1_score: 0.8555 - val_loss: 0.4952 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1626/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2885 - precision: 0.9083 - recall: 0.7867 - f1_score: 0.8427 - val_loss: 0.4981 - val_precision: 0.5745 - val_recall: 0.4500 - val_f1_score: 0.5047\n",
            "Epoch 1627/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2904 - precision: 0.8924 - recall: 0.7767 - f1_score: 0.8302 - val_loss: 0.4985 - val_precision: 0.5625 - val_recall: 0.4500 - val_f1_score: 0.5000\n",
            "Epoch 1628/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2882 - precision: 0.9289 - recall: 0.7933 - f1_score: 0.8551 - val_loss: 0.4954 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 1629/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2877 - precision: 0.9160 - recall: 0.8033 - f1_score: 0.8559 - val_loss: 0.5006 - val_precision: 0.5870 - val_recall: 0.4500 - val_f1_score: 0.5094\n",
            "Epoch 1630/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2916 - precision: 0.8805 - recall: 0.7800 - f1_score: 0.8272 - val_loss: 0.4974 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1631/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2884 - precision: 0.8922 - recall: 0.7967 - f1_score: 0.8413 - val_loss: 0.4957 - val_precision: 0.5870 - val_recall: 0.4500 - val_f1_score: 0.5094\n",
            "Epoch 1632/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2916 - precision: 0.9082 - recall: 0.7767 - f1_score: 0.8367 - val_loss: 0.4988 - val_precision: 0.5745 - val_recall: 0.4500 - val_f1_score: 0.5047\n",
            "Epoch 1633/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2905 - precision: 0.9091 - recall: 0.8000 - f1_score: 0.8507 - val_loss: 0.4965 - val_precision: 0.6279 - val_recall: 0.4500 - val_f1_score: 0.5243\n",
            "Epoch 1634/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2924 - precision: 0.9033 - recall: 0.7867 - f1_score: 0.8407 - val_loss: 0.4960 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 1635/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2906 - precision: 0.8841 - recall: 0.7667 - f1_score: 0.8208 - val_loss: 0.4955 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 1636/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2880 - precision: 0.9110 - recall: 0.7833 - f1_score: 0.8421 - val_loss: 0.4983 - val_precision: 0.5625 - val_recall: 0.4500 - val_f1_score: 0.5000\n",
            "Epoch 1637/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2889 - precision: 0.9170 - recall: 0.7800 - f1_score: 0.8425 - val_loss: 0.4960 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1638/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2890 - precision: 0.9193 - recall: 0.8000 - f1_score: 0.8554 - val_loss: 0.4998 - val_precision: 0.5625 - val_recall: 0.4500 - val_f1_score: 0.5000\n",
            "Epoch 1639/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2887 - precision: 0.8955 - recall: 0.8000 - f1_score: 0.8448 - val_loss: 0.4988 - val_precision: 0.5625 - val_recall: 0.4500 - val_f1_score: 0.5000\n",
            "Epoch 1640/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2873 - precision: 0.9228 - recall: 0.8033 - f1_score: 0.8576 - val_loss: 0.4957 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 1641/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2916 - precision: 0.9002 - recall: 0.7800 - f1_score: 0.8357 - val_loss: 0.4957 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 1642/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2870 - precision: 0.9192 - recall: 0.8000 - f1_score: 0.8540 - val_loss: 0.5001 - val_precision: 0.5833 - val_recall: 0.4667 - val_f1_score: 0.5185\n",
            "Epoch 1643/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2898 - precision: 0.9010 - recall: 0.8000 - f1_score: 0.8473 - val_loss: 0.4957 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 1644/3000\n",
            "300/300 [==============================] - 0s 59us/step - loss: 0.2873 - precision: 0.9230 - recall: 0.8033 - f1_score: 0.8589 - val_loss: 0.4959 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1645/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2870 - precision: 0.9245 - recall: 0.8033 - f1_score: 0.8594 - val_loss: 0.4980 - val_precision: 0.5745 - val_recall: 0.4500 - val_f1_score: 0.5047\n",
            "Epoch 1646/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.2907 - precision: 0.8993 - recall: 0.7733 - f1_score: 0.8311 - val_loss: 0.5032 - val_precision: 0.5870 - val_recall: 0.4500 - val_f1_score: 0.5094\n",
            "Epoch 1647/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2908 - precision: 0.8939 - recall: 0.7900 - f1_score: 0.8385 - val_loss: 0.4970 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 1648/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2874 - precision: 0.9191 - recall: 0.7967 - f1_score: 0.8525 - val_loss: 0.4965 - val_precision: 0.6279 - val_recall: 0.4500 - val_f1_score: 0.5243\n",
            "Epoch 1649/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2891 - precision: 0.9040 - recall: 0.8100 - f1_score: 0.8542 - val_loss: 0.4972 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1650/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2872 - precision: 0.9262 - recall: 0.7933 - f1_score: 0.8543 - val_loss: 0.4963 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 1651/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.2868 - precision: 0.9247 - recall: 0.7900 - f1_score: 0.8517 - val_loss: 0.4958 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 1652/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.2873 - precision: 0.9237 - recall: 0.8133 - f1_score: 0.8646 - val_loss: 0.4961 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1653/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.2903 - precision: 0.8795 - recall: 0.7767 - f1_score: 0.8242 - val_loss: 0.4994 - val_precision: 0.5745 - val_recall: 0.4500 - val_f1_score: 0.5047\n",
            "Epoch 1654/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.2869 - precision: 0.9214 - recall: 0.7767 - f1_score: 0.8424 - val_loss: 0.4986 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 1655/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2926 - precision: 0.8858 - recall: 0.8000 - f1_score: 0.8406 - val_loss: 0.4972 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1656/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.2875 - precision: 0.9100 - recall: 0.8000 - f1_score: 0.8510 - val_loss: 0.4971 - val_precision: 0.6042 - val_recall: 0.4833 - val_f1_score: 0.5370\n",
            "Epoch 1657/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.2925 - precision: 0.9099 - recall: 0.8067 - f1_score: 0.8546 - val_loss: 0.5040 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 1658/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2922 - precision: 0.8943 - recall: 0.7667 - f1_score: 0.8253 - val_loss: 0.4983 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1659/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2898 - precision: 0.8914 - recall: 0.7767 - f1_score: 0.8298 - val_loss: 0.4975 - val_precision: 0.5957 - val_recall: 0.4667 - val_f1_score: 0.5234\n",
            "Epoch 1660/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.2929 - precision: 0.8831 - recall: 0.7833 - f1_score: 0.8300 - val_loss: 0.4981 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1661/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.2872 - precision: 0.9020 - recall: 0.7933 - f1_score: 0.8437 - val_loss: 0.4977 - val_precision: 0.5957 - val_recall: 0.4667 - val_f1_score: 0.5234\n",
            "Epoch 1662/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2856 - precision: 0.9245 - recall: 0.8033 - f1_score: 0.8585 - val_loss: 0.4966 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1663/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2873 - precision: 0.9132 - recall: 0.7867 - f1_score: 0.8450 - val_loss: 0.5002 - val_precision: 0.5714 - val_recall: 0.4667 - val_f1_score: 0.5138\n",
            "Epoch 1664/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2882 - precision: 0.9121 - recall: 0.8067 - f1_score: 0.8557 - val_loss: 0.4981 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1665/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2889 - precision: 0.9084 - recall: 0.7900 - f1_score: 0.8450 - val_loss: 0.4968 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1666/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2875 - precision: 0.9139 - recall: 0.8100 - f1_score: 0.8585 - val_loss: 0.4964 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1667/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.2881 - precision: 0.9047 - recall: 0.7967 - f1_score: 0.8470 - val_loss: 0.4975 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1668/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.2918 - precision: 0.8956 - recall: 0.7733 - f1_score: 0.8294 - val_loss: 0.4974 - val_precision: 0.6279 - val_recall: 0.4500 - val_f1_score: 0.5243\n",
            "Epoch 1669/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.2888 - precision: 0.9109 - recall: 0.7900 - f1_score: 0.8459 - val_loss: 0.4993 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 1670/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.2864 - precision: 0.9052 - recall: 0.8033 - f1_score: 0.8505 - val_loss: 0.5000 - val_precision: 0.5745 - val_recall: 0.4500 - val_f1_score: 0.5047\n",
            "Epoch 1671/3000\n",
            "300/300 [==============================] - 0s 59us/step - loss: 0.2888 - precision: 0.9189 - recall: 0.7867 - f1_score: 0.8470 - val_loss: 0.4965 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 1672/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.2856 - precision: 0.9212 - recall: 0.8133 - f1_score: 0.8636 - val_loss: 0.4983 - val_precision: 0.5745 - val_recall: 0.4500 - val_f1_score: 0.5047\n",
            "Epoch 1673/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2886 - precision: 0.8997 - recall: 0.7867 - f1_score: 0.8391 - val_loss: 0.4969 - val_precision: 0.5745 - val_recall: 0.4500 - val_f1_score: 0.5047\n",
            "Epoch 1674/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2870 - precision: 0.9342 - recall: 0.8100 - f1_score: 0.8672 - val_loss: 0.4977 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1675/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2873 - precision: 0.9061 - recall: 0.7933 - f1_score: 0.8456 - val_loss: 0.5046 - val_precision: 0.6383 - val_recall: 0.5000 - val_f1_score: 0.5607\n",
            "Epoch 1676/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2886 - precision: 0.9141 - recall: 0.8000 - f1_score: 0.8524 - val_loss: 0.4974 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 1677/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2870 - precision: 0.9122 - recall: 0.7933 - f1_score: 0.8485 - val_loss: 0.4981 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 1678/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2862 - precision: 0.9231 - recall: 0.7900 - f1_score: 0.8512 - val_loss: 0.4969 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 1679/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2875 - precision: 0.9164 - recall: 0.7933 - f1_score: 0.8502 - val_loss: 0.4969 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1680/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.2853 - precision: 0.9062 - recall: 0.7767 - f1_score: 0.8364 - val_loss: 0.5026 - val_precision: 0.5870 - val_recall: 0.4500 - val_f1_score: 0.5094\n",
            "Epoch 1681/3000\n",
            "300/300 [==============================] - 0s 59us/step - loss: 0.2870 - precision: 0.9141 - recall: 0.7833 - f1_score: 0.8433 - val_loss: 0.4972 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1682/3000\n",
            "300/300 [==============================] - 0s 59us/step - loss: 0.2860 - precision: 0.9073 - recall: 0.7900 - f1_score: 0.8442 - val_loss: 0.4968 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1683/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2888 - precision: 0.9060 - recall: 0.8033 - f1_score: 0.8514 - val_loss: 0.4969 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1684/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.2895 - precision: 0.9035 - recall: 0.7800 - f1_score: 0.8371 - val_loss: 0.4969 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 1685/3000\n",
            "300/300 [==============================] - 0s 58us/step - loss: 0.2867 - precision: 0.9148 - recall: 0.7933 - f1_score: 0.8493 - val_loss: 0.4970 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 1686/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2891 - precision: 0.9168 - recall: 0.8000 - f1_score: 0.8540 - val_loss: 0.4972 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 1687/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2857 - precision: 0.9161 - recall: 0.7933 - f1_score: 0.8500 - val_loss: 0.4976 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 1688/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2912 - precision: 0.8972 - recall: 0.7567 - f1_score: 0.8199 - val_loss: 0.4986 - val_precision: 0.5833 - val_recall: 0.4667 - val_f1_score: 0.5185\n",
            "Epoch 1689/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2849 - precision: 0.9299 - recall: 0.8000 - f1_score: 0.8598 - val_loss: 0.4977 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 1690/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2864 - precision: 0.9115 - recall: 0.7967 - f1_score: 0.8500 - val_loss: 0.4972 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1691/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2848 - precision: 0.9126 - recall: 0.8033 - f1_score: 0.8544 - val_loss: 0.4993 - val_precision: 0.5745 - val_recall: 0.4500 - val_f1_score: 0.5047\n",
            "Epoch 1692/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2860 - precision: 0.9026 - recall: 0.8000 - f1_score: 0.8480 - val_loss: 0.4971 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 1693/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2838 - precision: 0.9006 - recall: 0.8133 - f1_score: 0.8546 - val_loss: 0.4990 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1694/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.2856 - precision: 0.9169 - recall: 0.8167 - f1_score: 0.8635 - val_loss: 0.5039 - val_precision: 0.5870 - val_recall: 0.4500 - val_f1_score: 0.5094\n",
            "Epoch 1695/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2863 - precision: 0.9108 - recall: 0.7867 - f1_score: 0.8436 - val_loss: 0.4980 - val_precision: 0.5957 - val_recall: 0.4667 - val_f1_score: 0.5234\n",
            "Epoch 1696/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.2834 - precision: 0.9118 - recall: 0.7933 - f1_score: 0.8477 - val_loss: 0.4976 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1697/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.2847 - precision: 0.9077 - recall: 0.8033 - f1_score: 0.8518 - val_loss: 0.4980 - val_precision: 0.6279 - val_recall: 0.4500 - val_f1_score: 0.5243\n",
            "Epoch 1698/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2871 - precision: 0.9049 - recall: 0.7900 - f1_score: 0.8434 - val_loss: 0.5030 - val_precision: 0.5870 - val_recall: 0.4500 - val_f1_score: 0.5094\n",
            "Epoch 1699/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2856 - precision: 0.9120 - recall: 0.7933 - f1_score: 0.8478 - val_loss: 0.5018 - val_precision: 0.5778 - val_recall: 0.4333 - val_f1_score: 0.4952\n",
            "Epoch 1700/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2850 - precision: 0.9305 - recall: 0.8033 - f1_score: 0.8616 - val_loss: 0.5015 - val_precision: 0.5714 - val_recall: 0.4667 - val_f1_score: 0.5138\n",
            "Epoch 1701/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2852 - precision: 0.9301 - recall: 0.8000 - f1_score: 0.8597 - val_loss: 0.5029 - val_precision: 0.5870 - val_recall: 0.4500 - val_f1_score: 0.5094\n",
            "Epoch 1702/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.2839 - precision: 0.9100 - recall: 0.8100 - f1_score: 0.8567 - val_loss: 0.4982 - val_precision: 0.6279 - val_recall: 0.4500 - val_f1_score: 0.5243\n",
            "Epoch 1703/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2828 - precision: 0.8977 - recall: 0.7867 - f1_score: 0.8385 - val_loss: 0.5192 - val_precision: 0.5849 - val_recall: 0.5167 - val_f1_score: 0.5487\n",
            "Epoch 1704/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2942 - precision: 0.9069 - recall: 0.7800 - f1_score: 0.8383 - val_loss: 0.4973 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 1705/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2838 - precision: 0.9218 - recall: 0.8133 - f1_score: 0.8634 - val_loss: 0.4977 - val_precision: 0.5745 - val_recall: 0.4500 - val_f1_score: 0.5047\n",
            "Epoch 1706/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.2854 - precision: 0.9162 - recall: 0.8033 - f1_score: 0.8559 - val_loss: 0.4976 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 1707/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.2930 - precision: 0.8903 - recall: 0.7800 - f1_score: 0.8314 - val_loss: 0.4975 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1708/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.2830 - precision: 0.9181 - recall: 0.7867 - f1_score: 0.8462 - val_loss: 0.4985 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1709/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.2850 - precision: 0.9021 - recall: 0.7900 - f1_score: 0.8414 - val_loss: 0.5010 - val_precision: 0.5625 - val_recall: 0.4500 - val_f1_score: 0.5000\n",
            "Epoch 1710/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2875 - precision: 0.9066 - recall: 0.7933 - f1_score: 0.8453 - val_loss: 0.5024 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 1711/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2874 - precision: 0.9055 - recall: 0.7833 - f1_score: 0.8396 - val_loss: 0.4980 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 1712/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2828 - precision: 0.9268 - recall: 0.8067 - f1_score: 0.8624 - val_loss: 0.4976 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1713/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.2830 - precision: 0.9177 - recall: 0.8167 - f1_score: 0.8640 - val_loss: 0.5063 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1714/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2829 - precision: 0.9112 - recall: 0.8133 - f1_score: 0.8593 - val_loss: 0.4995 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 1715/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.2850 - precision: 0.9012 - recall: 0.7867 - f1_score: 0.8396 - val_loss: 0.4996 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1716/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2865 - precision: 0.8912 - recall: 0.7800 - f1_score: 0.8316 - val_loss: 0.4984 - val_precision: 0.5870 - val_recall: 0.4500 - val_f1_score: 0.5094\n",
            "Epoch 1717/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2837 - precision: 0.8958 - recall: 0.8033 - f1_score: 0.8468 - val_loss: 0.4978 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 1718/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2851 - precision: 0.9101 - recall: 0.7833 - f1_score: 0.8414 - val_loss: 0.5012 - val_precision: 0.5745 - val_recall: 0.4500 - val_f1_score: 0.5047\n",
            "Epoch 1719/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2834 - precision: 0.9151 - recall: 0.7933 - f1_score: 0.8490 - val_loss: 0.4978 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 1720/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.2849 - precision: 0.9052 - recall: 0.7933 - f1_score: 0.8455 - val_loss: 0.4983 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 1721/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.2836 - precision: 0.9164 - recall: 0.8033 - f1_score: 0.8556 - val_loss: 0.4979 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 1722/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2857 - precision: 0.9026 - recall: 0.7833 - f1_score: 0.8386 - val_loss: 0.4986 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 1723/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2883 - precision: 0.8984 - recall: 0.7967 - f1_score: 0.8443 - val_loss: 0.5046 - val_precision: 0.5870 - val_recall: 0.4500 - val_f1_score: 0.5094\n",
            "Epoch 1724/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2910 - precision: 0.8898 - recall: 0.7900 - f1_score: 0.8366 - val_loss: 0.5029 - val_precision: 0.5625 - val_recall: 0.4500 - val_f1_score: 0.5000\n",
            "Epoch 1725/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2845 - precision: 0.9051 - recall: 0.7900 - f1_score: 0.8432 - val_loss: 0.5045 - val_precision: 0.6304 - val_recall: 0.4833 - val_f1_score: 0.5472\n",
            "Epoch 1726/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2846 - precision: 0.8819 - recall: 0.7800 - f1_score: 0.8275 - val_loss: 0.4998 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 1727/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2841 - precision: 0.9170 - recall: 0.8100 - f1_score: 0.8599 - val_loss: 0.5123 - val_precision: 0.5714 - val_recall: 0.4667 - val_f1_score: 0.5138\n",
            "Epoch 1728/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2888 - precision: 0.8995 - recall: 0.7900 - f1_score: 0.8407 - val_loss: 0.5080 - val_precision: 0.5577 - val_recall: 0.4833 - val_f1_score: 0.5179\n",
            "Epoch 1729/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2840 - precision: 0.9087 - recall: 0.8067 - f1_score: 0.8545 - val_loss: 0.4982 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1730/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2833 - precision: 0.8947 - recall: 0.8000 - f1_score: 0.8441 - val_loss: 0.5010 - val_precision: 0.5625 - val_recall: 0.4500 - val_f1_score: 0.5000\n",
            "Epoch 1731/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2879 - precision: 0.8879 - recall: 0.7933 - f1_score: 0.8379 - val_loss: 0.5009 - val_precision: 0.5745 - val_recall: 0.4500 - val_f1_score: 0.5047\n",
            "Epoch 1732/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2825 - precision: 0.9198 - recall: 0.8000 - f1_score: 0.8555 - val_loss: 0.4995 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1733/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2877 - precision: 0.8995 - recall: 0.7833 - f1_score: 0.8371 - val_loss: 0.5006 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1734/3000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.2847 - precision: 0.9006 - recall: 0.7900 - f1_score: 0.8410 - val_loss: 0.4989 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 1735/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.2847 - precision: 0.9005 - recall: 0.7867 - f1_score: 0.8395 - val_loss: 0.4988 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 1736/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2836 - precision: 0.9053 - recall: 0.8100 - f1_score: 0.8542 - val_loss: 0.4996 - val_precision: 0.5957 - val_recall: 0.4667 - val_f1_score: 0.5234\n",
            "Epoch 1737/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.2842 - precision: 0.9082 - recall: 0.8000 - f1_score: 0.8490 - val_loss: 0.4985 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 1738/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2829 - precision: 0.9135 - recall: 0.8000 - f1_score: 0.8520 - val_loss: 0.5005 - val_precision: 0.5745 - val_recall: 0.4500 - val_f1_score: 0.5047\n",
            "Epoch 1739/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2854 - precision: 0.9013 - recall: 0.7733 - f1_score: 0.8316 - val_loss: 0.5021 - val_precision: 0.5625 - val_recall: 0.4500 - val_f1_score: 0.5000\n",
            "Epoch 1740/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2848 - precision: 0.9035 - recall: 0.8000 - f1_score: 0.8481 - val_loss: 0.4986 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1741/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2841 - precision: 0.9238 - recall: 0.8133 - f1_score: 0.8645 - val_loss: 0.5000 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 1742/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2818 - precision: 0.9127 - recall: 0.8067 - f1_score: 0.8561 - val_loss: 0.5008 - val_precision: 0.5714 - val_recall: 0.4667 - val_f1_score: 0.5138\n",
            "Epoch 1743/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2815 - precision: 0.9166 - recall: 0.8033 - f1_score: 0.8560 - val_loss: 0.4988 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1744/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2815 - precision: 0.9197 - recall: 0.8100 - f1_score: 0.8608 - val_loss: 0.4994 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 1745/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2816 - precision: 0.9192 - recall: 0.8033 - f1_score: 0.8572 - val_loss: 0.5000 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1746/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2820 - precision: 0.9043 - recall: 0.7867 - f1_score: 0.8411 - val_loss: 0.4988 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 1747/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2843 - precision: 0.9055 - recall: 0.8033 - f1_score: 0.8512 - val_loss: 0.5097 - val_precision: 0.5957 - val_recall: 0.4667 - val_f1_score: 0.5234\n",
            "Epoch 1748/3000\n",
            "300/300 [==============================] - 0s 58us/step - loss: 0.2843 - precision: 0.8953 - recall: 0.7967 - f1_score: 0.8428 - val_loss: 0.4997 - val_precision: 0.6042 - val_recall: 0.4833 - val_f1_score: 0.5370\n",
            "Epoch 1749/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2821 - precision: 0.9186 - recall: 0.7833 - f1_score: 0.8452 - val_loss: 0.4996 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 1750/3000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.2809 - precision: 0.9137 - recall: 0.8033 - f1_score: 0.8542 - val_loss: 0.5031 - val_precision: 0.5714 - val_recall: 0.4667 - val_f1_score: 0.5138\n",
            "Epoch 1751/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2851 - precision: 0.8995 - recall: 0.8100 - f1_score: 0.8524 - val_loss: 0.4992 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1752/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2815 - precision: 0.9071 - recall: 0.8133 - f1_score: 0.8574 - val_loss: 0.5026 - val_precision: 0.5625 - val_recall: 0.4500 - val_f1_score: 0.5000\n",
            "Epoch 1753/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2837 - precision: 0.9047 - recall: 0.7967 - f1_score: 0.8471 - val_loss: 0.5002 - val_precision: 0.6042 - val_recall: 0.4833 - val_f1_score: 0.5370\n",
            "Epoch 1754/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2813 - precision: 0.9099 - recall: 0.7933 - f1_score: 0.8474 - val_loss: 0.5073 - val_precision: 0.5957 - val_recall: 0.4667 - val_f1_score: 0.5234\n",
            "Epoch 1755/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2852 - precision: 0.8958 - recall: 0.7767 - f1_score: 0.8303 - val_loss: 0.4998 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 1756/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2810 - precision: 0.9209 - recall: 0.8133 - f1_score: 0.8634 - val_loss: 0.4995 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1757/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2828 - precision: 0.9125 - recall: 0.8000 - f1_score: 0.8519 - val_loss: 0.5011 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1758/3000\n",
            "300/300 [==============================] - 0s 80us/step - loss: 0.2854 - precision: 0.9114 - recall: 0.7933 - f1_score: 0.8478 - val_loss: 0.5015 - val_precision: 0.5625 - val_recall: 0.4500 - val_f1_score: 0.5000\n",
            "Epoch 1759/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2820 - precision: 0.9199 - recall: 0.8100 - f1_score: 0.8614 - val_loss: 0.5002 - val_precision: 0.5957 - val_recall: 0.4667 - val_f1_score: 0.5234\n",
            "Epoch 1760/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.2821 - precision: 0.9228 - recall: 0.8000 - f1_score: 0.8565 - val_loss: 0.5005 - val_precision: 0.5833 - val_recall: 0.4667 - val_f1_score: 0.5185\n",
            "Epoch 1761/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2828 - precision: 0.9110 - recall: 0.7967 - f1_score: 0.8493 - val_loss: 0.5034 - val_precision: 0.6591 - val_recall: 0.4833 - val_f1_score: 0.5577\n",
            "Epoch 1762/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2831 - precision: 0.9022 - recall: 0.8000 - f1_score: 0.8478 - val_loss: 0.5020 - val_precision: 0.5833 - val_recall: 0.4667 - val_f1_score: 0.5185\n",
            "Epoch 1763/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.2839 - precision: 0.8972 - recall: 0.7900 - f1_score: 0.8396 - val_loss: 0.5001 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 1764/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2850 - precision: 0.9024 - recall: 0.8133 - f1_score: 0.8552 - val_loss: 0.5031 - val_precision: 0.5745 - val_recall: 0.4500 - val_f1_score: 0.5047\n",
            "Epoch 1765/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.2804 - precision: 0.9148 - recall: 0.8267 - f1_score: 0.8680 - val_loss: 0.5000 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 1766/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2831 - precision: 0.9149 - recall: 0.7900 - f1_score: 0.8473 - val_loss: 0.4997 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 1767/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.2798 - precision: 0.9330 - recall: 0.8233 - f1_score: 0.8746 - val_loss: 0.5005 - val_precision: 0.6042 - val_recall: 0.4833 - val_f1_score: 0.5370\n",
            "Epoch 1768/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2803 - precision: 0.9128 - recall: 0.8100 - f1_score: 0.8579 - val_loss: 0.5008 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1769/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.2840 - precision: 0.9069 - recall: 0.7800 - f1_score: 0.8384 - val_loss: 0.5022 - val_precision: 0.5532 - val_recall: 0.4333 - val_f1_score: 0.4860\n",
            "Epoch 1770/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2815 - precision: 0.9142 - recall: 0.8133 - f1_score: 0.8606 - val_loss: 0.4997 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1771/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2808 - precision: 0.9146 - recall: 0.8200 - f1_score: 0.8647 - val_loss: 0.5033 - val_precision: 0.5714 - val_recall: 0.4667 - val_f1_score: 0.5138\n",
            "Epoch 1772/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.2817 - precision: 0.9067 - recall: 0.8100 - f1_score: 0.8555 - val_loss: 0.5034 - val_precision: 0.5714 - val_recall: 0.4667 - val_f1_score: 0.5138\n",
            "Epoch 1773/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2794 - precision: 0.9247 - recall: 0.8000 - f1_score: 0.8567 - val_loss: 0.5016 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 1774/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2796 - precision: 0.9299 - recall: 0.8033 - f1_score: 0.8618 - val_loss: 0.5005 - val_precision: 0.5957 - val_recall: 0.4667 - val_f1_score: 0.5234\n",
            "Epoch 1775/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2804 - precision: 0.9197 - recall: 0.8033 - f1_score: 0.8570 - val_loss: 0.5047 - val_precision: 0.5714 - val_recall: 0.4667 - val_f1_score: 0.5138\n",
            "Epoch 1776/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.2849 - precision: 0.9178 - recall: 0.8067 - f1_score: 0.8581 - val_loss: 0.5014 - val_precision: 0.5957 - val_recall: 0.4667 - val_f1_score: 0.5234\n",
            "Epoch 1777/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2828 - precision: 0.9155 - recall: 0.8133 - f1_score: 0.8606 - val_loss: 0.5006 - val_precision: 0.6279 - val_recall: 0.4500 - val_f1_score: 0.5243\n",
            "Epoch 1778/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2820 - precision: 0.9147 - recall: 0.8233 - f1_score: 0.8664 - val_loss: 0.5001 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 1779/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2802 - precision: 0.9178 - recall: 0.8067 - f1_score: 0.8581 - val_loss: 0.4998 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 1780/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.2858 - precision: 0.9040 - recall: 0.7867 - f1_score: 0.8409 - val_loss: 0.5060 - val_precision: 0.5870 - val_recall: 0.4500 - val_f1_score: 0.5094\n",
            "Epoch 1781/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.2808 - precision: 0.9121 - recall: 0.8000 - f1_score: 0.8520 - val_loss: 0.5012 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 1782/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2816 - precision: 0.9160 - recall: 0.8000 - f1_score: 0.8536 - val_loss: 0.5054 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 1783/3000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.2812 - precision: 0.9177 - recall: 0.8100 - f1_score: 0.8604 - val_loss: 0.5005 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 1784/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.2787 - precision: 0.9233 - recall: 0.8100 - f1_score: 0.8628 - val_loss: 0.5021 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1785/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2812 - precision: 0.8994 - recall: 0.8033 - f1_score: 0.8486 - val_loss: 0.5004 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1786/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2853 - precision: 0.9086 - recall: 0.8033 - f1_score: 0.8522 - val_loss: 0.5022 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 1787/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2793 - precision: 0.9351 - recall: 0.8100 - f1_score: 0.8675 - val_loss: 0.5006 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1788/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2798 - precision: 0.9176 - recall: 0.8167 - f1_score: 0.8640 - val_loss: 0.5003 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 1789/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2798 - precision: 0.9208 - recall: 0.8133 - f1_score: 0.8633 - val_loss: 0.5049 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 1790/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2809 - precision: 0.9218 - recall: 0.8067 - f1_score: 0.8596 - val_loss: 0.5012 - val_precision: 0.5957 - val_recall: 0.4667 - val_f1_score: 0.5234\n",
            "Epoch 1791/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2803 - precision: 0.9060 - recall: 0.8033 - f1_score: 0.8515 - val_loss: 0.5027 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1792/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2797 - precision: 0.9318 - recall: 0.8167 - f1_score: 0.8692 - val_loss: 0.5020 - val_precision: 0.6042 - val_recall: 0.4833 - val_f1_score: 0.5370\n",
            "Epoch 1793/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2796 - precision: 0.9103 - recall: 0.8133 - f1_score: 0.8587 - val_loss: 0.5061 - val_precision: 0.5957 - val_recall: 0.4667 - val_f1_score: 0.5234\n",
            "Epoch 1794/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2797 - precision: 0.9224 - recall: 0.7933 - f1_score: 0.8518 - val_loss: 0.5017 - val_precision: 0.6279 - val_recall: 0.4500 - val_f1_score: 0.5243\n",
            "Epoch 1795/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2826 - precision: 0.8959 - recall: 0.7800 - f1_score: 0.8338 - val_loss: 0.5076 - val_precision: 0.5745 - val_recall: 0.4500 - val_f1_score: 0.5047\n",
            "Epoch 1796/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2800 - precision: 0.9241 - recall: 0.8167 - f1_score: 0.8664 - val_loss: 0.5018 - val_precision: 0.6042 - val_recall: 0.4833 - val_f1_score: 0.5370\n",
            "Epoch 1797/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2805 - precision: 0.9082 - recall: 0.7967 - f1_score: 0.8484 - val_loss: 0.5015 - val_precision: 0.6042 - val_recall: 0.4833 - val_f1_score: 0.5370\n",
            "Epoch 1798/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2787 - precision: 0.9206 - recall: 0.8133 - f1_score: 0.8635 - val_loss: 0.5022 - val_precision: 0.5957 - val_recall: 0.4667 - val_f1_score: 0.5234\n",
            "Epoch 1799/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2785 - precision: 0.9153 - recall: 0.8133 - f1_score: 0.8606 - val_loss: 0.5013 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 1800/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2812 - precision: 0.9175 - recall: 0.8067 - f1_score: 0.8575 - val_loss: 0.5012 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 1801/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2795 - precision: 0.9095 - recall: 0.8033 - f1_score: 0.8530 - val_loss: 0.5010 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1802/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2792 - precision: 0.9206 - recall: 0.8167 - f1_score: 0.8651 - val_loss: 0.5010 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 1803/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2791 - precision: 0.9153 - recall: 0.8067 - f1_score: 0.8571 - val_loss: 0.5032 - val_precision: 0.5745 - val_recall: 0.4500 - val_f1_score: 0.5047\n",
            "Epoch 1804/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2808 - precision: 0.9253 - recall: 0.8233 - f1_score: 0.8713 - val_loss: 0.5055 - val_precision: 0.5532 - val_recall: 0.4333 - val_f1_score: 0.4860\n",
            "Epoch 1805/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2792 - precision: 0.9166 - recall: 0.8067 - f1_score: 0.8581 - val_loss: 0.5025 - val_precision: 0.5833 - val_recall: 0.4667 - val_f1_score: 0.5185\n",
            "Epoch 1806/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2787 - precision: 0.9174 - recall: 0.8133 - f1_score: 0.8621 - val_loss: 0.5027 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1807/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2771 - precision: 0.9196 - recall: 0.8033 - f1_score: 0.8574 - val_loss: 0.5054 - val_precision: 0.5714 - val_recall: 0.4667 - val_f1_score: 0.5138\n",
            "Epoch 1808/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2807 - precision: 0.9137 - recall: 0.8067 - f1_score: 0.8562 - val_loss: 0.5223 - val_precision: 0.5849 - val_recall: 0.5167 - val_f1_score: 0.5487\n",
            "Epoch 1809/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2837 - precision: 0.9115 - recall: 0.7800 - f1_score: 0.8404 - val_loss: 0.5017 - val_precision: 0.5957 - val_recall: 0.4667 - val_f1_score: 0.5234\n",
            "Epoch 1810/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.2785 - precision: 0.9139 - recall: 0.8100 - f1_score: 0.8580 - val_loss: 0.5023 - val_precision: 0.6042 - val_recall: 0.4833 - val_f1_score: 0.5370\n",
            "Epoch 1811/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2780 - precision: 0.9283 - recall: 0.8133 - f1_score: 0.8665 - val_loss: 0.5044 - val_precision: 0.5625 - val_recall: 0.4500 - val_f1_score: 0.5000\n",
            "Epoch 1812/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2783 - precision: 0.9268 - recall: 0.8133 - f1_score: 0.8660 - val_loss: 0.5012 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 1813/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2780 - precision: 0.9094 - recall: 0.8133 - f1_score: 0.8584 - val_loss: 0.5015 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1814/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2794 - precision: 0.8965 - recall: 0.8067 - f1_score: 0.8490 - val_loss: 0.5012 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1815/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2786 - precision: 0.9093 - recall: 0.8267 - f1_score: 0.8656 - val_loss: 0.5013 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 1816/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2784 - precision: 0.9236 - recall: 0.8133 - f1_score: 0.8647 - val_loss: 0.5022 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 1817/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2794 - precision: 0.9234 - recall: 0.8000 - f1_score: 0.8572 - val_loss: 0.5011 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 1818/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2780 - precision: 0.9279 - recall: 0.8200 - f1_score: 0.8706 - val_loss: 0.5086 - val_precision: 0.5745 - val_recall: 0.4500 - val_f1_score: 0.5047\n",
            "Epoch 1819/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2794 - precision: 0.9086 - recall: 0.7967 - f1_score: 0.8488 - val_loss: 0.5043 - val_precision: 0.5625 - val_recall: 0.4500 - val_f1_score: 0.5000\n",
            "Epoch 1820/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2813 - precision: 0.9164 - recall: 0.8000 - f1_score: 0.8541 - val_loss: 0.5014 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 1821/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2810 - precision: 0.9058 - recall: 0.8000 - f1_score: 0.8492 - val_loss: 0.5018 - val_precision: 0.5870 - val_recall: 0.4500 - val_f1_score: 0.5094\n",
            "Epoch 1822/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.2785 - precision: 0.9162 - recall: 0.8033 - f1_score: 0.8559 - val_loss: 0.5143 - val_precision: 0.5600 - val_recall: 0.4667 - val_f1_score: 0.5091\n",
            "Epoch 1823/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.2905 - precision: 0.8768 - recall: 0.7633 - f1_score: 0.8158 - val_loss: 0.5018 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1824/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.2770 - precision: 0.9388 - recall: 0.8200 - f1_score: 0.8754 - val_loss: 0.5017 - val_precision: 0.6279 - val_recall: 0.4500 - val_f1_score: 0.5243\n",
            "Epoch 1825/3000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.2800 - precision: 0.9127 - recall: 0.7967 - f1_score: 0.8505 - val_loss: 0.5014 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1826/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2767 - precision: 0.9360 - recall: 0.8067 - f1_score: 0.8656 - val_loss: 0.5040 - val_precision: 0.5532 - val_recall: 0.4333 - val_f1_score: 0.4860\n",
            "Epoch 1827/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2817 - precision: 0.8954 - recall: 0.8033 - f1_score: 0.8468 - val_loss: 0.5025 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 1828/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2800 - precision: 0.9008 - recall: 0.7867 - f1_score: 0.8398 - val_loss: 0.5028 - val_precision: 0.6042 - val_recall: 0.4833 - val_f1_score: 0.5370\n",
            "Epoch 1829/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2797 - precision: 0.9044 - recall: 0.8033 - f1_score: 0.8503 - val_loss: 0.5019 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 1830/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2790 - precision: 0.9175 - recall: 0.8233 - f1_score: 0.8677 - val_loss: 0.5015 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 1831/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2773 - precision: 0.9214 - recall: 0.8167 - f1_score: 0.8658 - val_loss: 0.5015 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 1832/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2773 - precision: 0.9066 - recall: 0.8067 - f1_score: 0.8533 - val_loss: 0.5017 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 1833/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2766 - precision: 0.9355 - recall: 0.8267 - f1_score: 0.8775 - val_loss: 0.5020 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1834/3000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.2766 - precision: 0.9198 - recall: 0.8033 - f1_score: 0.8576 - val_loss: 0.5022 - val_precision: 0.5957 - val_recall: 0.4667 - val_f1_score: 0.5234\n",
            "Epoch 1835/3000\n",
            "300/300 [==============================] - 0s 118us/step - loss: 0.2766 - precision: 0.9234 - recall: 0.8067 - f1_score: 0.8610 - val_loss: 0.5101 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 1836/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2784 - precision: 0.9212 - recall: 0.8167 - f1_score: 0.8651 - val_loss: 0.5029 - val_precision: 0.6042 - val_recall: 0.4833 - val_f1_score: 0.5370\n",
            "Epoch 1837/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2784 - precision: 0.9283 - recall: 0.8167 - f1_score: 0.8688 - val_loss: 0.5023 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 1838/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2774 - precision: 0.9256 - recall: 0.8067 - f1_score: 0.8618 - val_loss: 0.5016 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 1839/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2769 - precision: 0.9356 - recall: 0.8233 - f1_score: 0.8757 - val_loss: 0.5074 - val_precision: 0.5833 - val_recall: 0.4667 - val_f1_score: 0.5185\n",
            "Epoch 1840/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2795 - precision: 0.9059 - recall: 0.8067 - f1_score: 0.8532 - val_loss: 0.5018 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 1841/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2788 - precision: 0.9212 - recall: 0.8133 - f1_score: 0.8634 - val_loss: 0.5018 - val_precision: 0.6279 - val_recall: 0.4500 - val_f1_score: 0.5243\n",
            "Epoch 1842/3000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.2770 - precision: 0.9175 - recall: 0.8067 - f1_score: 0.8584 - val_loss: 0.5026 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 1843/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2760 - precision: 0.9140 - recall: 0.8167 - f1_score: 0.8622 - val_loss: 0.5036 - val_precision: 0.5957 - val_recall: 0.4667 - val_f1_score: 0.5234\n",
            "Epoch 1844/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2767 - precision: 0.9252 - recall: 0.8133 - f1_score: 0.8655 - val_loss: 0.5019 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 1845/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2772 - precision: 0.9342 - recall: 0.8200 - f1_score: 0.8728 - val_loss: 0.5026 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 1846/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2771 - precision: 0.9277 - recall: 0.8000 - f1_score: 0.8588 - val_loss: 0.5067 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 1847/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2768 - precision: 0.9090 - recall: 0.7967 - f1_score: 0.8487 - val_loss: 0.5070 - val_precision: 0.5625 - val_recall: 0.4500 - val_f1_score: 0.5000\n",
            "Epoch 1848/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2793 - precision: 0.9039 - recall: 0.7833 - f1_score: 0.8392 - val_loss: 0.5028 - val_precision: 0.5957 - val_recall: 0.4667 - val_f1_score: 0.5234\n",
            "Epoch 1849/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2753 - precision: 0.9283 - recall: 0.8200 - f1_score: 0.8705 - val_loss: 0.5027 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 1850/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2783 - precision: 0.9175 - recall: 0.8100 - f1_score: 0.8594 - val_loss: 0.5024 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1851/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2766 - precision: 0.9090 - recall: 0.7967 - f1_score: 0.8490 - val_loss: 0.5052 - val_precision: 0.5625 - val_recall: 0.4500 - val_f1_score: 0.5000\n",
            "Epoch 1852/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2768 - precision: 0.9233 - recall: 0.8133 - f1_score: 0.8646 - val_loss: 0.5030 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 1853/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2750 - precision: 0.9281 - recall: 0.8200 - f1_score: 0.8706 - val_loss: 0.5025 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1854/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2771 - precision: 0.9047 - recall: 0.8267 - f1_score: 0.8638 - val_loss: 0.5022 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 1855/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2774 - precision: 0.9257 - recall: 0.8100 - f1_score: 0.8635 - val_loss: 0.5043 - val_precision: 0.5714 - val_recall: 0.4667 - val_f1_score: 0.5138\n",
            "Epoch 1856/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2786 - precision: 0.9199 - recall: 0.8100 - f1_score: 0.8610 - val_loss: 0.5061 - val_precision: 0.5714 - val_recall: 0.4667 - val_f1_score: 0.5138\n",
            "Epoch 1857/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2763 - precision: 0.9127 - recall: 0.8000 - f1_score: 0.8520 - val_loss: 0.5043 - val_precision: 0.5833 - val_recall: 0.4667 - val_f1_score: 0.5185\n",
            "Epoch 1858/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2762 - precision: 0.9254 - recall: 0.8167 - f1_score: 0.8665 - val_loss: 0.5024 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 1859/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2753 - precision: 0.9210 - recall: 0.8167 - f1_score: 0.8655 - val_loss: 0.5023 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 1860/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2749 - precision: 0.9249 - recall: 0.8167 - f1_score: 0.8670 - val_loss: 0.5024 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 1861/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.2759 - precision: 0.9040 - recall: 0.8167 - f1_score: 0.8580 - val_loss: 0.5065 - val_precision: 0.5625 - val_recall: 0.4500 - val_f1_score: 0.5000\n",
            "Epoch 1862/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2788 - precision: 0.9100 - recall: 0.7867 - f1_score: 0.8436 - val_loss: 0.5027 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1863/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2751 - precision: 0.9269 - recall: 0.8267 - f1_score: 0.8731 - val_loss: 0.5063 - val_precision: 0.5625 - val_recall: 0.4500 - val_f1_score: 0.5000\n",
            "Epoch 1864/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2748 - precision: 0.9330 - recall: 0.8267 - f1_score: 0.8764 - val_loss: 0.5031 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 1865/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2769 - precision: 0.9228 - recall: 0.8067 - f1_score: 0.8605 - val_loss: 0.5046 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1866/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2780 - precision: 0.9040 - recall: 0.7867 - f1_score: 0.8411 - val_loss: 0.5037 - val_precision: 0.5957 - val_recall: 0.4667 - val_f1_score: 0.5234\n",
            "Epoch 1867/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2748 - precision: 0.9253 - recall: 0.8167 - f1_score: 0.8673 - val_loss: 0.5027 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1868/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2754 - precision: 0.9256 - recall: 0.8233 - f1_score: 0.8706 - val_loss: 0.5037 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1869/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2779 - precision: 0.9072 - recall: 0.8100 - f1_score: 0.8555 - val_loss: 0.5031 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 1870/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2742 - precision: 0.9243 - recall: 0.8133 - f1_score: 0.8645 - val_loss: 0.5084 - val_precision: 0.6304 - val_recall: 0.4833 - val_f1_score: 0.5472\n",
            "Epoch 1871/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2776 - precision: 0.9197 - recall: 0.8000 - f1_score: 0.8556 - val_loss: 0.5033 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 1872/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2764 - precision: 0.9003 - recall: 0.8100 - f1_score: 0.8526 - val_loss: 0.5038 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 1873/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2775 - precision: 0.9105 - recall: 0.7900 - f1_score: 0.8447 - val_loss: 0.5099 - val_precision: 0.5745 - val_recall: 0.4500 - val_f1_score: 0.5047\n",
            "Epoch 1874/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.2767 - precision: 0.9121 - recall: 0.8033 - f1_score: 0.8533 - val_loss: 0.5060 - val_precision: 0.5745 - val_recall: 0.4500 - val_f1_score: 0.5047\n",
            "Epoch 1875/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2786 - precision: 0.9175 - recall: 0.8167 - f1_score: 0.8639 - val_loss: 0.5056 - val_precision: 0.5532 - val_recall: 0.4333 - val_f1_score: 0.4860\n",
            "Epoch 1876/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2751 - precision: 0.9184 - recall: 0.8267 - f1_score: 0.8700 - val_loss: 0.5034 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 1877/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.2744 - precision: 0.9221 - recall: 0.8200 - f1_score: 0.8678 - val_loss: 0.5027 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 1878/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2792 - precision: 0.9126 - recall: 0.8000 - f1_score: 0.8520 - val_loss: 0.5047 - val_precision: 0.6279 - val_recall: 0.4500 - val_f1_score: 0.5243\n",
            "Epoch 1879/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2799 - precision: 0.9011 - recall: 0.7900 - f1_score: 0.8410 - val_loss: 0.5028 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1880/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2768 - precision: 0.9103 - recall: 0.8200 - f1_score: 0.8625 - val_loss: 0.5032 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1881/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2806 - precision: 0.9186 - recall: 0.7967 - f1_score: 0.8532 - val_loss: 0.5042 - val_precision: 0.6279 - val_recall: 0.4500 - val_f1_score: 0.5243\n",
            "Epoch 1882/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2774 - precision: 0.9146 - recall: 0.8033 - f1_score: 0.8551 - val_loss: 0.5028 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 1883/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2738 - precision: 0.9332 - recall: 0.8300 - f1_score: 0.8781 - val_loss: 0.5042 - val_precision: 0.6042 - val_recall: 0.4833 - val_f1_score: 0.5370\n",
            "Epoch 1884/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2796 - precision: 0.9165 - recall: 0.8133 - f1_score: 0.8615 - val_loss: 0.5046 - val_precision: 0.6279 - val_recall: 0.4500 - val_f1_score: 0.5243\n",
            "Epoch 1885/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2739 - precision: 0.9277 - recall: 0.8100 - f1_score: 0.8644 - val_loss: 0.5028 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 1886/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2764 - precision: 0.9301 - recall: 0.8067 - f1_score: 0.8634 - val_loss: 0.5049 - val_precision: 0.5957 - val_recall: 0.4667 - val_f1_score: 0.5234\n",
            "Epoch 1887/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2729 - precision: 0.9310 - recall: 0.8133 - f1_score: 0.8681 - val_loss: 0.5045 - val_precision: 0.6279 - val_recall: 0.4500 - val_f1_score: 0.5243\n",
            "Epoch 1888/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.2753 - precision: 0.9173 - recall: 0.8100 - f1_score: 0.8598 - val_loss: 0.5084 - val_precision: 0.5510 - val_recall: 0.4500 - val_f1_score: 0.4954\n",
            "Epoch 1889/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2771 - precision: 0.9139 - recall: 0.7967 - f1_score: 0.8508 - val_loss: 0.5096 - val_precision: 0.6122 - val_recall: 0.5000 - val_f1_score: 0.5505\n",
            "Epoch 1890/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2796 - precision: 0.9018 - recall: 0.7867 - f1_score: 0.8397 - val_loss: 0.5058 - val_precision: 0.5625 - val_recall: 0.4500 - val_f1_score: 0.5000\n",
            "Epoch 1891/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2764 - precision: 0.9101 - recall: 0.8067 - f1_score: 0.8551 - val_loss: 0.5185 - val_precision: 0.5714 - val_recall: 0.4667 - val_f1_score: 0.5138\n",
            "Epoch 1892/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2771 - precision: 0.8984 - recall: 0.8000 - f1_score: 0.8459 - val_loss: 0.5057 - val_precision: 0.5745 - val_recall: 0.4500 - val_f1_score: 0.5047\n",
            "Epoch 1893/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2768 - precision: 0.9073 - recall: 0.8167 - f1_score: 0.8595 - val_loss: 0.5118 - val_precision: 0.5870 - val_recall: 0.4500 - val_f1_score: 0.5094\n",
            "Epoch 1894/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2764 - precision: 0.9316 - recall: 0.8133 - f1_score: 0.8681 - val_loss: 0.5070 - val_precision: 0.5510 - val_recall: 0.4500 - val_f1_score: 0.4954\n",
            "Epoch 1895/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2744 - precision: 0.9347 - recall: 0.8233 - f1_score: 0.8750 - val_loss: 0.5091 - val_precision: 0.5714 - val_recall: 0.4667 - val_f1_score: 0.5138\n",
            "Epoch 1896/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2758 - precision: 0.9215 - recall: 0.8200 - f1_score: 0.8676 - val_loss: 0.5072 - val_precision: 0.5745 - val_recall: 0.4500 - val_f1_score: 0.5047\n",
            "Epoch 1897/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2738 - precision: 0.9287 - recall: 0.8167 - f1_score: 0.8688 - val_loss: 0.5049 - val_precision: 0.5833 - val_recall: 0.4667 - val_f1_score: 0.5185\n",
            "Epoch 1898/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2750 - precision: 0.9213 - recall: 0.8133 - f1_score: 0.8636 - val_loss: 0.5037 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1899/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2782 - precision: 0.9170 - recall: 0.8067 - f1_score: 0.8579 - val_loss: 0.5059 - val_precision: 0.5745 - val_recall: 0.4500 - val_f1_score: 0.5047\n",
            "Epoch 1900/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2777 - precision: 0.9090 - recall: 0.8033 - f1_score: 0.8526 - val_loss: 0.5037 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1901/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2738 - precision: 0.9227 - recall: 0.8333 - f1_score: 0.8757 - val_loss: 0.5065 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 1902/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2747 - precision: 0.9216 - recall: 0.8300 - f1_score: 0.8732 - val_loss: 0.5040 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1903/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2739 - precision: 0.9349 - recall: 0.8167 - f1_score: 0.8717 - val_loss: 0.5070 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 1904/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2737 - precision: 0.8991 - recall: 0.8000 - f1_score: 0.8465 - val_loss: 0.5090 - val_precision: 0.5510 - val_recall: 0.4500 - val_f1_score: 0.4954\n",
            "Epoch 1905/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2786 - precision: 0.8993 - recall: 0.8100 - f1_score: 0.8520 - val_loss: 0.5074 - val_precision: 0.5652 - val_recall: 0.4333 - val_f1_score: 0.4906\n",
            "Epoch 1906/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2788 - precision: 0.9084 - recall: 0.7967 - f1_score: 0.8487 - val_loss: 0.5052 - val_precision: 0.5833 - val_recall: 0.4667 - val_f1_score: 0.5185\n",
            "Epoch 1907/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2744 - precision: 0.9096 - recall: 0.8133 - f1_score: 0.8580 - val_loss: 0.5089 - val_precision: 0.5625 - val_recall: 0.4500 - val_f1_score: 0.5000\n",
            "Epoch 1908/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.2756 - precision: 0.9065 - recall: 0.8067 - f1_score: 0.8535 - val_loss: 0.5045 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 1909/3000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.2745 - precision: 0.9153 - recall: 0.8200 - f1_score: 0.8648 - val_loss: 0.5036 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 1910/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.2749 - precision: 0.9033 - recall: 0.8167 - f1_score: 0.8575 - val_loss: 0.5054 - val_precision: 0.5918 - val_recall: 0.4833 - val_f1_score: 0.5321\n",
            "Epoch 1911/3000\n",
            "300/300 [==============================] - 0s 81us/step - loss: 0.2773 - precision: 0.9145 - recall: 0.8167 - f1_score: 0.8623 - val_loss: 0.5045 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 1912/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2727 - precision: 0.9309 - recall: 0.8100 - f1_score: 0.8660 - val_loss: 0.5040 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1913/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2732 - precision: 0.9240 - recall: 0.8133 - f1_score: 0.8650 - val_loss: 0.5065 - val_precision: 0.5625 - val_recall: 0.4500 - val_f1_score: 0.5000\n",
            "Epoch 1914/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2736 - precision: 0.9286 - recall: 0.8267 - f1_score: 0.8746 - val_loss: 0.5045 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1915/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2744 - precision: 0.9118 - recall: 0.8133 - f1_score: 0.8591 - val_loss: 0.5066 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 1916/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2729 - precision: 0.9125 - recall: 0.8033 - f1_score: 0.8543 - val_loss: 0.5067 - val_precision: 0.5745 - val_recall: 0.4500 - val_f1_score: 0.5047\n",
            "Epoch 1917/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2728 - precision: 0.9225 - recall: 0.8333 - f1_score: 0.8754 - val_loss: 0.5063 - val_precision: 0.5625 - val_recall: 0.4500 - val_f1_score: 0.5000\n",
            "Epoch 1918/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2721 - precision: 0.9248 - recall: 0.8233 - f1_score: 0.8709 - val_loss: 0.5039 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1919/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.2776 - precision: 0.9013 - recall: 0.7900 - f1_score: 0.8414 - val_loss: 0.5065 - val_precision: 0.5625 - val_recall: 0.4500 - val_f1_score: 0.5000\n",
            "Epoch 1920/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.2725 - precision: 0.9110 - recall: 0.8133 - f1_score: 0.8592 - val_loss: 0.5065 - val_precision: 0.6042 - val_recall: 0.4833 - val_f1_score: 0.5370\n",
            "Epoch 1921/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2731 - precision: 0.9132 - recall: 0.8000 - f1_score: 0.8525 - val_loss: 0.5051 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 1922/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.2733 - precision: 0.9209 - recall: 0.8233 - f1_score: 0.8690 - val_loss: 0.5071 - val_precision: 0.5625 - val_recall: 0.4500 - val_f1_score: 0.5000\n",
            "Epoch 1923/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2726 - precision: 0.9078 - recall: 0.8233 - f1_score: 0.8632 - val_loss: 0.5038 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 1924/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2751 - precision: 0.9105 - recall: 0.8167 - f1_score: 0.8608 - val_loss: 0.5086 - val_precision: 0.5714 - val_recall: 0.4667 - val_f1_score: 0.5138\n",
            "Epoch 1925/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2722 - precision: 0.9259 - recall: 0.8233 - f1_score: 0.8712 - val_loss: 0.5068 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 1926/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2726 - precision: 0.9206 - recall: 0.8167 - f1_score: 0.8654 - val_loss: 0.5060 - val_precision: 0.5714 - val_recall: 0.4667 - val_f1_score: 0.5138\n",
            "Epoch 1927/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2760 - precision: 0.9098 - recall: 0.8033 - f1_score: 0.8531 - val_loss: 0.5055 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1928/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2719 - precision: 0.9025 - recall: 0.8033 - f1_score: 0.8500 - val_loss: 0.5048 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1929/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2739 - precision: 0.9202 - recall: 0.8133 - f1_score: 0.8630 - val_loss: 0.5081 - val_precision: 0.5510 - val_recall: 0.4500 - val_f1_score: 0.4954\n",
            "Epoch 1930/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2717 - precision: 0.9250 - recall: 0.8167 - f1_score: 0.8672 - val_loss: 0.5040 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 1931/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2730 - precision: 0.9214 - recall: 0.8167 - f1_score: 0.8657 - val_loss: 0.5062 - val_precision: 0.5714 - val_recall: 0.4667 - val_f1_score: 0.5138\n",
            "Epoch 1932/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2734 - precision: 0.9098 - recall: 0.8000 - f1_score: 0.8510 - val_loss: 0.5040 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 1933/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2736 - precision: 0.9235 - recall: 0.8367 - f1_score: 0.8777 - val_loss: 0.5077 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 1934/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2735 - precision: 0.9107 - recall: 0.8200 - f1_score: 0.8628 - val_loss: 0.5077 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 1935/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2782 - precision: 0.8867 - recall: 0.7833 - f1_score: 0.8315 - val_loss: 0.5057 - val_precision: 0.6304 - val_recall: 0.4833 - val_f1_score: 0.5472\n",
            "Epoch 1936/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2720 - precision: 0.9247 - recall: 0.8167 - f1_score: 0.8669 - val_loss: 0.5064 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1937/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2722 - precision: 0.8959 - recall: 0.8067 - f1_score: 0.8488 - val_loss: 0.5056 - val_precision: 0.6042 - val_recall: 0.4833 - val_f1_score: 0.5370\n",
            "Epoch 1938/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2723 - precision: 0.9217 - recall: 0.8233 - f1_score: 0.8696 - val_loss: 0.5050 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1939/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2716 - precision: 0.9106 - recall: 0.8200 - f1_score: 0.8624 - val_loss: 0.5050 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1940/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2740 - precision: 0.9162 - recall: 0.8033 - f1_score: 0.8556 - val_loss: 0.5056 - val_precision: 0.6042 - val_recall: 0.4833 - val_f1_score: 0.5370\n",
            "Epoch 1941/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2718 - precision: 0.9258 - recall: 0.8300 - f1_score: 0.8752 - val_loss: 0.5047 - val_precision: 0.6279 - val_recall: 0.4500 - val_f1_score: 0.5243\n",
            "Epoch 1942/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2714 - precision: 0.9232 - recall: 0.8067 - f1_score: 0.8603 - val_loss: 0.5077 - val_precision: 0.5625 - val_recall: 0.4500 - val_f1_score: 0.5000\n",
            "Epoch 1943/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2735 - precision: 0.9133 - recall: 0.8267 - f1_score: 0.8669 - val_loss: 0.5093 - val_precision: 0.5714 - val_recall: 0.4667 - val_f1_score: 0.5138\n",
            "Epoch 1944/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2722 - precision: 0.9173 - recall: 0.8133 - f1_score: 0.8620 - val_loss: 0.5053 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 1945/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2701 - precision: 0.9312 - recall: 0.8333 - f1_score: 0.8783 - val_loss: 0.5050 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1946/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2742 - precision: 0.9169 - recall: 0.8200 - f1_score: 0.8650 - val_loss: 0.5048 - val_precision: 0.6279 - val_recall: 0.4500 - val_f1_score: 0.5243\n",
            "Epoch 1947/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2723 - precision: 0.9216 - recall: 0.8233 - f1_score: 0.8693 - val_loss: 0.5050 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1948/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2712 - precision: 0.9204 - recall: 0.8133 - f1_score: 0.8634 - val_loss: 0.5089 - val_precision: 0.5532 - val_recall: 0.4333 - val_f1_score: 0.4860\n",
            "Epoch 1949/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.2719 - precision: 0.9299 - recall: 0.8300 - f1_score: 0.8767 - val_loss: 0.5067 - val_precision: 0.6279 - val_recall: 0.4500 - val_f1_score: 0.5243\n",
            "Epoch 1950/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.2715 - precision: 0.9242 - recall: 0.8167 - f1_score: 0.8666 - val_loss: 0.5055 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1951/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.2700 - precision: 0.9280 - recall: 0.8200 - f1_score: 0.8703 - val_loss: 0.5057 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 1952/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2708 - precision: 0.9197 - recall: 0.8333 - f1_score: 0.8738 - val_loss: 0.5079 - val_precision: 0.5625 - val_recall: 0.4500 - val_f1_score: 0.5000\n",
            "Epoch 1953/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.2733 - precision: 0.8993 - recall: 0.8067 - f1_score: 0.8504 - val_loss: 0.5057 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 1954/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2708 - precision: 0.9153 - recall: 0.8233 - f1_score: 0.8667 - val_loss: 0.5049 - val_precision: 0.6279 - val_recall: 0.4500 - val_f1_score: 0.5243\n",
            "Epoch 1955/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2752 - precision: 0.9139 - recall: 0.8133 - f1_score: 0.8605 - val_loss: 0.5052 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1956/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2716 - precision: 0.9256 - recall: 0.8300 - f1_score: 0.8745 - val_loss: 0.5079 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 1957/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2708 - precision: 0.9028 - recall: 0.8000 - f1_score: 0.8480 - val_loss: 0.5053 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1958/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2741 - precision: 0.9175 - recall: 0.8133 - f1_score: 0.8619 - val_loss: 0.5059 - val_precision: 0.6304 - val_recall: 0.4833 - val_f1_score: 0.5472\n",
            "Epoch 1959/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2703 - precision: 0.9333 - recall: 0.8400 - f1_score: 0.8839 - val_loss: 0.5062 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 1960/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.2699 - precision: 0.9325 - recall: 0.8200 - f1_score: 0.8716 - val_loss: 0.5057 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1961/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2686 - precision: 0.8968 - recall: 0.8067 - f1_score: 0.8492 - val_loss: 0.5098 - val_precision: 0.5532 - val_recall: 0.4333 - val_f1_score: 0.4860\n",
            "Epoch 1962/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2725 - precision: 0.9160 - recall: 0.8033 - f1_score: 0.8559 - val_loss: 0.5065 - val_precision: 0.6042 - val_recall: 0.4833 - val_f1_score: 0.5370\n",
            "Epoch 1963/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2699 - precision: 0.9366 - recall: 0.8400 - f1_score: 0.8853 - val_loss: 0.5065 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 1964/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2722 - precision: 0.9133 - recall: 0.8133 - f1_score: 0.8601 - val_loss: 0.5053 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 1965/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2700 - precision: 0.9265 - recall: 0.8300 - f1_score: 0.8754 - val_loss: 0.5059 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 1966/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2715 - precision: 0.9099 - recall: 0.8133 - f1_score: 0.8587 - val_loss: 0.5079 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 1967/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2699 - precision: 0.9323 - recall: 0.8267 - f1_score: 0.8758 - val_loss: 0.5054 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1968/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2705 - precision: 0.9220 - recall: 0.8233 - f1_score: 0.8696 - val_loss: 0.5054 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 1969/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2704 - precision: 0.9281 - recall: 0.8067 - f1_score: 0.8622 - val_loss: 0.5062 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 1970/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2710 - precision: 0.9124 - recall: 0.8233 - f1_score: 0.8653 - val_loss: 0.5064 - val_precision: 0.6042 - val_recall: 0.4833 - val_f1_score: 0.5370\n",
            "Epoch 1971/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.2700 - precision: 0.9300 - recall: 0.8333 - f1_score: 0.8781 - val_loss: 0.5065 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 1972/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2713 - precision: 0.9086 - recall: 0.8100 - f1_score: 0.8561 - val_loss: 0.5139 - val_precision: 0.5833 - val_recall: 0.4667 - val_f1_score: 0.5185\n",
            "Epoch 1973/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2721 - precision: 0.9095 - recall: 0.8100 - f1_score: 0.8562 - val_loss: 0.5144 - val_precision: 0.5870 - val_recall: 0.4500 - val_f1_score: 0.5094\n",
            "Epoch 1974/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2711 - precision: 0.9432 - recall: 0.8300 - f1_score: 0.8825 - val_loss: 0.5074 - val_precision: 0.5957 - val_recall: 0.4667 - val_f1_score: 0.5234\n",
            "Epoch 1975/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2702 - precision: 0.9358 - recall: 0.8200 - f1_score: 0.8735 - val_loss: 0.5072 - val_precision: 0.6279 - val_recall: 0.4500 - val_f1_score: 0.5243\n",
            "Epoch 1976/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2733 - precision: 0.8909 - recall: 0.7900 - f1_score: 0.8371 - val_loss: 0.5064 - val_precision: 0.6279 - val_recall: 0.4500 - val_f1_score: 0.5243\n",
            "Epoch 1977/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2734 - precision: 0.9021 - recall: 0.8067 - f1_score: 0.8511 - val_loss: 0.5058 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 1978/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2707 - precision: 0.9251 - recall: 0.8167 - f1_score: 0.8674 - val_loss: 0.5055 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 1979/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2699 - precision: 0.9077 - recall: 0.8200 - f1_score: 0.8610 - val_loss: 0.5057 - val_precision: 0.6279 - val_recall: 0.4500 - val_f1_score: 0.5243\n",
            "Epoch 1980/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.2698 - precision: 0.9264 - recall: 0.8267 - f1_score: 0.8733 - val_loss: 0.5087 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 1981/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.2708 - precision: 0.9023 - recall: 0.8100 - f1_score: 0.8533 - val_loss: 0.5098 - val_precision: 0.5714 - val_recall: 0.4667 - val_f1_score: 0.5138\n",
            "Epoch 1982/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2700 - precision: 0.9172 - recall: 0.8333 - f1_score: 0.8724 - val_loss: 0.5063 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 1983/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2726 - precision: 0.9115 - recall: 0.8333 - f1_score: 0.8705 - val_loss: 0.5055 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 1984/3000\n",
            "300/300 [==============================] - 0s 59us/step - loss: 0.2681 - precision: 0.9453 - recall: 0.8333 - f1_score: 0.8853 - val_loss: 0.5118 - val_precision: 0.5625 - val_recall: 0.4500 - val_f1_score: 0.5000\n",
            "Epoch 1985/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2708 - precision: 0.9144 - recall: 0.8167 - f1_score: 0.8626 - val_loss: 0.5057 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 1986/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2688 - precision: 0.9241 - recall: 0.8200 - f1_score: 0.8686 - val_loss: 0.5063 - val_precision: 0.6304 - val_recall: 0.4833 - val_f1_score: 0.5472\n",
            "Epoch 1987/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2692 - precision: 0.9323 - recall: 0.8333 - f1_score: 0.8796 - val_loss: 0.5065 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 1988/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2682 - precision: 0.9235 - recall: 0.8133 - f1_score: 0.8647 - val_loss: 0.5217 - val_precision: 0.5686 - val_recall: 0.4833 - val_f1_score: 0.5225\n",
            "Epoch 1989/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2730 - precision: 0.9175 - recall: 0.8100 - f1_score: 0.8602 - val_loss: 0.5088 - val_precision: 0.5625 - val_recall: 0.4500 - val_f1_score: 0.5000\n",
            "Epoch 1990/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2694 - precision: 0.9356 - recall: 0.8300 - f1_score: 0.8793 - val_loss: 0.5060 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 1991/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2689 - precision: 0.9325 - recall: 0.8233 - f1_score: 0.8741 - val_loss: 0.5074 - val_precision: 0.5918 - val_recall: 0.4833 - val_f1_score: 0.5321\n",
            "Epoch 1992/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2696 - precision: 0.9234 - recall: 0.8300 - f1_score: 0.8736 - val_loss: 0.5095 - val_precision: 0.5625 - val_recall: 0.4500 - val_f1_score: 0.5000\n",
            "Epoch 1993/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2712 - precision: 0.9358 - recall: 0.8167 - f1_score: 0.8718 - val_loss: 0.5086 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 1994/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2684 - precision: 0.9307 - recall: 0.8200 - f1_score: 0.8713 - val_loss: 0.5080 - val_precision: 0.5833 - val_recall: 0.4667 - val_f1_score: 0.5185\n",
            "Epoch 1995/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2692 - precision: 0.9189 - recall: 0.8300 - f1_score: 0.8721 - val_loss: 0.5084 - val_precision: 0.5745 - val_recall: 0.4500 - val_f1_score: 0.5047\n",
            "Epoch 1996/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2705 - precision: 0.9173 - recall: 0.8167 - f1_score: 0.8633 - val_loss: 0.5061 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 1997/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2704 - precision: 0.9252 - recall: 0.8200 - f1_score: 0.8691 - val_loss: 0.5105 - val_precision: 0.5714 - val_recall: 0.4667 - val_f1_score: 0.5138\n",
            "Epoch 1998/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2698 - precision: 0.9230 - recall: 0.8367 - f1_score: 0.8776 - val_loss: 0.5091 - val_precision: 0.5600 - val_recall: 0.4667 - val_f1_score: 0.5091\n",
            "Epoch 1999/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2701 - precision: 0.9138 - recall: 0.8167 - f1_score: 0.8625 - val_loss: 0.5083 - val_precision: 0.5833 - val_recall: 0.4667 - val_f1_score: 0.5185\n",
            "Epoch 2000/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2682 - precision: 0.9362 - recall: 0.8300 - f1_score: 0.8798 - val_loss: 0.5064 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 2001/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2697 - precision: 0.9194 - recall: 0.8333 - f1_score: 0.8739 - val_loss: 0.5122 - val_precision: 0.5714 - val_recall: 0.4667 - val_f1_score: 0.5138\n",
            "Epoch 2002/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2697 - precision: 0.9275 - recall: 0.8133 - f1_score: 0.8664 - val_loss: 0.5095 - val_precision: 0.5625 - val_recall: 0.4500 - val_f1_score: 0.5000\n",
            "Epoch 2003/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2689 - precision: 0.9249 - recall: 0.8267 - f1_score: 0.8726 - val_loss: 0.5097 - val_precision: 0.5714 - val_recall: 0.4667 - val_f1_score: 0.5138\n",
            "Epoch 2004/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2726 - precision: 0.9210 - recall: 0.7833 - f1_score: 0.8463 - val_loss: 0.5080 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2005/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2719 - precision: 0.9270 - recall: 0.8100 - f1_score: 0.8643 - val_loss: 0.5101 - val_precision: 0.5714 - val_recall: 0.4667 - val_f1_score: 0.5138\n",
            "Epoch 2006/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2680 - precision: 0.9367 - recall: 0.8233 - f1_score: 0.8761 - val_loss: 0.5062 - val_precision: 0.6279 - val_recall: 0.4500 - val_f1_score: 0.5243\n",
            "Epoch 2007/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2692 - precision: 0.9312 - recall: 0.8200 - f1_score: 0.8718 - val_loss: 0.5098 - val_precision: 0.5625 - val_recall: 0.4500 - val_f1_score: 0.5000\n",
            "Epoch 2008/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2676 - precision: 0.9273 - recall: 0.8400 - f1_score: 0.8810 - val_loss: 0.5069 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2009/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2681 - precision: 0.9403 - recall: 0.8400 - f1_score: 0.8870 - val_loss: 0.5063 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2010/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2693 - precision: 0.9328 - recall: 0.8267 - f1_score: 0.8763 - val_loss: 0.5063 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2011/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2681 - precision: 0.9242 - recall: 0.8067 - f1_score: 0.8611 - val_loss: 0.5069 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 2012/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2681 - precision: 0.9439 - recall: 0.8267 - f1_score: 0.8809 - val_loss: 0.5102 - val_precision: 0.5714 - val_recall: 0.4667 - val_f1_score: 0.5138\n",
            "Epoch 2013/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2701 - precision: 0.9037 - recall: 0.8067 - f1_score: 0.8517 - val_loss: 0.5083 - val_precision: 0.6279 - val_recall: 0.4500 - val_f1_score: 0.5243\n",
            "Epoch 2014/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2677 - precision: 0.9364 - recall: 0.8200 - f1_score: 0.8738 - val_loss: 0.5087 - val_precision: 0.5714 - val_recall: 0.4667 - val_f1_score: 0.5138\n",
            "Epoch 2015/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.2685 - precision: 0.9128 - recall: 0.8067 - f1_score: 0.8562 - val_loss: 0.5065 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2016/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2673 - precision: 0.9294 - recall: 0.8333 - f1_score: 0.8784 - val_loss: 0.5073 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2017/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2673 - precision: 0.9303 - recall: 0.8300 - f1_score: 0.8770 - val_loss: 0.5079 - val_precision: 0.5918 - val_recall: 0.4833 - val_f1_score: 0.5321\n",
            "Epoch 2018/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2720 - precision: 0.9076 - recall: 0.8133 - f1_score: 0.8575 - val_loss: 0.5097 - val_precision: 0.5714 - val_recall: 0.4667 - val_f1_score: 0.5138\n",
            "Epoch 2019/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2684 - precision: 0.9349 - recall: 0.8133 - f1_score: 0.8695 - val_loss: 0.5070 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2020/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.2695 - precision: 0.9145 - recall: 0.8233 - f1_score: 0.8662 - val_loss: 0.5097 - val_precision: 0.5625 - val_recall: 0.4500 - val_f1_score: 0.5000\n",
            "Epoch 2021/3000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.2674 - precision: 0.9334 - recall: 0.8300 - f1_score: 0.8785 - val_loss: 0.5073 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2022/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2694 - precision: 0.9204 - recall: 0.8100 - f1_score: 0.8611 - val_loss: 0.5070 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 2023/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.2672 - precision: 0.9301 - recall: 0.8367 - f1_score: 0.8804 - val_loss: 0.5066 - val_precision: 0.6279 - val_recall: 0.4500 - val_f1_score: 0.5243\n",
            "Epoch 2024/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2682 - precision: 0.9246 - recall: 0.8300 - f1_score: 0.8744 - val_loss: 0.5105 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2025/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2758 - precision: 0.8926 - recall: 0.7767 - f1_score: 0.8302 - val_loss: 0.5102 - val_precision: 0.5714 - val_recall: 0.4667 - val_f1_score: 0.5138\n",
            "Epoch 2026/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2686 - precision: 0.9247 - recall: 0.8100 - f1_score: 0.8630 - val_loss: 0.5074 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2027/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.2680 - precision: 0.9223 - recall: 0.8300 - f1_score: 0.8737 - val_loss: 0.5079 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2028/3000\n",
            "300/300 [==============================] - 0s 78us/step - loss: 0.2666 - precision: 0.9319 - recall: 0.8300 - f1_score: 0.8771 - val_loss: 0.5088 - val_precision: 0.5833 - val_recall: 0.4667 - val_f1_score: 0.5185\n",
            "Epoch 2029/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2672 - precision: 0.9300 - recall: 0.8367 - f1_score: 0.8805 - val_loss: 0.5070 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2030/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2671 - precision: 0.9330 - recall: 0.8367 - f1_score: 0.8819 - val_loss: 0.5091 - val_precision: 0.5625 - val_recall: 0.4500 - val_f1_score: 0.5000\n",
            "Epoch 2031/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2665 - precision: 0.9213 - recall: 0.8200 - f1_score: 0.8675 - val_loss: 0.5086 - val_precision: 0.5957 - val_recall: 0.4667 - val_f1_score: 0.5234\n",
            "Epoch 2032/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2667 - precision: 0.9367 - recall: 0.8400 - f1_score: 0.8856 - val_loss: 0.5088 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 2033/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2699 - precision: 0.9105 - recall: 0.8100 - f1_score: 0.8572 - val_loss: 0.5079 - val_precision: 0.6279 - val_recall: 0.4500 - val_f1_score: 0.5243\n",
            "Epoch 2034/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2671 - precision: 0.9189 - recall: 0.8300 - f1_score: 0.8716 - val_loss: 0.5094 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2035/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2732 - precision: 0.9202 - recall: 0.8067 - f1_score: 0.8593 - val_loss: 0.5070 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2036/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2666 - precision: 0.9252 - recall: 0.8333 - f1_score: 0.8764 - val_loss: 0.5074 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 2037/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2677 - precision: 0.9274 - recall: 0.8167 - f1_score: 0.8683 - val_loss: 0.5131 - val_precision: 0.5510 - val_recall: 0.4500 - val_f1_score: 0.4954\n",
            "Epoch 2038/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2670 - precision: 0.9238 - recall: 0.8100 - f1_score: 0.8622 - val_loss: 0.5070 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2039/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2668 - precision: 0.9223 - recall: 0.8233 - f1_score: 0.8698 - val_loss: 0.5075 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2040/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2654 - precision: 0.9434 - recall: 0.8333 - f1_score: 0.8849 - val_loss: 0.5073 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 2041/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2665 - precision: 0.9283 - recall: 0.8267 - f1_score: 0.8741 - val_loss: 0.5082 - val_precision: 0.6304 - val_recall: 0.4833 - val_f1_score: 0.5472\n",
            "Epoch 2042/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.2657 - precision: 0.9413 - recall: 0.8367 - f1_score: 0.8856 - val_loss: 0.5073 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 2043/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2665 - precision: 0.9318 - recall: 0.8233 - f1_score: 0.8741 - val_loss: 0.5084 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2044/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.2662 - precision: 0.9361 - recall: 0.8300 - f1_score: 0.8797 - val_loss: 0.5076 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 2045/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2672 - precision: 0.9329 - recall: 0.8300 - f1_score: 0.8782 - val_loss: 0.5072 - val_precision: 0.6279 - val_recall: 0.4500 - val_f1_score: 0.5243\n",
            "Epoch 2046/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2687 - precision: 0.9145 - recall: 0.8100 - f1_score: 0.8588 - val_loss: 0.5079 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2047/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2666 - precision: 0.9199 - recall: 0.8167 - f1_score: 0.8649 - val_loss: 0.5100 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2048/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.2677 - precision: 0.9139 - recall: 0.8067 - f1_score: 0.8566 - val_loss: 0.5105 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2049/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2690 - precision: 0.9183 - recall: 0.8233 - f1_score: 0.8680 - val_loss: 0.5080 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2050/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2671 - precision: 0.9297 - recall: 0.8267 - f1_score: 0.8750 - val_loss: 0.5078 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2051/3000\n",
            "300/300 [==============================] - 0s 79us/step - loss: 0.2665 - precision: 0.9371 - recall: 0.8367 - f1_score: 0.8836 - val_loss: 0.5089 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2052/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2672 - precision: 0.9321 - recall: 0.8200 - f1_score: 0.8723 - val_loss: 0.5098 - val_precision: 0.5714 - val_recall: 0.4667 - val_f1_score: 0.5138\n",
            "Epoch 2053/3000\n",
            "300/300 [==============================] - 0s 79us/step - loss: 0.2662 - precision: 0.9367 - recall: 0.8333 - f1_score: 0.8817 - val_loss: 0.5074 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2054/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2664 - precision: 0.9263 - recall: 0.8267 - f1_score: 0.8730 - val_loss: 0.5075 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2055/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2663 - precision: 0.9190 - recall: 0.8300 - f1_score: 0.8720 - val_loss: 0.5082 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2056/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2655 - precision: 0.9365 - recall: 0.8333 - f1_score: 0.8814 - val_loss: 0.5098 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2057/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2736 - precision: 0.8977 - recall: 0.7867 - f1_score: 0.8382 - val_loss: 0.5077 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2058/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2689 - precision: 0.9260 - recall: 0.8333 - f1_score: 0.8772 - val_loss: 0.5075 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2059/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2740 - precision: 0.9015 - recall: 0.7933 - f1_score: 0.8431 - val_loss: 0.5075 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2060/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.2656 - precision: 0.9316 - recall: 0.8333 - f1_score: 0.8791 - val_loss: 0.5077 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2061/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2658 - precision: 0.9335 - recall: 0.8367 - f1_score: 0.8823 - val_loss: 0.5087 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2062/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2666 - precision: 0.9281 - recall: 0.8167 - f1_score: 0.8677 - val_loss: 0.5080 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2063/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2654 - precision: 0.9367 - recall: 0.8400 - f1_score: 0.8855 - val_loss: 0.5081 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 2064/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2651 - precision: 0.9327 - recall: 0.8267 - f1_score: 0.8755 - val_loss: 0.5080 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2065/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2666 - precision: 0.9183 - recall: 0.8133 - f1_score: 0.8621 - val_loss: 0.5097 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2066/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2660 - precision: 0.9258 - recall: 0.8333 - f1_score: 0.8769 - val_loss: 0.5103 - val_precision: 0.5625 - val_recall: 0.4500 - val_f1_score: 0.5000\n",
            "Epoch 2067/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2672 - precision: 0.9166 - recall: 0.8200 - f1_score: 0.8653 - val_loss: 0.5080 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2068/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.2684 - precision: 0.9170 - recall: 0.8167 - f1_score: 0.8635 - val_loss: 0.5151 - val_precision: 0.5745 - val_recall: 0.4500 - val_f1_score: 0.5047\n",
            "Epoch 2069/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2656 - precision: 0.9371 - recall: 0.8433 - f1_score: 0.8876 - val_loss: 0.5085 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2070/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2648 - precision: 0.9306 - recall: 0.8400 - f1_score: 0.8820 - val_loss: 0.5089 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 2071/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2662 - precision: 0.9375 - recall: 0.8333 - f1_score: 0.8820 - val_loss: 0.5084 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2072/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2666 - precision: 0.9224 - recall: 0.8300 - f1_score: 0.8736 - val_loss: 0.5078 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2073/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2628 - precision: 0.9334 - recall: 0.8400 - f1_score: 0.8838 - val_loss: 0.5181 - val_precision: 0.5870 - val_recall: 0.4500 - val_f1_score: 0.5094\n",
            "Epoch 2074/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2661 - precision: 0.9253 - recall: 0.8267 - f1_score: 0.8732 - val_loss: 0.5083 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 2075/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.2646 - precision: 0.9331 - recall: 0.8400 - f1_score: 0.8838 - val_loss: 0.5099 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2076/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2673 - precision: 0.9341 - recall: 0.8267 - f1_score: 0.8760 - val_loss: 0.5085 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2077/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2645 - precision: 0.9319 - recall: 0.8300 - f1_score: 0.8773 - val_loss: 0.5096 - val_precision: 0.5918 - val_recall: 0.4833 - val_f1_score: 0.5321\n",
            "Epoch 2078/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2665 - precision: 0.9063 - recall: 0.8367 - f1_score: 0.8699 - val_loss: 0.5111 - val_precision: 0.5625 - val_recall: 0.4500 - val_f1_score: 0.5000\n",
            "Epoch 2079/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2657 - precision: 0.9364 - recall: 0.8300 - f1_score: 0.8796 - val_loss: 0.5097 - val_precision: 0.5918 - val_recall: 0.4833 - val_f1_score: 0.5321\n",
            "Epoch 2080/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2655 - precision: 0.9273 - recall: 0.8467 - f1_score: 0.8849 - val_loss: 0.5082 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2081/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2640 - precision: 0.9324 - recall: 0.8333 - f1_score: 0.8798 - val_loss: 0.5083 - val_precision: 0.6279 - val_recall: 0.4500 - val_f1_score: 0.5243\n",
            "Epoch 2082/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2655 - precision: 0.9434 - recall: 0.8267 - f1_score: 0.8806 - val_loss: 0.5088 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2083/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.2646 - precision: 0.9266 - recall: 0.8267 - f1_score: 0.8734 - val_loss: 0.5110 - val_precision: 0.5625 - val_recall: 0.4500 - val_f1_score: 0.5000\n",
            "Epoch 2084/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2680 - precision: 0.9212 - recall: 0.8200 - f1_score: 0.8676 - val_loss: 0.5095 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2085/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.2635 - precision: 0.9458 - recall: 0.8367 - f1_score: 0.8872 - val_loss: 0.5093 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2086/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2642 - precision: 0.9257 - recall: 0.8267 - f1_score: 0.8733 - val_loss: 0.5130 - val_precision: 0.5714 - val_recall: 0.4667 - val_f1_score: 0.5138\n",
            "Epoch 2087/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.2634 - precision: 0.9303 - recall: 0.8433 - f1_score: 0.8843 - val_loss: 0.5092 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2088/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2653 - precision: 0.9267 - recall: 0.8167 - f1_score: 0.8676 - val_loss: 0.5087 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2089/3000\n",
            "300/300 [==============================] - 0s 59us/step - loss: 0.2662 - precision: 0.9073 - recall: 0.8133 - f1_score: 0.8575 - val_loss: 0.5086 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 2090/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.2725 - precision: 0.8869 - recall: 0.8133 - f1_score: 0.8483 - val_loss: 0.5088 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2091/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2635 - precision: 0.9393 - recall: 0.8367 - f1_score: 0.8847 - val_loss: 0.5106 - val_precision: 0.5800 - val_recall: 0.4833 - val_f1_score: 0.5273\n",
            "Epoch 2092/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2651 - precision: 0.9253 - recall: 0.8300 - f1_score: 0.8749 - val_loss: 0.5125 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2093/3000\n",
            "300/300 [==============================] - 0s 59us/step - loss: 0.2639 - precision: 0.9289 - recall: 0.8300 - f1_score: 0.8766 - val_loss: 0.5107 - val_precision: 0.5714 - val_recall: 0.4667 - val_f1_score: 0.5138\n",
            "Epoch 2094/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2651 - precision: 0.9324 - recall: 0.8233 - f1_score: 0.8742 - val_loss: 0.5104 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2095/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2637 - precision: 0.9414 - recall: 0.8467 - f1_score: 0.8911 - val_loss: 0.5100 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2096/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.2640 - precision: 0.9235 - recall: 0.8467 - f1_score: 0.8833 - val_loss: 0.5104 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2097/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2650 - precision: 0.9212 - recall: 0.8300 - f1_score: 0.8729 - val_loss: 0.5092 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2098/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2643 - precision: 0.9261 - recall: 0.8333 - f1_score: 0.8771 - val_loss: 0.5089 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 2099/3000\n",
            "300/300 [==============================] - 0s 59us/step - loss: 0.2643 - precision: 0.9202 - recall: 0.8333 - f1_score: 0.8742 - val_loss: 0.5092 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 2100/3000\n",
            "300/300 [==============================] - 0s 59us/step - loss: 0.2632 - precision: 0.9264 - recall: 0.8367 - f1_score: 0.8790 - val_loss: 0.5092 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 2101/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.2632 - precision: 0.9326 - recall: 0.8300 - f1_score: 0.8778 - val_loss: 0.5105 - val_precision: 0.6042 - val_recall: 0.4833 - val_f1_score: 0.5370\n",
            "Epoch 2102/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2620 - precision: 0.9380 - recall: 0.8500 - f1_score: 0.8917 - val_loss: 0.5121 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2103/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2652 - precision: 0.9250 - recall: 0.8200 - f1_score: 0.8691 - val_loss: 0.5108 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2104/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2636 - precision: 0.9285 - recall: 0.8200 - f1_score: 0.8708 - val_loss: 0.5099 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2105/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2635 - precision: 0.9293 - recall: 0.8367 - f1_score: 0.8804 - val_loss: 0.5116 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 2106/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2647 - precision: 0.9285 - recall: 0.8233 - f1_score: 0.8726 - val_loss: 0.5092 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 2107/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2635 - precision: 0.9199 - recall: 0.8367 - f1_score: 0.8760 - val_loss: 0.5094 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 2108/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2658 - precision: 0.9145 - recall: 0.8200 - f1_score: 0.8643 - val_loss: 0.5094 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2109/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2645 - precision: 0.9302 - recall: 0.8433 - f1_score: 0.8842 - val_loss: 0.5091 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2110/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.2642 - precision: 0.9187 - recall: 0.8333 - f1_score: 0.8739 - val_loss: 0.5119 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 2111/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2672 - precision: 0.9112 - recall: 0.7933 - f1_score: 0.8478 - val_loss: 0.5160 - val_precision: 0.6383 - val_recall: 0.5000 - val_f1_score: 0.5607\n",
            "Epoch 2112/3000\n",
            "300/300 [==============================] - 0s 58us/step - loss: 0.2674 - precision: 0.9151 - recall: 0.8200 - f1_score: 0.8643 - val_loss: 0.5100 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2113/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.2628 - precision: 0.9399 - recall: 0.8400 - f1_score: 0.8866 - val_loss: 0.5104 - val_precision: 0.6304 - val_recall: 0.4833 - val_f1_score: 0.5472\n",
            "Epoch 2114/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.2635 - precision: 0.9290 - recall: 0.8333 - f1_score: 0.8784 - val_loss: 0.5101 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 2115/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2650 - precision: 0.9100 - recall: 0.8133 - f1_score: 0.8588 - val_loss: 0.5096 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2116/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2642 - precision: 0.9261 - recall: 0.8333 - f1_score: 0.8772 - val_loss: 0.5116 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2117/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2664 - precision: 0.9193 - recall: 0.8133 - f1_score: 0.8622 - val_loss: 0.5109 - val_precision: 0.5918 - val_recall: 0.4833 - val_f1_score: 0.5321\n",
            "Epoch 2118/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2634 - precision: 0.9373 - recall: 0.8500 - f1_score: 0.8908 - val_loss: 0.5106 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 2119/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2628 - precision: 0.9302 - recall: 0.8400 - f1_score: 0.8825 - val_loss: 0.5097 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 2120/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2629 - precision: 0.9358 - recall: 0.8300 - f1_score: 0.8784 - val_loss: 0.5111 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2121/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2649 - precision: 0.9256 - recall: 0.8267 - f1_score: 0.8732 - val_loss: 0.5162 - val_precision: 0.5600 - val_recall: 0.4667 - val_f1_score: 0.5091\n",
            "Epoch 2122/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2634 - precision: 0.9168 - recall: 0.8433 - f1_score: 0.8785 - val_loss: 0.5131 - val_precision: 0.5714 - val_recall: 0.4667 - val_f1_score: 0.5138\n",
            "Epoch 2123/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2656 - precision: 0.9325 - recall: 0.8267 - f1_score: 0.8763 - val_loss: 0.5102 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 2124/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2659 - precision: 0.9087 - recall: 0.8300 - f1_score: 0.8674 - val_loss: 0.5101 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 2125/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2628 - precision: 0.9223 - recall: 0.8267 - f1_score: 0.8716 - val_loss: 0.5108 - val_precision: 0.6042 - val_recall: 0.4833 - val_f1_score: 0.5370\n",
            "Epoch 2126/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2648 - precision: 0.9275 - recall: 0.8433 - f1_score: 0.8832 - val_loss: 0.5150 - val_precision: 0.5600 - val_recall: 0.4667 - val_f1_score: 0.5091\n",
            "Epoch 2127/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.2627 - precision: 0.9249 - recall: 0.8200 - f1_score: 0.8690 - val_loss: 0.5113 - val_precision: 0.5918 - val_recall: 0.4833 - val_f1_score: 0.5321\n",
            "Epoch 2128/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2627 - precision: 0.9307 - recall: 0.8500 - f1_score: 0.8883 - val_loss: 0.5106 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2129/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2674 - precision: 0.9079 - recall: 0.8167 - f1_score: 0.8597 - val_loss: 0.5099 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 2130/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.2621 - precision: 0.9315 - recall: 0.8333 - f1_score: 0.8790 - val_loss: 0.5106 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 2131/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.2627 - precision: 0.9254 - recall: 0.8400 - f1_score: 0.8801 - val_loss: 0.5124 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 2132/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2671 - precision: 0.8901 - recall: 0.7867 - f1_score: 0.8348 - val_loss: 0.5122 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 2133/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2641 - precision: 0.9103 - recall: 0.8300 - f1_score: 0.8677 - val_loss: 0.5116 - val_precision: 0.5918 - val_recall: 0.4833 - val_f1_score: 0.5321\n",
            "Epoch 2134/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2636 - precision: 0.9076 - recall: 0.8233 - f1_score: 0.8633 - val_loss: 0.5116 - val_precision: 0.5918 - val_recall: 0.4833 - val_f1_score: 0.5321\n",
            "Epoch 2135/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2614 - precision: 0.9412 - recall: 0.8500 - f1_score: 0.8930 - val_loss: 0.5105 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2136/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2614 - precision: 0.9358 - recall: 0.8300 - f1_score: 0.8796 - val_loss: 0.5124 - val_precision: 0.5800 - val_recall: 0.4833 - val_f1_score: 0.5273\n",
            "Epoch 2137/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2654 - precision: 0.9087 - recall: 0.8167 - f1_score: 0.8597 - val_loss: 0.5127 - val_precision: 0.5625 - val_recall: 0.4500 - val_f1_score: 0.5000\n",
            "Epoch 2138/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2641 - precision: 0.9157 - recall: 0.8367 - f1_score: 0.8741 - val_loss: 0.5107 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2139/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2662 - precision: 0.9117 - recall: 0.8300 - f1_score: 0.8688 - val_loss: 0.5101 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2140/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2602 - precision: 0.9199 - recall: 0.8433 - f1_score: 0.8799 - val_loss: 0.5260 - val_precision: 0.5714 - val_recall: 0.4667 - val_f1_score: 0.5138\n",
            "Epoch 2141/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2655 - precision: 0.9324 - recall: 0.8267 - f1_score: 0.8760 - val_loss: 0.5118 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2142/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2665 - precision: 0.9115 - recall: 0.8267 - f1_score: 0.8669 - val_loss: 0.5102 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 2143/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2640 - precision: 0.9150 - recall: 0.8233 - f1_score: 0.8660 - val_loss: 0.5104 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2144/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2629 - precision: 0.9258 - recall: 0.8400 - f1_score: 0.8808 - val_loss: 0.5103 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 2145/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2616 - precision: 0.9261 - recall: 0.8367 - f1_score: 0.8788 - val_loss: 0.5112 - val_precision: 0.5918 - val_recall: 0.4833 - val_f1_score: 0.5321\n",
            "Epoch 2146/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2690 - precision: 0.9147 - recall: 0.8333 - f1_score: 0.8718 - val_loss: 0.5129 - val_precision: 0.5625 - val_recall: 0.4500 - val_f1_score: 0.5000\n",
            "Epoch 2147/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2616 - precision: 0.9397 - recall: 0.8367 - f1_score: 0.8851 - val_loss: 0.5104 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 2148/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2621 - precision: 0.9408 - recall: 0.8400 - f1_score: 0.8873 - val_loss: 0.5120 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 2149/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2633 - precision: 0.9172 - recall: 0.8167 - f1_score: 0.8634 - val_loss: 0.5103 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 2150/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2665 - precision: 0.9072 - recall: 0.8133 - f1_score: 0.8576 - val_loss: 0.5105 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 2151/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2630 - precision: 0.9265 - recall: 0.8433 - f1_score: 0.8824 - val_loss: 0.5123 - val_precision: 0.5714 - val_recall: 0.4667 - val_f1_score: 0.5138\n",
            "Epoch 2152/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2612 - precision: 0.9270 - recall: 0.8433 - f1_score: 0.8830 - val_loss: 0.5111 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2153/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2619 - precision: 0.9268 - recall: 0.8300 - f1_score: 0.8752 - val_loss: 0.5113 - val_precision: 0.6304 - val_recall: 0.4833 - val_f1_score: 0.5472\n",
            "Epoch 2154/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2617 - precision: 0.9432 - recall: 0.8367 - f1_score: 0.8861 - val_loss: 0.5111 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 2155/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2612 - precision: 0.9320 - recall: 0.8267 - f1_score: 0.8757 - val_loss: 0.5104 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2156/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2639 - precision: 0.9286 - recall: 0.8300 - f1_score: 0.8762 - val_loss: 0.5118 - val_precision: 0.5918 - val_recall: 0.4833 - val_f1_score: 0.5321\n",
            "Epoch 2157/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2623 - precision: 0.9258 - recall: 0.8300 - f1_score: 0.8753 - val_loss: 0.5128 - val_precision: 0.5625 - val_recall: 0.4500 - val_f1_score: 0.5000\n",
            "Epoch 2158/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2624 - precision: 0.9349 - recall: 0.8200 - f1_score: 0.8735 - val_loss: 0.5160 - val_precision: 0.5510 - val_recall: 0.4500 - val_f1_score: 0.4954\n",
            "Epoch 2159/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2699 - precision: 0.9125 - recall: 0.8300 - f1_score: 0.8691 - val_loss: 0.5110 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 2160/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2609 - precision: 0.9284 - recall: 0.8200 - f1_score: 0.8708 - val_loss: 0.5107 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2161/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2616 - precision: 0.9292 - recall: 0.8467 - f1_score: 0.8854 - val_loss: 0.5107 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 2162/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2601 - precision: 0.9234 - recall: 0.8433 - f1_score: 0.8815 - val_loss: 0.5164 - val_precision: 0.5510 - val_recall: 0.4500 - val_f1_score: 0.4954\n",
            "Epoch 2163/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2611 - precision: 0.9211 - recall: 0.8167 - f1_score: 0.8657 - val_loss: 0.5111 - val_precision: 0.5957 - val_recall: 0.4667 - val_f1_score: 0.5234\n",
            "Epoch 2164/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2605 - precision: 0.9400 - recall: 0.8367 - f1_score: 0.8852 - val_loss: 0.5113 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2165/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.2616 - precision: 0.9360 - recall: 0.8233 - f1_score: 0.8758 - val_loss: 0.5106 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 2166/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2609 - precision: 0.9406 - recall: 0.8333 - f1_score: 0.8834 - val_loss: 0.5106 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2167/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2595 - precision: 0.9402 - recall: 0.8367 - f1_score: 0.8848 - val_loss: 0.5123 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 2168/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2608 - precision: 0.9356 - recall: 0.8233 - f1_score: 0.8758 - val_loss: 0.5105 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 2169/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2625 - precision: 0.9293 - recall: 0.8367 - f1_score: 0.8803 - val_loss: 0.5135 - val_precision: 0.5625 - val_recall: 0.4500 - val_f1_score: 0.5000\n",
            "Epoch 2170/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2633 - precision: 0.9294 - recall: 0.8333 - f1_score: 0.8787 - val_loss: 0.5150 - val_precision: 0.5714 - val_recall: 0.4667 - val_f1_score: 0.5138\n",
            "Epoch 2171/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2600 - precision: 0.9377 - recall: 0.8533 - f1_score: 0.8933 - val_loss: 0.5151 - val_precision: 0.6042 - val_recall: 0.4833 - val_f1_score: 0.5370\n",
            "Epoch 2172/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2616 - precision: 0.9074 - recall: 0.8167 - f1_score: 0.8596 - val_loss: 0.5106 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2173/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2601 - precision: 0.9262 - recall: 0.8333 - f1_score: 0.8768 - val_loss: 0.5160 - val_precision: 0.5510 - val_recall: 0.4500 - val_f1_score: 0.4954\n",
            "Epoch 2174/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2594 - precision: 0.9414 - recall: 0.8500 - f1_score: 0.8931 - val_loss: 0.5130 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 2175/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2632 - precision: 0.9182 - recall: 0.8133 - f1_score: 0.8619 - val_loss: 0.5107 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2176/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2608 - precision: 0.9267 - recall: 0.8400 - f1_score: 0.8810 - val_loss: 0.5127 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2177/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2624 - precision: 0.9208 - recall: 0.8200 - f1_score: 0.8674 - val_loss: 0.5148 - val_precision: 0.5714 - val_recall: 0.4667 - val_f1_score: 0.5138\n",
            "Epoch 2178/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2600 - precision: 0.9389 - recall: 0.8300 - f1_score: 0.8807 - val_loss: 0.5109 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2179/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2588 - precision: 0.9359 - recall: 0.8367 - f1_score: 0.8833 - val_loss: 0.5165 - val_precision: 0.5600 - val_recall: 0.4667 - val_f1_score: 0.5091\n",
            "Epoch 2180/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2618 - precision: 0.9189 - recall: 0.8400 - f1_score: 0.8775 - val_loss: 0.5107 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2181/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2600 - precision: 0.9189 - recall: 0.8300 - f1_score: 0.8721 - val_loss: 0.5199 - val_precision: 0.5472 - val_recall: 0.4833 - val_f1_score: 0.5133\n",
            "Epoch 2182/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2605 - precision: 0.9283 - recall: 0.8333 - f1_score: 0.8779 - val_loss: 0.5112 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 2183/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2605 - precision: 0.9123 - recall: 0.8333 - f1_score: 0.8706 - val_loss: 0.5129 - val_precision: 0.5714 - val_recall: 0.4667 - val_f1_score: 0.5138\n",
            "Epoch 2184/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2694 - precision: 0.9076 - recall: 0.8200 - f1_score: 0.8611 - val_loss: 0.5115 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 2185/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2611 - precision: 0.9206 - recall: 0.8400 - f1_score: 0.8780 - val_loss: 0.5109 - val_precision: 0.6279 - val_recall: 0.4500 - val_f1_score: 0.5243\n",
            "Epoch 2186/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2603 - precision: 0.9299 - recall: 0.8400 - f1_score: 0.8826 - val_loss: 0.5116 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2187/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2596 - precision: 0.9256 - recall: 0.8233 - f1_score: 0.8705 - val_loss: 0.5115 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 2188/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2589 - precision: 0.9295 - recall: 0.8400 - f1_score: 0.8822 - val_loss: 0.5118 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2189/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.2606 - precision: 0.9343 - recall: 0.8367 - f1_score: 0.8820 - val_loss: 0.5121 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2190/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2622 - precision: 0.9399 - recall: 0.8267 - f1_score: 0.8792 - val_loss: 0.5140 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2191/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2593 - precision: 0.9284 - recall: 0.8267 - f1_score: 0.8742 - val_loss: 0.5131 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2192/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2680 - precision: 0.9031 - recall: 0.8167 - f1_score: 0.8573 - val_loss: 0.5112 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 2193/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2595 - precision: 0.9256 - recall: 0.8300 - f1_score: 0.8751 - val_loss: 0.5170 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2194/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2644 - precision: 0.9126 - recall: 0.8400 - f1_score: 0.8748 - val_loss: 0.5134 - val_precision: 0.5714 - val_recall: 0.4667 - val_f1_score: 0.5138\n",
            "Epoch 2195/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2610 - precision: 0.9269 - recall: 0.8467 - f1_score: 0.8847 - val_loss: 0.5112 - val_precision: 0.6279 - val_recall: 0.4500 - val_f1_score: 0.5243\n",
            "Epoch 2196/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2602 - precision: 0.9300 - recall: 0.8467 - f1_score: 0.8862 - val_loss: 0.5114 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 2197/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2593 - precision: 0.9435 - recall: 0.8367 - f1_score: 0.8864 - val_loss: 0.5117 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 2198/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2588 - precision: 0.9151 - recall: 0.8300 - f1_score: 0.8697 - val_loss: 0.5124 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2199/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2604 - precision: 0.9255 - recall: 0.8300 - f1_score: 0.8751 - val_loss: 0.5136 - val_precision: 0.5714 - val_recall: 0.4667 - val_f1_score: 0.5138\n",
            "Epoch 2200/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2580 - precision: 0.9371 - recall: 0.8467 - f1_score: 0.8892 - val_loss: 0.5124 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 2201/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2596 - precision: 0.9269 - recall: 0.8433 - f1_score: 0.8831 - val_loss: 0.5122 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 2202/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2593 - precision: 0.9369 - recall: 0.8400 - f1_score: 0.8853 - val_loss: 0.5114 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2203/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2594 - precision: 0.9373 - recall: 0.8400 - f1_score: 0.8856 - val_loss: 0.5114 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 2204/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2590 - precision: 0.9326 - recall: 0.8300 - f1_score: 0.8781 - val_loss: 0.5155 - val_precision: 0.5600 - val_recall: 0.4667 - val_f1_score: 0.5091\n",
            "Epoch 2205/3000\n",
            "300/300 [==============================] - 0s 80us/step - loss: 0.2601 - precision: 0.9120 - recall: 0.8333 - f1_score: 0.8708 - val_loss: 0.5150 - val_precision: 0.5714 - val_recall: 0.4667 - val_f1_score: 0.5138\n",
            "Epoch 2206/3000\n",
            "300/300 [==============================] - 0s 80us/step - loss: 0.2589 - precision: 0.9397 - recall: 0.8367 - f1_score: 0.8846 - val_loss: 0.5141 - val_precision: 0.5625 - val_recall: 0.4500 - val_f1_score: 0.5000\n",
            "Epoch 2207/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2600 - precision: 0.9261 - recall: 0.8367 - f1_score: 0.8790 - val_loss: 0.5150 - val_precision: 0.5625 - val_recall: 0.4500 - val_f1_score: 0.5000\n",
            "Epoch 2208/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2616 - precision: 0.9223 - recall: 0.8300 - f1_score: 0.8734 - val_loss: 0.5116 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2209/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.2604 - precision: 0.9184 - recall: 0.8267 - f1_score: 0.8700 - val_loss: 0.5119 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2210/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2590 - precision: 0.9364 - recall: 0.8367 - f1_score: 0.8836 - val_loss: 0.5122 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2211/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2582 - precision: 0.9341 - recall: 0.8433 - f1_score: 0.8861 - val_loss: 0.5129 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 2212/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2581 - precision: 0.9342 - recall: 0.8533 - f1_score: 0.8917 - val_loss: 0.5115 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2213/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2588 - precision: 0.9192 - recall: 0.8367 - f1_score: 0.8759 - val_loss: 0.5160 - val_precision: 0.5600 - val_recall: 0.4667 - val_f1_score: 0.5091\n",
            "Epoch 2214/3000\n",
            "300/300 [==============================] - 0s 109us/step - loss: 0.2612 - precision: 0.9320 - recall: 0.8300 - f1_score: 0.8779 - val_loss: 0.5188 - val_precision: 0.5625 - val_recall: 0.4500 - val_f1_score: 0.5000\n",
            "Epoch 2215/3000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.2585 - precision: 0.9236 - recall: 0.8433 - f1_score: 0.8813 - val_loss: 0.5187 - val_precision: 0.6250 - val_recall: 0.5000 - val_f1_score: 0.5556\n",
            "Epoch 2216/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2617 - precision: 0.9216 - recall: 0.8200 - f1_score: 0.8677 - val_loss: 0.5116 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 2217/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2579 - precision: 0.9409 - recall: 0.8500 - f1_score: 0.8930 - val_loss: 0.5127 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 2218/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2599 - precision: 0.9232 - recall: 0.8400 - f1_score: 0.8796 - val_loss: 0.5126 - val_precision: 0.5957 - val_recall: 0.4667 - val_f1_score: 0.5234\n",
            "Epoch 2219/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2617 - precision: 0.9260 - recall: 0.8333 - f1_score: 0.8771 - val_loss: 0.5117 - val_precision: 0.6279 - val_recall: 0.4500 - val_f1_score: 0.5243\n",
            "Epoch 2220/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.2572 - precision: 0.9326 - recall: 0.8300 - f1_score: 0.8780 - val_loss: 0.5138 - val_precision: 0.5800 - val_recall: 0.4833 - val_f1_score: 0.5273\n",
            "Epoch 2221/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2601 - precision: 0.9154 - recall: 0.8267 - f1_score: 0.8686 - val_loss: 0.5138 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2222/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2586 - precision: 0.9403 - recall: 0.8433 - f1_score: 0.8891 - val_loss: 0.5125 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2223/3000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.2586 - precision: 0.9298 - recall: 0.8300 - f1_score: 0.8770 - val_loss: 0.5154 - val_precision: 0.5600 - val_recall: 0.4667 - val_f1_score: 0.5091\n",
            "Epoch 2224/3000\n",
            "300/300 [==============================] - 0s 105us/step - loss: 0.2577 - precision: 0.9075 - recall: 0.8400 - f1_score: 0.8722 - val_loss: 0.5124 - val_precision: 0.6304 - val_recall: 0.4833 - val_f1_score: 0.5472\n",
            "Epoch 2225/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2583 - precision: 0.9369 - recall: 0.8467 - f1_score: 0.8893 - val_loss: 0.5125 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 2226/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2612 - precision: 0.9176 - recall: 0.8200 - f1_score: 0.8657 - val_loss: 0.5132 - val_precision: 0.6042 - val_recall: 0.4833 - val_f1_score: 0.5370\n",
            "Epoch 2227/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2583 - precision: 0.9313 - recall: 0.8567 - f1_score: 0.8923 - val_loss: 0.5120 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2228/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2575 - precision: 0.9321 - recall: 0.8333 - f1_score: 0.8796 - val_loss: 0.5161 - val_precision: 0.5714 - val_recall: 0.4667 - val_f1_score: 0.5138\n",
            "Epoch 2229/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2598 - precision: 0.9197 - recall: 0.8300 - f1_score: 0.8723 - val_loss: 0.5123 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2230/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.2605 - precision: 0.9176 - recall: 0.8267 - f1_score: 0.8695 - val_loss: 0.5133 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 2231/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.2606 - precision: 0.9300 - recall: 0.8333 - f1_score: 0.8787 - val_loss: 0.5129 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2232/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2573 - precision: 0.9396 - recall: 0.8567 - f1_score: 0.8957 - val_loss: 0.5121 - val_precision: 0.6279 - val_recall: 0.4500 - val_f1_score: 0.5243\n",
            "Epoch 2233/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2585 - precision: 0.9260 - recall: 0.8267 - f1_score: 0.8731 - val_loss: 0.5136 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 2234/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2623 - precision: 0.9330 - recall: 0.8300 - f1_score: 0.8782 - val_loss: 0.5154 - val_precision: 0.5625 - val_recall: 0.4500 - val_f1_score: 0.5000\n",
            "Epoch 2235/3000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.2561 - precision: 0.9367 - recall: 0.8467 - f1_score: 0.8891 - val_loss: 0.5142 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 2236/3000\n",
            "300/300 [==============================] - 0s 117us/step - loss: 0.2586 - precision: 0.9187 - recall: 0.8333 - f1_score: 0.8736 - val_loss: 0.5139 - val_precision: 0.6383 - val_recall: 0.5000 - val_f1_score: 0.5607\n",
            "Epoch 2237/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2565 - precision: 0.9344 - recall: 0.8500 - f1_score: 0.8899 - val_loss: 0.5129 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 2238/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.2601 - precision: 0.9148 - recall: 0.8233 - f1_score: 0.8664 - val_loss: 0.5141 - val_precision: 0.5800 - val_recall: 0.4833 - val_f1_score: 0.5273\n",
            "Epoch 2239/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2557 - precision: 0.9416 - recall: 0.8600 - f1_score: 0.8986 - val_loss: 0.5142 - val_precision: 0.5870 - val_recall: 0.4500 - val_f1_score: 0.5094\n",
            "Epoch 2240/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2600 - precision: 0.9090 - recall: 0.8300 - f1_score: 0.8675 - val_loss: 0.5128 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2241/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.2571 - precision: 0.9302 - recall: 0.8367 - f1_score: 0.8807 - val_loss: 0.5127 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2242/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2568 - precision: 0.9413 - recall: 0.8500 - f1_score: 0.8931 - val_loss: 0.5146 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 2243/3000\n",
            "300/300 [==============================] - 0s 78us/step - loss: 0.2576 - precision: 0.9327 - recall: 0.8333 - f1_score: 0.8797 - val_loss: 0.5128 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2244/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2557 - precision: 0.9233 - recall: 0.8400 - f1_score: 0.8796 - val_loss: 0.5205 - val_precision: 0.5510 - val_recall: 0.4500 - val_f1_score: 0.4954\n",
            "Epoch 2245/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.2571 - precision: 0.9332 - recall: 0.8467 - f1_score: 0.8874 - val_loss: 0.5137 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 2246/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2572 - precision: 0.9365 - recall: 0.8333 - f1_score: 0.8818 - val_loss: 0.5132 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2247/3000\n",
            "300/300 [==============================] - 0s 129us/step - loss: 0.2583 - precision: 0.9411 - recall: 0.8367 - f1_score: 0.8855 - val_loss: 0.5141 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2248/3000\n",
            "300/300 [==============================] - 0s 113us/step - loss: 0.2579 - precision: 0.9310 - recall: 0.8500 - f1_score: 0.8885 - val_loss: 0.5127 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2249/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2585 - precision: 0.9260 - recall: 0.8400 - f1_score: 0.8807 - val_loss: 0.5146 - val_precision: 0.5800 - val_recall: 0.4833 - val_f1_score: 0.5273\n",
            "Epoch 2250/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.2617 - precision: 0.9262 - recall: 0.8400 - f1_score: 0.8809 - val_loss: 0.5181 - val_precision: 0.5600 - val_recall: 0.4667 - val_f1_score: 0.5091\n",
            "Epoch 2251/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2574 - precision: 0.9234 - recall: 0.8433 - f1_score: 0.8814 - val_loss: 0.5158 - val_precision: 0.5714 - val_recall: 0.4667 - val_f1_score: 0.5138\n",
            "Epoch 2252/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.2594 - precision: 0.9085 - recall: 0.8300 - f1_score: 0.8674 - val_loss: 0.5185 - val_precision: 0.5490 - val_recall: 0.4667 - val_f1_score: 0.5045\n",
            "Epoch 2253/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2586 - precision: 0.9356 - recall: 0.8400 - f1_score: 0.8848 - val_loss: 0.5173 - val_precision: 0.5600 - val_recall: 0.4667 - val_f1_score: 0.5091\n",
            "Epoch 2254/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2570 - precision: 0.9251 - recall: 0.8433 - f1_score: 0.8817 - val_loss: 0.5176 - val_precision: 0.5510 - val_recall: 0.4500 - val_f1_score: 0.4954\n",
            "Epoch 2255/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2577 - precision: 0.9481 - recall: 0.8433 - f1_score: 0.8922 - val_loss: 0.5147 - val_precision: 0.5800 - val_recall: 0.4833 - val_f1_score: 0.5273\n",
            "Epoch 2256/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2571 - precision: 0.9479 - recall: 0.8500 - f1_score: 0.8959 - val_loss: 0.5168 - val_precision: 0.5510 - val_recall: 0.4500 - val_f1_score: 0.4954\n",
            "Epoch 2257/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.2618 - precision: 0.9326 - recall: 0.8267 - f1_score: 0.8763 - val_loss: 0.5135 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 2258/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.2573 - precision: 0.9226 - recall: 0.8267 - f1_score: 0.8717 - val_loss: 0.5130 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2259/3000\n",
            "300/300 [==============================] - 0s 106us/step - loss: 0.2563 - precision: 0.9375 - recall: 0.8433 - f1_score: 0.8872 - val_loss: 0.5148 - val_precision: 0.5870 - val_recall: 0.4500 - val_f1_score: 0.5094\n",
            "Epoch 2260/3000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.2590 - precision: 0.9144 - recall: 0.8267 - f1_score: 0.8681 - val_loss: 0.5174 - val_precision: 0.5600 - val_recall: 0.4667 - val_f1_score: 0.5091\n",
            "Epoch 2261/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2597 - precision: 0.9166 - recall: 0.8400 - f1_score: 0.8765 - val_loss: 0.5162 - val_precision: 0.5714 - val_recall: 0.4667 - val_f1_score: 0.5138\n",
            "Epoch 2262/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2589 - precision: 0.9321 - recall: 0.8200 - f1_score: 0.8720 - val_loss: 0.5148 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2263/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2582 - precision: 0.9306 - recall: 0.8500 - f1_score: 0.8884 - val_loss: 0.5136 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2264/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2576 - precision: 0.9280 - recall: 0.8267 - f1_score: 0.8740 - val_loss: 0.5153 - val_precision: 0.5714 - val_recall: 0.4667 - val_f1_score: 0.5138\n",
            "Epoch 2265/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2574 - precision: 0.9311 - recall: 0.8500 - f1_score: 0.8884 - val_loss: 0.5137 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2266/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2556 - precision: 0.9511 - recall: 0.8400 - f1_score: 0.8920 - val_loss: 0.5154 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2267/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2574 - precision: 0.9214 - recall: 0.8267 - f1_score: 0.8711 - val_loss: 0.5197 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2268/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2601 - precision: 0.9217 - recall: 0.8333 - f1_score: 0.8751 - val_loss: 0.5132 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 2269/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2580 - precision: 0.9251 - recall: 0.8233 - f1_score: 0.8706 - val_loss: 0.5157 - val_precision: 0.5714 - val_recall: 0.4667 - val_f1_score: 0.5138\n",
            "Epoch 2270/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2572 - precision: 0.9374 - recall: 0.8533 - f1_score: 0.8932 - val_loss: 0.5133 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 2271/3000\n",
            "300/300 [==============================] - 0s 101us/step - loss: 0.2558 - precision: 0.9249 - recall: 0.8300 - f1_score: 0.8744 - val_loss: 0.5175 - val_precision: 0.5600 - val_recall: 0.4667 - val_f1_score: 0.5091\n",
            "Epoch 2272/3000\n",
            "300/300 [==============================] - 0s 109us/step - loss: 0.2558 - precision: 0.9271 - recall: 0.8500 - f1_score: 0.8864 - val_loss: 0.5140 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2273/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2554 - precision: 0.9369 - recall: 0.8500 - f1_score: 0.8911 - val_loss: 0.5139 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2274/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2549 - precision: 0.9300 - recall: 0.8367 - f1_score: 0.8808 - val_loss: 0.5235 - val_precision: 0.5833 - val_recall: 0.4667 - val_f1_score: 0.5185\n",
            "Epoch 2275/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2555 - precision: 0.9369 - recall: 0.8333 - f1_score: 0.8819 - val_loss: 0.5151 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 2276/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2556 - precision: 0.9345 - recall: 0.8533 - f1_score: 0.8918 - val_loss: 0.5146 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2277/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2567 - precision: 0.9294 - recall: 0.8367 - f1_score: 0.8805 - val_loss: 0.5189 - val_precision: 0.6042 - val_recall: 0.4833 - val_f1_score: 0.5370\n",
            "Epoch 2278/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2624 - precision: 0.9115 - recall: 0.8233 - f1_score: 0.8648 - val_loss: 0.5166 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2279/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2583 - precision: 0.9134 - recall: 0.8367 - f1_score: 0.8731 - val_loss: 0.5165 - val_precision: 0.5625 - val_recall: 0.4500 - val_f1_score: 0.5000\n",
            "Epoch 2280/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2573 - precision: 0.9312 - recall: 0.8500 - f1_score: 0.8885 - val_loss: 0.5163 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2281/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2559 - precision: 0.9435 - recall: 0.8367 - f1_score: 0.8869 - val_loss: 0.5160 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2282/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2572 - precision: 0.9292 - recall: 0.8267 - f1_score: 0.8740 - val_loss: 0.5196 - val_precision: 0.5600 - val_recall: 0.4667 - val_f1_score: 0.5091\n",
            "Epoch 2283/3000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.2547 - precision: 0.9226 - recall: 0.8433 - f1_score: 0.8808 - val_loss: 0.5144 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2284/3000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.2549 - precision: 0.9368 - recall: 0.8433 - f1_score: 0.8875 - val_loss: 0.5143 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2285/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2554 - precision: 0.9396 - recall: 0.8333 - f1_score: 0.8829 - val_loss: 0.5138 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2286/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2559 - precision: 0.9266 - recall: 0.8367 - f1_score: 0.8792 - val_loss: 0.5144 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2287/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.2547 - precision: 0.9389 - recall: 0.8467 - f1_score: 0.8895 - val_loss: 0.5143 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2288/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2583 - precision: 0.9325 - recall: 0.8333 - f1_score: 0.8799 - val_loss: 0.5142 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2289/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2568 - precision: 0.9434 - recall: 0.8367 - f1_score: 0.8864 - val_loss: 0.5172 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 2290/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2566 - precision: 0.9195 - recall: 0.8333 - f1_score: 0.8742 - val_loss: 0.5149 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2291/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2543 - precision: 0.9396 - recall: 0.8333 - f1_score: 0.8822 - val_loss: 0.5233 - val_precision: 0.5625 - val_recall: 0.4500 - val_f1_score: 0.5000\n",
            "Epoch 2292/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2570 - precision: 0.9287 - recall: 0.8367 - f1_score: 0.8800 - val_loss: 0.5152 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 2293/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2550 - precision: 0.9341 - recall: 0.8467 - f1_score: 0.8880 - val_loss: 0.5140 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2294/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2561 - precision: 0.9169 - recall: 0.8533 - f1_score: 0.8837 - val_loss: 0.5151 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2295/3000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.2567 - precision: 0.9153 - recall: 0.8200 - f1_score: 0.8646 - val_loss: 0.5154 - val_precision: 0.6042 - val_recall: 0.4833 - val_f1_score: 0.5370\n",
            "Epoch 2296/3000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.2543 - precision: 0.9375 - recall: 0.8500 - f1_score: 0.8900 - val_loss: 0.5163 - val_precision: 0.5714 - val_recall: 0.4667 - val_f1_score: 0.5138\n",
            "Epoch 2297/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2560 - precision: 0.9255 - recall: 0.8300 - f1_score: 0.8751 - val_loss: 0.5166 - val_precision: 0.5714 - val_recall: 0.4667 - val_f1_score: 0.5138\n",
            "Epoch 2298/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.2542 - precision: 0.9446 - recall: 0.8567 - f1_score: 0.8984 - val_loss: 0.5142 - val_precision: 0.6279 - val_recall: 0.4500 - val_f1_score: 0.5243\n",
            "Epoch 2299/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2552 - precision: 0.9224 - recall: 0.8367 - f1_score: 0.8772 - val_loss: 0.5198 - val_precision: 0.5510 - val_recall: 0.4500 - val_f1_score: 0.4954\n",
            "Epoch 2300/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2552 - precision: 0.9401 - recall: 0.8367 - f1_score: 0.8852 - val_loss: 0.5142 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2301/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2537 - precision: 0.9373 - recall: 0.8467 - f1_score: 0.8894 - val_loss: 0.5149 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2302/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2559 - precision: 0.9259 - recall: 0.8333 - f1_score: 0.8772 - val_loss: 0.5149 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2303/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2543 - precision: 0.9157 - recall: 0.8367 - f1_score: 0.8739 - val_loss: 0.5162 - val_precision: 0.5957 - val_recall: 0.4667 - val_f1_score: 0.5234\n",
            "Epoch 2304/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2568 - precision: 0.9415 - recall: 0.8433 - f1_score: 0.8890 - val_loss: 0.5143 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2305/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2554 - precision: 0.9336 - recall: 0.8467 - f1_score: 0.8879 - val_loss: 0.5156 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 2306/3000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.2547 - precision: 0.9297 - recall: 0.8433 - f1_score: 0.8843 - val_loss: 0.5159 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 2307/3000\n",
            "300/300 [==============================] - 0s 101us/step - loss: 0.2546 - precision: 0.9170 - recall: 0.8400 - f1_score: 0.8766 - val_loss: 0.5170 - val_precision: 0.5625 - val_recall: 0.4500 - val_f1_score: 0.5000\n",
            "Epoch 2308/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2536 - precision: 0.9444 - recall: 0.8467 - f1_score: 0.8926 - val_loss: 0.5151 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2309/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2535 - precision: 0.9407 - recall: 0.8367 - f1_score: 0.8855 - val_loss: 0.5160 - val_precision: 0.6042 - val_recall: 0.4833 - val_f1_score: 0.5370\n",
            "Epoch 2310/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2521 - precision: 0.9344 - recall: 0.8567 - f1_score: 0.8936 - val_loss: 0.5217 - val_precision: 0.6122 - val_recall: 0.5000 - val_f1_score: 0.5505\n",
            "Epoch 2311/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2571 - precision: 0.9223 - recall: 0.8300 - f1_score: 0.8736 - val_loss: 0.5186 - val_precision: 0.5400 - val_recall: 0.4500 - val_f1_score: 0.4909\n",
            "Epoch 2312/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.2610 - precision: 0.9085 - recall: 0.8167 - f1_score: 0.8593 - val_loss: 0.5179 - val_precision: 0.5714 - val_recall: 0.4667 - val_f1_score: 0.5138\n",
            "Epoch 2313/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2545 - precision: 0.9136 - recall: 0.8467 - f1_score: 0.8785 - val_loss: 0.5154 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2314/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2528 - precision: 0.9409 - recall: 0.8467 - f1_score: 0.8911 - val_loss: 0.5147 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2315/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2531 - precision: 0.9448 - recall: 0.8500 - f1_score: 0.8948 - val_loss: 0.5172 - val_precision: 0.5714 - val_recall: 0.4667 - val_f1_score: 0.5138\n",
            "Epoch 2316/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2544 - precision: 0.9406 - recall: 0.8467 - f1_score: 0.8909 - val_loss: 0.5149 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2317/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2540 - precision: 0.9332 - recall: 0.8367 - f1_score: 0.8818 - val_loss: 0.5243 - val_precision: 0.5400 - val_recall: 0.4500 - val_f1_score: 0.4909\n",
            "Epoch 2318/3000\n",
            "300/300 [==============================] - 0s 111us/step - loss: 0.2576 - precision: 0.9159 - recall: 0.8300 - f1_score: 0.8705 - val_loss: 0.5150 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2319/3000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.2541 - precision: 0.9342 - recall: 0.8500 - f1_score: 0.8900 - val_loss: 0.5152 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 2320/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2538 - precision: 0.9162 - recall: 0.8433 - f1_score: 0.8781 - val_loss: 0.5172 - val_precision: 0.6250 - val_recall: 0.5000 - val_f1_score: 0.5556\n",
            "Epoch 2321/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2532 - precision: 0.9419 - recall: 0.8500 - f1_score: 0.8924 - val_loss: 0.5163 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2322/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2529 - precision: 0.9085 - recall: 0.8333 - f1_score: 0.8691 - val_loss: 0.5161 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2323/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2534 - precision: 0.9436 - recall: 0.8433 - f1_score: 0.8906 - val_loss: 0.5149 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2324/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2558 - precision: 0.9199 - recall: 0.8433 - f1_score: 0.8799 - val_loss: 0.5154 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2325/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2563 - precision: 0.9314 - recall: 0.8267 - f1_score: 0.8751 - val_loss: 0.5158 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2326/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2539 - precision: 0.9292 - recall: 0.8467 - f1_score: 0.8852 - val_loss: 0.5161 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2327/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2532 - precision: 0.9398 - recall: 0.8400 - f1_score: 0.8869 - val_loss: 0.5150 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 2328/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2531 - precision: 0.9339 - recall: 0.8467 - f1_score: 0.8881 - val_loss: 0.5155 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2329/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2539 - precision: 0.9413 - recall: 0.8533 - f1_score: 0.8951 - val_loss: 0.5159 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 2330/3000\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.2524 - precision: 0.9372 - recall: 0.8400 - f1_score: 0.8858 - val_loss: 0.5165 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 2331/3000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.2527 - precision: 0.9440 - recall: 0.8500 - f1_score: 0.8942 - val_loss: 0.5163 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2332/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2532 - precision: 0.9439 - recall: 0.8433 - f1_score: 0.8904 - val_loss: 0.5170 - val_precision: 0.6122 - val_recall: 0.5000 - val_f1_score: 0.5505\n",
            "Epoch 2333/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2552 - precision: 0.9410 - recall: 0.8533 - f1_score: 0.8949 - val_loss: 0.5181 - val_precision: 0.5625 - val_recall: 0.4500 - val_f1_score: 0.5000\n",
            "Epoch 2334/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2548 - precision: 0.9234 - recall: 0.8467 - f1_score: 0.8832 - val_loss: 0.5160 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2335/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.2542 - precision: 0.9417 - recall: 0.8567 - f1_score: 0.8968 - val_loss: 0.5155 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2336/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2538 - precision: 0.9440 - recall: 0.8467 - f1_score: 0.8926 - val_loss: 0.5181 - val_precision: 0.5870 - val_recall: 0.4500 - val_f1_score: 0.5094\n",
            "Epoch 2337/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2531 - precision: 0.9136 - recall: 0.8433 - f1_score: 0.8768 - val_loss: 0.5181 - val_precision: 0.5625 - val_recall: 0.4500 - val_f1_score: 0.5000\n",
            "Epoch 2338/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2542 - precision: 0.9410 - recall: 0.8533 - f1_score: 0.8950 - val_loss: 0.5169 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 2339/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2521 - precision: 0.9282 - recall: 0.8500 - f1_score: 0.8871 - val_loss: 0.5171 - val_precision: 0.6042 - val_recall: 0.4833 - val_f1_score: 0.5370\n",
            "Epoch 2340/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2550 - precision: 0.9221 - recall: 0.8367 - f1_score: 0.8771 - val_loss: 0.5159 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2341/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2526 - precision: 0.9499 - recall: 0.8633 - f1_score: 0.9041 - val_loss: 0.5154 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2342/3000\n",
            "300/300 [==============================] - 0s 103us/step - loss: 0.2538 - precision: 0.9185 - recall: 0.8300 - f1_score: 0.8720 - val_loss: 0.5162 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2343/3000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.2535 - precision: 0.9197 - recall: 0.8367 - f1_score: 0.8762 - val_loss: 0.5162 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2344/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2537 - precision: 0.9290 - recall: 0.8400 - f1_score: 0.8818 - val_loss: 0.5167 - val_precision: 0.6304 - val_recall: 0.4833 - val_f1_score: 0.5472\n",
            "Epoch 2345/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2520 - precision: 0.9416 - recall: 0.8633 - f1_score: 0.9006 - val_loss: 0.5158 - val_precision: 0.6304 - val_recall: 0.4833 - val_f1_score: 0.5472\n",
            "Epoch 2346/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2521 - precision: 0.9507 - recall: 0.8500 - f1_score: 0.8972 - val_loss: 0.5161 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2347/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2526 - precision: 0.9440 - recall: 0.8367 - f1_score: 0.8868 - val_loss: 0.5193 - val_precision: 0.5600 - val_recall: 0.4667 - val_f1_score: 0.5091\n",
            "Epoch 2348/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2520 - precision: 0.9418 - recall: 0.8567 - f1_score: 0.8969 - val_loss: 0.5158 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2349/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2517 - precision: 0.9305 - recall: 0.8400 - f1_score: 0.8827 - val_loss: 0.5185 - val_precision: 0.5600 - val_recall: 0.4667 - val_f1_score: 0.5091\n",
            "Epoch 2350/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.2528 - precision: 0.9456 - recall: 0.8633 - f1_score: 0.9023 - val_loss: 0.5167 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2351/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.2527 - precision: 0.9234 - recall: 0.8400 - f1_score: 0.8796 - val_loss: 0.5206 - val_precision: 0.5510 - val_recall: 0.4500 - val_f1_score: 0.4954\n",
            "Epoch 2352/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2565 - precision: 0.9308 - recall: 0.8467 - f1_score: 0.8864 - val_loss: 0.5169 - val_precision: 0.5957 - val_recall: 0.4667 - val_f1_score: 0.5234\n",
            "Epoch 2353/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2522 - precision: 0.9232 - recall: 0.8467 - f1_score: 0.8832 - val_loss: 0.5159 - val_precision: 0.6279 - val_recall: 0.4500 - val_f1_score: 0.5243\n",
            "Epoch 2354/3000\n",
            "300/300 [==============================] - 0s 112us/step - loss: 0.2526 - precision: 0.9240 - recall: 0.8500 - f1_score: 0.8852 - val_loss: 0.5162 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2355/3000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.2546 - precision: 0.9275 - recall: 0.8500 - f1_score: 0.8870 - val_loss: 0.5172 - val_precision: 0.6042 - val_recall: 0.4833 - val_f1_score: 0.5370\n",
            "Epoch 2356/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2580 - precision: 0.9369 - recall: 0.8367 - f1_score: 0.8838 - val_loss: 0.5171 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 2357/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2525 - precision: 0.9368 - recall: 0.8333 - f1_score: 0.8817 - val_loss: 0.5181 - val_precision: 0.5800 - val_recall: 0.4833 - val_f1_score: 0.5273\n",
            "Epoch 2358/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2534 - precision: 0.9375 - recall: 0.8433 - f1_score: 0.8872 - val_loss: 0.5173 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2359/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2548 - precision: 0.9193 - recall: 0.8367 - f1_score: 0.8760 - val_loss: 0.5179 - val_precision: 0.6122 - val_recall: 0.5000 - val_f1_score: 0.5505\n",
            "Epoch 2360/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2523 - precision: 0.9300 - recall: 0.8400 - f1_score: 0.8819 - val_loss: 0.5204 - val_precision: 0.5400 - val_recall: 0.4500 - val_f1_score: 0.4909\n",
            "Epoch 2361/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2504 - precision: 0.9406 - recall: 0.8500 - f1_score: 0.8927 - val_loss: 0.5167 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 2362/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2542 - precision: 0.9333 - recall: 0.8367 - f1_score: 0.8822 - val_loss: 0.5161 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2363/3000\n",
            "300/300 [==============================] - 0s 59us/step - loss: 0.2547 - precision: 0.9298 - recall: 0.8367 - f1_score: 0.8805 - val_loss: 0.5175 - val_precision: 0.6042 - val_recall: 0.4833 - val_f1_score: 0.5370\n",
            "Epoch 2364/3000\n",
            "300/300 [==============================] - 0s 58us/step - loss: 0.2511 - precision: 0.9437 - recall: 0.8567 - f1_score: 0.8977 - val_loss: 0.5161 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2365/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.2545 - precision: 0.9151 - recall: 0.8300 - f1_score: 0.8703 - val_loss: 0.5254 - val_precision: 0.5490 - val_recall: 0.4667 - val_f1_score: 0.5045\n",
            "Epoch 2366/3000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.2513 - precision: 0.9161 - recall: 0.8500 - f1_score: 0.8816 - val_loss: 0.5162 - val_precision: 0.6279 - val_recall: 0.4500 - val_f1_score: 0.5243\n",
            "Epoch 2367/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.2545 - precision: 0.9257 - recall: 0.8400 - f1_score: 0.8804 - val_loss: 0.5164 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2368/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2537 - precision: 0.9380 - recall: 0.8467 - f1_score: 0.8897 - val_loss: 0.5165 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 2369/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2537 - precision: 0.9209 - recall: 0.8233 - f1_score: 0.8692 - val_loss: 0.5178 - val_precision: 0.6383 - val_recall: 0.5000 - val_f1_score: 0.5607\n",
            "Epoch 2370/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2506 - precision: 0.9363 - recall: 0.8400 - f1_score: 0.8850 - val_loss: 0.5235 - val_precision: 0.5400 - val_recall: 0.4500 - val_f1_score: 0.4909\n",
            "Epoch 2371/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2538 - precision: 0.9295 - recall: 0.8300 - f1_score: 0.8767 - val_loss: 0.5212 - val_precision: 0.5600 - val_recall: 0.4667 - val_f1_score: 0.5091\n",
            "Epoch 2372/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2513 - precision: 0.9481 - recall: 0.8467 - f1_score: 0.8943 - val_loss: 0.5164 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2373/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2514 - precision: 0.9406 - recall: 0.8500 - f1_score: 0.8928 - val_loss: 0.5173 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 2374/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2519 - precision: 0.9064 - recall: 0.8367 - f1_score: 0.8700 - val_loss: 0.5243 - val_precision: 0.5510 - val_recall: 0.4500 - val_f1_score: 0.4954\n",
            "Epoch 2375/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2534 - precision: 0.9288 - recall: 0.8300 - f1_score: 0.8765 - val_loss: 0.5165 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2376/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.2515 - precision: 0.9408 - recall: 0.8433 - f1_score: 0.8890 - val_loss: 0.5163 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2377/3000\n",
            "300/300 [==============================] - 0s 81us/step - loss: 0.2525 - precision: 0.9122 - recall: 0.8367 - f1_score: 0.8726 - val_loss: 0.5218 - val_precision: 0.5600 - val_recall: 0.4667 - val_f1_score: 0.5091\n",
            "Epoch 2378/3000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.2514 - precision: 0.9365 - recall: 0.8400 - f1_score: 0.8855 - val_loss: 0.5212 - val_precision: 0.5400 - val_recall: 0.4500 - val_f1_score: 0.4909\n",
            "Epoch 2379/3000\n",
            "300/300 [==============================] - 0s 81us/step - loss: 0.2513 - precision: 0.9436 - recall: 0.8433 - f1_score: 0.8902 - val_loss: 0.5193 - val_precision: 0.5918 - val_recall: 0.4833 - val_f1_score: 0.5321\n",
            "Epoch 2380/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2542 - precision: 0.9377 - recall: 0.8400 - f1_score: 0.8858 - val_loss: 0.5165 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2381/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2503 - precision: 0.9329 - recall: 0.8367 - f1_score: 0.8820 - val_loss: 0.5228 - val_precision: 0.5600 - val_recall: 0.4667 - val_f1_score: 0.5091\n",
            "Epoch 2382/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2526 - precision: 0.9241 - recall: 0.8533 - f1_score: 0.8871 - val_loss: 0.5282 - val_precision: 0.5745 - val_recall: 0.4500 - val_f1_score: 0.5047\n",
            "Epoch 2383/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2541 - precision: 0.9142 - recall: 0.8267 - f1_score: 0.8679 - val_loss: 0.5171 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 2384/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2548 - precision: 0.9203 - recall: 0.8467 - f1_score: 0.8816 - val_loss: 0.5171 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2385/3000\n",
            "300/300 [==============================] - 0s 59us/step - loss: 0.2525 - precision: 0.9308 - recall: 0.8500 - f1_score: 0.8883 - val_loss: 0.5180 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2386/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2506 - precision: 0.9308 - recall: 0.8433 - f1_score: 0.8846 - val_loss: 0.5182 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2387/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2526 - precision: 0.9307 - recall: 0.8467 - f1_score: 0.8866 - val_loss: 0.5178 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2388/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2534 - precision: 0.9126 - recall: 0.8367 - f1_score: 0.8728 - val_loss: 0.5181 - val_precision: 0.6042 - val_recall: 0.4833 - val_f1_score: 0.5370\n",
            "Epoch 2389/3000\n",
            "300/300 [==============================] - 0s 110us/step - loss: 0.2513 - precision: 0.9479 - recall: 0.8467 - f1_score: 0.8941 - val_loss: 0.5175 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2390/3000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.2505 - precision: 0.9431 - recall: 0.8500 - f1_score: 0.8932 - val_loss: 0.5167 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2391/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2517 - precision: 0.9130 - recall: 0.8400 - f1_score: 0.8748 - val_loss: 0.5184 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2392/3000\n",
            "300/300 [==============================] - 0s 59us/step - loss: 0.2542 - precision: 0.9193 - recall: 0.8333 - f1_score: 0.8741 - val_loss: 0.5168 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2393/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2505 - precision: 0.9155 - recall: 0.8300 - f1_score: 0.8703 - val_loss: 0.5170 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2394/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2510 - precision: 0.9447 - recall: 0.8533 - f1_score: 0.8963 - val_loss: 0.5199 - val_precision: 0.5600 - val_recall: 0.4667 - val_f1_score: 0.5091\n",
            "Epoch 2395/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2489 - precision: 0.9399 - recall: 0.8500 - f1_score: 0.8925 - val_loss: 0.5177 - val_precision: 0.5957 - val_recall: 0.4667 - val_f1_score: 0.5234\n",
            "Epoch 2396/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2509 - precision: 0.9337 - recall: 0.8467 - f1_score: 0.8880 - val_loss: 0.5180 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2397/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.2509 - precision: 0.9444 - recall: 0.8467 - f1_score: 0.8925 - val_loss: 0.5178 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2398/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2495 - precision: 0.9475 - recall: 0.8400 - f1_score: 0.8902 - val_loss: 0.5174 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2399/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2504 - precision: 0.9479 - recall: 0.8433 - f1_score: 0.8918 - val_loss: 0.5172 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2400/3000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.2527 - precision: 0.9276 - recall: 0.8400 - f1_score: 0.8811 - val_loss: 0.5180 - val_precision: 0.6304 - val_recall: 0.4833 - val_f1_score: 0.5472\n",
            "Epoch 2401/3000\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.2512 - precision: 0.9396 - recall: 0.8500 - f1_score: 0.8916 - val_loss: 0.5199 - val_precision: 0.5625 - val_recall: 0.4500 - val_f1_score: 0.5000\n",
            "Epoch 2402/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.2519 - precision: 0.9264 - recall: 0.8367 - f1_score: 0.8789 - val_loss: 0.5209 - val_precision: 0.5510 - val_recall: 0.4500 - val_f1_score: 0.4954\n",
            "Epoch 2403/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2498 - precision: 0.9445 - recall: 0.8633 - f1_score: 0.9018 - val_loss: 0.5171 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2404/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2498 - precision: 0.9179 - recall: 0.8567 - f1_score: 0.8859 - val_loss: 0.5215 - val_precision: 0.5686 - val_recall: 0.4833 - val_f1_score: 0.5225\n",
            "Epoch 2405/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2513 - precision: 0.9445 - recall: 0.8467 - f1_score: 0.8928 - val_loss: 0.5212 - val_precision: 0.5400 - val_recall: 0.4500 - val_f1_score: 0.4909\n",
            "Epoch 2406/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2520 - precision: 0.9451 - recall: 0.8500 - f1_score: 0.8949 - val_loss: 0.5182 - val_precision: 0.5957 - val_recall: 0.4667 - val_f1_score: 0.5234\n",
            "Epoch 2407/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2489 - precision: 0.9406 - recall: 0.8433 - f1_score: 0.8887 - val_loss: 0.5214 - val_precision: 0.5600 - val_recall: 0.4667 - val_f1_score: 0.5091\n",
            "Epoch 2408/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2501 - precision: 0.9445 - recall: 0.8500 - f1_score: 0.8947 - val_loss: 0.5175 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2409/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.2492 - precision: 0.9433 - recall: 0.8367 - f1_score: 0.8864 - val_loss: 0.5227 - val_precision: 0.6042 - val_recall: 0.4833 - val_f1_score: 0.5370\n",
            "Epoch 2410/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.2531 - precision: 0.9255 - recall: 0.8333 - f1_score: 0.8765 - val_loss: 0.5175 - val_precision: 0.6279 - val_recall: 0.4500 - val_f1_score: 0.5243\n",
            "Epoch 2411/3000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.2507 - precision: 0.9302 - recall: 0.8433 - f1_score: 0.8846 - val_loss: 0.5265 - val_precision: 0.6122 - val_recall: 0.5000 - val_f1_score: 0.5505\n",
            "Epoch 2412/3000\n",
            "300/300 [==============================] - 0s 112us/step - loss: 0.2526 - precision: 0.9205 - recall: 0.8500 - f1_score: 0.8837 - val_loss: 0.5174 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2413/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2507 - precision: 0.9270 - recall: 0.8433 - f1_score: 0.8831 - val_loss: 0.5179 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2414/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2492 - precision: 0.9263 - recall: 0.8467 - f1_score: 0.8846 - val_loss: 0.5202 - val_precision: 0.5625 - val_recall: 0.4500 - val_f1_score: 0.5000\n",
            "Epoch 2415/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2525 - precision: 0.9331 - recall: 0.8467 - f1_score: 0.8875 - val_loss: 0.5205 - val_precision: 0.5625 - val_recall: 0.4500 - val_f1_score: 0.5000\n",
            "Epoch 2416/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2481 - precision: 0.9342 - recall: 0.8500 - f1_score: 0.8900 - val_loss: 0.5183 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 2417/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2490 - precision: 0.9264 - recall: 0.8400 - f1_score: 0.8809 - val_loss: 0.5191 - val_precision: 0.5800 - val_recall: 0.4833 - val_f1_score: 0.5273\n",
            "Epoch 2418/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2491 - precision: 0.9372 - recall: 0.8500 - f1_score: 0.8913 - val_loss: 0.5173 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2419/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2491 - precision: 0.9310 - recall: 0.8467 - f1_score: 0.8864 - val_loss: 0.5192 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2420/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2527 - precision: 0.9370 - recall: 0.8400 - f1_score: 0.8855 - val_loss: 0.5195 - val_precision: 0.5957 - val_recall: 0.4667 - val_f1_score: 0.5234\n",
            "Epoch 2421/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2496 - precision: 0.9371 - recall: 0.8467 - f1_score: 0.8892 - val_loss: 0.5233 - val_precision: 0.5490 - val_recall: 0.4667 - val_f1_score: 0.5045\n",
            "Epoch 2422/3000\n",
            "300/300 [==============================] - 0s 105us/step - loss: 0.2508 - precision: 0.9405 - recall: 0.8367 - f1_score: 0.8851 - val_loss: 0.5199 - val_precision: 0.6250 - val_recall: 0.5000 - val_f1_score: 0.5556\n",
            "Epoch 2423/3000\n",
            "300/300 [==============================] - 0s 104us/step - loss: 0.2497 - precision: 0.9450 - recall: 0.8567 - f1_score: 0.8986 - val_loss: 0.5181 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2424/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2516 - precision: 0.9292 - recall: 0.8367 - f1_score: 0.8803 - val_loss: 0.5214 - val_precision: 0.5510 - val_recall: 0.4500 - val_f1_score: 0.4954\n",
            "Epoch 2425/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.2505 - precision: 0.9302 - recall: 0.8500 - f1_score: 0.8883 - val_loss: 0.5188 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 2426/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.2504 - precision: 0.9148 - recall: 0.8367 - f1_score: 0.8735 - val_loss: 0.5183 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2427/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2487 - precision: 0.9354 - recall: 0.8600 - f1_score: 0.8959 - val_loss: 0.5195 - val_precision: 0.5800 - val_recall: 0.4833 - val_f1_score: 0.5273\n",
            "Epoch 2428/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2492 - precision: 0.9372 - recall: 0.8467 - f1_score: 0.8895 - val_loss: 0.5177 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2429/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2510 - precision: 0.9293 - recall: 0.8500 - f1_score: 0.8872 - val_loss: 0.5207 - val_precision: 0.5625 - val_recall: 0.4500 - val_f1_score: 0.5000\n",
            "Epoch 2430/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2492 - precision: 0.9336 - recall: 0.8433 - f1_score: 0.8861 - val_loss: 0.5298 - val_precision: 0.5870 - val_recall: 0.4500 - val_f1_score: 0.5094\n",
            "Epoch 2431/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2504 - precision: 0.9258 - recall: 0.8367 - f1_score: 0.8788 - val_loss: 0.5177 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 2432/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2485 - precision: 0.9488 - recall: 0.8567 - f1_score: 0.9003 - val_loss: 0.5177 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 2433/3000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.2493 - precision: 0.9377 - recall: 0.8467 - f1_score: 0.8895 - val_loss: 0.5180 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2434/3000\n",
            "300/300 [==============================] - 0s 122us/step - loss: 0.2495 - precision: 0.9329 - recall: 0.8400 - f1_score: 0.8838 - val_loss: 0.5192 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2435/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2484 - precision: 0.9416 - recall: 0.8533 - f1_score: 0.8952 - val_loss: 0.5193 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 2436/3000\n",
            "300/300 [==============================] - 0s 59us/step - loss: 0.2515 - precision: 0.9398 - recall: 0.8400 - f1_score: 0.8869 - val_loss: 0.5191 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2437/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2480 - precision: 0.9440 - recall: 0.8467 - f1_score: 0.8924 - val_loss: 0.5195 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2438/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.2492 - precision: 0.9250 - recall: 0.8533 - f1_score: 0.8874 - val_loss: 0.5190 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2439/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2499 - precision: 0.9408 - recall: 0.8500 - f1_score: 0.8928 - val_loss: 0.5189 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 2440/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.2485 - precision: 0.9302 - recall: 0.8367 - f1_score: 0.8805 - val_loss: 0.5188 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2441/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.2481 - precision: 0.9374 - recall: 0.8533 - f1_score: 0.8931 - val_loss: 0.5201 - val_precision: 0.5918 - val_recall: 0.4833 - val_f1_score: 0.5321\n",
            "Epoch 2442/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2478 - precision: 0.9416 - recall: 0.8567 - f1_score: 0.8970 - val_loss: 0.5192 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2443/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2484 - precision: 0.9427 - recall: 0.8633 - f1_score: 0.9010 - val_loss: 0.5190 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2444/3000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.2480 - precision: 0.9518 - recall: 0.8500 - f1_score: 0.8979 - val_loss: 0.5184 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2445/3000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.2476 - precision: 0.9341 - recall: 0.8567 - f1_score: 0.8933 - val_loss: 0.5248 - val_precision: 0.5490 - val_recall: 0.4667 - val_f1_score: 0.5045\n",
            "Epoch 2446/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2484 - precision: 0.9411 - recall: 0.8467 - f1_score: 0.8910 - val_loss: 0.5185 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2447/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2493 - precision: 0.9299 - recall: 0.8400 - f1_score: 0.8826 - val_loss: 0.5227 - val_precision: 0.5600 - val_recall: 0.4667 - val_f1_score: 0.5091\n",
            "Epoch 2448/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2494 - precision: 0.9554 - recall: 0.8667 - f1_score: 0.9087 - val_loss: 0.5186 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2449/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2514 - precision: 0.9255 - recall: 0.8300 - f1_score: 0.8747 - val_loss: 0.5222 - val_precision: 0.5957 - val_recall: 0.4667 - val_f1_score: 0.5234\n",
            "Epoch 2450/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2505 - precision: 0.9346 - recall: 0.8333 - f1_score: 0.8803 - val_loss: 0.5215 - val_precision: 0.5600 - val_recall: 0.4667 - val_f1_score: 0.5091\n",
            "Epoch 2451/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2511 - precision: 0.9434 - recall: 0.8633 - f1_score: 0.9013 - val_loss: 0.5196 - val_precision: 0.6042 - val_recall: 0.4833 - val_f1_score: 0.5370\n",
            "Epoch 2452/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2532 - precision: 0.9240 - recall: 0.8533 - f1_score: 0.8872 - val_loss: 0.5188 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2453/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2485 - precision: 0.9346 - recall: 0.8600 - f1_score: 0.8953 - val_loss: 0.5194 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2454/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2473 - precision: 0.9338 - recall: 0.8467 - f1_score: 0.8878 - val_loss: 0.5183 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2455/3000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.2481 - precision: 0.9449 - recall: 0.8533 - f1_score: 0.8967 - val_loss: 0.5190 - val_precision: 0.6304 - val_recall: 0.4833 - val_f1_score: 0.5472\n",
            "Epoch 2456/3000\n",
            "300/300 [==============================] - 0s 106us/step - loss: 0.2478 - precision: 0.9458 - recall: 0.8600 - f1_score: 0.9006 - val_loss: 0.5190 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2457/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2480 - precision: 0.9297 - recall: 0.8367 - f1_score: 0.8803 - val_loss: 0.5264 - val_precision: 0.5490 - val_recall: 0.4667 - val_f1_score: 0.5045\n",
            "Epoch 2458/3000\n",
            "300/300 [==============================] - 0s 57us/step - loss: 0.2533 - precision: 0.9253 - recall: 0.8200 - f1_score: 0.8688 - val_loss: 0.5185 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2459/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.2496 - precision: 0.9410 - recall: 0.8500 - f1_score: 0.8931 - val_loss: 0.5230 - val_precision: 0.5600 - val_recall: 0.4667 - val_f1_score: 0.5091\n",
            "Epoch 2460/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.2502 - precision: 0.9503 - recall: 0.8400 - f1_score: 0.8916 - val_loss: 0.5221 - val_precision: 0.5510 - val_recall: 0.4500 - val_f1_score: 0.4954\n",
            "Epoch 2461/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2485 - precision: 0.9368 - recall: 0.8433 - f1_score: 0.8874 - val_loss: 0.5195 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2462/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2496 - precision: 0.9359 - recall: 0.8700 - f1_score: 0.9016 - val_loss: 0.5184 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 2463/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2485 - precision: 0.9271 - recall: 0.8500 - f1_score: 0.8868 - val_loss: 0.5186 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2464/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2480 - precision: 0.9370 - recall: 0.8500 - f1_score: 0.8913 - val_loss: 0.5194 - val_precision: 0.6304 - val_recall: 0.4833 - val_f1_score: 0.5472\n",
            "Epoch 2465/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2489 - precision: 0.9341 - recall: 0.8533 - f1_score: 0.8917 - val_loss: 0.5206 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2466/3000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.2490 - precision: 0.9372 - recall: 0.8467 - f1_score: 0.8895 - val_loss: 0.5228 - val_precision: 0.5957 - val_recall: 0.4667 - val_f1_score: 0.5234\n",
            "Epoch 2467/3000\n",
            "300/300 [==============================] - 0s 114us/step - loss: 0.2492 - precision: 0.9222 - recall: 0.8400 - f1_score: 0.8787 - val_loss: 0.5186 - val_precision: 0.6279 - val_recall: 0.4500 - val_f1_score: 0.5243\n",
            "Epoch 2468/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2485 - precision: 0.9486 - recall: 0.8600 - f1_score: 0.9019 - val_loss: 0.5231 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2469/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2512 - precision: 0.9267 - recall: 0.8267 - f1_score: 0.8734 - val_loss: 0.5207 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2470/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2486 - precision: 0.9363 - recall: 0.8333 - f1_score: 0.8818 - val_loss: 0.5187 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2471/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2486 - precision: 0.9369 - recall: 0.8467 - f1_score: 0.8895 - val_loss: 0.5205 - val_precision: 0.5800 - val_recall: 0.4833 - val_f1_score: 0.5273\n",
            "Epoch 2472/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2475 - precision: 0.9452 - recall: 0.8633 - f1_score: 0.9021 - val_loss: 0.5187 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2473/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2489 - precision: 0.9418 - recall: 0.8633 - f1_score: 0.9007 - val_loss: 0.5194 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 2474/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2481 - precision: 0.9374 - recall: 0.8467 - f1_score: 0.8895 - val_loss: 0.5214 - val_precision: 0.5625 - val_recall: 0.4500 - val_f1_score: 0.5000\n",
            "Epoch 2475/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2507 - precision: 0.9397 - recall: 0.8367 - f1_score: 0.8851 - val_loss: 0.5203 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 2476/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2490 - precision: 0.9301 - recall: 0.8400 - f1_score: 0.8823 - val_loss: 0.5201 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2477/3000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.2518 - precision: 0.9336 - recall: 0.8333 - f1_score: 0.8796 - val_loss: 0.5193 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2478/3000\n",
            "300/300 [==============================] - 0s 113us/step - loss: 0.2478 - precision: 0.9402 - recall: 0.8433 - f1_score: 0.8885 - val_loss: 0.5191 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 2479/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2491 - precision: 0.9196 - recall: 0.8400 - f1_score: 0.8779 - val_loss: 0.5192 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 2480/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2474 - precision: 0.9380 - recall: 0.8533 - f1_score: 0.8936 - val_loss: 0.5201 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 2481/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2477 - precision: 0.9247 - recall: 0.8567 - f1_score: 0.8891 - val_loss: 0.5247 - val_precision: 0.5510 - val_recall: 0.4500 - val_f1_score: 0.4954\n",
            "Epoch 2482/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2491 - precision: 0.9322 - recall: 0.8600 - f1_score: 0.8940 - val_loss: 0.5213 - val_precision: 0.6000 - val_recall: 0.5000 - val_f1_score: 0.5455\n",
            "Epoch 2483/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2471 - precision: 0.9381 - recall: 0.8633 - f1_score: 0.8990 - val_loss: 0.5189 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2484/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2468 - precision: 0.9445 - recall: 0.8533 - f1_score: 0.8965 - val_loss: 0.5196 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2485/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2492 - precision: 0.9395 - recall: 0.8333 - f1_score: 0.8820 - val_loss: 0.5204 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 2486/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.2478 - precision: 0.9347 - recall: 0.8433 - f1_score: 0.8863 - val_loss: 0.5194 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 2487/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2501 - precision: 0.9255 - recall: 0.8600 - f1_score: 0.8910 - val_loss: 0.5189 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2488/3000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.2487 - precision: 0.9234 - recall: 0.8433 - f1_score: 0.8815 - val_loss: 0.5201 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2489/3000\n",
            "300/300 [==============================] - 0s 110us/step - loss: 0.2459 - precision: 0.9516 - recall: 0.8600 - f1_score: 0.9032 - val_loss: 0.5198 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2490/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2466 - precision: 0.9310 - recall: 0.8567 - f1_score: 0.8917 - val_loss: 0.5207 - val_precision: 0.5800 - val_recall: 0.4833 - val_f1_score: 0.5273\n",
            "Epoch 2491/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2509 - precision: 0.9377 - recall: 0.8533 - f1_score: 0.8931 - val_loss: 0.5197 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2492/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2458 - precision: 0.9451 - recall: 0.8600 - f1_score: 0.9004 - val_loss: 0.5191 - val_precision: 0.6279 - val_recall: 0.4500 - val_f1_score: 0.5243\n",
            "Epoch 2493/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2473 - precision: 0.9375 - recall: 0.8533 - f1_score: 0.8933 - val_loss: 0.5209 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2494/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2505 - precision: 0.9288 - recall: 0.8433 - f1_score: 0.8836 - val_loss: 0.5190 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2495/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2478 - precision: 0.9306 - recall: 0.8400 - f1_score: 0.8825 - val_loss: 0.5212 - val_precision: 0.5800 - val_recall: 0.4833 - val_f1_score: 0.5273\n",
            "Epoch 2496/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2490 - precision: 0.9227 - recall: 0.8400 - f1_score: 0.8794 - val_loss: 0.5226 - val_precision: 0.5625 - val_recall: 0.4500 - val_f1_score: 0.5000\n",
            "Epoch 2497/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2471 - precision: 0.9485 - recall: 0.8600 - f1_score: 0.9020 - val_loss: 0.5198 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2498/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2454 - precision: 0.9481 - recall: 0.8633 - f1_score: 0.9029 - val_loss: 0.5194 - val_precision: 0.6279 - val_recall: 0.4500 - val_f1_score: 0.5243\n",
            "Epoch 2499/3000\n",
            "300/300 [==============================] - 0s 113us/step - loss: 0.2475 - precision: 0.9491 - recall: 0.8567 - f1_score: 0.9003 - val_loss: 0.5198 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2500/3000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.2471 - precision: 0.9399 - recall: 0.8400 - f1_score: 0.8871 - val_loss: 0.5269 - val_precision: 0.5400 - val_recall: 0.4500 - val_f1_score: 0.4909\n",
            "Epoch 2501/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2486 - precision: 0.9516 - recall: 0.8533 - f1_score: 0.8994 - val_loss: 0.5240 - val_precision: 0.5490 - val_recall: 0.4667 - val_f1_score: 0.5045\n",
            "Epoch 2502/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2480 - precision: 0.9358 - recall: 0.8400 - f1_score: 0.8850 - val_loss: 0.5194 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2503/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2506 - precision: 0.9262 - recall: 0.8367 - f1_score: 0.8786 - val_loss: 0.5219 - val_precision: 0.5625 - val_recall: 0.4500 - val_f1_score: 0.5000\n",
            "Epoch 2504/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2471 - precision: 0.9524 - recall: 0.8667 - f1_score: 0.9074 - val_loss: 0.5193 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2505/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2469 - precision: 0.9341 - recall: 0.8533 - f1_score: 0.8915 - val_loss: 0.5205 - val_precision: 0.6042 - val_recall: 0.4833 - val_f1_score: 0.5370\n",
            "Epoch 2506/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.2454 - precision: 0.9379 - recall: 0.8467 - f1_score: 0.8897 - val_loss: 0.5218 - val_precision: 0.5800 - val_recall: 0.4833 - val_f1_score: 0.5273\n",
            "Epoch 2507/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2459 - precision: 0.9492 - recall: 0.8633 - f1_score: 0.9037 - val_loss: 0.5200 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2508/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2470 - precision: 0.9265 - recall: 0.8400 - f1_score: 0.8806 - val_loss: 0.5196 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2509/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2492 - precision: 0.9299 - recall: 0.8400 - f1_score: 0.8823 - val_loss: 0.5261 - val_precision: 0.6042 - val_recall: 0.4833 - val_f1_score: 0.5370\n",
            "Epoch 2510/3000\n",
            "300/300 [==============================] - 0s 83us/step - loss: 0.2499 - precision: 0.9163 - recall: 0.8400 - f1_score: 0.8763 - val_loss: 0.5208 - val_precision: 0.6042 - val_recall: 0.4833 - val_f1_score: 0.5370\n",
            "Epoch 2511/3000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.2492 - precision: 0.9337 - recall: 0.8467 - f1_score: 0.8879 - val_loss: 0.5212 - val_precision: 0.6042 - val_recall: 0.4833 - val_f1_score: 0.5370\n",
            "Epoch 2512/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.2477 - precision: 0.9292 - recall: 0.8333 - f1_score: 0.8784 - val_loss: 0.5212 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2513/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2487 - precision: 0.9197 - recall: 0.8400 - f1_score: 0.8779 - val_loss: 0.5249 - val_precision: 0.5510 - val_recall: 0.4500 - val_f1_score: 0.4954\n",
            "Epoch 2514/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2459 - precision: 0.9419 - recall: 0.8633 - f1_score: 0.9009 - val_loss: 0.5202 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2515/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2470 - precision: 0.9335 - recall: 0.8567 - f1_score: 0.8928 - val_loss: 0.5216 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2516/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2524 - precision: 0.9190 - recall: 0.8333 - f1_score: 0.8741 - val_loss: 0.5199 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2517/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2472 - precision: 0.9450 - recall: 0.8533 - f1_score: 0.8967 - val_loss: 0.5199 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2518/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2478 - precision: 0.9310 - recall: 0.8433 - f1_score: 0.8847 - val_loss: 0.5209 - val_precision: 0.6042 - val_recall: 0.4833 - val_f1_score: 0.5370\n",
            "Epoch 2519/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2439 - precision: 0.9378 - recall: 0.8600 - f1_score: 0.8967 - val_loss: 0.5247 - val_precision: 0.5490 - val_recall: 0.4667 - val_f1_score: 0.5045\n",
            "Epoch 2520/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2456 - precision: 0.9339 - recall: 0.8433 - f1_score: 0.8857 - val_loss: 0.5303 - val_precision: 0.5510 - val_recall: 0.4500 - val_f1_score: 0.4954\n",
            "Epoch 2521/3000\n",
            "300/300 [==============================] - 0s 104us/step - loss: 0.2467 - precision: 0.9354 - recall: 0.8633 - f1_score: 0.8978 - val_loss: 0.5208 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2522/3000\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.2457 - precision: 0.9374 - recall: 0.8467 - f1_score: 0.8894 - val_loss: 0.5197 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2523/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2447 - precision: 0.9408 - recall: 0.8567 - f1_score: 0.8965 - val_loss: 0.5197 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2524/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2473 - precision: 0.9168 - recall: 0.8433 - f1_score: 0.8784 - val_loss: 0.5211 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2525/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2450 - precision: 0.9412 - recall: 0.8433 - f1_score: 0.8890 - val_loss: 0.5209 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2526/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2466 - precision: 0.9419 - recall: 0.8667 - f1_score: 0.9026 - val_loss: 0.5203 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2527/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2454 - precision: 0.9455 - recall: 0.8433 - f1_score: 0.8909 - val_loss: 0.5251 - val_precision: 0.5490 - val_recall: 0.4667 - val_f1_score: 0.5045\n",
            "Epoch 2528/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2456 - precision: 0.9353 - recall: 0.8667 - f1_score: 0.8994 - val_loss: 0.5261 - val_precision: 0.5490 - val_recall: 0.4667 - val_f1_score: 0.5045\n",
            "Epoch 2529/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2459 - precision: 0.9406 - recall: 0.8500 - f1_score: 0.8928 - val_loss: 0.5249 - val_precision: 0.5490 - val_recall: 0.4667 - val_f1_score: 0.5045\n",
            "Epoch 2530/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2471 - precision: 0.9376 - recall: 0.8500 - f1_score: 0.8909 - val_loss: 0.5215 - val_precision: 0.6304 - val_recall: 0.4833 - val_f1_score: 0.5472\n",
            "Epoch 2531/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.2467 - precision: 0.9381 - recall: 0.8533 - f1_score: 0.8936 - val_loss: 0.5229 - val_precision: 0.6042 - val_recall: 0.4833 - val_f1_score: 0.5370\n",
            "Epoch 2532/3000\n",
            "300/300 [==============================] - 0s 144us/step - loss: 0.2462 - precision: 0.9422 - recall: 0.8467 - f1_score: 0.8915 - val_loss: 0.5213 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2533/3000\n",
            "300/300 [==============================] - 0s 111us/step - loss: 0.2450 - precision: 0.9448 - recall: 0.8533 - f1_score: 0.8966 - val_loss: 0.5199 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2534/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2458 - precision: 0.9440 - recall: 0.8433 - f1_score: 0.8901 - val_loss: 0.5199 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 2535/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2459 - precision: 0.9310 - recall: 0.8567 - f1_score: 0.8922 - val_loss: 0.5256 - val_precision: 0.5490 - val_recall: 0.4667 - val_f1_score: 0.5045\n",
            "Epoch 2536/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2458 - precision: 0.9346 - recall: 0.8500 - f1_score: 0.8900 - val_loss: 0.5210 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2537/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2448 - precision: 0.9376 - recall: 0.8500 - f1_score: 0.8916 - val_loss: 0.5213 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2538/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2484 - precision: 0.9206 - recall: 0.8467 - f1_score: 0.8820 - val_loss: 0.5206 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2539/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2463 - precision: 0.9340 - recall: 0.8400 - f1_score: 0.8845 - val_loss: 0.5211 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2540/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2443 - precision: 0.9446 - recall: 0.8567 - f1_score: 0.8982 - val_loss: 0.5218 - val_precision: 0.6122 - val_recall: 0.5000 - val_f1_score: 0.5505\n",
            "Epoch 2541/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2440 - precision: 0.9484 - recall: 0.8667 - f1_score: 0.9055 - val_loss: 0.5207 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 2542/3000\n",
            "300/300 [==============================] - 0s 119us/step - loss: 0.2483 - precision: 0.9259 - recall: 0.8433 - f1_score: 0.8820 - val_loss: 0.5207 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2543/3000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.2460 - precision: 0.9295 - recall: 0.8367 - f1_score: 0.8805 - val_loss: 0.5210 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2544/3000\n",
            "300/300 [==============================] - 0s 79us/step - loss: 0.2451 - precision: 0.9449 - recall: 0.8633 - f1_score: 0.9021 - val_loss: 0.5223 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2545/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2457 - precision: 0.9313 - recall: 0.8600 - f1_score: 0.8940 - val_loss: 0.5211 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2546/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.2435 - precision: 0.9488 - recall: 0.8567 - f1_score: 0.9003 - val_loss: 0.5228 - val_precision: 0.5882 - val_recall: 0.5000 - val_f1_score: 0.5405\n",
            "Epoch 2547/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2477 - precision: 0.9244 - recall: 0.8533 - f1_score: 0.8874 - val_loss: 0.5206 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2548/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.2451 - precision: 0.9346 - recall: 0.8600 - f1_score: 0.8955 - val_loss: 0.5207 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2549/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2438 - precision: 0.9372 - recall: 0.8533 - f1_score: 0.8928 - val_loss: 0.5218 - val_precision: 0.6042 - val_recall: 0.4833 - val_f1_score: 0.5370\n",
            "Epoch 2550/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.2457 - precision: 0.9466 - recall: 0.8633 - f1_score: 0.9025 - val_loss: 0.5203 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2551/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2462 - precision: 0.9412 - recall: 0.8533 - f1_score: 0.8949 - val_loss: 0.5217 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 2552/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.2473 - precision: 0.9330 - recall: 0.8333 - f1_score: 0.8798 - val_loss: 0.5211 - val_precision: 0.5870 - val_recall: 0.4500 - val_f1_score: 0.5094\n",
            "Epoch 2553/3000\n",
            "300/300 [==============================] - 0s 125us/step - loss: 0.2442 - precision: 0.9378 - recall: 0.8500 - f1_score: 0.8917 - val_loss: 0.5216 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2554/3000\n",
            "300/300 [==============================] - 0s 108us/step - loss: 0.2453 - precision: 0.9267 - recall: 0.8500 - f1_score: 0.8862 - val_loss: 0.5210 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2555/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.2441 - precision: 0.9483 - recall: 0.8667 - f1_score: 0.9053 - val_loss: 0.5212 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 2556/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.2435 - precision: 0.9243 - recall: 0.8433 - f1_score: 0.8814 - val_loss: 0.5216 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2557/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2447 - precision: 0.9287 - recall: 0.8633 - f1_score: 0.8947 - val_loss: 0.5210 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2558/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2434 - precision: 0.9521 - recall: 0.8600 - f1_score: 0.9036 - val_loss: 0.5211 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2559/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2443 - precision: 0.9444 - recall: 0.8533 - f1_score: 0.8965 - val_loss: 0.5216 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2560/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2480 - precision: 0.9321 - recall: 0.8467 - f1_score: 0.8865 - val_loss: 0.5220 - val_precision: 0.6304 - val_recall: 0.4833 - val_f1_score: 0.5472\n",
            "Epoch 2561/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2469 - precision: 0.9301 - recall: 0.8433 - f1_score: 0.8844 - val_loss: 0.5222 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2562/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2455 - precision: 0.9307 - recall: 0.8467 - f1_score: 0.8862 - val_loss: 0.5224 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2563/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2438 - precision: 0.9445 - recall: 0.8567 - f1_score: 0.8981 - val_loss: 0.5217 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2564/3000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.2482 - precision: 0.9284 - recall: 0.8633 - f1_score: 0.8945 - val_loss: 0.5230 - val_precision: 0.5957 - val_recall: 0.4667 - val_f1_score: 0.5234\n",
            "Epoch 2565/3000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.2460 - precision: 0.9365 - recall: 0.8500 - f1_score: 0.8910 - val_loss: 0.5229 - val_precision: 0.5957 - val_recall: 0.4667 - val_f1_score: 0.5234\n",
            "Epoch 2566/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2450 - precision: 0.9256 - recall: 0.8467 - f1_score: 0.8837 - val_loss: 0.5213 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2567/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.2465 - precision: 0.9256 - recall: 0.8400 - f1_score: 0.8804 - val_loss: 0.5216 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2568/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2436 - precision: 0.9408 - recall: 0.8467 - f1_score: 0.8911 - val_loss: 0.5230 - val_precision: 0.6122 - val_recall: 0.5000 - val_f1_score: 0.5505\n",
            "Epoch 2569/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.2437 - precision: 0.9315 - recall: 0.8567 - f1_score: 0.8925 - val_loss: 0.5258 - val_precision: 0.5400 - val_recall: 0.4500 - val_f1_score: 0.4909\n",
            "Epoch 2570/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.2434 - precision: 0.9598 - recall: 0.8600 - f1_score: 0.9069 - val_loss: 0.5227 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2571/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2436 - precision: 0.9376 - recall: 0.8600 - f1_score: 0.8967 - val_loss: 0.5212 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 2572/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.2443 - precision: 0.9335 - recall: 0.8467 - f1_score: 0.8876 - val_loss: 0.5274 - val_precision: 0.5490 - val_recall: 0.4667 - val_f1_score: 0.5045\n",
            "Epoch 2573/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2433 - precision: 0.9450 - recall: 0.8567 - f1_score: 0.8986 - val_loss: 0.5218 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2574/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2424 - precision: 0.9380 - recall: 0.8500 - f1_score: 0.8917 - val_loss: 0.5215 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2575/3000\n",
            "300/300 [==============================] - 0s 106us/step - loss: 0.2421 - precision: 0.9528 - recall: 0.8600 - f1_score: 0.9036 - val_loss: 0.5212 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 2576/3000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.2443 - precision: 0.9236 - recall: 0.8500 - f1_score: 0.8851 - val_loss: 0.5221 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2577/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2447 - precision: 0.9268 - recall: 0.8467 - f1_score: 0.8847 - val_loss: 0.5237 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2578/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2459 - precision: 0.9201 - recall: 0.8467 - f1_score: 0.8817 - val_loss: 0.5276 - val_precision: 0.5490 - val_recall: 0.4667 - val_f1_score: 0.5045\n",
            "Epoch 2579/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2443 - precision: 0.9415 - recall: 0.8567 - f1_score: 0.8970 - val_loss: 0.5241 - val_precision: 0.5918 - val_recall: 0.4833 - val_f1_score: 0.5321\n",
            "Epoch 2580/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.2427 - precision: 0.9499 - recall: 0.8733 - f1_score: 0.9098 - val_loss: 0.5225 - val_precision: 0.6042 - val_recall: 0.4833 - val_f1_score: 0.5370\n",
            "Epoch 2581/3000\n",
            "300/300 [==============================] - 0s 58us/step - loss: 0.2440 - precision: 0.9403 - recall: 0.8533 - f1_score: 0.8944 - val_loss: 0.5228 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2582/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2420 - precision: 0.9486 - recall: 0.8500 - f1_score: 0.8963 - val_loss: 0.5243 - val_precision: 0.5714 - val_recall: 0.4667 - val_f1_score: 0.5138\n",
            "Epoch 2583/3000\n",
            "300/300 [==============================] - 0s 59us/step - loss: 0.2427 - precision: 0.9445 - recall: 0.8600 - f1_score: 0.9000 - val_loss: 0.5217 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2584/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2431 - precision: 0.9379 - recall: 0.8500 - f1_score: 0.8914 - val_loss: 0.5270 - val_precision: 0.5510 - val_recall: 0.4500 - val_f1_score: 0.4954\n",
            "Epoch 2585/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2434 - precision: 0.9344 - recall: 0.8533 - f1_score: 0.8918 - val_loss: 0.5261 - val_precision: 0.5600 - val_recall: 0.4667 - val_f1_score: 0.5091\n",
            "Epoch 2586/3000\n",
            "300/300 [==============================] - 0s 109us/step - loss: 0.2435 - precision: 0.9446 - recall: 0.8433 - f1_score: 0.8907 - val_loss: 0.5217 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2587/3000\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.2429 - precision: 0.9275 - recall: 0.8500 - f1_score: 0.8869 - val_loss: 0.5225 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2588/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2425 - precision: 0.9409 - recall: 0.8567 - f1_score: 0.8962 - val_loss: 0.5216 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2589/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2407 - precision: 0.9246 - recall: 0.8600 - f1_score: 0.8909 - val_loss: 0.5342 - val_precision: 0.5745 - val_recall: 0.4500 - val_f1_score: 0.5047\n",
            "Epoch 2590/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2425 - precision: 0.9230 - recall: 0.8500 - f1_score: 0.8844 - val_loss: 0.5224 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 2591/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2441 - precision: 0.9241 - recall: 0.8567 - f1_score: 0.8889 - val_loss: 0.5227 - val_precision: 0.5870 - val_recall: 0.4500 - val_f1_score: 0.5094\n",
            "Epoch 2592/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2436 - precision: 0.9279 - recall: 0.8467 - f1_score: 0.8850 - val_loss: 0.5229 - val_precision: 0.6042 - val_recall: 0.4833 - val_f1_score: 0.5370\n",
            "Epoch 2593/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2435 - precision: 0.9405 - recall: 0.8400 - f1_score: 0.8873 - val_loss: 0.5253 - val_precision: 0.5600 - val_recall: 0.4667 - val_f1_score: 0.5091\n",
            "Epoch 2594/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2455 - precision: 0.9300 - recall: 0.8400 - f1_score: 0.8823 - val_loss: 0.5219 - val_precision: 0.6279 - val_recall: 0.4500 - val_f1_score: 0.5243\n",
            "Epoch 2595/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2450 - precision: 0.9245 - recall: 0.8567 - f1_score: 0.8892 - val_loss: 0.5216 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2596/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2423 - precision: 0.9520 - recall: 0.8533 - f1_score: 0.8995 - val_loss: 0.5221 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2597/3000\n",
            "300/300 [==============================] - 0s 111us/step - loss: 0.2459 - precision: 0.9438 - recall: 0.8433 - f1_score: 0.8906 - val_loss: 0.5235 - val_precision: 0.5745 - val_recall: 0.4500 - val_f1_score: 0.5047\n",
            "Epoch 2598/3000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.2439 - precision: 0.9349 - recall: 0.8267 - f1_score: 0.8764 - val_loss: 0.5218 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2599/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2425 - precision: 0.9421 - recall: 0.8633 - f1_score: 0.9008 - val_loss: 0.5294 - val_precision: 0.5400 - val_recall: 0.4500 - val_f1_score: 0.4909\n",
            "Epoch 2600/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2440 - precision: 0.9416 - recall: 0.8600 - f1_score: 0.8988 - val_loss: 0.5216 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2601/3000\n",
            "300/300 [==============================] - 0s 59us/step - loss: 0.2444 - precision: 0.9373 - recall: 0.8467 - f1_score: 0.8897 - val_loss: 0.5237 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2602/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2438 - precision: 0.9336 - recall: 0.8467 - f1_score: 0.8879 - val_loss: 0.5245 - val_precision: 0.5510 - val_recall: 0.4500 - val_f1_score: 0.4954\n",
            "Epoch 2603/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2429 - precision: 0.9419 - recall: 0.8633 - f1_score: 0.9008 - val_loss: 0.5235 - val_precision: 0.5870 - val_recall: 0.4500 - val_f1_score: 0.5094\n",
            "Epoch 2604/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2426 - precision: 0.9270 - recall: 0.8500 - f1_score: 0.8864 - val_loss: 0.5216 - val_precision: 0.6444 - val_recall: 0.4833 - val_f1_score: 0.5524\n",
            "Epoch 2605/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2426 - precision: 0.9446 - recall: 0.8567 - f1_score: 0.8977 - val_loss: 0.5218 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2606/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2424 - precision: 0.9415 - recall: 0.8567 - f1_score: 0.8970 - val_loss: 0.5233 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 2607/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.2432 - precision: 0.9402 - recall: 0.8367 - f1_score: 0.8853 - val_loss: 0.5222 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2608/3000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.2415 - precision: 0.9489 - recall: 0.8633 - f1_score: 0.9037 - val_loss: 0.5220 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2609/3000\n",
            "300/300 [==============================] - 0s 116us/step - loss: 0.2417 - precision: 0.9530 - recall: 0.8733 - f1_score: 0.9110 - val_loss: 0.5265 - val_precision: 0.5714 - val_recall: 0.4667 - val_f1_score: 0.5138\n",
            "Epoch 2610/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2437 - precision: 0.9445 - recall: 0.8500 - f1_score: 0.8946 - val_loss: 0.5226 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2611/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.2422 - precision: 0.9418 - recall: 0.8500 - f1_score: 0.8928 - val_loss: 0.5240 - val_precision: 0.5800 - val_recall: 0.4833 - val_f1_score: 0.5273\n",
            "Epoch 2612/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2415 - precision: 0.9487 - recall: 0.8567 - f1_score: 0.9001 - val_loss: 0.5222 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2613/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.2420 - precision: 0.9521 - recall: 0.8567 - f1_score: 0.9015 - val_loss: 0.5237 - val_precision: 0.5957 - val_recall: 0.4667 - val_f1_score: 0.5234\n",
            "Epoch 2614/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2431 - precision: 0.9495 - recall: 0.8567 - f1_score: 0.9003 - val_loss: 0.5226 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2615/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.2423 - precision: 0.9345 - recall: 0.8533 - f1_score: 0.8920 - val_loss: 0.5239 - val_precision: 0.5957 - val_recall: 0.4667 - val_f1_score: 0.5234\n",
            "Epoch 2616/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2429 - precision: 0.9347 - recall: 0.8600 - f1_score: 0.8956 - val_loss: 0.5227 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2617/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.2405 - precision: 0.9246 - recall: 0.8567 - f1_score: 0.8892 - val_loss: 0.5266 - val_precision: 0.5490 - val_recall: 0.4667 - val_f1_score: 0.5045\n",
            "Epoch 2618/3000\n",
            "300/300 [==============================] - 0s 105us/step - loss: 0.2409 - precision: 0.9458 - recall: 0.8767 - f1_score: 0.9096 - val_loss: 0.5219 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2619/3000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.2422 - precision: 0.9443 - recall: 0.8533 - f1_score: 0.8960 - val_loss: 0.5226 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2620/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2407 - precision: 0.9482 - recall: 0.8500 - f1_score: 0.8962 - val_loss: 0.5266 - val_precision: 0.5600 - val_recall: 0.4667 - val_f1_score: 0.5091\n",
            "Epoch 2621/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2469 - precision: 0.9380 - recall: 0.8567 - f1_score: 0.8953 - val_loss: 0.5258 - val_precision: 0.5600 - val_recall: 0.4667 - val_f1_score: 0.5091\n",
            "Epoch 2622/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2417 - precision: 0.9382 - recall: 0.8567 - f1_score: 0.8954 - val_loss: 0.5246 - val_precision: 0.6000 - val_recall: 0.5000 - val_f1_score: 0.5455\n",
            "Epoch 2623/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2409 - precision: 0.9481 - recall: 0.8533 - f1_score: 0.8982 - val_loss: 0.5229 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2624/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2406 - precision: 0.9512 - recall: 0.8567 - f1_score: 0.9010 - val_loss: 0.5227 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2625/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2405 - precision: 0.9245 - recall: 0.8567 - f1_score: 0.8892 - val_loss: 0.5282 - val_precision: 0.5400 - val_recall: 0.4500 - val_f1_score: 0.4909\n",
            "Epoch 2626/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2421 - precision: 0.9276 - recall: 0.8533 - f1_score: 0.8887 - val_loss: 0.5225 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2627/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2423 - precision: 0.9387 - recall: 0.8600 - f1_score: 0.8974 - val_loss: 0.5234 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2628/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2403 - precision: 0.9480 - recall: 0.8533 - f1_score: 0.8981 - val_loss: 0.5250 - val_precision: 0.5714 - val_recall: 0.4667 - val_f1_score: 0.5138\n",
            "Epoch 2629/3000\n",
            "300/300 [==============================] - 0s 102us/step - loss: 0.2432 - precision: 0.9354 - recall: 0.8633 - f1_score: 0.8976 - val_loss: 0.5249 - val_precision: 0.5510 - val_recall: 0.4500 - val_f1_score: 0.4954\n",
            "Epoch 2630/3000\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.2411 - precision: 0.9448 - recall: 0.8633 - f1_score: 0.9021 - val_loss: 0.5226 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2631/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2412 - precision: 0.9268 - recall: 0.8433 - f1_score: 0.8830 - val_loss: 0.5239 - val_precision: 0.6042 - val_recall: 0.4833 - val_f1_score: 0.5370\n",
            "Epoch 2632/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.2426 - precision: 0.9369 - recall: 0.8467 - f1_score: 0.8892 - val_loss: 0.5237 - val_precision: 0.6042 - val_recall: 0.4833 - val_f1_score: 0.5370\n",
            "Epoch 2633/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2414 - precision: 0.9492 - recall: 0.8667 - f1_score: 0.9057 - val_loss: 0.5226 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2634/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2410 - precision: 0.9288 - recall: 0.8567 - f1_score: 0.8908 - val_loss: 0.5230 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2635/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2429 - precision: 0.9354 - recall: 0.8567 - f1_score: 0.8942 - val_loss: 0.5229 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2636/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.2417 - precision: 0.9459 - recall: 0.8633 - f1_score: 0.9023 - val_loss: 0.5223 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2637/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2415 - precision: 0.9418 - recall: 0.8600 - f1_score: 0.8989 - val_loss: 0.5262 - val_precision: 0.5490 - val_recall: 0.4667 - val_f1_score: 0.5045\n",
            "Epoch 2638/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2412 - precision: 0.9378 - recall: 0.8533 - f1_score: 0.8935 - val_loss: 0.5289 - val_precision: 0.5490 - val_recall: 0.4667 - val_f1_score: 0.5045\n",
            "Epoch 2639/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2428 - precision: 0.9456 - recall: 0.8567 - f1_score: 0.8987 - val_loss: 0.5270 - val_precision: 0.5490 - val_recall: 0.4667 - val_f1_score: 0.5045\n",
            "Epoch 2640/3000\n",
            "300/300 [==============================] - 0s 116us/step - loss: 0.2428 - precision: 0.9210 - recall: 0.8533 - f1_score: 0.8858 - val_loss: 0.5244 - val_precision: 0.5957 - val_recall: 0.4667 - val_f1_score: 0.5234\n",
            "Epoch 2641/3000\n",
            "300/300 [==============================] - 0s 118us/step - loss: 0.2413 - precision: 0.9448 - recall: 0.8567 - f1_score: 0.8983 - val_loss: 0.5261 - val_precision: 0.5625 - val_recall: 0.4500 - val_f1_score: 0.5000\n",
            "Epoch 2642/3000\n",
            "300/300 [==============================] - 0s 79us/step - loss: 0.2418 - precision: 0.9346 - recall: 0.8600 - f1_score: 0.8955 - val_loss: 0.5272 - val_precision: 0.5510 - val_recall: 0.4500 - val_f1_score: 0.4954\n",
            "Epoch 2643/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2418 - precision: 0.9496 - recall: 0.8733 - f1_score: 0.9098 - val_loss: 0.5236 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2644/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.2404 - precision: 0.9453 - recall: 0.8600 - f1_score: 0.9002 - val_loss: 0.5231 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2645/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2422 - precision: 0.9444 - recall: 0.8500 - f1_score: 0.8947 - val_loss: 0.5227 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2646/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.2415 - precision: 0.9458 - recall: 0.8667 - f1_score: 0.9045 - val_loss: 0.5237 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2647/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2417 - precision: 0.9327 - recall: 0.8633 - f1_score: 0.8962 - val_loss: 0.5243 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2648/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2409 - precision: 0.9347 - recall: 0.8533 - f1_score: 0.8914 - val_loss: 0.5243 - val_precision: 0.5957 - val_recall: 0.4667 - val_f1_score: 0.5234\n",
            "Epoch 2649/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.2410 - precision: 0.9562 - recall: 0.8700 - f1_score: 0.9106 - val_loss: 0.5232 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2650/3000\n",
            "300/300 [==============================] - 0s 173us/step - loss: 0.2400 - precision: 0.9422 - recall: 0.8533 - f1_score: 0.8949 - val_loss: 0.5238 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2651/3000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.2421 - precision: 0.9372 - recall: 0.8500 - f1_score: 0.8907 - val_loss: 0.5246 - val_precision: 0.5957 - val_recall: 0.4667 - val_f1_score: 0.5234\n",
            "Epoch 2652/3000\n",
            "300/300 [==============================] - 0s 79us/step - loss: 0.2397 - precision: 0.9450 - recall: 0.8600 - f1_score: 0.9002 - val_loss: 0.5233 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2653/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.2423 - precision: 0.9366 - recall: 0.8367 - f1_score: 0.8838 - val_loss: 0.5232 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2654/3000\n",
            "300/300 [==============================] - 0s 79us/step - loss: 0.2396 - precision: 0.9485 - recall: 0.8700 - f1_score: 0.9074 - val_loss: 0.5233 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2655/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2429 - precision: 0.9421 - recall: 0.8667 - f1_score: 0.9027 - val_loss: 0.5247 - val_precision: 0.6250 - val_recall: 0.5000 - val_f1_score: 0.5556\n",
            "Epoch 2656/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2405 - precision: 0.9479 - recall: 0.8533 - f1_score: 0.8979 - val_loss: 0.5230 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2657/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2409 - precision: 0.9378 - recall: 0.8500 - f1_score: 0.8916 - val_loss: 0.5236 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2658/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2398 - precision: 0.9300 - recall: 0.8533 - f1_score: 0.8896 - val_loss: 0.5263 - val_precision: 0.5600 - val_recall: 0.4667 - val_f1_score: 0.5091\n",
            "Epoch 2659/3000\n",
            "300/300 [==============================] - 0s 105us/step - loss: 0.2450 - precision: 0.9393 - recall: 0.8533 - f1_score: 0.8939 - val_loss: 0.5236 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2660/3000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.2391 - precision: 0.9486 - recall: 0.8567 - f1_score: 0.9002 - val_loss: 0.5285 - val_precision: 0.5600 - val_recall: 0.4667 - val_f1_score: 0.5091\n",
            "Epoch 2661/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.2396 - precision: 0.9425 - recall: 0.8700 - f1_score: 0.9045 - val_loss: 0.5239 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2662/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2406 - precision: 0.9450 - recall: 0.8633 - f1_score: 0.9020 - val_loss: 0.5233 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 2663/3000\n",
            "300/300 [==============================] - 0s 81us/step - loss: 0.2404 - precision: 0.9392 - recall: 0.8633 - f1_score: 0.8993 - val_loss: 0.5231 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2664/3000\n",
            "300/300 [==============================] - 0s 79us/step - loss: 0.2404 - precision: 0.9340 - recall: 0.8567 - f1_score: 0.8934 - val_loss: 0.5304 - val_precision: 0.5294 - val_recall: 0.4500 - val_f1_score: 0.4865\n",
            "Epoch 2665/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2393 - precision: 0.9487 - recall: 0.8633 - f1_score: 0.9039 - val_loss: 0.5243 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2666/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2389 - precision: 0.9492 - recall: 0.8600 - f1_score: 0.9019 - val_loss: 0.5393 - val_precision: 0.6000 - val_recall: 0.5000 - val_f1_score: 0.5455\n",
            "Epoch 2667/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2440 - precision: 0.9371 - recall: 0.8567 - f1_score: 0.8949 - val_loss: 0.5237 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2668/3000\n",
            "300/300 [==============================] - 0s 78us/step - loss: 0.2408 - precision: 0.9348 - recall: 0.8567 - f1_score: 0.8938 - val_loss: 0.5254 - val_precision: 0.5918 - val_recall: 0.4833 - val_f1_score: 0.5321\n",
            "Epoch 2669/3000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.2396 - precision: 0.9488 - recall: 0.8667 - f1_score: 0.9055 - val_loss: 0.5233 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2670/3000\n",
            "300/300 [==============================] - 0s 114us/step - loss: 0.2381 - precision: 0.9454 - recall: 0.8633 - f1_score: 0.9024 - val_loss: 0.5256 - val_precision: 0.5918 - val_recall: 0.4833 - val_f1_score: 0.5321\n",
            "Epoch 2671/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2406 - precision: 0.9455 - recall: 0.8567 - f1_score: 0.8985 - val_loss: 0.5256 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2672/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.2386 - precision: 0.9500 - recall: 0.8667 - f1_score: 0.9055 - val_loss: 0.5240 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2673/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.2407 - precision: 0.9426 - recall: 0.8667 - f1_score: 0.9029 - val_loss: 0.5242 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 2674/3000\n",
            "300/300 [==============================] - 0s 78us/step - loss: 0.2393 - precision: 0.9344 - recall: 0.8567 - f1_score: 0.8937 - val_loss: 0.5234 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2675/3000\n",
            "300/300 [==============================] - 0s 81us/step - loss: 0.2390 - precision: 0.9456 - recall: 0.8600 - f1_score: 0.9003 - val_loss: 0.5255 - val_precision: 0.5918 - val_recall: 0.4833 - val_f1_score: 0.5321\n",
            "Epoch 2676/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.2411 - precision: 0.9519 - recall: 0.8567 - f1_score: 0.9017 - val_loss: 0.5243 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 2677/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2387 - precision: 0.9454 - recall: 0.8600 - f1_score: 0.9004 - val_loss: 0.5240 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2678/3000\n",
            "300/300 [==============================] - 0s 75us/step - loss: 0.2388 - precision: 0.9525 - recall: 0.8600 - f1_score: 0.9037 - val_loss: 0.5246 - val_precision: 0.6304 - val_recall: 0.4833 - val_f1_score: 0.5472\n",
            "Epoch 2679/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2397 - precision: 0.9446 - recall: 0.8533 - f1_score: 0.8966 - val_loss: 0.5247 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2680/3000\n",
            "300/300 [==============================] - 0s 141us/step - loss: 0.2382 - precision: 0.9482 - recall: 0.8567 - f1_score: 0.8999 - val_loss: 0.5295 - val_precision: 0.5490 - val_recall: 0.4667 - val_f1_score: 0.5045\n",
            "Epoch 2681/3000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.2428 - precision: 0.9241 - recall: 0.8500 - f1_score: 0.8855 - val_loss: 0.5241 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2682/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.2420 - precision: 0.9378 - recall: 0.8533 - f1_score: 0.8935 - val_loss: 0.5281 - val_precision: 0.5957 - val_recall: 0.4667 - val_f1_score: 0.5234\n",
            "Epoch 2683/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2447 - precision: 0.9184 - recall: 0.8400 - f1_score: 0.8771 - val_loss: 0.5283 - val_precision: 0.5510 - val_recall: 0.4500 - val_f1_score: 0.4954\n",
            "Epoch 2684/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2385 - precision: 0.9463 - recall: 0.8767 - f1_score: 0.9100 - val_loss: 0.5246 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2685/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2399 - precision: 0.9488 - recall: 0.8633 - f1_score: 0.9038 - val_loss: 0.5243 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2686/3000\n",
            "300/300 [==============================] - 0s 74us/step - loss: 0.2394 - precision: 0.9320 - recall: 0.8500 - f1_score: 0.8881 - val_loss: 0.5257 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2687/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2378 - precision: 0.9448 - recall: 0.8633 - f1_score: 0.9017 - val_loss: 0.5246 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2688/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2402 - precision: 0.9244 - recall: 0.8600 - f1_score: 0.8908 - val_loss: 0.5240 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2689/3000\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.2380 - precision: 0.9422 - recall: 0.8700 - f1_score: 0.9044 - val_loss: 0.5250 - val_precision: 0.6042 - val_recall: 0.4833 - val_f1_score: 0.5370\n",
            "Epoch 2690/3000\n",
            "300/300 [==============================] - 0s 125us/step - loss: 0.2388 - precision: 0.9426 - recall: 0.8567 - f1_score: 0.8972 - val_loss: 0.5252 - val_precision: 0.6042 - val_recall: 0.4833 - val_f1_score: 0.5370\n",
            "Epoch 2691/3000\n",
            "300/300 [==============================] - 0s 81us/step - loss: 0.2385 - precision: 0.9489 - recall: 0.8667 - f1_score: 0.9055 - val_loss: 0.5250 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2692/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2376 - precision: 0.9389 - recall: 0.8667 - f1_score: 0.9012 - val_loss: 0.5300 - val_precision: 0.5490 - val_recall: 0.4667 - val_f1_score: 0.5045\n",
            "Epoch 2693/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2407 - precision: 0.9422 - recall: 0.8667 - f1_score: 0.9027 - val_loss: 0.5254 - val_precision: 0.5957 - val_recall: 0.4667 - val_f1_score: 0.5234\n",
            "Epoch 2694/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.2409 - precision: 0.9318 - recall: 0.8533 - f1_score: 0.8906 - val_loss: 0.5263 - val_precision: 0.5957 - val_recall: 0.4667 - val_f1_score: 0.5234\n",
            "Epoch 2695/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2394 - precision: 0.9500 - recall: 0.8667 - f1_score: 0.9055 - val_loss: 0.5239 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2696/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.2374 - precision: 0.9250 - recall: 0.8600 - f1_score: 0.8910 - val_loss: 0.5315 - val_precision: 0.5385 - val_recall: 0.4667 - val_f1_score: 0.5000\n",
            "Epoch 2697/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2376 - precision: 0.9450 - recall: 0.8600 - f1_score: 0.9004 - val_loss: 0.5239 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2698/3000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.2417 - precision: 0.9093 - recall: 0.8367 - f1_score: 0.8711 - val_loss: 0.5258 - val_precision: 0.6250 - val_recall: 0.5000 - val_f1_score: 0.5556\n",
            "Epoch 2699/3000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.2373 - precision: 0.9498 - recall: 0.8767 - f1_score: 0.9115 - val_loss: 0.5242 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2700/3000\n",
            "300/300 [==============================] - 0s 121us/step - loss: 0.2375 - precision: 0.9475 - recall: 0.8567 - f1_score: 0.8995 - val_loss: 0.5257 - val_precision: 0.6042 - val_recall: 0.4833 - val_f1_score: 0.5370\n",
            "Epoch 2701/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.2388 - precision: 0.9421 - recall: 0.8700 - f1_score: 0.9046 - val_loss: 0.5267 - val_precision: 0.5600 - val_recall: 0.4667 - val_f1_score: 0.5091\n",
            "Epoch 2702/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.2386 - precision: 0.9460 - recall: 0.8700 - f1_score: 0.9061 - val_loss: 0.5247 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2703/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2382 - precision: 0.9252 - recall: 0.8600 - f1_score: 0.8911 - val_loss: 0.5303 - val_precision: 0.5490 - val_recall: 0.4667 - val_f1_score: 0.5045\n",
            "Epoch 2704/3000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.2388 - precision: 0.9469 - recall: 0.8733 - f1_score: 0.9081 - val_loss: 0.5279 - val_precision: 0.5490 - val_recall: 0.4667 - val_f1_score: 0.5045\n",
            "Epoch 2705/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2379 - precision: 0.9431 - recall: 0.8567 - f1_score: 0.8970 - val_loss: 0.5249 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2706/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.2371 - precision: 0.9520 - recall: 0.8633 - f1_score: 0.9053 - val_loss: 0.5245 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2707/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2386 - precision: 0.9496 - recall: 0.8633 - f1_score: 0.9040 - val_loss: 0.5258 - val_precision: 0.6042 - val_recall: 0.4833 - val_f1_score: 0.5370\n",
            "Epoch 2708/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2374 - precision: 0.9484 - recall: 0.8600 - f1_score: 0.9018 - val_loss: 0.5267 - val_precision: 0.6000 - val_recall: 0.5000 - val_f1_score: 0.5455\n",
            "Epoch 2709/3000\n",
            "300/300 [==============================] - 0s 90us/step - loss: 0.2376 - precision: 0.9454 - recall: 0.8667 - f1_score: 0.9041 - val_loss: 0.5249 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2710/3000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.2390 - precision: 0.9546 - recall: 0.8567 - f1_score: 0.9028 - val_loss: 0.5250 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2711/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2380 - precision: 0.9346 - recall: 0.8567 - f1_score: 0.8939 - val_loss: 0.5257 - val_precision: 0.6250 - val_recall: 0.5000 - val_f1_score: 0.5556\n",
            "Epoch 2712/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2368 - precision: 0.9459 - recall: 0.8667 - f1_score: 0.9040 - val_loss: 0.5242 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2713/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2442 - precision: 0.9285 - recall: 0.8567 - f1_score: 0.8908 - val_loss: 0.5251 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2714/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2377 - precision: 0.9552 - recall: 0.8567 - f1_score: 0.9031 - val_loss: 0.5243 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2715/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2370 - precision: 0.9627 - recall: 0.8633 - f1_score: 0.9101 - val_loss: 0.5258 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2716/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2366 - precision: 0.9498 - recall: 0.8733 - f1_score: 0.9094 - val_loss: 0.5248 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2717/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2375 - precision: 0.9443 - recall: 0.8600 - f1_score: 0.8996 - val_loss: 0.5267 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2718/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2402 - precision: 0.9283 - recall: 0.8533 - f1_score: 0.8890 - val_loss: 0.5252 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2719/3000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.2382 - precision: 0.9485 - recall: 0.8567 - f1_score: 0.8996 - val_loss: 0.5251 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2720/3000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.2389 - precision: 0.9448 - recall: 0.8467 - f1_score: 0.8925 - val_loss: 0.5246 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 2721/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.2369 - precision: 0.9387 - recall: 0.8700 - f1_score: 0.9027 - val_loss: 0.5247 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2722/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2387 - precision: 0.9444 - recall: 0.8500 - f1_score: 0.8944 - val_loss: 0.5248 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 2723/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2392 - precision: 0.9297 - recall: 0.8400 - f1_score: 0.8826 - val_loss: 0.5251 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2724/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.2396 - precision: 0.9458 - recall: 0.8567 - f1_score: 0.8987 - val_loss: 0.5260 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2725/3000\n",
            "300/300 [==============================] - 0s 58us/step - loss: 0.2412 - precision: 0.9272 - recall: 0.8533 - f1_score: 0.8885 - val_loss: 0.5252 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2726/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.2382 - precision: 0.9384 - recall: 0.8567 - f1_score: 0.8955 - val_loss: 0.5254 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2727/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2396 - precision: 0.9277 - recall: 0.8533 - f1_score: 0.8888 - val_loss: 0.5253 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2728/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.2407 - precision: 0.9519 - recall: 0.8600 - f1_score: 0.9034 - val_loss: 0.5248 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2729/3000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.2404 - precision: 0.9343 - recall: 0.8600 - f1_score: 0.8955 - val_loss: 0.5256 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2730/3000\n",
            "300/300 [==============================] - 0s 104us/step - loss: 0.2380 - precision: 0.9489 - recall: 0.8667 - f1_score: 0.9057 - val_loss: 0.5257 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2731/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2375 - precision: 0.9420 - recall: 0.8767 - f1_score: 0.9079 - val_loss: 0.5295 - val_precision: 0.5490 - val_recall: 0.4667 - val_f1_score: 0.5045\n",
            "Epoch 2732/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2387 - precision: 0.9452 - recall: 0.8667 - f1_score: 0.9042 - val_loss: 0.5319 - val_precision: 0.5385 - val_recall: 0.4667 - val_f1_score: 0.5000\n",
            "Epoch 2733/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2388 - precision: 0.9533 - recall: 0.8633 - f1_score: 0.9051 - val_loss: 0.5274 - val_precision: 0.5800 - val_recall: 0.4833 - val_f1_score: 0.5273\n",
            "Epoch 2734/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2359 - precision: 0.9446 - recall: 0.8733 - f1_score: 0.9069 - val_loss: 0.5251 - val_precision: 0.6304 - val_recall: 0.4833 - val_f1_score: 0.5472\n",
            "Epoch 2735/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2381 - precision: 0.9489 - recall: 0.8600 - f1_score: 0.9021 - val_loss: 0.5264 - val_precision: 0.6250 - val_recall: 0.5000 - val_f1_score: 0.5556\n",
            "Epoch 2736/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2365 - precision: 0.9454 - recall: 0.8700 - f1_score: 0.9060 - val_loss: 0.5256 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2737/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2370 - precision: 0.9518 - recall: 0.8600 - f1_score: 0.9034 - val_loss: 0.5262 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2738/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2374 - precision: 0.9371 - recall: 0.8467 - f1_score: 0.8895 - val_loss: 0.5276 - val_precision: 0.5600 - val_recall: 0.4667 - val_f1_score: 0.5091\n",
            "Epoch 2739/3000\n",
            "300/300 [==============================] - 0s 109us/step - loss: 0.2397 - precision: 0.9279 - recall: 0.8600 - f1_score: 0.8927 - val_loss: 0.5280 - val_precision: 0.5833 - val_recall: 0.4667 - val_f1_score: 0.5185\n",
            "Epoch 2740/3000\n",
            "300/300 [==============================] - 0s 108us/step - loss: 0.2355 - precision: 0.9528 - recall: 0.8700 - f1_score: 0.9093 - val_loss: 0.5267 - val_precision: 0.5870 - val_recall: 0.4500 - val_f1_score: 0.5094\n",
            "Epoch 2741/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2390 - precision: 0.9354 - recall: 0.8633 - f1_score: 0.8978 - val_loss: 0.5256 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2742/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2355 - precision: 0.9386 - recall: 0.8633 - f1_score: 0.8991 - val_loss: 0.5291 - val_precision: 0.5490 - val_recall: 0.4667 - val_f1_score: 0.5045\n",
            "Epoch 2743/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2392 - precision: 0.9387 - recall: 0.8667 - f1_score: 0.9012 - val_loss: 0.5257 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2744/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2359 - precision: 0.9523 - recall: 0.8633 - f1_score: 0.9056 - val_loss: 0.5269 - val_precision: 0.6250 - val_recall: 0.5000 - val_f1_score: 0.5556\n",
            "Epoch 2745/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.2385 - precision: 0.9380 - recall: 0.8500 - f1_score: 0.8917 - val_loss: 0.5297 - val_precision: 0.5490 - val_recall: 0.4667 - val_f1_score: 0.5045\n",
            "Epoch 2746/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.2380 - precision: 0.9457 - recall: 0.8600 - f1_score: 0.9006 - val_loss: 0.5279 - val_precision: 0.5686 - val_recall: 0.4833 - val_f1_score: 0.5225\n",
            "Epoch 2747/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.2378 - precision: 0.9488 - recall: 0.8667 - f1_score: 0.9055 - val_loss: 0.5256 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2748/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2356 - precision: 0.9485 - recall: 0.8600 - f1_score: 0.9020 - val_loss: 0.5262 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2749/3000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.2366 - precision: 0.9496 - recall: 0.8733 - f1_score: 0.9098 - val_loss: 0.5254 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2750/3000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.2377 - precision: 0.9529 - recall: 0.8700 - f1_score: 0.9093 - val_loss: 0.5253 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2751/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2366 - precision: 0.9527 - recall: 0.8700 - f1_score: 0.9094 - val_loss: 0.5265 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2752/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2363 - precision: 0.9428 - recall: 0.8667 - f1_score: 0.9025 - val_loss: 0.5284 - val_precision: 0.5745 - val_recall: 0.4500 - val_f1_score: 0.5047\n",
            "Epoch 2753/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2356 - precision: 0.9525 - recall: 0.8733 - f1_score: 0.9111 - val_loss: 0.5265 - val_precision: 0.6304 - val_recall: 0.4833 - val_f1_score: 0.5472\n",
            "Epoch 2754/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2371 - precision: 0.9458 - recall: 0.8700 - f1_score: 0.9057 - val_loss: 0.5256 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2755/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2381 - precision: 0.9421 - recall: 0.8667 - f1_score: 0.9027 - val_loss: 0.5293 - val_precision: 0.5833 - val_recall: 0.4667 - val_f1_score: 0.5185\n",
            "Epoch 2756/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2385 - precision: 0.9323 - recall: 0.8633 - f1_score: 0.8963 - val_loss: 0.5271 - val_precision: 0.5745 - val_recall: 0.4500 - val_f1_score: 0.5047\n",
            "Epoch 2757/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2362 - precision: 0.9340 - recall: 0.8500 - f1_score: 0.8899 - val_loss: 0.5268 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2758/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2364 - precision: 0.9452 - recall: 0.8700 - f1_score: 0.9056 - val_loss: 0.5317 - val_precision: 0.5490 - val_recall: 0.4667 - val_f1_score: 0.5045\n",
            "Epoch 2759/3000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.2386 - precision: 0.9520 - recall: 0.8600 - f1_score: 0.9034 - val_loss: 0.5260 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2760/3000\n",
            "300/300 [==============================] - 0s 104us/step - loss: 0.2367 - precision: 0.9455 - recall: 0.8633 - f1_score: 0.9024 - val_loss: 0.5266 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2761/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2377 - precision: 0.9330 - recall: 0.8433 - f1_score: 0.8858 - val_loss: 0.5261 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2762/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2357 - precision: 0.9523 - recall: 0.8667 - f1_score: 0.9074 - val_loss: 0.5254 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2763/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2361 - precision: 0.9379 - recall: 0.8567 - f1_score: 0.8954 - val_loss: 0.5257 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 2764/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2363 - precision: 0.9480 - recall: 0.8533 - f1_score: 0.8980 - val_loss: 0.5299 - val_precision: 0.5600 - val_recall: 0.4667 - val_f1_score: 0.5091\n",
            "Epoch 2765/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2359 - precision: 0.9498 - recall: 0.8700 - f1_score: 0.9079 - val_loss: 0.5257 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 2766/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2366 - precision: 0.9472 - recall: 0.8533 - f1_score: 0.8976 - val_loss: 0.5278 - val_precision: 0.5918 - val_recall: 0.4833 - val_f1_score: 0.5321\n",
            "Epoch 2767/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2363 - precision: 0.9418 - recall: 0.8600 - f1_score: 0.8987 - val_loss: 0.5302 - val_precision: 0.5600 - val_recall: 0.4667 - val_f1_score: 0.5091\n",
            "Epoch 2768/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2351 - precision: 0.9560 - recall: 0.8567 - f1_score: 0.9035 - val_loss: 0.5267 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2769/3000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.2366 - precision: 0.9411 - recall: 0.8533 - f1_score: 0.8946 - val_loss: 0.5262 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2770/3000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.2365 - precision: 0.9273 - recall: 0.8600 - f1_score: 0.8921 - val_loss: 0.5302 - val_precision: 0.5600 - val_recall: 0.4667 - val_f1_score: 0.5091\n",
            "Epoch 2771/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2388 - precision: 0.9559 - recall: 0.8600 - f1_score: 0.9052 - val_loss: 0.5337 - val_precision: 0.5400 - val_recall: 0.4500 - val_f1_score: 0.4909\n",
            "Epoch 2772/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.2359 - precision: 0.9491 - recall: 0.8633 - f1_score: 0.9041 - val_loss: 0.5258 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2773/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2345 - precision: 0.9454 - recall: 0.8633 - f1_score: 0.9019 - val_loss: 0.5259 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 2774/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.2361 - precision: 0.9457 - recall: 0.8733 - f1_score: 0.9077 - val_loss: 0.5284 - val_precision: 0.5769 - val_recall: 0.5000 - val_f1_score: 0.5357\n",
            "Epoch 2775/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2370 - precision: 0.9554 - recall: 0.8433 - f1_score: 0.8954 - val_loss: 0.5274 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2776/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2347 - precision: 0.9400 - recall: 0.8700 - f1_score: 0.9034 - val_loss: 0.5262 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2777/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2357 - precision: 0.9483 - recall: 0.8633 - f1_score: 0.9036 - val_loss: 0.5259 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2778/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2361 - precision: 0.9446 - recall: 0.8633 - f1_score: 0.9019 - val_loss: 0.5270 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2779/3000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.2346 - precision: 0.9482 - recall: 0.8733 - f1_score: 0.9088 - val_loss: 0.5273 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2780/3000\n",
            "300/300 [==============================] - 0s 110us/step - loss: 0.2395 - precision: 0.9375 - recall: 0.8500 - f1_score: 0.8911 - val_loss: 0.5272 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2781/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2352 - precision: 0.9510 - recall: 0.8533 - f1_score: 0.8993 - val_loss: 0.5274 - val_precision: 0.6250 - val_recall: 0.5000 - val_f1_score: 0.5556\n",
            "Epoch 2782/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.2357 - precision: 0.9496 - recall: 0.8700 - f1_score: 0.9077 - val_loss: 0.5315 - val_precision: 0.5957 - val_recall: 0.4667 - val_f1_score: 0.5234\n",
            "Epoch 2783/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.2368 - precision: 0.9348 - recall: 0.8600 - f1_score: 0.8957 - val_loss: 0.5262 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2784/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2358 - precision: 0.9423 - recall: 0.8667 - f1_score: 0.9026 - val_loss: 0.5262 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2785/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2362 - precision: 0.9459 - recall: 0.8700 - f1_score: 0.9059 - val_loss: 0.5265 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2786/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2372 - precision: 0.9283 - recall: 0.8567 - f1_score: 0.8908 - val_loss: 0.5269 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2787/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.2367 - precision: 0.9379 - recall: 0.8633 - f1_score: 0.8989 - val_loss: 0.5309 - val_precision: 0.5532 - val_recall: 0.4333 - val_f1_score: 0.4860\n",
            "Epoch 2788/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2346 - precision: 0.9533 - recall: 0.8800 - f1_score: 0.9152 - val_loss: 0.5278 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2789/3000\n",
            "300/300 [==============================] - 0s 98us/step - loss: 0.2348 - precision: 0.9453 - recall: 0.8633 - f1_score: 0.9025 - val_loss: 0.5278 - val_precision: 0.6250 - val_recall: 0.5000 - val_f1_score: 0.5556\n",
            "Epoch 2790/3000\n",
            "300/300 [==============================] - 0s 106us/step - loss: 0.2384 - precision: 0.9167 - recall: 0.8467 - f1_score: 0.8801 - val_loss: 0.5271 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2791/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2347 - precision: 0.9565 - recall: 0.8667 - f1_score: 0.9088 - val_loss: 0.5267 - val_precision: 0.6304 - val_recall: 0.4833 - val_f1_score: 0.5472\n",
            "Epoch 2792/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2333 - precision: 0.9458 - recall: 0.8767 - f1_score: 0.9097 - val_loss: 0.5380 - val_precision: 0.5600 - val_recall: 0.4667 - val_f1_score: 0.5091\n",
            "Epoch 2793/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2352 - precision: 0.9378 - recall: 0.8667 - f1_score: 0.9007 - val_loss: 0.5272 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2794/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2356 - precision: 0.9387 - recall: 0.8700 - f1_score: 0.9028 - val_loss: 0.5286 - val_precision: 0.6250 - val_recall: 0.5000 - val_f1_score: 0.5556\n",
            "Epoch 2795/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2348 - precision: 0.9420 - recall: 0.8667 - f1_score: 0.9027 - val_loss: 0.5265 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2796/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2344 - precision: 0.9484 - recall: 0.8567 - f1_score: 0.8991 - val_loss: 0.5293 - val_precision: 0.5686 - val_recall: 0.4833 - val_f1_score: 0.5225\n",
            "Epoch 2797/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2398 - precision: 0.9423 - recall: 0.8633 - f1_score: 0.9008 - val_loss: 0.5275 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2798/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2366 - precision: 0.9390 - recall: 0.8633 - f1_score: 0.8993 - val_loss: 0.5299 - val_precision: 0.5745 - val_recall: 0.4500 - val_f1_score: 0.5047\n",
            "Epoch 2799/3000\n",
            "300/300 [==============================] - 0s 104us/step - loss: 0.2360 - precision: 0.9344 - recall: 0.8567 - f1_score: 0.8938 - val_loss: 0.5303 - val_precision: 0.5600 - val_recall: 0.4667 - val_f1_score: 0.5091\n",
            "Epoch 2800/3000\n",
            "300/300 [==============================] - 0s 104us/step - loss: 0.2350 - precision: 0.9494 - recall: 0.8767 - f1_score: 0.9114 - val_loss: 0.5267 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2801/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2352 - precision: 0.9384 - recall: 0.8567 - f1_score: 0.8954 - val_loss: 0.5313 - val_precision: 0.5600 - val_recall: 0.4667 - val_f1_score: 0.5091\n",
            "Epoch 2802/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2359 - precision: 0.9459 - recall: 0.8733 - f1_score: 0.9079 - val_loss: 0.5274 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2803/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2387 - precision: 0.9213 - recall: 0.8600 - f1_score: 0.8893 - val_loss: 0.5267 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2804/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2355 - precision: 0.9552 - recall: 0.8633 - f1_score: 0.9066 - val_loss: 0.5274 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2805/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2354 - precision: 0.9486 - recall: 0.8700 - f1_score: 0.9075 - val_loss: 0.5280 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2806/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2390 - precision: 0.9262 - recall: 0.8500 - f1_score: 0.8862 - val_loss: 0.5298 - val_precision: 0.5490 - val_recall: 0.4667 - val_f1_score: 0.5045\n",
            "Epoch 2807/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2337 - precision: 0.9460 - recall: 0.8733 - f1_score: 0.9082 - val_loss: 0.5279 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2808/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.2361 - precision: 0.9495 - recall: 0.8733 - f1_score: 0.9098 - val_loss: 0.5267 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2809/3000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.2344 - precision: 0.9462 - recall: 0.8700 - f1_score: 0.9062 - val_loss: 0.5283 - val_precision: 0.6042 - val_recall: 0.4833 - val_f1_score: 0.5370\n",
            "Epoch 2810/3000\n",
            "300/300 [==============================] - 0s 109us/step - loss: 0.2349 - precision: 0.9452 - recall: 0.8700 - f1_score: 0.9059 - val_loss: 0.5272 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2811/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2335 - precision: 0.9523 - recall: 0.8700 - f1_score: 0.9087 - val_loss: 0.5270 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2812/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2354 - precision: 0.9380 - recall: 0.8567 - f1_score: 0.8955 - val_loss: 0.5350 - val_precision: 0.5385 - val_recall: 0.4667 - val_f1_score: 0.5000\n",
            "Epoch 2813/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2376 - precision: 0.9458 - recall: 0.8667 - f1_score: 0.9040 - val_loss: 0.5294 - val_precision: 0.5870 - val_recall: 0.4500 - val_f1_score: 0.5094\n",
            "Epoch 2814/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2336 - precision: 0.9529 - recall: 0.8733 - f1_score: 0.9111 - val_loss: 0.5272 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2815/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2337 - precision: 0.9491 - recall: 0.8700 - f1_score: 0.9077 - val_loss: 0.5299 - val_precision: 0.5957 - val_recall: 0.4667 - val_f1_score: 0.5234\n",
            "Epoch 2816/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2339 - precision: 0.9482 - recall: 0.8567 - f1_score: 0.8999 - val_loss: 0.5283 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2817/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2363 - precision: 0.9280 - recall: 0.8600 - f1_score: 0.8925 - val_loss: 0.5285 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 2818/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2370 - precision: 0.9324 - recall: 0.8533 - f1_score: 0.8907 - val_loss: 0.5292 - val_precision: 0.6122 - val_recall: 0.5000 - val_f1_score: 0.5505\n",
            "Epoch 2819/3000\n",
            "300/300 [==============================] - 0s 85us/step - loss: 0.2369 - precision: 0.9342 - recall: 0.8567 - f1_score: 0.8936 - val_loss: 0.5272 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2820/3000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.2356 - precision: 0.9316 - recall: 0.8633 - f1_score: 0.8961 - val_loss: 0.5330 - val_precision: 0.5510 - val_recall: 0.4500 - val_f1_score: 0.4954\n",
            "Epoch 2821/3000\n",
            "300/300 [==============================] - 0s 76us/step - loss: 0.2360 - precision: 0.9420 - recall: 0.8667 - f1_score: 0.9024 - val_loss: 0.5276 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2822/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2333 - precision: 0.9283 - recall: 0.8600 - f1_score: 0.8921 - val_loss: 0.5270 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 2823/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2325 - precision: 0.9456 - recall: 0.8700 - f1_score: 0.9056 - val_loss: 0.5273 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2824/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2354 - precision: 0.9451 - recall: 0.8600 - f1_score: 0.8999 - val_loss: 0.5328 - val_precision: 0.5385 - val_recall: 0.4667 - val_f1_score: 0.5000\n",
            "Epoch 2825/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2327 - precision: 0.9460 - recall: 0.8800 - f1_score: 0.9115 - val_loss: 0.5278 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2826/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2326 - precision: 0.9449 - recall: 0.8700 - f1_score: 0.9055 - val_loss: 0.5278 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2827/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2335 - precision: 0.9427 - recall: 0.8800 - f1_score: 0.9103 - val_loss: 0.5280 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2828/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2358 - precision: 0.9459 - recall: 0.8767 - f1_score: 0.9097 - val_loss: 0.5282 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2829/3000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.2350 - precision: 0.9348 - recall: 0.8633 - f1_score: 0.8976 - val_loss: 0.5272 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 2830/3000\n",
            "300/300 [==============================] - 0s 112us/step - loss: 0.2338 - precision: 0.9597 - recall: 0.8667 - f1_score: 0.9103 - val_loss: 0.5309 - val_precision: 0.5600 - val_recall: 0.4667 - val_f1_score: 0.5091\n",
            "Epoch 2831/3000\n",
            "300/300 [==============================] - 0s 79us/step - loss: 0.2351 - precision: 0.9455 - recall: 0.8633 - f1_score: 0.9023 - val_loss: 0.5272 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 2832/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2327 - precision: 0.9491 - recall: 0.8733 - f1_score: 0.9096 - val_loss: 0.5304 - val_precision: 0.5600 - val_recall: 0.4667 - val_f1_score: 0.5091\n",
            "Epoch 2833/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2324 - precision: 0.9522 - recall: 0.8667 - f1_score: 0.9074 - val_loss: 0.5279 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2834/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2338 - precision: 0.9350 - recall: 0.8633 - f1_score: 0.8974 - val_loss: 0.5361 - val_precision: 0.5385 - val_recall: 0.4667 - val_f1_score: 0.5000\n",
            "Epoch 2835/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.2350 - precision: 0.9381 - recall: 0.8633 - f1_score: 0.8990 - val_loss: 0.5325 - val_precision: 0.5490 - val_recall: 0.4667 - val_f1_score: 0.5045\n",
            "Epoch 2836/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2329 - precision: 0.9465 - recall: 0.8733 - f1_score: 0.9079 - val_loss: 0.5301 - val_precision: 0.5600 - val_recall: 0.4667 - val_f1_score: 0.5091\n",
            "Epoch 2837/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2360 - precision: 0.9422 - recall: 0.8733 - f1_score: 0.9061 - val_loss: 0.5273 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2838/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.2346 - precision: 0.9315 - recall: 0.8667 - f1_score: 0.8978 - val_loss: 0.5297 - val_precision: 0.6000 - val_recall: 0.5000 - val_f1_score: 0.5455\n",
            "Epoch 2839/3000\n",
            "300/300 [==============================] - 0s 93us/step - loss: 0.2368 - precision: 0.9447 - recall: 0.8633 - f1_score: 0.9021 - val_loss: 0.5276 - val_precision: 0.6304 - val_recall: 0.4833 - val_f1_score: 0.5472\n",
            "Epoch 2840/3000\n",
            "300/300 [==============================] - 0s 109us/step - loss: 0.2329 - precision: 0.9529 - recall: 0.8733 - f1_score: 0.9112 - val_loss: 0.5292 - val_precision: 0.6042 - val_recall: 0.4833 - val_f1_score: 0.5370\n",
            "Epoch 2841/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2321 - precision: 0.9419 - recall: 0.8633 - f1_score: 0.9007 - val_loss: 0.5429 - val_precision: 0.5800 - val_recall: 0.4833 - val_f1_score: 0.5273\n",
            "Epoch 2842/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2358 - precision: 0.9314 - recall: 0.8600 - f1_score: 0.8942 - val_loss: 0.5370 - val_precision: 0.5294 - val_recall: 0.4500 - val_f1_score: 0.4865\n",
            "Epoch 2843/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2330 - precision: 0.9557 - recall: 0.8700 - f1_score: 0.9103 - val_loss: 0.5276 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2844/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2328 - precision: 0.9303 - recall: 0.8567 - f1_score: 0.8918 - val_loss: 0.5296 - val_precision: 0.5686 - val_recall: 0.4833 - val_f1_score: 0.5225\n",
            "Epoch 2845/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2319 - precision: 0.9458 - recall: 0.8667 - f1_score: 0.9044 - val_loss: 0.5337 - val_precision: 0.5490 - val_recall: 0.4667 - val_f1_score: 0.5045\n",
            "Epoch 2846/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2399 - precision: 0.9091 - recall: 0.8400 - f1_score: 0.8731 - val_loss: 0.5325 - val_precision: 0.5532 - val_recall: 0.4333 - val_f1_score: 0.4860\n",
            "Epoch 2847/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2335 - precision: 0.9537 - recall: 0.8933 - f1_score: 0.9223 - val_loss: 0.5285 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2848/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2323 - precision: 0.9464 - recall: 0.8867 - f1_score: 0.9155 - val_loss: 0.5275 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2849/3000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.2331 - precision: 0.9457 - recall: 0.8700 - f1_score: 0.9061 - val_loss: 0.5276 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2850/3000\n",
            "300/300 [==============================] - 0s 112us/step - loss: 0.2340 - precision: 0.9412 - recall: 0.8600 - f1_score: 0.8986 - val_loss: 0.5278 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2851/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2327 - precision: 0.9443 - recall: 0.8633 - f1_score: 0.9016 - val_loss: 0.5288 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2852/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2336 - precision: 0.9243 - recall: 0.8567 - f1_score: 0.8889 - val_loss: 0.5323 - val_precision: 0.5490 - val_recall: 0.4667 - val_f1_score: 0.5045\n",
            "Epoch 2853/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2331 - precision: 0.9491 - recall: 0.8767 - f1_score: 0.9112 - val_loss: 0.5296 - val_precision: 0.6250 - val_recall: 0.5000 - val_f1_score: 0.5556\n",
            "Epoch 2854/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2316 - precision: 0.9536 - recall: 0.8933 - f1_score: 0.9222 - val_loss: 0.5282 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2855/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.2324 - precision: 0.9425 - recall: 0.8767 - f1_score: 0.9083 - val_loss: 0.5278 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2856/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2316 - precision: 0.9525 - recall: 0.8733 - f1_score: 0.9109 - val_loss: 0.5290 - val_precision: 0.6250 - val_recall: 0.5000 - val_f1_score: 0.5556\n",
            "Epoch 2857/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2364 - precision: 0.9407 - recall: 0.8600 - f1_score: 0.8984 - val_loss: 0.5283 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2858/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2355 - precision: 0.9488 - recall: 0.8633 - f1_score: 0.9039 - val_loss: 0.5281 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2859/3000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.2308 - precision: 0.9487 - recall: 0.8667 - f1_score: 0.9055 - val_loss: 0.5306 - val_precision: 0.5686 - val_recall: 0.4833 - val_f1_score: 0.5225\n",
            "Epoch 2860/3000\n",
            "300/300 [==============================] - 0s 106us/step - loss: 0.2325 - precision: 0.9492 - recall: 0.8767 - f1_score: 0.9113 - val_loss: 0.5309 - val_precision: 0.5625 - val_recall: 0.4500 - val_f1_score: 0.5000\n",
            "Epoch 2861/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2353 - precision: 0.9389 - recall: 0.8667 - f1_score: 0.9011 - val_loss: 0.5308 - val_precision: 0.5957 - val_recall: 0.4667 - val_f1_score: 0.5234\n",
            "Epoch 2862/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2356 - precision: 0.9375 - recall: 0.8500 - f1_score: 0.8914 - val_loss: 0.5291 - val_precision: 0.6042 - val_recall: 0.4833 - val_f1_score: 0.5370\n",
            "Epoch 2863/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2329 - precision: 0.9454 - recall: 0.8700 - f1_score: 0.9061 - val_loss: 0.5287 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2864/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2356 - precision: 0.9336 - recall: 0.8533 - f1_score: 0.8915 - val_loss: 0.5283 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 2865/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2314 - precision: 0.9553 - recall: 0.8667 - f1_score: 0.9085 - val_loss: 0.5294 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2866/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2329 - precision: 0.9428 - recall: 0.8633 - f1_score: 0.9008 - val_loss: 0.5290 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2867/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2324 - precision: 0.9555 - recall: 0.8733 - f1_score: 0.9123 - val_loss: 0.5286 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 2868/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2314 - precision: 0.9431 - recall: 0.8767 - f1_score: 0.9085 - val_loss: 0.5301 - val_precision: 0.5800 - val_recall: 0.4833 - val_f1_score: 0.5273\n",
            "Epoch 2869/3000\n",
            "300/300 [==============================] - 0s 116us/step - loss: 0.2332 - precision: 0.9549 - recall: 0.8633 - f1_score: 0.9064 - val_loss: 0.5290 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2870/3000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.2360 - precision: 0.9282 - recall: 0.8567 - f1_score: 0.8906 - val_loss: 0.5286 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 2871/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2320 - precision: 0.9600 - recall: 0.8867 - f1_score: 0.9218 - val_loss: 0.5300 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2872/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2315 - precision: 0.9493 - recall: 0.8700 - f1_score: 0.9078 - val_loss: 0.5290 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2873/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2312 - precision: 0.9505 - recall: 0.8833 - f1_score: 0.9153 - val_loss: 0.5283 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 2874/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2345 - precision: 0.9384 - recall: 0.8667 - f1_score: 0.9009 - val_loss: 0.5313 - val_precision: 0.5490 - val_recall: 0.4667 - val_f1_score: 0.5045\n",
            "Epoch 2875/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2313 - precision: 0.9464 - recall: 0.8733 - f1_score: 0.9082 - val_loss: 0.5296 - val_precision: 0.6042 - val_recall: 0.4833 - val_f1_score: 0.5370\n",
            "Epoch 2876/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2316 - precision: 0.9559 - recall: 0.8667 - f1_score: 0.9090 - val_loss: 0.5286 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2877/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2320 - precision: 0.9451 - recall: 0.8700 - f1_score: 0.9059 - val_loss: 0.5297 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2878/3000\n",
            "300/300 [==============================] - 0s 101us/step - loss: 0.2309 - precision: 0.9501 - recall: 0.8767 - f1_score: 0.9118 - val_loss: 0.5332 - val_precision: 0.5490 - val_recall: 0.4667 - val_f1_score: 0.5045\n",
            "Epoch 2879/3000\n",
            "300/300 [==============================] - 0s 96us/step - loss: 0.2332 - precision: 0.9405 - recall: 0.8733 - f1_score: 0.9054 - val_loss: 0.5325 - val_precision: 0.5490 - val_recall: 0.4667 - val_f1_score: 0.5045\n",
            "Epoch 2880/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.2338 - precision: 0.9456 - recall: 0.8700 - f1_score: 0.9060 - val_loss: 0.5287 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 2881/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.2337 - precision: 0.9493 - recall: 0.8800 - f1_score: 0.9132 - val_loss: 0.5284 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 2882/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2329 - precision: 0.9354 - recall: 0.8633 - f1_score: 0.8976 - val_loss: 0.5365 - val_precision: 0.5400 - val_recall: 0.4500 - val_f1_score: 0.4909\n",
            "Epoch 2883/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2322 - precision: 0.9484 - recall: 0.8700 - f1_score: 0.9069 - val_loss: 0.5289 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2884/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2330 - precision: 0.9456 - recall: 0.8700 - f1_score: 0.9059 - val_loss: 0.5283 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2885/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2308 - precision: 0.9533 - recall: 0.8833 - f1_score: 0.9169 - val_loss: 0.5288 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 2886/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2309 - precision: 0.9453 - recall: 0.8700 - f1_score: 0.9058 - val_loss: 0.5288 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2887/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2321 - precision: 0.9250 - recall: 0.8567 - f1_score: 0.8895 - val_loss: 0.5366 - val_precision: 0.5385 - val_recall: 0.4667 - val_f1_score: 0.5000\n",
            "Epoch 2888/3000\n",
            "300/300 [==============================] - 0s 97us/step - loss: 0.2320 - precision: 0.9501 - recall: 0.8867 - f1_score: 0.9173 - val_loss: 0.5313 - val_precision: 0.5918 - val_recall: 0.4833 - val_f1_score: 0.5321\n",
            "Epoch 2889/3000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.2303 - precision: 0.9524 - recall: 0.8767 - f1_score: 0.9120 - val_loss: 0.5302 - val_precision: 0.6250 - val_recall: 0.5000 - val_f1_score: 0.5556\n",
            "Epoch 2890/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2318 - precision: 0.9487 - recall: 0.8600 - f1_score: 0.9021 - val_loss: 0.5287 - val_precision: 0.6304 - val_recall: 0.4833 - val_f1_score: 0.5472\n",
            "Epoch 2891/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2304 - precision: 0.9210 - recall: 0.8600 - f1_score: 0.8894 - val_loss: 0.5330 - val_precision: 0.5490 - val_recall: 0.4667 - val_f1_score: 0.5045\n",
            "Epoch 2892/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2322 - precision: 0.9323 - recall: 0.8633 - f1_score: 0.8962 - val_loss: 0.5346 - val_precision: 0.5490 - val_recall: 0.4667 - val_f1_score: 0.5045\n",
            "Epoch 2893/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2306 - precision: 0.9463 - recall: 0.8900 - f1_score: 0.9171 - val_loss: 0.5290 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2894/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2341 - precision: 0.9328 - recall: 0.8633 - f1_score: 0.8964 - val_loss: 0.5293 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2895/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2320 - precision: 0.9422 - recall: 0.8633 - f1_score: 0.9010 - val_loss: 0.5312 - val_precision: 0.6000 - val_recall: 0.5000 - val_f1_score: 0.5455\n",
            "Epoch 2896/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2307 - precision: 0.9444 - recall: 0.8600 - f1_score: 0.9000 - val_loss: 0.5329 - val_precision: 0.5600 - val_recall: 0.4667 - val_f1_score: 0.5091\n",
            "Epoch 2897/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2323 - precision: 0.9498 - recall: 0.8733 - f1_score: 0.9098 - val_loss: 0.5294 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2898/3000\n",
            "300/300 [==============================] - 0s 109us/step - loss: 0.2319 - precision: 0.9294 - recall: 0.8733 - f1_score: 0.9004 - val_loss: 0.5309 - val_precision: 0.5800 - val_recall: 0.4833 - val_f1_score: 0.5273\n",
            "Epoch 2899/3000\n",
            "300/300 [==============================] - 0s 91us/step - loss: 0.2317 - precision: 0.9535 - recall: 0.8800 - f1_score: 0.9150 - val_loss: 0.5288 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2900/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2304 - precision: 0.9487 - recall: 0.8633 - f1_score: 0.9038 - val_loss: 0.5318 - val_precision: 0.5686 - val_recall: 0.4833 - val_f1_score: 0.5225\n",
            "Epoch 2901/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2348 - precision: 0.9386 - recall: 0.8700 - f1_score: 0.9026 - val_loss: 0.5289 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2902/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2310 - precision: 0.9489 - recall: 0.8667 - f1_score: 0.9058 - val_loss: 0.5290 - val_precision: 0.6304 - val_recall: 0.4833 - val_f1_score: 0.5472\n",
            "Epoch 2903/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2319 - precision: 0.9366 - recall: 0.8567 - f1_score: 0.8941 - val_loss: 0.5314 - val_precision: 0.5686 - val_recall: 0.4833 - val_f1_score: 0.5225\n",
            "Epoch 2904/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2302 - precision: 0.9562 - recall: 0.8833 - f1_score: 0.9181 - val_loss: 0.5291 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2905/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2330 - precision: 0.9414 - recall: 0.8600 - f1_score: 0.8987 - val_loss: 0.5292 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2906/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2321 - precision: 0.9352 - recall: 0.8667 - f1_score: 0.8996 - val_loss: 0.5298 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2907/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.2337 - precision: 0.9423 - recall: 0.8633 - f1_score: 0.9008 - val_loss: 0.5307 - val_precision: 0.5957 - val_recall: 0.4667 - val_f1_score: 0.5234\n",
            "Epoch 2908/3000\n",
            "300/300 [==============================] - 0s 119us/step - loss: 0.2299 - precision: 0.9386 - recall: 0.8667 - f1_score: 0.9011 - val_loss: 0.5337 - val_precision: 0.5400 - val_recall: 0.4500 - val_f1_score: 0.4909\n",
            "Epoch 2909/3000\n",
            "300/300 [==============================] - 0s 92us/step - loss: 0.2314 - precision: 0.9423 - recall: 0.8733 - f1_score: 0.9064 - val_loss: 0.5305 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2910/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2395 - precision: 0.9259 - recall: 0.8433 - f1_score: 0.8824 - val_loss: 0.5330 - val_precision: 0.5510 - val_recall: 0.4500 - val_f1_score: 0.4954\n",
            "Epoch 2911/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2314 - precision: 0.9558 - recall: 0.8633 - f1_score: 0.9070 - val_loss: 0.5365 - val_precision: 0.5385 - val_recall: 0.4667 - val_f1_score: 0.5000\n",
            "Epoch 2912/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2297 - precision: 0.9530 - recall: 0.8767 - f1_score: 0.9131 - val_loss: 0.5297 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2913/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2309 - precision: 0.9516 - recall: 0.8633 - f1_score: 0.9046 - val_loss: 0.5299 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2914/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2301 - precision: 0.9417 - recall: 0.8667 - f1_score: 0.9022 - val_loss: 0.5295 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2915/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2301 - precision: 0.9558 - recall: 0.8733 - f1_score: 0.9119 - val_loss: 0.5293 - val_precision: 0.6304 - val_recall: 0.4833 - val_f1_score: 0.5472\n",
            "Epoch 2916/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2302 - precision: 0.9430 - recall: 0.8733 - f1_score: 0.9067 - val_loss: 0.5350 - val_precision: 0.5490 - val_recall: 0.4667 - val_f1_score: 0.5045\n",
            "Epoch 2917/3000\n",
            "300/300 [==============================] - 0s 80us/step - loss: 0.2334 - precision: 0.9425 - recall: 0.8733 - f1_score: 0.9064 - val_loss: 0.5300 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2918/3000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.2292 - precision: 0.9528 - recall: 0.8833 - f1_score: 0.9164 - val_loss: 0.5299 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2919/3000\n",
            "300/300 [==============================] - 0s 81us/step - loss: 0.2317 - precision: 0.9522 - recall: 0.8633 - f1_score: 0.9054 - val_loss: 0.5313 - val_precision: 0.5957 - val_recall: 0.4667 - val_f1_score: 0.5234\n",
            "Epoch 2920/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2293 - precision: 0.9531 - recall: 0.8833 - f1_score: 0.9167 - val_loss: 0.5294 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2921/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2312 - precision: 0.9419 - recall: 0.8667 - f1_score: 0.9024 - val_loss: 0.5317 - val_precision: 0.5686 - val_recall: 0.4833 - val_f1_score: 0.5225\n",
            "Epoch 2922/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2302 - precision: 0.9572 - recall: 0.8867 - f1_score: 0.9203 - val_loss: 0.5311 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2923/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2294 - precision: 0.9529 - recall: 0.8733 - f1_score: 0.9109 - val_loss: 0.5335 - val_precision: 0.5532 - val_recall: 0.4333 - val_f1_score: 0.4860\n",
            "Epoch 2924/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2316 - precision: 0.9530 - recall: 0.8800 - f1_score: 0.9146 - val_loss: 0.5304 - val_precision: 0.6042 - val_recall: 0.4833 - val_f1_score: 0.5370\n",
            "Epoch 2925/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2294 - precision: 0.9491 - recall: 0.8733 - f1_score: 0.9094 - val_loss: 0.5298 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2926/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2301 - precision: 0.9492 - recall: 0.8700 - f1_score: 0.9078 - val_loss: 0.5301 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2927/3000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.2310 - precision: 0.9495 - recall: 0.8700 - f1_score: 0.9078 - val_loss: 0.5295 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2928/3000\n",
            "300/300 [==============================] - 0s 94us/step - loss: 0.2324 - precision: 0.9556 - recall: 0.8700 - f1_score: 0.9105 - val_loss: 0.5302 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2929/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2316 - precision: 0.9484 - recall: 0.8633 - f1_score: 0.9030 - val_loss: 0.5298 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2930/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2289 - precision: 0.9422 - recall: 0.8700 - f1_score: 0.9046 - val_loss: 0.5305 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2931/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2284 - precision: 0.9527 - recall: 0.8800 - f1_score: 0.9145 - val_loss: 0.5298 - val_precision: 0.6304 - val_recall: 0.4833 - val_f1_score: 0.5472\n",
            "Epoch 2932/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2333 - precision: 0.9381 - recall: 0.8567 - f1_score: 0.8953 - val_loss: 0.5312 - val_precision: 0.6042 - val_recall: 0.4833 - val_f1_score: 0.5370\n",
            "Epoch 2933/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2285 - precision: 0.9495 - recall: 0.8767 - f1_score: 0.9113 - val_loss: 0.5303 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2934/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2292 - precision: 0.9630 - recall: 0.8667 - f1_score: 0.9122 - val_loss: 0.5296 - val_precision: 0.6136 - val_recall: 0.4500 - val_f1_score: 0.5192\n",
            "Epoch 2935/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2309 - precision: 0.9409 - recall: 0.8667 - f1_score: 0.9013 - val_loss: 0.5341 - val_precision: 0.5400 - val_recall: 0.4500 - val_f1_score: 0.4909\n",
            "Epoch 2936/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2304 - precision: 0.9500 - recall: 0.8833 - f1_score: 0.9153 - val_loss: 0.5315 - val_precision: 0.5957 - val_recall: 0.4667 - val_f1_score: 0.5234\n",
            "Epoch 2937/3000\n",
            "300/300 [==============================] - 0s 110us/step - loss: 0.2300 - precision: 0.9421 - recall: 0.8667 - f1_score: 0.9028 - val_loss: 0.5296 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2938/3000\n",
            "300/300 [==============================] - 0s 87us/step - loss: 0.2283 - precision: 0.9530 - recall: 0.8700 - f1_score: 0.9093 - val_loss: 0.5321 - val_precision: 0.5686 - val_recall: 0.4833 - val_f1_score: 0.5225\n",
            "Epoch 2939/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2301 - precision: 0.9429 - recall: 0.8733 - f1_score: 0.9065 - val_loss: 0.5338 - val_precision: 0.5600 - val_recall: 0.4667 - val_f1_score: 0.5091\n",
            "Epoch 2940/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2295 - precision: 0.9562 - recall: 0.8767 - f1_score: 0.9145 - val_loss: 0.5301 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2941/3000\n",
            "300/300 [==============================] - 0s 70us/step - loss: 0.2294 - precision: 0.9537 - recall: 0.8733 - f1_score: 0.9114 - val_loss: 0.5309 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2942/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.2288 - precision: 0.9114 - recall: 0.8567 - f1_score: 0.8829 - val_loss: 0.5368 - val_precision: 0.5385 - val_recall: 0.4667 - val_f1_score: 0.5000\n",
            "Epoch 2943/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2294 - precision: 0.9610 - recall: 0.8733 - f1_score: 0.9145 - val_loss: 0.5333 - val_precision: 0.5714 - val_recall: 0.4667 - val_f1_score: 0.5138\n",
            "Epoch 2944/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2300 - precision: 0.9529 - recall: 0.8700 - f1_score: 0.9094 - val_loss: 0.5299 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 2945/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2309 - precision: 0.9419 - recall: 0.8667 - f1_score: 0.9026 - val_loss: 0.5316 - val_precision: 0.6042 - val_recall: 0.4833 - val_f1_score: 0.5370\n",
            "Epoch 2946/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2286 - precision: 0.9539 - recall: 0.8633 - f1_score: 0.9058 - val_loss: 0.5401 - val_precision: 0.5490 - val_recall: 0.4667 - val_f1_score: 0.5045\n",
            "Epoch 2947/3000\n",
            "300/300 [==============================] - 0s 103us/step - loss: 0.2295 - precision: 0.9426 - recall: 0.8633 - f1_score: 0.9010 - val_loss: 0.5327 - val_precision: 0.5957 - val_recall: 0.4667 - val_f1_score: 0.5234\n",
            "Epoch 2948/3000\n",
            "300/300 [==============================] - 0s 105us/step - loss: 0.2291 - precision: 0.9347 - recall: 0.8600 - f1_score: 0.8955 - val_loss: 0.5325 - val_precision: 0.5769 - val_recall: 0.5000 - val_f1_score: 0.5357\n",
            "Epoch 2949/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.2297 - precision: 0.9486 - recall: 0.8800 - f1_score: 0.9127 - val_loss: 0.5305 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 2950/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.2302 - precision: 0.9427 - recall: 0.8767 - f1_score: 0.9083 - val_loss: 0.5313 - val_precision: 0.6042 - val_recall: 0.4833 - val_f1_score: 0.5370\n",
            "Epoch 2951/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2277 - precision: 0.9415 - recall: 0.8533 - f1_score: 0.8950 - val_loss: 0.5360 - val_precision: 0.5490 - val_recall: 0.4667 - val_f1_score: 0.5045\n",
            "Epoch 2952/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2305 - precision: 0.9456 - recall: 0.8800 - f1_score: 0.9115 - val_loss: 0.5345 - val_precision: 0.5490 - val_recall: 0.4667 - val_f1_score: 0.5045\n",
            "Epoch 2953/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2326 - precision: 0.9416 - recall: 0.8533 - f1_score: 0.8951 - val_loss: 0.5369 - val_precision: 0.5385 - val_recall: 0.4667 - val_f1_score: 0.5000\n",
            "Epoch 2954/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2287 - precision: 0.9580 - recall: 0.8900 - f1_score: 0.9221 - val_loss: 0.5304 - val_precision: 0.6304 - val_recall: 0.4833 - val_f1_score: 0.5472\n",
            "Epoch 2955/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2284 - precision: 0.9355 - recall: 0.8800 - f1_score: 0.9067 - val_loss: 0.5335 - val_precision: 0.5686 - val_recall: 0.4833 - val_f1_score: 0.5225\n",
            "Epoch 2956/3000\n",
            "300/300 [==============================] - 0s 72us/step - loss: 0.2293 - precision: 0.9563 - recall: 0.8733 - f1_score: 0.9128 - val_loss: 0.5301 - val_precision: 0.6364 - val_recall: 0.4667 - val_f1_score: 0.5385\n",
            "Epoch 2957/3000\n",
            "300/300 [==============================] - 0s 100us/step - loss: 0.2295 - precision: 0.9420 - recall: 0.8633 - f1_score: 0.9009 - val_loss: 0.5332 - val_precision: 0.5714 - val_recall: 0.4667 - val_f1_score: 0.5138\n",
            "Epoch 2958/3000\n",
            "300/300 [==============================] - 0s 95us/step - loss: 0.2289 - precision: 0.9495 - recall: 0.8833 - f1_score: 0.9152 - val_loss: 0.5307 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2959/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2285 - precision: 0.9599 - recall: 0.8733 - f1_score: 0.9144 - val_loss: 0.5310 - val_precision: 0.6000 - val_recall: 0.4500 - val_f1_score: 0.5143\n",
            "Epoch 2960/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.2282 - precision: 0.9499 - recall: 0.8833 - f1_score: 0.9153 - val_loss: 0.5310 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2961/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2304 - precision: 0.9462 - recall: 0.8733 - f1_score: 0.9080 - val_loss: 0.5321 - val_precision: 0.6042 - val_recall: 0.4833 - val_f1_score: 0.5370\n",
            "Epoch 2962/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2294 - precision: 0.9430 - recall: 0.8733 - f1_score: 0.9067 - val_loss: 0.5315 - val_precision: 0.5957 - val_recall: 0.4667 - val_f1_score: 0.5234\n",
            "Epoch 2963/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2281 - precision: 0.9382 - recall: 0.8633 - f1_score: 0.8987 - val_loss: 0.5340 - val_precision: 0.5600 - val_recall: 0.4667 - val_f1_score: 0.5091\n",
            "Epoch 2964/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.2302 - precision: 0.9529 - recall: 0.8867 - f1_score: 0.9184 - val_loss: 0.5309 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2965/3000\n",
            "300/300 [==============================] - 0s 59us/step - loss: 0.2340 - precision: 0.9381 - recall: 0.8633 - f1_score: 0.8991 - val_loss: 0.5308 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2966/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2311 - precision: 0.9464 - recall: 0.8800 - f1_score: 0.9116 - val_loss: 0.5329 - val_precision: 0.5714 - val_recall: 0.4667 - val_f1_score: 0.5138\n",
            "Epoch 2967/3000\n",
            "300/300 [==============================] - 0s 101us/step - loss: 0.2297 - precision: 0.9382 - recall: 0.8567 - f1_score: 0.8955 - val_loss: 0.5331 - val_precision: 0.5882 - val_recall: 0.5000 - val_f1_score: 0.5405\n",
            "Epoch 2968/3000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.2285 - precision: 0.9422 - recall: 0.8700 - f1_score: 0.9045 - val_loss: 0.5366 - val_precision: 0.5490 - val_recall: 0.4667 - val_f1_score: 0.5045\n",
            "Epoch 2969/3000\n",
            "300/300 [==============================] - 0s 80us/step - loss: 0.2299 - precision: 0.9425 - recall: 0.8767 - f1_score: 0.9084 - val_loss: 0.5375 - val_precision: 0.5294 - val_recall: 0.4500 - val_f1_score: 0.4865\n",
            "Epoch 2970/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2303 - precision: 0.9426 - recall: 0.8700 - f1_score: 0.9045 - val_loss: 0.5366 - val_precision: 0.5490 - val_recall: 0.4667 - val_f1_score: 0.5045\n",
            "Epoch 2971/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.2302 - precision: 0.9492 - recall: 0.8733 - f1_score: 0.9094 - val_loss: 0.5321 - val_precision: 0.5957 - val_recall: 0.4667 - val_f1_score: 0.5234\n",
            "Epoch 2972/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.2282 - precision: 0.9492 - recall: 0.8800 - f1_score: 0.9129 - val_loss: 0.5305 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2973/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2283 - precision: 0.9497 - recall: 0.8800 - f1_score: 0.9134 - val_loss: 0.5321 - val_precision: 0.5957 - val_recall: 0.4667 - val_f1_score: 0.5234\n",
            "Epoch 2974/3000\n",
            "300/300 [==============================] - 0s 61us/step - loss: 0.2292 - precision: 0.9551 - recall: 0.8800 - f1_score: 0.9150 - val_loss: 0.5338 - val_precision: 0.5957 - val_recall: 0.4667 - val_f1_score: 0.5234\n",
            "Epoch 2975/3000\n",
            "300/300 [==============================] - 0s 64us/step - loss: 0.2283 - precision: 0.9458 - recall: 0.8733 - f1_score: 0.9080 - val_loss: 0.5333 - val_precision: 0.5833 - val_recall: 0.4667 - val_f1_score: 0.5185\n",
            "Epoch 2976/3000\n",
            "300/300 [==============================] - 0s 59us/step - loss: 0.2286 - precision: 0.9497 - recall: 0.8800 - f1_score: 0.9135 - val_loss: 0.5391 - val_precision: 0.5400 - val_recall: 0.4500 - val_f1_score: 0.4909\n",
            "Epoch 2977/3000\n",
            "300/300 [==============================] - 0s 86us/step - loss: 0.2293 - precision: 0.9530 - recall: 0.8800 - f1_score: 0.9147 - val_loss: 0.5333 - val_precision: 0.5686 - val_recall: 0.4833 - val_f1_score: 0.5225\n",
            "Epoch 2978/3000\n",
            "300/300 [==============================] - 0s 81us/step - loss: 0.2283 - precision: 0.9454 - recall: 0.8700 - f1_score: 0.9059 - val_loss: 0.5367 - val_precision: 0.5490 - val_recall: 0.4667 - val_f1_score: 0.5045\n",
            "Epoch 2979/3000\n",
            "300/300 [==============================] - 0s 77us/step - loss: 0.2269 - precision: 0.9531 - recall: 0.8800 - f1_score: 0.9150 - val_loss: 0.5313 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2980/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.2280 - precision: 0.9432 - recall: 0.8733 - f1_score: 0.9066 - val_loss: 0.5370 - val_precision: 0.5490 - val_recall: 0.4667 - val_f1_score: 0.5045\n",
            "Epoch 2981/3000\n",
            "300/300 [==============================] - 0s 60us/step - loss: 0.2311 - precision: 0.9463 - recall: 0.8767 - f1_score: 0.9100 - val_loss: 0.5333 - val_precision: 0.5833 - val_recall: 0.4667 - val_f1_score: 0.5185\n",
            "Epoch 2982/3000\n",
            "300/300 [==============================] - 0s 59us/step - loss: 0.2285 - precision: 0.9464 - recall: 0.8700 - f1_score: 0.9062 - val_loss: 0.5337 - val_precision: 0.5833 - val_recall: 0.4667 - val_f1_score: 0.5185\n",
            "Epoch 2983/3000\n",
            "300/300 [==============================] - 0s 58us/step - loss: 0.2276 - precision: 0.9640 - recall: 0.8833 - f1_score: 0.9215 - val_loss: 0.5314 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2984/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2294 - precision: 0.9391 - recall: 0.8767 - f1_score: 0.9066 - val_loss: 0.5311 - val_precision: 0.6304 - val_recall: 0.4833 - val_f1_score: 0.5472\n",
            "Epoch 2985/3000\n",
            "300/300 [==============================] - 0s 63us/step - loss: 0.2316 - precision: 0.9283 - recall: 0.8667 - f1_score: 0.8962 - val_loss: 0.5318 - val_precision: 0.6087 - val_recall: 0.4667 - val_f1_score: 0.5283\n",
            "Epoch 2986/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2268 - precision: 0.9573 - recall: 0.8767 - f1_score: 0.9148 - val_loss: 0.5312 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2987/3000\n",
            "300/300 [==============================] - 0s 88us/step - loss: 0.2281 - precision: 0.9322 - recall: 0.8667 - f1_score: 0.8977 - val_loss: 0.5362 - val_precision: 0.5490 - val_recall: 0.4667 - val_f1_score: 0.5045\n",
            "Epoch 2988/3000\n",
            "300/300 [==============================] - 0s 99us/step - loss: 0.2294 - precision: 0.9429 - recall: 0.8767 - f1_score: 0.9085 - val_loss: 0.5358 - val_precision: 0.5400 - val_recall: 0.4500 - val_f1_score: 0.4909\n",
            "Epoch 2989/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2267 - precision: 0.9500 - recall: 0.8867 - f1_score: 0.9171 - val_loss: 0.5317 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2990/3000\n",
            "300/300 [==============================] - 0s 73us/step - loss: 0.2278 - precision: 0.9354 - recall: 0.8733 - f1_score: 0.9032 - val_loss: 0.5313 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2991/3000\n",
            "300/300 [==============================] - 0s 66us/step - loss: 0.2296 - precision: 0.9253 - recall: 0.8633 - f1_score: 0.8932 - val_loss: 0.5336 - val_precision: 0.5957 - val_recall: 0.4667 - val_f1_score: 0.5234\n",
            "Epoch 2992/3000\n",
            "300/300 [==============================] - 0s 69us/step - loss: 0.2320 - precision: 0.9595 - recall: 0.8700 - f1_score: 0.9123 - val_loss: 0.5348 - val_precision: 0.5600 - val_recall: 0.4667 - val_f1_score: 0.5091\n",
            "Epoch 2993/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2270 - precision: 0.9538 - recall: 0.8900 - f1_score: 0.9206 - val_loss: 0.5312 - val_precision: 0.6222 - val_recall: 0.4667 - val_f1_score: 0.5333\n",
            "Epoch 2994/3000\n",
            "300/300 [==============================] - 0s 71us/step - loss: 0.2278 - precision: 0.9530 - recall: 0.8767 - f1_score: 0.9130 - val_loss: 0.5317 - val_precision: 0.6170 - val_recall: 0.4833 - val_f1_score: 0.5421\n",
            "Epoch 2995/3000\n",
            "300/300 [==============================] - 0s 68us/step - loss: 0.2281 - precision: 0.9389 - recall: 0.8667 - f1_score: 0.9013 - val_loss: 0.5311 - val_precision: 0.6304 - val_recall: 0.4833 - val_f1_score: 0.5472\n",
            "Epoch 2996/3000\n",
            "300/300 [==============================] - 0s 67us/step - loss: 0.2284 - precision: 0.9360 - recall: 0.8767 - f1_score: 0.9052 - val_loss: 0.5326 - val_precision: 0.5957 - val_recall: 0.4667 - val_f1_score: 0.5234\n",
            "Epoch 2997/3000\n",
            "300/300 [==============================] - 0s 106us/step - loss: 0.2278 - precision: 0.9514 - recall: 0.8600 - f1_score: 0.9033 - val_loss: 0.5336 - val_precision: 0.5745 - val_recall: 0.4500 - val_f1_score: 0.5047\n",
            "Epoch 2998/3000\n",
            "300/300 [==============================] - 0s 89us/step - loss: 0.2278 - precision: 0.9412 - recall: 0.8633 - f1_score: 0.9004 - val_loss: 0.5333 - val_precision: 0.5686 - val_recall: 0.4833 - val_f1_score: 0.5225\n",
            "Epoch 2999/3000\n",
            "300/300 [==============================] - 0s 65us/step - loss: 0.2273 - precision: 0.9488 - recall: 0.8700 - f1_score: 0.9075 - val_loss: 0.5353 - val_precision: 0.5600 - val_recall: 0.4667 - val_f1_score: 0.5091\n",
            "Epoch 3000/3000\n",
            "300/300 [==============================] - 0s 62us/step - loss: 0.2270 - precision: 0.9536 - recall: 0.8833 - f1_score: 0.9170 - val_loss: 0.5334 - val_precision: 0.5957 - val_recall: 0.4667 - val_f1_score: 0.5234\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "s0u1rWuECaAi"
      },
      "cell_type": "markdown",
      "source": [
        "We now plot the training history."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Azy4air5CaAj",
        "outputId": "e74bb0c0-9d40-4f56-e1e7-5107039e19cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "plt.plot(history_sgd.history['f1_score'])\n",
        "plt.plot(history_sgd.history['val_f1_score'])\n",
        "plt.title('model f1 score')\n",
        "plt.ylabel('f1 score')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history_sgd.history['loss'])\n",
        "plt.plot(history_sgd.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "VX-zJoQORhzC"
      },
      "cell_type": "markdown",
      "source": [
        "#### Adam optimizer\n",
        "We train our model with Adam optimizer."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Oj3Up3P9RhzC",
        "outputId": "5f4ea75c-9317-418f-f0e4-28e0bfcf9439",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "optimizer = Adam(0.001)\n",
        "loss = 'binary_crossentropy'\n",
        "metrics = [get_metrics(0.5)['precision'], get_metrics(0.5)['recall'], get_metrics(0.5)['f1_score']]\n",
        "\n",
        "model_adam = get_model(optimizer, loss, metrics)\n",
        "\n",
        "history_adam = model_adam.fit(X_train, Y_train,\n",
        "          epochs=40,\n",
        "          batch_size=32,\n",
        "          validation_data=(X_valid, Y_valid)\n",
        "         )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_4 (Dense)              (None, 3)                 15555     \n",
            "=================================================================\n",
            "Total params: 15,555\n",
            "Trainable params: 15,555\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 300 samples, validate on 60 samples\n",
            "Epoch 1/40\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 1.6789 - precision: 0.3511 - recall: 0.3467 - f1_score: 0.3488 - val_loss: 1.2042 - val_precision: 0.3667 - val_recall: 0.3667 - val_f1_score: 0.3667\n",
            "Epoch 2/40\n",
            "300/300 [==============================] - 0s 130us/step - loss: 0.9662 - precision: 0.3547 - recall: 0.3333 - f1_score: 0.3406 - val_loss: 0.9400 - val_precision: 0.4167 - val_recall: 0.4167 - val_f1_score: 0.4167\n",
            "Epoch 3/40\n",
            "300/300 [==============================] - 0s 127us/step - loss: 0.8276 - precision: 0.4035 - recall: 0.3767 - f1_score: 0.3887 - val_loss: 0.6715 - val_precision: 0.4365 - val_recall: 0.4000 - val_f1_score: 0.4174\n",
            "Epoch 4/40\n",
            "300/300 [==============================] - 0s 129us/step - loss: 0.6621 - precision: 0.4817 - recall: 0.3067 - f1_score: 0.3666 - val_loss: 0.5870 - val_precision: 0.6669 - val_recall: 0.4000 - val_f1_score: 0.5000\n",
            "Epoch 5/40\n",
            "300/300 [==============================] - 0s 123us/step - loss: 0.5774 - precision: 0.5634 - recall: 0.3367 - f1_score: 0.4148 - val_loss: 0.5748 - val_precision: 0.6333 - val_recall: 0.2167 - val_f1_score: 0.3219\n",
            "Epoch 6/40\n",
            "300/300 [==============================] - 0s 131us/step - loss: 0.5329 - precision: 0.7594 - recall: 0.3633 - f1_score: 0.4837 - val_loss: 0.5565 - val_precision: 0.5702 - val_recall: 0.2833 - val_f1_score: 0.3738\n",
            "Epoch 7/40\n",
            "300/300 [==============================] - 0s 161us/step - loss: 0.5270 - precision: 0.6849 - recall: 0.4133 - f1_score: 0.5057 - val_loss: 0.6476 - val_precision: 0.5201 - val_recall: 0.4833 - val_f1_score: 0.5009\n",
            "Epoch 8/40\n",
            "300/300 [==============================] - 0s 143us/step - loss: 0.5806 - precision: 0.5888 - recall: 0.4600 - f1_score: 0.5107 - val_loss: 0.5382 - val_precision: 0.4979 - val_recall: 0.3500 - val_f1_score: 0.4110\n",
            "Epoch 9/40\n",
            "300/300 [==============================] - 0s 127us/step - loss: 0.5015 - precision: 0.6707 - recall: 0.4133 - f1_score: 0.5037 - val_loss: 0.5541 - val_precision: 0.5754 - val_recall: 0.3167 - val_f1_score: 0.4078\n",
            "Epoch 10/40\n",
            "300/300 [==============================] - 0s 147us/step - loss: 0.4990 - precision: 0.6812 - recall: 0.4033 - f1_score: 0.4994 - val_loss: 0.5117 - val_precision: 0.7436 - val_recall: 0.3333 - val_f1_score: 0.4593\n",
            "Epoch 11/40\n",
            "300/300 [==============================] - 0s 122us/step - loss: 0.5203 - precision: 0.7200 - recall: 0.4633 - f1_score: 0.5500 - val_loss: 0.5628 - val_precision: 0.5704 - val_recall: 0.4000 - val_f1_score: 0.4696\n",
            "Epoch 12/40\n",
            "300/300 [==============================] - 0s 124us/step - loss: 0.5260 - precision: 0.6749 - recall: 0.5067 - f1_score: 0.5715 - val_loss: 0.5859 - val_precision: 0.5431 - val_recall: 0.5000 - val_f1_score: 0.5206\n",
            "Epoch 13/40\n",
            "300/300 [==============================] - 0s 119us/step - loss: 0.5474 - precision: 0.6443 - recall: 0.4800 - f1_score: 0.5371 - val_loss: 0.4942 - val_precision: 0.6811 - val_recall: 0.5000 - val_f1_score: 0.5766\n",
            "Epoch 14/40\n",
            "300/300 [==============================] - 0s 124us/step - loss: 0.4707 - precision: 0.6873 - recall: 0.5100 - f1_score: 0.5835 - val_loss: 0.5343 - val_precision: 0.6279 - val_recall: 0.3667 - val_f1_score: 0.4628\n",
            "Epoch 15/40\n",
            "300/300 [==============================] - 0s 125us/step - loss: 0.5110 - precision: 0.6780 - recall: 0.4400 - f1_score: 0.5252 - val_loss: 0.6602 - val_precision: 0.5246 - val_recall: 0.4500 - val_f1_score: 0.4835\n",
            "Epoch 16/40\n",
            "300/300 [==============================] - 0s 121us/step - loss: 0.4839 - precision: 0.6787 - recall: 0.6000 - f1_score: 0.6356 - val_loss: 0.6001 - val_precision: 0.5304 - val_recall: 0.4500 - val_f1_score: 0.4863\n",
            "Epoch 17/40\n",
            "300/300 [==============================] - 0s 117us/step - loss: 0.4727 - precision: 0.6929 - recall: 0.4967 - f1_score: 0.5688 - val_loss: 0.6429 - val_precision: 0.6141 - val_recall: 0.5833 - val_f1_score: 0.5982\n",
            "Epoch 18/40\n",
            "300/300 [==============================] - 0s 126us/step - loss: 0.5299 - precision: 0.6265 - recall: 0.5500 - f1_score: 0.5842 - val_loss: 0.6450 - val_precision: 0.4696 - val_recall: 0.3500 - val_f1_score: 0.4003\n",
            "Epoch 19/40\n",
            "300/300 [==============================] - 0s 134us/step - loss: 0.5456 - precision: 0.6340 - recall: 0.5233 - f1_score: 0.5699 - val_loss: 0.4830 - val_precision: 0.5705 - val_recall: 0.4667 - val_f1_score: 0.5110\n",
            "Epoch 20/40\n",
            "300/300 [==============================] - 0s 136us/step - loss: 0.4414 - precision: 0.7122 - recall: 0.5300 - f1_score: 0.6009 - val_loss: 0.6560 - val_precision: 0.4998 - val_recall: 0.4667 - val_f1_score: 0.4827\n",
            "Epoch 21/40\n",
            "300/300 [==============================] - 0s 131us/step - loss: 0.5305 - precision: 0.6018 - recall: 0.5233 - f1_score: 0.5566 - val_loss: 0.5257 - val_precision: 0.5464 - val_recall: 0.5000 - val_f1_score: 0.5222\n",
            "Epoch 22/40\n",
            "300/300 [==============================] - 0s 122us/step - loss: 0.4834 - precision: 0.6758 - recall: 0.5833 - f1_score: 0.6235 - val_loss: 0.5087 - val_precision: 0.5651 - val_recall: 0.4667 - val_f1_score: 0.5105\n",
            "Epoch 23/40\n",
            "300/300 [==============================] - 0s 120us/step - loss: 0.5001 - precision: 0.6519 - recall: 0.5600 - f1_score: 0.5999 - val_loss: 0.5183 - val_precision: 0.6543 - val_recall: 0.5333 - val_f1_score: 0.5874\n",
            "Epoch 24/40\n",
            "300/300 [==============================] - 0s 130us/step - loss: 0.4432 - precision: 0.7143 - recall: 0.6000 - f1_score: 0.6492 - val_loss: 0.4796 - val_precision: 0.7500 - val_recall: 0.5500 - val_f1_score: 0.6345\n",
            "Epoch 25/40\n",
            "300/300 [==============================] - 0s 131us/step - loss: 0.4345 - precision: 0.7282 - recall: 0.5900 - f1_score: 0.6496 - val_loss: 0.5371 - val_precision: 0.5948 - val_recall: 0.5167 - val_f1_score: 0.5527\n",
            "Epoch 26/40\n",
            "300/300 [==============================] - 0s 134us/step - loss: 0.4306 - precision: 0.7160 - recall: 0.6033 - f1_score: 0.6523 - val_loss: 0.5022 - val_precision: 0.5482 - val_recall: 0.4833 - val_f1_score: 0.5137\n",
            "Epoch 27/40\n",
            "300/300 [==============================] - 0s 122us/step - loss: 0.4810 - precision: 0.6603 - recall: 0.5533 - f1_score: 0.5983 - val_loss: 0.4965 - val_precision: 0.5548 - val_recall: 0.5000 - val_f1_score: 0.5260\n",
            "Epoch 28/40\n",
            "300/300 [==============================] - 0s 126us/step - loss: 0.4200 - precision: 0.7363 - recall: 0.6367 - f1_score: 0.6817 - val_loss: 0.5421 - val_precision: 0.6533 - val_recall: 0.5000 - val_f1_score: 0.5664\n",
            "Epoch 29/40\n",
            "300/300 [==============================] - 0s 130us/step - loss: 0.4290 - precision: 0.7329 - recall: 0.6100 - f1_score: 0.6615 - val_loss: 0.6918 - val_precision: 0.5500 - val_recall: 0.5333 - val_f1_score: 0.5414\n",
            "Epoch 30/40\n",
            "300/300 [==============================] - 0s 129us/step - loss: 0.4623 - precision: 0.6507 - recall: 0.5533 - f1_score: 0.5952 - val_loss: 0.4799 - val_precision: 0.6033 - val_recall: 0.4833 - val_f1_score: 0.5366\n",
            "Epoch 31/40\n",
            "300/300 [==============================] - 0s 127us/step - loss: 0.3760 - precision: 0.8022 - recall: 0.6400 - f1_score: 0.7095 - val_loss: 0.5261 - val_precision: 0.5432 - val_recall: 0.4667 - val_f1_score: 0.5014\n",
            "Epoch 32/40\n",
            "300/300 [==============================] - 0s 118us/step - loss: 0.4062 - precision: 0.7432 - recall: 0.6133 - f1_score: 0.6704 - val_loss: 0.5218 - val_precision: 0.6269 - val_recall: 0.5333 - val_f1_score: 0.5762\n",
            "Epoch 33/40\n",
            "300/300 [==============================] - 0s 135us/step - loss: 0.4065 - precision: 0.7602 - recall: 0.6267 - f1_score: 0.6856 - val_loss: 0.4762 - val_precision: 0.7097 - val_recall: 0.4833 - val_f1_score: 0.5748\n",
            "Epoch 34/40\n",
            "300/300 [==============================] - 0s 134us/step - loss: 0.3755 - precision: 0.7722 - recall: 0.6267 - f1_score: 0.6908 - val_loss: 0.5248 - val_precision: 0.6799 - val_recall: 0.4167 - val_f1_score: 0.5156\n",
            "Epoch 35/40\n",
            "300/300 [==============================] - 0s 136us/step - loss: 0.4043 - precision: 0.7384 - recall: 0.6300 - f1_score: 0.6767 - val_loss: 0.5953 - val_precision: 0.5364 - val_recall: 0.4833 - val_f1_score: 0.5085\n",
            "Epoch 36/40\n",
            "300/300 [==============================] - 0s 130us/step - loss: 0.4358 - precision: 0.7025 - recall: 0.5800 - f1_score: 0.6308 - val_loss: 0.5308 - val_precision: 0.6678 - val_recall: 0.5667 - val_f1_score: 0.6120\n",
            "Epoch 37/40\n",
            "300/300 [==============================] - 0s 124us/step - loss: 0.3865 - precision: 0.7356 - recall: 0.6433 - f1_score: 0.6850 - val_loss: 0.5642 - val_precision: 0.5403 - val_recall: 0.4833 - val_f1_score: 0.5101\n",
            "Epoch 38/40\n",
            "300/300 [==============================] - 0s 123us/step - loss: 0.3945 - precision: 0.7433 - recall: 0.6433 - f1_score: 0.6865 - val_loss: 0.4888 - val_precision: 0.6970 - val_recall: 0.4833 - val_f1_score: 0.5690\n",
            "Epoch 39/40\n",
            "300/300 [==============================] - 0s 127us/step - loss: 0.4084 - precision: 0.7337 - recall: 0.6200 - f1_score: 0.6694 - val_loss: 0.4769 - val_precision: 0.6821 - val_recall: 0.5000 - val_f1_score: 0.5770\n",
            "Epoch 40/40\n",
            "300/300 [==============================] - 0s 124us/step - loss: 0.3911 - precision: 0.7430 - recall: 0.6200 - f1_score: 0.6731 - val_loss: 0.5339 - val_precision: 0.5310 - val_recall: 0.5000 - val_f1_score: 0.5148\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "c8ZJ3SWAChEd"
      },
      "cell_type": "markdown",
      "source": [
        "We now plot the training history."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "XV-A2El1ChEe",
        "outputId": "a29fe7b8-b431-4e2e-f4b3-3977a7e3be49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "plt.plot(history_adam.history['f1_score'])\n",
        "plt.plot(history_adam.history['val_f1_score'])\n",
        "plt.title('model f1 score')\n",
        "plt.ylabel('f1 score')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history_adam.history['loss'])\n",
        "plt.plot(history_adam.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xd4lFX2wPHvSS+EBEhIQkd6r6KABVSkqCCi2LAruj/XspZV1u6uq659114QK4pgQUUpCoIC0nvvBEISIAkppM79/XEnIT2TkMmEzPk8T55M3nln5uSFzJnbzhVjDEoppRSAj6cDUEopVXdoUlBKKVVIk4JSSqlCmhSUUkoV0qSglFKqkCYFpZRShTQpKOUiEZkiIv9y8dw9InLByT6PUrVNk4JSSqlCmhSUUkoV0qSg6hVnt82DIrJORDJE5AMRiRaRn0QkTUTmiUijIuePFpGNIpIiIgtEpEuR+/qIyCrn474Egkq81sUissb52MUi0rOaMd8mIjtE5KiIzBSRZs7jIiKviEiiiKQ6f6fuzvtGicgmZ2wHROSBal0wpUrQpKDqo3HAMKAjcAnwE/APIBL7f/5uABHpCEwF7gWigFnA9yISICIBwLfAJ0Bj4Cvn8+J8bF9gMnA70AR4B5gpIoFVCVREzgOeBcYDscBe4Avn3RcC5zh/jwjgSuCI874PgNuNMWFAd+DXqryuUuXRpKDqo/8ZYxKMMQeARcCfxpjVxphs4Bugj/O8K4EfjTFzjTG5wItAMDAIOBPwB141xuQaY6YDy4u8xm3AO8aYP40x+caYj4Bs5+Oq4lpgsjFmlTO+ScBAEWkD5AJhQGdAjDGbjTHxzsflAl1FpKExJtkYs6qKr6tUmTQpqPooocjt42X83MB5uxn2kzkAxhgHsB9o7rzvgCleMXJvkdutgfudXUcpIpICtHQ+ripKxpCObQ00N8b8CrwOvAEkiMi7ItLQeeo4YBSwV0R+E5GBVXxdpcqkSUF5s4PYN3fA9uFj39gPAPFAc+exAq2K3N4PPGOMiSjyFWKMmXqSMYRiu6MOABhj/muM6Qd0w3YjPeg8vtwYMwZoiu3mmlbF11WqTJoUlDebBlwkIueLiD9wP7YLaDGwBMgD7hYRPxG5DBhQ5LHvAXeIyBnOAeFQEblIRMKqGMPnwE0i0ts5HvFvbHfXHhE53fn8/kAGkAXkO8c8rhWRcGe31zEg/ySug1KFNCkor2WM2QpMAP4HHMYOSl9ijMkxxuQAlwE3AsnY8Yevizx2BXZc4XXn/Tuc51Y1hl+Ax4AZ2NZJO+Aq590NscknGdvFdAQ77gFwHbBHRI4Bdzh/D6VOmugmO0oppQpoS0EppVQhTQpKKaUKaVJQSilVSJOCUkqpQn6eDqCqIiMjTZs2bTwdhlJKnVJWrlx52BgTVdl5p1xSaNOmDStWrPB0GEopdUoRkb2Vn6XdR0oppYrQpKCUUqqQJgWllFKFTrkxhbLk5uYSFxdHVlaWp0Nxu6CgIFq0aIG/v7+nQ1FK1UP1IinExcURFhZGmzZtKF7Usn4xxnDkyBHi4uJo27atp8NRStVD9aL7KCsriyZNmtTrhAAgIjRp0sQrWkRKKc+oF0kBqPcJoYC3/J5KKc+oN0mhMlm5+RxKzSIv3+HpUJRSqs7ymqSQnecgMS2LXDckhZSUFN58880qP27UqFGkpKTUeDxKKVVdXpMUfH1st0u+o+b3jygvKeTnV7wZ1qxZs4iIiKjxeJRSqrrqxewjV/g5k0KeG5LCww8/zM6dO+nduzf+/v40aNCA2NhY1qxZw6ZNm7j00kvZv38/WVlZ3HPPPUycOBE4UbIjPT2dkSNHctZZZ7F48WKaN2/Od999R3BwcI3HqpRSFal3SeGp7zey6eCxUscNkJmdR6CfD36+VWsgdW3WkCcu6Vbu/c899xwbNmxgzZo1LFiwgIsuuogNGzYUThudPHkyjRs35vjx45x++umMGzeOJk2aFHuO7du3M3XqVN577z3Gjx/PjBkzmDBBd1hUStWuepcUylMwZ6c2Nh8dMGBAsXUE//3vf/nmm28A2L9/P9u3by+VFNq2bUvv3r0B6NevH3v27KmFSJVSqrh6lxQq+kS/4UAqjUMDaBbh3m6Z0NDQwtsLFixg3rx5LFmyhJCQEIYMGVLmOoPAwMDC276+vhw/ftytMSqlVFm8ZqAZ7GCzOwaaw8LCSEtLK/O+1NRUGjVqREhICFu2bGHp0qU1/vpKKVVT6l1LoSLuSgpNmjRh8ODBdO/eneDgYKKjowvvGzFiBG+//TY9e/akU6dOnHnmmTX++kopVVPEmNroZa85/fv3NyU32dm8eTNdunSp9LG7ktIxBto1beCu8GqFq7+vUkoVEJGVxpj+lZ3ntu4jEZksIokisqGCc4aIyBoR2Sgiv7krlgK+PuKWKalKKVVfuHNMYQoworw7RSQCeBMYbYzpBlzhxlgA93UfKaVUfeG2pGCMWQgcreCUa4CvjTH7nOcnuiuWAn7OpHCqdZkppVRt8eTso45AIxFZICIrReT68k4UkYkiskJEViQlJVX7BX19fDAYHJoUlFKqTJ5MCn5AP+AiYDjwmIh0LOtEY8y7xpj+xpj+UVFR1X5Bd9Y/Ukqp+sCTU1LjgMPGmAwgQ0QWAr2Abe56waL1jwLc9SJKKXUK82RL4TvgbBHxE5EQ4Axgsztf0F0theqWzgZ49dVXyczMrNF4lFKqutw5JXUqsAToJCJxInKLiNwhIncAGGM2Az8D64BlwPvGmHKnr9YETQpKKVUxt3UfGWOuduGcF4AX3BVDSe5KCkVLZw8bNoymTZsybdo0srOzGTt2LE899RQZGRmMHz+euLg48vPzeeyxx0hISODgwYMMHTqUyMhI5s+fX6NxKaVUVdW/Mhc/PQyH1pd5lx+G07LzCfDzgaqUz47pASOfK/fuoqWz58yZw/Tp01m2bBnGGEaPHs3ChQtJSkqiWbNm/Pjjj4CtiRQeHs7LL7/M/PnziYyMrNKvqZRS7uBVBfEEQQS3rlOYM2cOc+bMoU+fPvTt25ctW7awfft2evTowbx583jooYdYtGgR4eHhbotBKaWqq/61FCr4RA+wP/4YoYF+tGwc4paXN8YwadIkbr/99lL3rVy5klmzZjFp0iQuvPBCHn/8cbfEoJRS1eVVLQVwT6mLoqWzhw8fzuTJk0lPTwfgwIEDJCYmcvDgQUJCQpgwYQIPPPAAq1atKvVYpZTytPrXUqiEO4riFS2dPXLkSK655hoGDhwIQIMGDfj000/ZsWMHDz74ID4+Pvj7+/PWW28BMHHiREaOHElsbKwONCulPM6rSmcD7DuSwfFcB51iwtwRXq3Q0tlKqaryeOnsusp2Hzk8HYZSStVJXpgUfLRSqlJKlaPeJAVX3+R9fQTDqVsUT5OZUsqd6kVSCAoK4siRIy69YRYUxcs/Bd9cjTEcOXKEoKAgT4eilKqn6sXsoxYtWhAXF4crey1k5eZzOD0HkxxoVzafYoKCgmjRooWnw1BK1VP1Iin4+/vTtm1bl85duTeZ2z5fzJSbTmdIp6ZujkwppU4tp95H5ZMUEeIPQEpmrocjUUqpusfrkkKjELu9TkpmjocjUUqpusfrkkLDINtjlqwtBaWUKsXrkoKfrw8Ng/xIPa5JQSmlSvK6pAAQERJAsnYfKaVUKV6ZFBqF+OtAs1JKlcErk0J4SIAONCulVBm8Mik0CvEnRccUlFKqFK9MChHB2n2klFJlcVtSEJHJIpIoIhsqOe90EckXkcvdFUtJ4SEBHMvKPWWL4imllLu4s6UwBRhR0Qki4gs8D8x2YxylNArxxxg4pl1ISilVjNuSgjFmIXC0ktPuAmYAie6KoywFpS50WqpSShXnsTEFEWkOjAXeru3XjigodaEtBaWUKsaTA82vAg8ZY/IrO1FEJorIChFZ4Up57MpEBBcUxdOWglJKFeXJ0tn9gS9EBCASGCUiecaYb0ueaIx5F3gXoH///ic9OnyiKJ62FJRSqiiPJQVjTOEGCCIyBfihrITgDifGFDQpKKVUUW5LCiIyFRgCRIpIHPAE4A9gjKn1cYSiGgb5IwKp2n2klFLFuC0pGGOursK5N7orjrL4+Ajhwf7aUlBKqRK8ckUz2HEFnX2klFLFeW1SCA/219lHSilVgtcmBS2frZRSpXltUtCNdpRSqjQvTgr+pGpLQSmlivHepBAcQFp2Hrn5Dk+HopRSdYbXJoVGoXYBW6rOQFJKqUJemxTCtf6RUkqV4rVJQesfKaVUaV6bFLT+kVJKlea1SeFES0G7j5RSqoDXJoXwkIIxBW0pKKVUAa9NCmGBfvj6CCnHtaWglFIFvDYpiAgRwVrqQimlivLapAC2C0mTglJKneDVScGWz9buI6WUKuDVSSEi2J/kDG0pKKVUAe9OCiEBWuZCKaWK8PKk4K/ls5VSqgivTgqNQvzJzMknOy/f06EopVSd4NVJIdy5qln3VVBKKcurk0KjglXNOq6glFKAG5OCiEwWkUQR2VDO/deKyDrn12IR6eWuWMoTEWxbCskZOq6glFLg3pbCFGBEBffvBs41xvQE/gm868ZYIGEjzH4EstMKD0VoS0EppYpxW1IwxiwEjlZw/2JjTLLzx6VAC3fFAkDKfljyOhw60XApTAo6A0kppYC6M6ZwC/BTeXeKyEQRWSEiK5KSkqr3CrHO3qlD6woP6UY7SilVnMeTgogMxSaFh8o7xxjzrjGmvzGmf1RUVPVeKCwGQptC/NrCQyEBvvj7im60o5RSTn6efHER6Qm8D4w0xhxx84vZ1kKRpCAizlXN2n2klFLgwZaCiLQCvgauM8Zsq5UXje0JiZshN6vwkNY/UkqpE9zWUhCRqcAQIFJE4oAnAH8AY8zbwONAE+BNEQHIM8b0d1c8gG0pmHxI3AjN+wFaKVUppYpyW1Iwxlxdyf23Are66/XLVDDYHL+2MCmEh/iz/2hmrYahlFJ1lccHmmtVRGsICi82rtBIN9pRSqlC3pUUCgebT0xLjQgJ0EqpSinl5F1JAWxSSNgI+bZ1EBHiT3aeg6xcrZSqlFJemBR6Q342JG0FitQ/0taCUkp5YVKI6Wm/O8cVCiul6riCUkp5YVJo0g78QwuTQrgmBaWUKuR9ScHHF2J6FCaFgu4jLYqnlFLemBTADjYfWg8OB41CtXy2UkoV8N6kkJsBR3fqQLNSShXhvUkBIH4twQG+BPr56D7NSimFtyaFqE7gGwjxawC7VkFbCkop5a1JwdcforsWmZYaoLOPlFIKb00KcGJvBWMID9b6R0opBd6eFLJSIWWfls9WSiknl5KCiNwjIg3F+kBEVonIhe4Ozq2KDDbbMQVtKSillKsthZuNMceAC4Eo4CbgObdFVRuadgPxdSaFAFIzczHGeDoqpZTyKFeTgji/jwI+NMasLXLs1OQfBE27FLYUcvIdZOZopVSllHdzNSmsFJE52KQwW0TCAIf7wqolMT0hfg2Ngu0GdLqqWSnl7VxNCrcADwOnG2MysXst3+S2qGpLbC/ISKKppACQnKGDzUop7+ZqUhgIbDXGpIjIBOBRINV9YdUS52Bzs+N2b4VUbSkopbycq0nhLSBTRHoBfwf2Ah+7LaraEtMdEJqk2aSgq5qVUt7O1aSQZ+zUnDHAa8aY14Cwih4gIpNFJFFENpRzv4jIf0Vkh4isE5G+VQu9BgSGQZP2hB3dCOieCkop5WpSSBORScB1wI8i4osdV6jIFGBEBfePBDo4vyZiWyO1L7YXAUnrAd1TQSmlXE0KVwLZ2PUKh4DmwAsVPcAYsxA4WsEpY4CPjbUUiBCRWBfjqTmxPZFjcTQLyNCWglLK67mUFJyJ4DMgXEQuBrKMMSc7ptAc2F/k5zjnsVJEZKKIrBCRFUlJSSf5siU4B5tPD9yvq5qVUl7P1TIX44FlwBXAeOBPEbn8JF+7rMVvZS4pNsa8a4zpb4zpHxUVdZIvW0JMTwB6+e0jVesfKaW8nJ+L5z2CXaOQCCAiUcA8YPpJvHYc0LLIzy2AgyfxfNUT0hgiWtElezc/aktBKeXlXB1T8ClICE5HqvDY8swErnfOQjoTSDXGxJ/kc1ZPbC9Oy9upA81KKa/nakvhZxGZDUx1/nwlMKuiB4jIVGAIECkiccATOGcsGWPedj5+FLADyMSTK6RjexG9+XvyHKf+ejyllDoZLiUFY8yDIjIOGIwdC3jXGPNNJY+5upL7DXCnq4G6VWxvAGKObyfhWBbRDYM8HJBSSnmGqy0FjDEzgBlujMVznIPN3WQP364+wO3ntvNwQEop5RkVjguISJqIHCvjK01EjtVWkG4XFg0NYjgn7AAzVsXpvgpKKa9VYUvBGFNhKYt6JbYXveN3si0hnQ0HjtGjRbinI1JKqVrnvXs0lxTbi/CMXTT0y2XGqjhPR6OUUh6hSaFAbE/EOLiubTrfrTlATt6pv4eQUkpVlSaFAs7B5tHRh0nOzGX+1sRKHqCUUvWPJoUCEa0gKIIOjl1EhQUyY6V2ISmlvI8mhQIiENMDn0PrubR3M37dksiR9GxPR6WUUrVKk0JRsb0gcRPj+sSQ5zDMXFv7pZiUUsqTNCkUFdMT8rLo7HuIbs0a6iwkpZTX0aRQVKwdbObQOsb1bcGGA8fYeijNszEppVQt0qRQVJMO4BcE8esY07sZfj6irQWllFfRpFCUrx9Ed4ND62jSIJAhnZryzeoD5OXrmgWllHfQpFBSTE84tA6M4fJ+zUlKy2bRjsOejkoppWqFJoWSYntCViqk7GVo56ZEhPjrmgWllNfQpFBSTC/7PX4dgX6+jO7VjDmbEkg9rlt1KqXqP00KJUV3BfGF+LUAjOvbgpw8Bz+u88xOoUopVZs0KZTkHwxRney4AtCzRTjtmzbQWUhKKa+gSaEsMT0h3iYFEWFc3xas3JvM7sMZHg5MKaXcS5NCWWJ7QvohSLeVUsf2aY6PwNfaWlBK1XOaFMriLKNd0FqICQ9icPtIvltzULfqVErVa25NCiIyQkS2isgOEXm4jPtbich8EVktIutEZJQ743FZTA/7/dDawkMjusew72gm2xLSPRSUUkq5n9uSgoj4Am8AI4GuwNUi0rXEaY8C04wxfYCrgDfdFU+VBEdAROvClgLABV2iAZi76ZCnolJKKbdzZ0thALDDGLPLGJMDfAGMKXGOARo6b4cDdadWdWzPwhlIANENg+jdMoI5mxI8GJRSSrmXO5NCc2B/kZ/jnMeKehKYICJxwCzgLjfGUzUxveDoLsg6VnhoWNdo1sWlEp963IOBKaWU+7gzKUgZx0qO0l4NTDHGtABGAZ+ISKmYRGSiiKwQkRVJSUluCLUMBWW0EzYUHhrezXYhzdPWglKqnnJnUogDWhb5uQWlu4duAaYBGGOWAEFAZMknMsa8a4zpb4zpHxUV5aZwSygxAwmgXVQDTosM1S4kpVS95c6ksBzoICJtRSQAO5A8s8Q5+4DzAUSkCzYp1FJToBJhMRAaVWxcQUQY1jWaJTuPaC0kpVS95LakYIzJA/4KzAY2Y2cZbRSRp0VktPO0+4HbRGQtMBW40dSVhQAixVY2F7iwWzR5DsOCrYkeCkwppdzHz51PboyZhR1ALnrs8SK3NwGD3RnDSYntCYv/B3nZ4BcIQO+WjYhsEMDcTQmM6V1y3FwppU5tuqK5IjE9wZEHiZsKD/n6CBd0iWbB1iSy8/I9GJxSStU8TQoViT2xt0JRF3aLJj07j6W7jnogKKWUch9NChVp1BYCwooNNgMMahdJSIAvczbq6malVP2iSaEiPj62DlKJlkKQvy/ndoxi3uYEHI66MS6ulFI1QZNCZWJ72gVsjuLjB8O6RpNwLJt1B1I9FJhSStU8TQqViekJuZlwZGexw+d1boqvj2gXklKqXtGkUJmCchclxhUiQgIY0KYxc3V1s1KqHtGkUJmozuAbAPFrS911Ybdotiem6zadSql6Q5NCZXz9oWmXUi0FsOMKoHssKKXqD00Krigod1GiAkeLRiF0jW3InI3ahaSUqh80KbgithccPwrHDpS668Ju0azcl8zh9GwPBKZUHTT/WVg5xdNRqGrSpOCKwjLapccVhnWNxhj4ZbO2FpQi8ygsehGWvOHpSFQ1aVJwRXQ3QEotYgPoGtuQ5hHB2oWkFMDmmbZe2OFtkF43quCrqtGk4IrABtCkPRxcXequgj0WFu04TEZ2ngeCU6oO2TAD/EPs7b1/eDYWVS2aFFzVaQRsnwMHVpW668Ju0eTkOVi0XT8Z1bg6sr2GckHaIdi9CM64wyaGvYs9HZGqBk0Krjrn79AgGn68r1TJiwFtGtM4NICPFu+lruwRVC9kHoX/9au7/dN7/oDsdE9HUXds+g4w0PNKaDlAk8IpSpOCq4IawvBnbBfSyg+L3eXn68PfhnVkya4jfL8uvuZf2xjIPV7zz1vXrfkMju6E2f+Ajd96OprikvfClFEw/9+ejqTu2DADortD087QerCtGXY82dNRqSpy685r9U73cbDqY5j3NHQZDQ2aFt51zYBWfLViP//6YRNDO0URFuRfc6/76z/tFL+7VkFwRM09b13mcMCKD6F5fxAf+OZ2CG8BLfq7/hwZh2HLD/bTfO5xW8Oq5PdWA2HQX6se37bZ9vvaqXDBE4U783mtlH2w/08437mxYutBgIF9f9quV3XK0JZCVYjARS/ZN5O5jxe7y9dH+OeY7iSlZ/PK3O0195pHd9ktQTOPwPL3a+5567rdv9lWwhm3w9VTbdfd1KvsJ3RXxK+Dd86F7++BOY/A/H/Z67jmc/uGHrfcfv3yFGSnVT2+bT+DX5Bdv7L5+6o/vr7Z+I393u0y+715P1seRgebTzmaFKoqsgMMvtt+Qtzze7G7erWM4JoBrZiyeDebDh6rmdeb+wT4+EGLAbD0Le/pRloxGYIb2xZZaCRc+xXk5cDn4yGrknLlm3+AycPBOODmOfDwfnjsMDx+GCbtgwe2wj1r4PIPIT8Hts+tWmzZ6bBnEfS/BSJawaqPqv971hcbZthE0Lit/dk/2LbydFzhlKNJoTrOfgDCW8GP90N+brG7/j68M41CAnjsuw0nvwHP3sV23vdZf4MLnoTMw7D605N7zlPBsXjY8iP0mQD+QfZYVCe48hM4sgOm3VDqugN27GXRS/DltbZe1cT50OoMOx7kW0Z3XqszISTSdjFVxa4FNpl0Ggl9r4fdC22Lzlsd3mEXdnYfV/x460F2DE4H408pmhSqIyAERv0HkrbA0jeL3RUe4s/DIzuzcm8y01fGVf81HA74eRI0bA4D/2r/wFoMgMX/hfx6vh5i1cdg8qH/TcWPn3YuXPwq7JoPsx4oPl01Nwu+ngi/PA3dL4cbf4SwmIpfx8cXOo+CbXMgrwplSrb9DIHhNqn0ngDia2P2Vhu/BgS6jS1+vPUg++8Yt8wjYanqcWtSEJERIrJVRHaIyMPlnDNeRDaJyEYR+dyd8dSoTiOh0yhY8DykFn/zH9e3Bae3acSzP20mOSOnes+/fhrEr4Hzn7BJSMS2GFL2Of8I66n8PNsd0+48aHxa6fv7Xmevw8opdowAIC0BPrrYXrPzHoVx79vuC1d0GQ05abDrN9fOdzjsmET7823ro2EsdBwOqz8ru/VS3xkD66fbBNCwWfH7Wg6wCVO7kE4pbksKIuILvAGMBLoCV4tI1xLndAAmAYONMd2Ae90Vj1uMeM72W/88qdhhHx/hn5d251hWHv+ZvbXqz5uTAfOegmZ9oMcVJ453HAFRXeD3V+rvoq7ts23hwf63lH/OeY9D10vtYP/vr8B750HCRhj/MZzzoE2grmp7DgSE2W46V8SvhoxE+29RoO8N9tjWn1x/3foicRMc3grdLyt9X2CYLSapSeGU4s6WwgBghzFmlzEmB/gCGFPinNuAN4wxyQDGmEQ3xlPzGrWGcx+0byglBis7xzTkpkFt+GL5Plbvq+Jc7cWvQ9pBGP4s+BT5J/LxgbPutX+IBVMi65sVkyGsWfE33ZJ8fGDs23Zgc96TgIGbf4auJf97ucAvEDpeaN/QSyxKLNO22XaKbIdhJ461v8DG7I0Dzhtm2NZAl3KufetBELfCdu+dCo6n1N8PXC5yZ1JoDuwv8nOc81hRHYGOIvKHiCwVkTLfCURkooisEJEVSUl1rJTEwLsgsqPt4y4xM+jeYR1pGhbIo99uIN/VQedjB+GPV+0bXOuBpe/vPs4Ocv/+Sg0EX8cc3Q07foF+N4BvJUto/IPh6i/g3Ifgtl/tJ9Lq6nKJHcTft7Tyc7f9DC3PgJDGJ475+tlB8R2/2O49b2GMTQqnnQsNoso+p/VgyM+Gg6XLw9Q5SVvhlW4w41avTgzuTAplteFLXmk/oAMwBLgaeF9ESq3OMsa8a4zpb4zpHxVVzn8+T/ELgFEvQvIe+GCY7dLY+jMcT6ZBoB+PXdyVjQeP8elSF+fX//ovW2XygqfKvt/XHwbdBfuXwt4lNfZrVEvmUVj4ol0LUBOD3ys/tJ/C+17v2vkNomDoPyofUK5M+2HgG1j5eoNjB+0sm47DS9/X9zr73RtmhxU4uMr+vy8566io1gMBsSVB6rLcLJh+s51wsGH6ifEqL+TOpBAHtCzycwvgYBnnfGeMyTXG7Aa2YpPEqeW0c21i8A+BJW/C1Cvh+Tbw5kAu2vciDzZbzydzFpNwrJIm9ME1dnHVGXecmO9dlj4TIKQJ/P4yefkOHvhqLXdPXV17dZeO7IQfH7CfqgpWW68+ydk3edn2DbXTyNIDlu4W2ADaDbVTUyu6htvn2O9ldW1FtLKD46s/da0bqj7Y8DX4+EPni8s/J7iRLT1f1xexzX3MluW46nPbSp/3BOyc7+moPMKdSWE50EFE2opIAHAVUHI071tgKICIRGK7k07NCd8DboNb5sCk/XY65NBHISwGWfcldx59lnn8heRXB5E092U7D78kY2D2I7Zb4pwHKn6tgBA44y+wfQ4vffI101fGMXPtQaat2F/x406GMbZ75YtrbZG6VR/Z1at/WQytBtkaQFknsWBv00y7avv0CgaY3anLJZC6v8yNlAptm23sL8LSAAAgAElEQVTf/KM6l31/vxvsIPmOee6JsS5xOGxS6DCs8tIrrQfB/mV1d3bWlh9h2btw5p12fGnMmxDZCabfZFtCXsZtScEYkwf8FZgNbAamGWM2isjTIjLaedps4IiIbALmAw8aY464K6Za4R8Mbc6yA9DXfQMP7YWJCzhw+iSMwxD1x1OYl7vAR6Ptp8qC1blbfoC9v9vukKDwSl/G0f9Wsn2C6bTzA/4+ohNnntaYf/24ufLWSFUZY4vRvX+BXSW89w84+364dwNc+ob9FDj8GchIOrlxjhWToVFbaDukxkKvko4jbddVeV1IucftorWOI8qf3dRxJIRGwUovGHDev9ROhqio66hA60GQm1HmJlUel3oAvrvTjkld8IQ9FtgArvrMziz8cgLkZLr2XGmHbLmPU3w8wq3rFIwxs4wxHY0x7YwxzziPPW6Mmem8bYwx9xljuhpjehhjvnBnPB7h6wfN+tD8oodpcPcf3BjyBm/kjyU9YZf9z/hCB/jyOttKiOoMfW+s9CmNMTw17wBTcs5jtO9S/q+nL89d1pOcPAePfLOh5rqRHA5bKvyrG+yn+FEvwt82wvmPQVj0ifOa97Xlkpe8Ub2B1oRNsG8x9L+5+Gyr2hTaxA6Klre6efciW/OqrPGEAn4B0PtaOxiddsg9cdYVG2aAX3DFs8QKtBpkv9e1LiRHPnx9m23BXP5h8aKGTdrBZe/DoQ12zKyivylj7Ae8NwbAVzee8jXKdEVzLWrZOITX/nolv7ecSPejz/FlrymYfjfAviWQstd+4q5k1o0xhud+2sJHS/aS3f8OxNcPFv+PNpGh3H9hR+ZtTuCHdfH2P/zeJTDnUXhrsB0DqMqq3YKEsGIyDL4X7lppu8gCQss+//zH7SfoX56uwhVxWjHZDvT2vrbqj61JXS6xq9QPl1HQcNvP4B8Krc+q+Dn6Xm9X8dbnAef8PNt67DTCfqquTFi03bmwrq1XWPiCTVQXvWSTQEkdL4TzHrGLIpe+VfZzJO+BTy61H/CadrP/P+Y+bsfdTlGaFGpZeIg/H998Bpf1acFDfwbwYMYEcu7ZBPestfPdK/HaL9t5Z+EurjuzNXeNORvpdZV9A0pL4OYB0dwWtZn8b+/E8WJH+HAELH3bdmktfw8+HuPavrkOB/xwr50NdPb9tu6Sj28lv1gLW45j/VcQt5K8fAezNx7iug/+5J4vKhgEz06HtV9At0vtp3VP6nwRAPmbZvLnriM8//MWu5ueMXY8od3QE7WYytOkHbQ525a9cDhqIWgP2LPQTuF1peuoQOvBtjVYVwbh9y6G356HnldBr6vKP++s++1A+pxHbY2rAo58myjeHGjXYVz0kh1LvOxdO/j+7f/Vnd+1ijQpeECAnw8vje/FvRd0YPrKOG78aBWpQSWXcJT29m87eXXedq7o14KnRndDROyn+Pwc+Ohi/F5szyNp/+R8xxJW+/WCyyfD33fCrfPs7YOr4b2hcGh9+S/icMD3d9uB5HMehPMec32F8Fn34giJ4uC0v3H2879y+ycrWX8gle/WHOSzP8vpVtow3ZaZqGgFcy1Iy8pl1j5f9gV1YtOvn3Plu0t5a8FOHvxqHTkH18OxONe6SgD63WhbfrsXuDPkiu1fbqcM17TMo3badGBDO5XXVa0H2/GzxE01H1NVZR6FGbdBozZw0YsVn1uwULJJe9s1lLIfErfA5BHw88P29/q/pXD6rfbc8OYw6gU75lLT01praQGgbrLjISLCvRd0pGWjEB7+eh1jXv+dwe0jaRYRTGx4ELHhwTSLCCImPIhAP18+WryH537awiW9mvHcuJ74+DjfqJu0s7Nedvxip6p2HsXkHdG8Mn8Pk/36c17BoHX3cbaW0NRr4IMLYew70HV08aAcDph5F6z51C4KGzLJpYRgjGHF3mQ+WbKXsGNjeMbvfa5usppOY67jvM5NuXnKcv49azPndoyiZeOQEw9M2Qd/vGab3S0H1NCVdV1yRg7frzvI3E0JLN11hNx8w33B/bibz5k8thm5DWK5/ZOVbFwwjT4AHS507Yk7X4wJbkTyovdp2GYIfr61/Nlr1Scw8692D4pL/ltzm9wk74VPx9l/t3HvV95qKqp1wbjCYojpUTPxVIcx9v94egLcOteW4qhMYJgdeH7vPLvbXtohCGgAl71ny9CU/BvpOR62fA/zn7Gzs6K7nXzcx1NgykXQ6+rqbQpVBXKq7Sncv39/s2LFCk+HUaOW7DzCcz9vYf/RTI6WUUAvskEgh9OzGdY1mjev7Yt/JW8yOXkOLv7fItKy8pjzt3OK7wKXdshOKz2wAoY+cqJWkCPfmRA+g3MfhqGTSj1vdl4+CanZxKceJz41i/jULA6lHufP3UfZciiNsCA/xvdtxt/33kZgfib8dTn4BXIg5TjDX1lI9+YN+fzWM21C2zHPrhx1OOCqT20Nolp0JD2by99ewu7DGbSNDGVY12gu6BJN35BE/N46A0a+gBlwG5e/vYQnE++lW2woPhNdn7e+6cM7ab9nKlNi/sH1108kKLShG3+bIrbNhqlX2zfh48l27n2fCTD83y7NaitX/Fr47ArIy7IryQve5KvilR7QvI+tUVWe1DhY8Jz9PxkaZUubh0bZrsXC25Fll0J3xZ/vwk8PwoXPVP3NdetPdjZSl9Ew8j/lr+IGu+vfG2fYgom3/monIVRXbhZ8epmd1nvtV7YbsxpEZKUxptKtCzUp1DHHc/IL33QPpBwnPiWL+NTjhAf7c9+FHQn0q6Rv32nN/hQue/MPrh7QimfGlvhklptlZ1Ss+8IWlhvzOsx60G4cNGQSDLEFbY9m5PDViv3MWh/PgZTjHE4vnbAaBvnRrmkDxvdvyZjezQgJ8IOdv8InY+HCf9nV18CXy/fx0Iz1PHVJF27Im27XNTTtavdIKGuQz40yc/K4+r0/2RJ/jA9vPJ1B7SOLn/D66XaV9A3fs2TdFs6YcSYbOvyFnhOeden5kzNyuPaFL5nCEzTlCFkSiG/H4fj3GGtnL5U3WA/23yZps+3iC4m0i/lc7b6LW2mrxUZ2hBt/sDuf/fa8nSoc1sxOIT5tiGvPVdSOX2Da9XYh2rXT7R7M1fH17bDzF3hge9m/U8Im2xI5nmw/nWcesYP2JQWF2+5QF8bgilk5Bb6/17b4rv6iejPdcjIq/vcravMPdm+Pcx601Xurw5FvZ/9t/h7GfQA9Lq/e8+B6UtDuozomOMCX06IacFqUC7M6KtC7ZQQ3D27L+7/v5pJezTjztCKDuP5Btp80uqvd2W3XfNvfO/QRzDkPsnpfMp8u2csP6+PJyXPQp1UEw7pGExseTEx4EM2c32PDgwgNLOO/ULvzbH/zby9Ar2sgtAnj+7dkwdrttJ5zC8gqO4X14lftQrxyGGNYsDWJbs0b0jSsCl0VFcjNd3DnZ6tYH5fC2xP6lU4IYGch/f4qZB7lTMcqRAyv7DuNd/IcBPhV/kby6rxtbMluzNG7VrJtw3z2LvqMUdsW0mjrTDuNs8Mwu2q25RlwZLtNAIc22O+HtxV/I+x5lR3ErGyWz+Ed8PkVdt/wa7860S1y/uO2xPs3t9uJBqffBsOecv2Nbc3ntgUZ1dkmhIaxrj2uLK0H2Q8iR3bYHQyL2vMHfHG1vT63zoOY7rYVmZViP3VnHrZrYTIO2727P7/Sdo31cXHG2uLX7bas7YfBFVOqP/XZ1esG0OVi292z6GW7hqVFv6q9ljF2I6/N39uKzCeREKpCWwr12PGcfIa/uhAfgZ/uOYfggDJaGdtmw8y7yOk/kRkh4/l06V42HjxGg0A/xvZpzoQzW9MpxoV+15ISt8Bbg+wK5VEvQPw68r6YgEmN46OGd3DzPf/Cp4JusPTsPP4+fS2z1h8i2N+Xmwa34fZz2hEeUs1uA2ySeXD6OqavjOPfY3twzRmtyj7xwCo7ID/mTdg+m+zdS+mU/DLPj+vJlaeX8xinbQlpjHxtEdcMaMU/L+0OwIKtidz56QrOD93JMx12ErZ7lu3TLqphc9vXHtMDorvb7+u/sl0pkR3gio9sEi9LWoKtu5WTDrfMLbvllZNpS5IsfdOOLV36lt0kqPyLBYtetIPKbc+FKz+1O9idjMM74PV+cMlrdjC+wKaZtisxohVc97X9XpGsY7blsmu+rRxwzgPlt6aMgQXP2hZT10vtOMDJdOVU1fEU+3cQEAq3L3R9nw+w//YLnrWTSYaVUwutCrT7SAGweOdhrnnvT8KD/QkP9ickwJcGgX6EBPoRGuBLSIAfxjiYuzmRtKw8OseEMeHM1lzapzkNymoFVMUPf7Ore4dMsm8wwY35tdeL3DwPHr+4KzefVXZ9px2J6dz+yQp2H87g7vM7sPtwBjPXHiQs0I87hrTjxkFtbDdVFb0wewtvzN/JvRd04N4LOpZ/ojHwSnfbTbLvT0z3yxizbzzJmTn8ev+Qcsd0jDFcP3kZ6+JSWfDAEBqFnnjzWbk3mZunLCfAz4ePb+xHl9xNdg+IqE42ATirruY7DMt2H2X2xkMEB/jyYPtD+HxzG2Sn2ZkyfSYUf9HsNDsAeXg73PBD5Z9Gdy+C7/7PDhYHhNnZMg2bOb9aOL83t4v4Vn5oW3SjX6+ZN1Jj4KVONsmMe88eW/6+XUPToj9cM6149dmK5OXYWXJrp9oEM+ql0mt8jIHZ/7CJsPcEGP3fyqdWu8PO+XYtw5n/ByNc64JkxWT799PrGrj0zartEVIOTQqq0LerD7Bsz1Eys/PIyMknMyeP9Ox8MrPzyMzJJys3n7M6RDLhzNb0b93ITnWtCelJ8N8+dspp23Ng3GRMaCS3fLSCxTsPM+vus0t1k/20Pp4HvlpLkL8v/7umD4Pa2e6dzfHHeHH2Vn7ZkkhUWCB3ndeeq05v5VJ3DsBHi/fwxMyNXD2gFf8e273y3/Gnh+DPt+3tq6byi+nHLR+t4IXLe3JF/5ZlPmTupgRu+3gFT17SlRsHl0542xLSuP6DZWTk5PHBDaczoK19A8zNd7Bk5xF+2nCIuZsOcTg9B39fITffcMtZbXn03MbI17fZefK9rrHJISDUvjF+Pt4ev+bL4ns8VCQ7za5tSd5jB3aPHbRf6QkUK2R81t/szn819f8B7LTO/cvsyvj5z9gFZB2GwxUfVq1rBuyb/q//tPtyl3wOR74dN1v9ia0TNvzfnlstDzbxLX/PJu62Z1d87uYfYNp1dszkqs+rP6hegiYFVTds/gGO7rTFxpyf5BKOZTHs5d/oEB3GtNsH4usj5OU7eGH2Vt5ZuIveLSN4a0JfYsNLN7VX7DnKf2ZvZdnuo7RsHMzd53Xggi7RxT6VlzRrfTx3fr6KC7pE89a1fV2bIrp7kR209Q2Eh3Zj/EO45PXfScvK45f7zi31HNl5+Vz4ykICfH2Ydc/Z5bYmDqQc57oP/uRA8nEeuLATWw6lMW9zAqnHcwkJ8GVo56aM6h7LkE5RvDB7K1MW72HSyM7cfnYb+wa64Dk7kHzFFLvvxrovbTeXq33rFcnPtbPTjh2wC7Cq2gfuimXv2b1HOl9sWyN9JsDFr1W+f0ZFln9gnzO2t21tBIXDNxNtHaIqTK12q5wMePssWwyz5enQ8kxodYbdd71ot9yeP+wkjZgecMPMqifKCmhSUHXaN6vj+NuXa3lkVBfG9m3O3VNXs3jnESac2YrHLu5a4SwrYwy/bUvihdlb2XjQVmZtGxlKn5YR9GkVQZ9WjegUE4a/rw9Ldh7hhsnL6NEinM9uPYMgfxe7D/Lz4OXO0KwvXDsNgDkbDzHxk5W8PL4Xl/VtUez0t3/byXM/beGTWwZwdoeK9/w4mpHDTR8uY21cKmFBfgzrEs2I7jGc0zGqWHwOh+GuL1bz47p4XrqiF+P6tbBF+WbcZgdejcPOajnnQdd+Jxf9uC6er1bu54XLexEVFlj5A6oiYaPtYwcb99BHauYNe8ssux9CWIwtO7/zVxj2Txh898k/d005vAOWvWOrDSdssP9+iF3H0PIMO2Y072k7WeDm2TW+wl+TgqrTjDFM/GQlv21LokloAEczcnhmbA8u79ei8gc7ORx20dzKvcms3pfM6v0pJKXZ+k5B/j70aB7OlkNpRDcMYvodA4kIqWK/eOIW+6nTOePGGMOo//5Odm4+c+87F1/nAsLEtCyGvrCAge0ief+GSv/mAMjKzWdbQhqdYxpW2AWWnZfPzVOWs3TXUd6/vj9DOze1A8s/3mcHoGu4e+eb1XHcP20tDgN9W0Xw+W1nup5IXeFwwLd/sZvvFB1srgn7l9u9TDKPwsWvQP+bavb5a1J2GsQth31/2tXPcSvsRIGwWFuCv7LB9mrQpKDqvMS0LIa/spAGQX68dW0/ujc/icVV2DftAynHWb0vxX7tT8YYeOPavjSPqMKsjwr8vCGeOz5dxWtX9WZMb1ua5MGv1vLtmgPM/du5tImsueZ+gbSsXK56dym7kjL47LYz6NuqUY2/BsC0Fft5aMY6Bp7WhHF9W3D/V2sZ07sZr17Zu+bGmdwtNe5EF82pJD/Prk8Jb1n5/hTVpElBnRIOp2cT4pwFdSpwOAwjX1tEnsPBnL+dy4YDqYx54w9uP/c0Jo3s4rbXTUrL5vK3F5N6PJfpdwyifdOTW8dS0ud/7uMf36zn7A6RvHd9f4L8fXlj/g5emL2V+4Z15O7zT35DRGMMM9ce5LmftnDHue24YVCbkw9cuczVpKAF8ZRHRTYIPGUSAoCPj3D3+R3YmZTBj+vjeer7jUQ2COSvQ9u79XWjwgL5+OYB+PkIN0xexqHUmiuO9vGSPfzjm/UM7RRVmBAA/m9IOy7r05yX527j+7Uld9KtmvjU49z60Qru+WINyZk5PP/zFuJTj9dA9KqmaVJQqopGdo+hQ9MG/OPr9azal8LfR3QqXl/KTVo3CWXKTQNIPZ7LDZOXkZJZuuxIVX3w+24e/24jw7pG8/Z1/YqNH4gIz47rQf/WjXjgq7Ws2Z9S5ed3OAyfLt3LsJcXsnjnER69qAs/33MOeQ7DMz9uPun4Vc3T7iOlqmHm2oPcPXU1PZqH892dg09Ura0Fi3cc5oYPl5HvMLRpEkqH6AZ0jA6jQ3QYHaMb0DYy1KUaWe/8tpNnf9rCyO4xvHZVn3IHvI+kZ3Ppm39wPMfBd38d7PL4zK6kdB7+ej3Ldh9lcPsmPDu2J62a2LImr8zdxmu/bOfz284oXIui3EvHFJRyo3yH4Y35OxjVI4b2TatRBuQkrd6XzK9bEtmekM62xDT2Hskk32H/ln19hDZNQogJDyIiJIDGIQE0CvGnUWgAjUICaBQawMq9yfz3l+1c3DOWV67sXWnl3e0JaVz25mKaNwpm+l8GVbjaPS/fwXuLdvPKvG0E+vnw2EVduaJ/i2KD1Vm5+Qx75TeC/HwrXNdRV+TmO3h/0W4+/GM3DwzvxPhyFjDWZZoUlPIi2Xn57ErKYFtCGtsT0tmemMbh9BySM3JIzswh5XhuqW2Gx/ZpzguX93R5v4fftiVx85TlDO0UxTvX9cfXR8jOy2dHYjpbD6Wx9VAaWw6lsSn+GElp2QzvFs3TY7oT3bDsYoYFK8AfvagLt5592sleArf5c9cRHv12A9sT04kNDyI+NYunx3Tj+oFtPB1alWhSUEoVyncYjh3P5WhmDimZOeTlG/q3aVy41sJVnyzZw2PfbaRvqwiOZeWx+3BGYQslwNeHdk0b0DkmjBHdYxjeLabC5zLGcNOU5azYk8yv959L03KSh6ccSc/m37O2MGNVHM0jgnl6TDfO6hDJXZ+vZs6mBB4e2Zk7zq3dsu8no04kBREZAbwG+ALvG2OeK+e8y4GvgNONMRW+42tSUMqzXp67jR/WHqRd0wZ0ig6jU0wYnWPCaBMZWuVuoN2HMxj+ykIucnZj1QUOh+GL5ft5/uctZObkcdvZp3HXeR0Kqwzn5ju4b9pavl97kHvO78C9F3Q4JdZxeHw/BRHxBd4AhgFxwHIRmWmM2VTivDDgbuBPd8WilKo59w3ryH3DKqgyWwVtI0O57Zy2vDF/J1cPaFVYJLA8uw9n8OO6g+TmG4wxGMBhDMZQeLtV4xDG929ZrXGKTQeP8ei3dlbZGW0b88zY7qXGjPx9fXj1yt4E+/vw2i/bOZ6bz6SRnauVGIwxbDmUxu/bD/P7jsME+/syskcM53eJPvkqxdXkzlcdAOwwxuwCEJEvgDFAyZ27/wn8B3jAjbEopeqoO4e255tVB3j8uw38cNdZZY5xpGfn8fqvO/jg913k5p/o3fARO3XWR0AQELsd7ZQ/9vD0mO4MbOda/aDEtCxenrONaSv20ygkgJfH92Jsn+blvtH7+gjPXdaTYH9f3l24i8ycPJ4e3d2lWWgJx7JYtP0wv29P4vcdRzicbkuztIsKJT07j583HiLAz4ehnaIY1SO21hOEO1+pObC/yM9xwBlFTxCRPkBLY8wPIlJuUhCRicBEgFatar4miFLKc0IC/Hjs4q785bNVfLp0b7Gy48YYvltzkGd/2kzCsWzG9W3BQyM6ERUWWO4b9rxNCTz5/Uaufm8pl/Zuxj9GdSl3vOJ4Tj7vL9rFW7/tJDffwY2D2nLP+R1c2szJx0d4cnQ3ggJ8eee3XWTlOnh+XM/CcZrcfAd7j2SyKymdnUkZ7EpKZ21cCtsS0gFoEhrA4PaRnN0hkrM6RBIbHozDYVi1L5kf1sUza308szcmEOjnw5BOUVzUsxnnd25a9m6HNchtYwoicgUw3Bhzq/Pn64ABxpi7nD/7AL8CNxpj9ojIAuABHVNQyvsYY7jug2WsjUvh1/uHEBUWyIYDqTw5cyMr9ibTs0U4T47u5nLdp6zcfN5csJO3f9tJgK8PfxvWkRsGti5shTgchm9WH+CF2Vs5dCyLEd1ieHhk52rVrjLG8L9fd/Dy3G0MateEkAA/diWls+9oJnmOE++vUWGBdI4J46z2Ngl0iWlYYcvC4TCs3JfMj84EkZiWzfUDW/P0mO5VjhHqwECziAwEnjTGDHf+PAnAGPOs8+dwYCeQ7nxIDHAUGF1RYtCkoFT9tCMxnRGvLmRE9xgaBvszddk+GocE8PcRnbiiX8tqLRDccziDJ7/fyIKtSXSOCePpMd3JdxiembWJDQeO0atFOI9c1LXSsQxXvL9oF6/P30HTsEDaRTXgtKhQ53d7u+FJrHovqAjcODSg2nWv6kJS8AO2AecDB4DlwDXGmI3lnL8AbSko5dWenbWZdxbuwtdHuH5ga+69oCPhwSdXQsQYw5xNCTz9/SYOpNh6S80jgvn7iE5c0rNZra5G9ySPzz4yxuSJyF+B2dgpqZONMRtF5GlghTFmprteWyl1arrngg6EBPgxskcMHaNrZqW4iDC8WwzndIhiyuI9+PsKE85sXbP7RNQjunhNKaW8gJbOVkopVWWaFJRSShXSpKCUUqqQJgWllFKFNCkopZQqpElBKaVUIU0KSimlCmlSUEopVeiUW7wmIknA3mo+PBI4XIPh1CSNrXrqcmxQt+PT2KrnVI2ttTEmqrInOOWSwskQkRWurOjzBI2teupybFC349PYqqe+x6bdR0oppQppUlBKKVXI25LCu54OoAIaW/XU5digbsensVVPvY7Nq8YUlFJKVczbWgpKKaUqoElBKaVUIa9JCiIyQkS2isgOEXnY0/EUJSJ7RGS9iKwREY/uICQik0UkUUQ2FDnWWETmish253fXdk+vndieFJEDzmu3RkRGeSi2liIyX0Q2i8hGEbnHedzj166C2Dx+7UQkSESWichaZ2xPOY+3FZE/ndftSxEJqEOxTRGR3UWuW+/ajq1IjL4islpEfnD+fPLXzRhT77+w24HuBE4DAoC1QFdPx1Ukvj1ApKfjcMZyDtAX2FDk2H+Ah523Hwaer0OxPYnd29vT1y0W6Ou8HYbdn7xrXbh2FcTm8WsHCNDAedsf+BM4E5gGXOU8/jbwlzoU2xTgck//n3PGdR/wOfCD8+eTvm7e0lIYAOwwxuwyxuQAXwBjPBxTnWSMWQgcLXF4DPCR8/ZHwKW1GpRTObHVCcaYeGPMKuftNGAz0Jw6cO0qiM3jjJXu/NHf+WWA84DpzuOeum7lxVYniEgL4CLgfefPQg1cN29JCs2B/UV+jqOO/FE4GWCOiKwUkYmeDqYM0caYeLBvMEBTD8dT0l9FZJ2ze8kjXVtFiUgboA/2k2WdunYlYoM6cO2cXSBrgERgLrZVn2KMyXOe4rG/15KxGWMKrtszzuv2iogEeiI24FXg74DD+XMTauC6eUtSkDKO1ZmMDww2xvQFRgJ3isg5ng7oFPIW0A7oDcQDL3kyGBFpAMwA7jXGHPNkLCWVEVuduHbGmHxjTG+gBbZV36Ws02o3KueLlohNRLoDk4DOwOlAY+Ch2o5LRC4GEo0xK4seLuPUKl83b0kKcUDLIj+3AA56KJZSjDEHnd8TgW+wfxh1SYKIxAI4vyd6OJ5CxpgE5x+uA3gPD147EfHHvul+Zoz52nm4Tly7smKrS9fOGU8KsADbbx8hIn7Ouzz+91okthHO7jhjjMkGPsQz120wMFpE9mC7w8/DthxO+rp5S1JYDnRwjswHAFcBMz0cEwAiEioiYQW3gQuBDRU/qtbNBG5w3r4B+M6DsRRT8IbrNBYPXTtnf+4HwGZjzMtF7vL4tSsvtrpw7UQkSkQinLeDgQuwYx7zgcudp3nqupUV25YiSV6wffa1ft2MMZOMMS2MMW2w72e/GmOupSaum6dHz2vrCxiFnXWxE3jE0/EUies07GyotcBGT8cGTMV2JeRiW1i3YPsqfwG2O783rkOxfQKsB9Zh34BjPRTbWdim+jpgjfNrVF24dhXE5vFrB/QEVjtj2AA87jx+GrAM2AF8BQTWodh+dV63DcCnOGcoeeoLGMKJ2Ucnfd20zIVSSqlC3oIXhjwAAAHdSURBVNJ9pJRSygWaFJRSShXSpKCUUqqQJgWllFKFNCkopZQqpElBqVokIkMKKloqVRdpUlBKKVVIk4JSZRCRCc5a+mtE5B1nYbR0EXlJRFaJyC8iEuU8t7eILHUWSPumoLCciLQXkXnOevyrRKSd8+kbiMh0EdkiIp85V8YqVSdoUlCqBBHpAlyJLVTYG8gHrgVCgVXGFi/8DXjC+ZCPgYeMMT2xK10Ljn8GvGGM6QUMwq7GBlul9F7snganYevYKFUn+FV+ilJe53ygH7Dc+SE+GFvIzgF86TznU+BrEQkHIowxvzmPfwR85axn1dwY8w2AMSYLwPl8y4wxcc6f1wBtgN/d/2spVTlNCkqVJsBHxphJxQ6KPFbivIpqxFTUJZRd5HY++neo6hDtPlKqtF+Ay0WkKRTus9wa+/dSUIHyGuB3Y0wqkCwiZzuPXwf8Zux+BXEicqnzOQJFJKRWfwulqkE/oShVgjFmk4g8it0NzwdblfVOIAPoJiIrgVTsuAPYEsVvO9/0dwE3OY9fB7wjIk87n+OKWvw1lKoWrZKqlItEJN0Y08DTcSjlTtp9pJRSqpC2FJRSShXSloJSSqlCmhSUUkoV0qSglFKqkCYFpZRShTQpKKWUKvT/hWtoivDkOBYAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "677HYTowThsH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Dense models test"
      ]
    },
    {
      "metadata": {
        "id": "2JTtLHcXLl1b",
        "colab_type": "code",
        "outputId": "3fe707ce-5974-43d9-9f81-a3a210772a70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "model_sgd.evaluate(X_test, Y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "300/300 [==============================] - 0s 70us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5230206135908763,\n",
              " 0.5967174990971883,\n",
              " 0.5366666666666666,\n",
              " 0.5645968508720398]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "UPnyPQVJOEg2",
        "colab_type": "code",
        "outputId": "429d34d0-5ab6-48c6-a50e-8dd3115a0378",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "model_adam.evaluate(X_test, Y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "300/300 [==============================] - 0s 99us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.530429060459137, 0.5482738896210988, 0.4966666662693024, 0.5206804414590199]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "RQ3ttaGiVXIg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Dense models are pretty weak against changing sizes and mooving shapes. That's because the network do not recognize patterns.\n",
        "That is why we will use a ConvNet that is able to learn patterns."
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Rir-JDLPBaOp"
      },
      "cell_type": "markdown",
      "source": [
        "### ConvNet compilation"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "w8wZPXceBaOr",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_model_conv(optimizer, loss, metrics):\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(16, (5, 5), padding='same', activation='relu', input_shape=(IMAGE_SIZE, IMAGE_SIZE, 1)))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(Conv2D(32, (3, 3), padding='same', activation='relu'))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  \n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(1024, activation='relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(3, activation='softmax'))\n",
        "  \n",
        "  model.compile(optimizer=optimizer,\n",
        "               loss=loss,\n",
        "               metrics=metrics)\n",
        "  model.summary()\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FrKx2QdDFBEY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### ConvNet training"
      ]
    },
    {
      "metadata": {
        "id": "h9aJT8jDUemi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We reshape data for ConvNet training.\n",
        "New shape must be : (n_data, image_size, image_size, n_channels)"
      ]
    },
    {
      "metadata": {
        "id": "EcG7HFY7UlXE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], IMAGE_SIZE, IMAGE_SIZE, 1)\n",
        "X_valid = X_valid.reshape(X_valid.shape[0], IMAGE_SIZE, IMAGE_SIZE, 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], IMAGE_SIZE, IMAGE_SIZE, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j0sq4oURVF5U",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we can train our ConvNet model."
      ]
    },
    {
      "metadata": {
        "id": "RvokQ-TSFBjY",
        "colab_type": "code",
        "outputId": "34bd7271-0336-4b10-801c-200962cf3925",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "optimizer = Adam(0.00001)\n",
        "loss = 'binary_crossentropy'\n",
        "metrics = ['accuracy', get_metrics(0.5)['precision'], get_metrics(0.5)['recall'], get_metrics(0.5)['f1_score']]\n",
        "\n",
        "model_conv = get_model_conv(optimizer, loss, metrics)\n",
        "\n",
        "model_conv.fit(X_train, Y_train,\n",
        "          epochs=500,\n",
        "          batch_size=32,\n",
        "          validation_data=(X_valid, Y_valid)\n",
        "         )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 72, 72, 16)        416       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 36, 36, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 36, 36, 32)        4640      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 18, 18, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 10368)             0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1024)              10617856  \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 3)                 3075      \n",
            "=================================================================\n",
            "Total params: 10,625,987\n",
            "Trainable params: 10,625,987\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 300 samples, validate on 60 samples\n",
            "Epoch 1/500\n",
            "300/300 [==============================] - 6s 20ms/step - loss: 0.6477 - acc: 0.6656 - precision: 0.1422 - recall: 0.0100 - f1_score: 0.0186 - val_loss: 0.6289 - val_acc: 0.6667 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00\n",
            "Epoch 2/500\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.6287 - acc: 0.6667 - precision: 0.2133 - recall: 0.0100 - f1_score: 0.0190 - val_loss: 0.6171 - val_acc: 0.6667 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00\n",
            "Epoch 3/500\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.6140 - acc: 0.6678 - precision: 0.1067 - recall: 0.0033 - f1_score: 0.0065 - val_loss: 0.6116 - val_acc: 0.6667 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00\n",
            "Epoch 4/500\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.6180 - acc: 0.6811 - precision: 0.8533 - recall: 0.0433 - f1_score: 0.0818 - val_loss: 0.6060 - val_acc: 0.6722 - val_precision: 0.5333 - val_recall: 0.0167 - val_f1_score: 0.0323\n",
            "Epoch 5/500\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.6040 - acc: 0.6822 - precision: 0.7467 - recall: 0.0567 - f1_score: 0.1032 - val_loss: 0.6016 - val_acc: 0.6722 - val_precision: 0.5333 - val_recall: 0.0167 - val_f1_score: 0.0323\n",
            "Epoch 6/500\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.6058 - acc: 0.6733 - precision: 0.5067 - recall: 0.0367 - f1_score: 0.0675 - val_loss: 0.5969 - val_acc: 0.6722 - val_precision: 0.5333 - val_recall: 0.0167 - val_f1_score: 0.0323\n",
            "Epoch 7/500\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.5910 - acc: 0.6911 - precision: 0.8898 - recall: 0.0833 - f1_score: 0.1492 - val_loss: 0.5910 - val_acc: 0.6889 - val_precision: 1.0000 - val_recall: 0.0667 - val_f1_score: 0.1250\n",
            "Epoch 8/500\n",
            "300/300 [==============================] - 4s 13ms/step - loss: 0.5853 - acc: 0.6878 - precision: 0.9140 - recall: 0.0767 - f1_score: 0.1372 - val_loss: 0.5870 - val_acc: 0.6778 - val_precision: 0.5333 - val_recall: 0.0333 - val_f1_score: 0.0627\n",
            "Epoch 9/500\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.5893 - acc: 0.6922 - precision: 0.8187 - recall: 0.0867 - f1_score: 0.1546 - val_loss: 0.5819 - val_acc: 0.7056 - val_precision: 1.0000 - val_recall: 0.1167 - val_f1_score: 0.2088\n",
            "Epoch 10/500\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.5864 - acc: 0.6911 - precision: 0.7742 - recall: 0.1000 - f1_score: 0.1742 - val_loss: 0.5791 - val_acc: 0.7111 - val_precision: 1.0000 - val_recall: 0.1333 - val_f1_score: 0.2345\n",
            "Epoch 11/500\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.5735 - acc: 0.7044 - precision: 0.8842 - recall: 0.1333 - f1_score: 0.2274 - val_loss: 0.5728 - val_acc: 0.7056 - val_precision: 1.0000 - val_recall: 0.1167 - val_f1_score: 0.2088\n",
            "Epoch 12/500\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.5810 - acc: 0.6956 - precision: 0.8264 - recall: 0.1100 - f1_score: 0.1918 - val_loss: 0.5684 - val_acc: 0.7167 - val_precision: 1.0000 - val_recall: 0.1500 - val_f1_score: 0.2608\n",
            "Epoch 13/500\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.5664 - acc: 0.7033 - precision: 0.8649 - recall: 0.1300 - f1_score: 0.2241 - val_loss: 0.5648 - val_acc: 0.7111 - val_precision: 0.9067 - val_recall: 0.1500 - val_f1_score: 0.2573\n",
            "Epoch 14/500\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.5589 - acc: 0.7056 - precision: 0.8304 - recall: 0.1400 - f1_score: 0.2317 - val_loss: 0.5615 - val_acc: 0.7111 - val_precision: 1.0000 - val_recall: 0.1333 - val_f1_score: 0.2345\n",
            "Epoch 15/500\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.5620 - acc: 0.6911 - precision: 0.7704 - recall: 0.1067 - f1_score: 0.1833 - val_loss: 0.5558 - val_acc: 0.7167 - val_precision: 1.0000 - val_recall: 0.1500 - val_f1_score: 0.2608\n",
            "Epoch 16/500\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.5435 - acc: 0.7167 - precision: 0.9279 - recall: 0.1600 - f1_score: 0.2693 - val_loss: 0.5546 - val_acc: 0.7111 - val_precision: 0.8000 - val_recall: 0.1833 - val_f1_score: 0.2981\n",
            "Epoch 17/500\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.5464 - acc: 0.7211 - precision: 0.8050 - recall: 0.2067 - f1_score: 0.3234 - val_loss: 0.5494 - val_acc: 0.7222 - val_precision: 1.0000 - val_recall: 0.1667 - val_f1_score: 0.2851\n",
            "Epoch 18/500\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.5416 - acc: 0.7144 - precision: 0.8307 - recall: 0.1800 - f1_score: 0.2889 - val_loss: 0.5432 - val_acc: 0.7167 - val_precision: 1.0000 - val_recall: 0.1500 - val_f1_score: 0.2608\n",
            "Epoch 19/500\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.5370 - acc: 0.7233 - precision: 0.9042 - recall: 0.2000 - f1_score: 0.3226 - val_loss: 0.5397 - val_acc: 0.7111 - val_precision: 0.8000 - val_recall: 0.1833 - val_f1_score: 0.2981\n",
            "Epoch 20/500\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.5371 - acc: 0.7300 - precision: 0.7998 - recall: 0.2600 - f1_score: 0.3857 - val_loss: 0.5424 - val_acc: 0.7222 - val_precision: 0.8250 - val_recall: 0.2167 - val_f1_score: 0.3430\n",
            "Epoch 21/500\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.5253 - acc: 0.7322 - precision: 0.8569 - recall: 0.2433 - f1_score: 0.3754 - val_loss: 0.5321 - val_acc: 0.7111 - val_precision: 0.8000 - val_recall: 0.1833 - val_f1_score: 0.2981\n",
            "Epoch 22/500\n",
            "300/300 [==============================] - 4s 13ms/step - loss: 0.5232 - acc: 0.7222 - precision: 0.8738 - recall: 0.1967 - f1_score: 0.3175 - val_loss: 0.5278 - val_acc: 0.7167 - val_precision: 0.9067 - val_recall: 0.1667 - val_f1_score: 0.2816\n",
            "Epoch 23/500\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.5158 - acc: 0.7267 - precision: 0.8214 - recall: 0.2233 - f1_score: 0.3481 - val_loss: 0.5239 - val_acc: 0.7167 - val_precision: 0.8000 - val_recall: 0.2000 - val_f1_score: 0.3200\n",
            "Epoch 24/500\n",
            "300/300 [==============================] - 4s 13ms/step - loss: 0.5090 - acc: 0.7389 - precision: 0.9153 - recall: 0.2400 - f1_score: 0.3736 - val_loss: 0.5200 - val_acc: 0.7167 - val_precision: 0.8000 - val_recall: 0.2000 - val_f1_score: 0.3200\n",
            "Epoch 25/500\n",
            "300/300 [==============================] - 4s 13ms/step - loss: 0.5091 - acc: 0.7411 - precision: 0.8621 - recall: 0.2667 - f1_score: 0.4037 - val_loss: 0.5154 - val_acc: 0.7222 - val_precision: 1.0000 - val_recall: 0.1667 - val_f1_score: 0.2851\n",
            "Epoch 26/500\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.5010 - acc: 0.7556 - precision: 0.8836 - recall: 0.3100 - f1_score: 0.4561 - val_loss: 0.5132 - val_acc: 0.7278 - val_precision: 0.8250 - val_recall: 0.2333 - val_f1_score: 0.3638\n",
            "Epoch 27/500\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.5083 - acc: 0.7489 - precision: 0.8760 - recall: 0.2933 - f1_score: 0.4311 - val_loss: 0.5095 - val_acc: 0.7222 - val_precision: 0.8000 - val_recall: 0.2167 - val_f1_score: 0.3408\n",
            "Epoch 28/500\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.5008 - acc: 0.7544 - precision: 0.8604 - recall: 0.3200 - f1_score: 0.4561 - val_loss: 0.5043 - val_acc: 0.7333 - val_precision: 0.8667 - val_recall: 0.2333 - val_f1_score: 0.3675\n",
            "Epoch 29/500\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.4928 - acc: 0.7489 - precision: 0.8792 - recall: 0.2867 - f1_score: 0.4290 - val_loss: 0.4994 - val_acc: 0.7222 - val_precision: 0.8000 - val_recall: 0.2167 - val_f1_score: 0.3408\n",
            "Epoch 30/500\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.4908 - acc: 0.7444 - precision: 0.8585 - recall: 0.2833 - f1_score: 0.4223 - val_loss: 0.4955 - val_acc: 0.7333 - val_precision: 0.8667 - val_recall: 0.2333 - val_f1_score: 0.3675\n",
            "Epoch 31/500\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.4860 - acc: 0.7578 - precision: 0.8676 - recall: 0.3200 - f1_score: 0.4625 - val_loss: 0.4936 - val_acc: 0.7500 - val_precision: 0.8833 - val_recall: 0.2833 - val_f1_score: 0.4284\n",
            "Epoch 32/500\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.4839 - acc: 0.7611 - precision: 0.8508 - recall: 0.3433 - f1_score: 0.4876 - val_loss: 0.4890 - val_acc: 0.7222 - val_precision: 0.8000 - val_recall: 0.2167 - val_f1_score: 0.3408\n",
            "Epoch 33/500\n",
            "300/300 [==============================] - 4s 13ms/step - loss: 0.4789 - acc: 0.7600 - precision: 0.8884 - recall: 0.3200 - f1_score: 0.4673 - val_loss: 0.4857 - val_acc: 0.7333 - val_precision: 0.8250 - val_recall: 0.2500 - val_f1_score: 0.3836\n",
            "Epoch 34/500\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.4814 - acc: 0.7622 - precision: 0.8034 - recall: 0.3767 - f1_score: 0.5089 - val_loss: 0.4848 - val_acc: 0.7833 - val_precision: 0.9152 - val_recall: 0.3833 - val_f1_score: 0.5400\n",
            "Epoch 35/500\n",
            "300/300 [==============================] - 4s 13ms/step - loss: 0.4658 - acc: 0.7711 - precision: 0.8579 - recall: 0.3733 - f1_score: 0.5183 - val_loss: 0.4776 - val_acc: 0.7333 - val_precision: 0.8667 - val_recall: 0.2333 - val_f1_score: 0.3675\n",
            "Epoch 36/500\n",
            "300/300 [==============================] - 4s 13ms/step - loss: 0.4568 - acc: 0.7789 - precision: 0.8892 - recall: 0.3867 - f1_score: 0.5358 - val_loss: 0.4747 - val_acc: 0.7722 - val_precision: 0.9067 - val_recall: 0.3500 - val_f1_score: 0.5046\n",
            "Epoch 37/500\n",
            "300/300 [==============================] - 4s 14ms/step - loss: 0.4629 - acc: 0.7822 - precision: 0.8768 - recall: 0.4100 - f1_score: 0.5474 - val_loss: 0.4709 - val_acc: 0.7444 - val_precision: 0.8833 - val_recall: 0.2667 - val_f1_score: 0.4095\n",
            "Epoch 38/500\n",
            "300/300 [==============================] - 4s 13ms/step - loss: 0.4637 - acc: 0.7744 - precision: 0.8534 - recall: 0.3933 - f1_score: 0.5361 - val_loss: 0.4669 - val_acc: 0.7556 - val_precision: 0.8963 - val_recall: 0.3000 - val_f1_score: 0.4494\n",
            "Epoch 39/500\n",
            "300/300 [==============================] - 4s 13ms/step - loss: 0.4520 - acc: 0.7856 - precision: 0.8928 - recall: 0.4000 - f1_score: 0.5428 - val_loss: 0.4665 - val_acc: 0.7944 - val_precision: 0.9222 - val_recall: 0.4167 - val_f1_score: 0.5738\n",
            "Epoch 40/500\n",
            "300/300 [==============================] - 4s 13ms/step - loss: 0.4468 - acc: 0.7867 - precision: 0.8479 - recall: 0.4433 - f1_score: 0.5787 - val_loss: 0.4598 - val_acc: 0.7833 - val_precision: 0.9152 - val_recall: 0.3833 - val_f1_score: 0.5400\n",
            "Epoch 41/500\n",
            "300/300 [==============================] - 4s 13ms/step - loss: 0.4432 - acc: 0.7889 - precision: 0.8588 - recall: 0.4400 - f1_score: 0.5767 - val_loss: 0.4564 - val_acc: 0.7889 - val_precision: 0.9222 - val_recall: 0.4000 - val_f1_score: 0.5580\n",
            "Epoch 42/500\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.4361 - acc: 0.8000 - precision: 0.8719 - recall: 0.4700 - f1_score: 0.6081 - val_loss: 0.4550 - val_acc: 0.8000 - val_precision: 0.9282 - val_recall: 0.4333 - val_f1_score: 0.5908\n",
            "Epoch 43/500\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.4409 - acc: 0.7889 - precision: 0.8606 - recall: 0.4433 - f1_score: 0.5783 - val_loss: 0.4515 - val_acc: 0.7667 - val_precision: 0.9067 - val_recall: 0.3333 - val_f1_score: 0.4874\n",
            "Epoch 44/500\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.4463 - acc: 0.7767 - precision: 0.8049 - recall: 0.4367 - f1_score: 0.5619 - val_loss: 0.4481 - val_acc: 0.8056 - val_precision: 0.9333 - val_recall: 0.4500 - val_f1_score: 0.6071\n",
            "Epoch 45/500\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.4249 - acc: 0.8144 - precision: 0.8722 - recall: 0.5233 - f1_score: 0.6495 - val_loss: 0.4473 - val_acc: 0.8000 - val_precision: 0.8741 - val_recall: 0.4667 - val_f1_score: 0.6080\n",
            "Epoch 46/500\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.4291 - acc: 0.7978 - precision: 0.8452 - recall: 0.4800 - f1_score: 0.6096 - val_loss: 0.4418 - val_acc: 0.7778 - val_precision: 0.8733 - val_recall: 0.3833 - val_f1_score: 0.5298\n",
            "Epoch 47/500\n",
            "300/300 [==============================] - 4s 13ms/step - loss: 0.4329 - acc: 0.7944 - precision: 0.8365 - recall: 0.4733 - f1_score: 0.6013 - val_loss: 0.4397 - val_acc: 0.8056 - val_precision: 0.9282 - val_recall: 0.4500 - val_f1_score: 0.6060\n",
            "Epoch 48/500\n",
            "300/300 [==============================] - 4s 14ms/step - loss: 0.4261 - acc: 0.7933 - precision: 0.8282 - recall: 0.4800 - f1_score: 0.6046 - val_loss: 0.4388 - val_acc: 0.8056 - val_precision: 0.8785 - val_recall: 0.4833 - val_f1_score: 0.6235\n",
            "Epoch 49/500\n",
            "300/300 [==============================] - 4s 14ms/step - loss: 0.4202 - acc: 0.8067 - precision: 0.8456 - recall: 0.5133 - f1_score: 0.6359 - val_loss: 0.4338 - val_acc: 0.8111 - val_precision: 0.9333 - val_recall: 0.4667 - val_f1_score: 0.6222\n",
            "Epoch 50/500\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.4168 - acc: 0.7989 - precision: 0.8356 - recall: 0.4933 - f1_score: 0.6190 - val_loss: 0.4308 - val_acc: 0.8111 - val_precision: 0.9333 - val_recall: 0.4667 - val_f1_score: 0.6222\n",
            "Epoch 51/500\n",
            "300/300 [==============================] - 4s 13ms/step - loss: 0.4049 - acc: 0.8256 - precision: 0.8705 - recall: 0.5633 - f1_score: 0.6813 - val_loss: 0.4295 - val_acc: 0.8167 - val_precision: 0.8844 - val_recall: 0.5167 - val_f1_score: 0.6514\n",
            "Epoch 52/500\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.4058 - acc: 0.8222 - precision: 0.8568 - recall: 0.5600 - f1_score: 0.6737 - val_loss: 0.4271 - val_acc: 0.8000 - val_precision: 0.8926 - val_recall: 0.4500 - val_f1_score: 0.5960\n",
            "Epoch 53/500\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.4034 - acc: 0.8189 - precision: 0.8659 - recall: 0.5433 - f1_score: 0.6655 - val_loss: 0.4242 - val_acc: 0.8222 - val_precision: 0.9120 - val_recall: 0.5167 - val_f1_score: 0.6596\n",
            "Epoch 54/500\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.3994 - acc: 0.8244 - precision: 0.8592 - recall: 0.5633 - f1_score: 0.6773 - val_loss: 0.4211 - val_acc: 0.8167 - val_precision: 0.8844 - val_recall: 0.5167 - val_f1_score: 0.6514\n",
            "Epoch 55/500\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.3980 - acc: 0.8389 - precision: 0.8558 - recall: 0.6233 - f1_score: 0.7192 - val_loss: 0.4186 - val_acc: 0.8167 - val_precision: 0.8651 - val_recall: 0.5333 - val_f1_score: 0.6575\n",
            "Epoch 56/500\n",
            "300/300 [==============================] - 4s 13ms/step - loss: 0.3973 - acc: 0.8222 - precision: 0.8488 - recall: 0.5667 - f1_score: 0.6776 - val_loss: 0.4221 - val_acc: 0.8222 - val_precision: 0.9137 - val_recall: 0.5167 - val_f1_score: 0.6594\n",
            "Epoch 57/500\n",
            "300/300 [==============================] - 4s 13ms/step - loss: 0.3913 - acc: 0.8256 - precision: 0.8316 - recall: 0.5967 - f1_score: 0.6930 - val_loss: 0.4139 - val_acc: 0.8167 - val_precision: 0.8651 - val_recall: 0.5333 - val_f1_score: 0.6575\n",
            "Epoch 58/500\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.3963 - acc: 0.8311 - precision: 0.8296 - recall: 0.6200 - f1_score: 0.7086 - val_loss: 0.4125 - val_acc: 0.8222 - val_precision: 0.8682 - val_recall: 0.5500 - val_f1_score: 0.6700\n",
            "Epoch 59/500\n",
            "300/300 [==============================] - 4s 13ms/step - loss: 0.3962 - acc: 0.8244 - precision: 0.8588 - recall: 0.5700 - f1_score: 0.6813 - val_loss: 0.4135 - val_acc: 0.8222 - val_precision: 0.8890 - val_recall: 0.5333 - val_f1_score: 0.6667\n",
            "Epoch 60/500\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.3767 - acc: 0.8489 - precision: 0.8903 - recall: 0.6267 - f1_score: 0.7342 - val_loss: 0.4078 - val_acc: 0.8111 - val_precision: 0.8249 - val_recall: 0.5500 - val_f1_score: 0.6589\n",
            "Epoch 61/500\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.3884 - acc: 0.8300 - precision: 0.8424 - recall: 0.6000 - f1_score: 0.6990 - val_loss: 0.4066 - val_acc: 0.8167 - val_precision: 0.8655 - val_recall: 0.5333 - val_f1_score: 0.6592\n",
            "Epoch 62/500\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.3866 - acc: 0.8278 - precision: 0.8399 - recall: 0.5967 - f1_score: 0.6951 - val_loss: 0.4059 - val_acc: 0.8278 - val_precision: 0.8724 - val_recall: 0.5667 - val_f1_score: 0.6864\n",
            "Epoch 63/500\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.3772 - acc: 0.8300 - precision: 0.8299 - recall: 0.6133 - f1_score: 0.6995 - val_loss: 0.4014 - val_acc: 0.8278 - val_precision: 0.8536 - val_recall: 0.5833 - val_f1_score: 0.6930\n",
            "Epoch 64/500\n",
            "300/300 [==============================] - 4s 13ms/step - loss: 0.3738 - acc: 0.8433 - precision: 0.8810 - recall: 0.6167 - f1_score: 0.7216 - val_loss: 0.4019 - val_acc: 0.8278 - val_precision: 0.8724 - val_recall: 0.5667 - val_f1_score: 0.6864\n",
            "Epoch 65/500\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.3743 - acc: 0.8433 - precision: 0.8467 - recall: 0.6500 - f1_score: 0.7323 - val_loss: 0.3979 - val_acc: 0.8389 - val_precision: 0.8781 - val_recall: 0.6000 - val_f1_score: 0.7129\n",
            "Epoch 66/500\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.3798 - acc: 0.8333 - precision: 0.8345 - recall: 0.6233 - f1_score: 0.7118 - val_loss: 0.4001 - val_acc: 0.8333 - val_precision: 0.8754 - val_recall: 0.5833 - val_f1_score: 0.6999\n",
            "Epoch 67/500\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.3703 - acc: 0.8433 - precision: 0.8326 - recall: 0.6633 - f1_score: 0.7373 - val_loss: 0.3957 - val_acc: 0.8389 - val_precision: 0.8974 - val_recall: 0.5833 - val_f1_score: 0.7070\n",
            "Epoch 68/500\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.3706 - acc: 0.8344 - precision: 0.8382 - recall: 0.6233 - f1_score: 0.7115 - val_loss: 0.3976 - val_acc: 0.8278 - val_precision: 0.8720 - val_recall: 0.5667 - val_f1_score: 0.6869\n",
            "Epoch 69/500\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.3649 - acc: 0.8489 - precision: 0.8567 - recall: 0.6600 - f1_score: 0.7421 - val_loss: 0.3908 - val_acc: 0.8333 - val_precision: 0.8411 - val_recall: 0.6167 - val_f1_score: 0.7115\n",
            "Epoch 70/500\n",
            "300/300 [==============================] - 4s 13ms/step - loss: 0.3582 - acc: 0.8567 - precision: 0.8815 - recall: 0.6600 - f1_score: 0.7535 - val_loss: 0.3912 - val_acc: 0.8333 - val_precision: 0.8755 - val_recall: 0.5833 - val_f1_score: 0.6990\n",
            "Epoch 71/500\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.3527 - acc: 0.8489 - precision: 0.8387 - recall: 0.6733 - f1_score: 0.7436 - val_loss: 0.3882 - val_acc: 0.8389 - val_precision: 0.8786 - val_recall: 0.6000 - val_f1_score: 0.7125\n",
            "Epoch 72/500\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.3478 - acc: 0.8622 - precision: 0.8737 - recall: 0.6900 - f1_score: 0.7684 - val_loss: 0.3870 - val_acc: 0.8389 - val_precision: 0.8786 - val_recall: 0.6000 - val_f1_score: 0.7125\n",
            "Epoch 73/500\n",
            "300/300 [==============================] - 4s 13ms/step - loss: 0.3546 - acc: 0.8500 - precision: 0.8669 - recall: 0.6500 - f1_score: 0.7411 - val_loss: 0.3871 - val_acc: 0.8389 - val_precision: 0.8786 - val_recall: 0.6000 - val_f1_score: 0.7125\n",
            "Epoch 74/500\n",
            "300/300 [==============================] - 4s 14ms/step - loss: 0.3446 - acc: 0.8678 - precision: 0.8736 - recall: 0.7033 - f1_score: 0.7778 - val_loss: 0.3827 - val_acc: 0.8389 - val_precision: 0.8447 - val_recall: 0.6333 - val_f1_score: 0.7235\n",
            "Epoch 75/500\n",
            "300/300 [==============================] - 4s 13ms/step - loss: 0.3438 - acc: 0.8644 - precision: 0.8796 - recall: 0.6900 - f1_score: 0.7713 - val_loss: 0.3825 - val_acc: 0.8500 - val_precision: 0.8842 - val_recall: 0.6333 - val_f1_score: 0.7376\n",
            "Epoch 76/500\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.3527 - acc: 0.8622 - precision: 0.8619 - recall: 0.7000 - f1_score: 0.7714 - val_loss: 0.3799 - val_acc: 0.8500 - val_precision: 0.8842 - val_recall: 0.6333 - val_f1_score: 0.7376\n",
            "Epoch 77/500\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.3392 - acc: 0.8678 - precision: 0.8805 - recall: 0.6967 - f1_score: 0.7760 - val_loss: 0.3800 - val_acc: 0.8333 - val_precision: 0.8593 - val_recall: 0.6000 - val_f1_score: 0.7056\n",
            "Epoch 78/500\n",
            "300/300 [==============================] - 4s 15ms/step - loss: 0.3357 - acc: 0.8700 - precision: 0.8849 - recall: 0.7000 - f1_score: 0.7803 - val_loss: 0.3775 - val_acc: 0.8500 - val_precision: 0.8842 - val_recall: 0.6333 - val_f1_score: 0.7376\n",
            "Epoch 79/500\n",
            "300/300 [==============================] - 4s 13ms/step - loss: 0.3423 - acc: 0.8622 - precision: 0.8636 - recall: 0.6967 - f1_score: 0.7705 - val_loss: 0.3765 - val_acc: 0.8500 - val_precision: 0.8842 - val_recall: 0.6333 - val_f1_score: 0.7376\n",
            "Epoch 80/500\n",
            "300/300 [==============================] - 4s 13ms/step - loss: 0.3332 - acc: 0.8778 - precision: 0.8743 - recall: 0.7367 - f1_score: 0.7979 - val_loss: 0.3738 - val_acc: 0.8500 - val_precision: 0.8513 - val_recall: 0.6667 - val_f1_score: 0.7475\n",
            "Epoch 81/500\n",
            "300/300 [==============================] - 4s 13ms/step - loss: 0.3385 - acc: 0.8633 - precision: 0.8547 - recall: 0.7100 - f1_score: 0.7751 - val_loss: 0.3747 - val_acc: 0.8500 - val_precision: 0.8842 - val_recall: 0.6333 - val_f1_score: 0.7376\n",
            "Epoch 82/500\n",
            "300/300 [==============================] - 4s 15ms/step - loss: 0.3366 - acc: 0.8644 - precision: 0.8718 - recall: 0.6933 - f1_score: 0.7703 - val_loss: 0.3736 - val_acc: 0.8389 - val_precision: 0.8447 - val_recall: 0.6333 - val_f1_score: 0.7235\n",
            "Epoch 83/500\n",
            "300/300 [==============================] - 4s 14ms/step - loss: 0.3521 - acc: 0.8589 - precision: 0.8449 - recall: 0.7067 - f1_score: 0.7690 - val_loss: 0.3698 - val_acc: 0.8556 - val_precision: 0.8543 - val_recall: 0.6833 - val_f1_score: 0.7587\n",
            "Epoch 84/500\n",
            "300/300 [==============================] - 4s 15ms/step - loss: 0.3420 - acc: 0.8556 - precision: 0.8556 - recall: 0.6833 - f1_score: 0.7577 - val_loss: 0.3796 - val_acc: 0.8333 - val_precision: 0.8754 - val_recall: 0.5833 - val_f1_score: 0.6999\n",
            "Epoch 85/500\n",
            "300/300 [==============================] - 4s 15ms/step - loss: 0.3419 - acc: 0.8544 - precision: 0.8581 - recall: 0.6800 - f1_score: 0.7565 - val_loss: 0.3684 - val_acc: 0.8500 - val_precision: 0.8513 - val_recall: 0.6667 - val_f1_score: 0.7475\n",
            "Epoch 86/500\n",
            "300/300 [==============================] - 4s 12ms/step - loss: 0.3287 - acc: 0.8822 - precision: 0.8902 - recall: 0.7367 - f1_score: 0.8054 - val_loss: 0.3734 - val_acc: 0.8333 - val_precision: 0.8593 - val_recall: 0.6000 - val_f1_score: 0.7056\n",
            "Epoch 87/500\n",
            "300/300 [==============================] - 4s 13ms/step - loss: 0.3175 - acc: 0.8756 - precision: 0.8665 - recall: 0.7400 - f1_score: 0.7972 - val_loss: 0.3679 - val_acc: 0.8444 - val_precision: 0.8479 - val_recall: 0.6500 - val_f1_score: 0.7352\n",
            "Epoch 88/500\n",
            "300/300 [==============================] - 4s 14ms/step - loss: 0.3160 - acc: 0.8789 - precision: 0.8931 - recall: 0.7233 - f1_score: 0.7979 - val_loss: 0.3664 - val_acc: 0.8556 - val_precision: 0.8543 - val_recall: 0.6833 - val_f1_score: 0.7587\n",
            "Epoch 89/500\n",
            "300/300 [==============================] - 4s 14ms/step - loss: 0.3184 - acc: 0.8778 - precision: 0.8730 - recall: 0.7433 - f1_score: 0.8024 - val_loss: 0.3664 - val_acc: 0.8500 - val_precision: 0.8688 - val_recall: 0.6500 - val_f1_score: 0.7422\n",
            "Epoch 90/500\n",
            "300/300 [==============================] - 4s 14ms/step - loss: 0.3130 - acc: 0.8811 - precision: 0.8784 - recall: 0.7467 - f1_score: 0.8063 - val_loss: 0.3671 - val_acc: 0.8500 - val_precision: 0.8688 - val_recall: 0.6500 - val_f1_score: 0.7422\n",
            "Epoch 91/500\n",
            "300/300 [==============================] - 5s 16ms/step - loss: 0.3188 - acc: 0.8767 - precision: 0.8698 - recall: 0.7400 - f1_score: 0.7990 - val_loss: 0.3650 - val_acc: 0.8389 - val_precision: 0.8312 - val_recall: 0.6500 - val_f1_score: 0.7283\n",
            "Epoch 92/500\n",
            "128/300 [===========>..................] - ETA: 2s - loss: 0.3133 - acc: 0.8698 - precision: 0.8592 - recall: 0.7266 - f1_score: 0.7871"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pZ1KLyOXV6Mp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### ConvNet test"
      ]
    },
    {
      "metadata": {
        "id": "EnliW6weV7w6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_conv.evaluate(X_test, Y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}